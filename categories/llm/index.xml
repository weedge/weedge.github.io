<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>LLM on 时间飘过</title>
    <link>https://weedge.github.io/categories/llm/</link>
    <description>Recent content in LLM on 时间飘过</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 08 Mar 2024 10:26:23 +0800</lastBuildDate><atom:link href="https://weedge.github.io/categories/llm/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>论文：Retrieval-Augmented Generation for Large Language Models: A Survey</title>
      <link>https://weedge.github.io/post/paper/rag/rag-for-llms-a-survey/</link>
      <pubDate>Fri, 08 Mar 2024 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/paper/rag/rag-for-llms-a-survey/</guid>
      <description>&lt;p&gt;大型语言模型（LLMs）展示了显著的能力，但面临着幻觉、过时知识和不透明、不可追踪的推理过程等挑战。检索增强生成（RAG）已经成为一个有前途的解决方案，通过整合外部数据库的知识。这增强了模型的准确性和可信度，特别适用于知识密集型任务，并允许持续的知识更新和领域特定信息的整合。RAG通过将LLMs的内在知识与庞大、动态的外部数据库资源相结合，产生了协同效应。这篇综述论文详细考察了RAG范式的发展，包括天真的RAG、高级的RAG和模块化的RAG。它对RAG框架的三方基础进行了细致的审查，其中包括检索、生成和增强技术。该论文突出了嵌入在每个关键组成部分的最先进技术，提供了对RAG系统进展的深刻理解。此外，该论文介绍了评估RAG模型的指标和基准，以及最新的评估框架。总之，该论文勾勒了研究的前景，包括挑战的识别、多模态的扩展以及RAG基础设施及其生态系统的进展&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;论文地址:  &lt;a href=&#34;https://arxiv.org/pdf/2312.10997.pdf&#34;&gt;Retrieval-Augmented Generation for Large Language Models: A Survey&lt;/a&gt; |  &lt;a href=&#34;https://github.com/Tongji-KGLLM/RAG-Survey/blob/main/assets/RAG_Slide_ENG.pdf&#34;&gt;PPT&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>

<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>时间飘过</title>
    <link>https://weedge.github.io/</link>
    <description>Recent content on 时间飘过</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 21 Nov 2022 10:26:23 +0800</lastBuildDate>
    
        <atom:link href="https://weedge.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://weedge.github.io/about/</link>
      <pubDate>Sun, 20 Jan 2013 21:38:52 +0800</pubDate>
      
      <guid>https://weedge.github.io/about/</guid>
      
        <description>
&lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css&#34;&gt;
&lt;style type=&#34;text/css&#34;&gt;.dark-theme .aplayer{background:#212121}.dark-theme .aplayer.aplayer-withlist .aplayer-info{border-bottom-color:#5c5c5c}.dark-theme .aplayer.aplayer-fixed .aplayer-list{border-color:#5c5c5c}.dark-theme .aplayer .aplayer-body{background-color:#212121}.dark-theme .aplayer .aplayer-info{border-top-color:#212121}.dark-theme .aplayer .aplayer-info .aplayer-music .aplayer-title{color:#fff}.dark-theme .aplayer .aplayer-info .aplayer-music .aplayer-author{color:#fff}.dark-theme .aplayer .aplayer-info .aplayer-controller .aplayer-time{color:#eee}.dark-theme .aplayer .aplayer-info .aplayer-controller .aplayer-time .aplayer-icon path{fill:#eee}.dark-theme .aplayer .aplayer-list{background-color:#212121}.dark-theme .aplayer .aplayer-list::-webkit-scrollbar-thumb{background-color:#999}.dark-theme .aplayer .aplayer-list::-webkit-scrollbar-thumb:hover{background-color:#bbb}.dark-theme .aplayer .aplayer-list li{color:#fff;border-top-color:#666}.dark-theme .aplayer .aplayer-list li:hover{background:#4e4e4e}.dark-theme .aplayer .aplayer-list li.aplayer-list-light{background:#6c6c6c}.dark-theme .aplayer .aplayer-list li .aplayer-list-index{color:#ddd}.dark-theme .aplayer .aplayer-list li .aplayer-list-author{color:#ddd}.dark-theme .aplayer .aplayer-lrc{text-shadow:-1px -1px 0 #666}.dark-theme .aplayer .aplayer-lrc:before{background:-moz-linear-gradient(top, #212121 0%, rgba(33,33,33,0) 100%);background:-webkit-linear-gradient(top, #212121 0%, rgba(33,33,33,0) 100%);background:linear-gradient(to bottom, #212121 0%, rgba(33,33,33,0) 100%);filter:progid:DXImageTransform.Microsoft.gradient( startColorstr=&#39;#212121&#39;, endColorstr=&#39;#00212121&#39;,GradientType=0 )}.dark-theme .aplayer .aplayer-lrc:after{background:-moz-linear-gradient(top, rgba(33,33,33,0) 0%, rgba(33,33,33,0.8) 100%);background:-webkit-linear-gradient(top, rgba(33,33,33,0) 0%, rgba(33,33,33,0.8) 100%);background:linear-gradient(to bottom, rgba(33,33,33,0) 0%, rgba(33,33,33,0.8) 100%);filter:progid:DXImageTransform.Microsoft.gradient( startColorstr=&#39;#00212121&#39;, endColorstr=&#39;#cc212121&#39;,GradientType=0 )}.dark-theme .aplayer .aplayer-lrc p{color:#fff}.dark-theme .aplayer .aplayer-miniswitcher{background:#484848}.dark-theme .aplayer .aplayer-miniswitcher .aplayer-icon path{fill:#eee}&lt;/style&gt;
&lt;script src=&#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js&#34;&gt;&lt;/script&gt;

&lt;script src=&#34;https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js&#34;&gt;&lt;/script&gt;&lt;meting-js auto=&#34;https://music.163.com/#/playlist?id=2154973386&#34; theme=&#34;#2980b9&#34;&gt;&lt;/meting-js&gt;
&lt;p&gt;简单的木头人，简单，呆木，喜欢自言自语，愚人自扰型。时间飞逝，仅仅记录，留住某人某事，某些好玩的技术，KISS and just do IT.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对自己一定要有信心，每个人都有自己的节奏，不能因为一次次小小挫折而一蹶不振，生活本非如意，何须过度纠结～&lt;/p&gt;
&lt;p&gt;不以物喜，不以己悲； 上善若水～ inner peace～ 足已&lt;/p&gt;
&lt;p&gt;念经～～敲木鱼～&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;正确评估自己的能力，不做 「佛塔下的🐭」，合作双赢共处&lt;/p&gt;
&lt;h4 id=&#34;人生&#34;&gt;人生&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;“物来顺应，未来不迎，当时不杂，既过不恋” &amp;ndash; 曾国藩&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;Yesterday is a history, tomorrow is a mystery, only today is a gift, that is why we call it present. &amp;quot; &amp;ndash; 功夫熊猫 (inner peace)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;规律&#34;&gt;规律&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;”路漫漫其修远兮，吾将上下而求索“ &amp;ndash; 屈原《离骚》&lt;/li&gt;
&lt;li&gt;&amp;ldquo;众里寻他千百度。蓦然回首，那人却在，灯火阑珊处&amp;rdquo; &amp;ndash; 辛弃疾《青玉案·元夕》&lt;/li&gt;
&lt;li&gt;&amp;ldquo;道生一，一生二，二生三，三生万物&amp;rdquo; &amp;ndash; 老子《&lt;a href=&#34;https://baike.baidu.com/item/%E9%81%93%E5%BE%B7%E7%BB%8F/327138&#34;&gt;道德经&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;strong&gt;万物之始，大道至简，衍化至繁&lt;/strong&gt;&amp;rdquo; &amp;ndash; 老子《&lt;a href=&#34;https://baike.baidu.com/item/%E9%81%93%E5%BE%B7%E7%BB%8F/327138&#34;&gt;道德经&lt;/a&gt;》&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>设计草稿-直播间赠送礼物功能</title>
      <link>https://weedge.github.io/post/zb-gift/</link>
      <pubDate>Mon, 21 Nov 2022 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/zb-gift/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;直播线上互动，已成为当下生活的一部分，特别是受疫情影响，成为互联网的主要流量入口；研究了下各个平台直播间送礼物的功能，发现大同小异，在礼物分组，一些定制化的礼物有区分，整体交互流程大致相同，主要是直播间主播上播，用户通过礼物打赏给主播们(一个直播间可能有多名主播在互动)，礼物是通过虚拟币(**币) 换算，早期互联网用户线上互动礼物，玩家最多的应该是QQ币了，只不过以前的打赏赠送场景是在web2.0刚开始的时候，交互的大多是文字和图片，相关产品场景，虚拟空间(个人空间，博客，种菜等娱乐互动场景)；随着底层网络基建的发展，4G之后出现了大量的视频网站，用户可以录一些视频内容来互动；到后来音视频流媒体的发展，相关的在线直播间开始涌现，用户之间享受一波直播红利带来的互动，当然影响相对于前面的形式更加实时和直接；现在的5G和未来6G，以及物联网都会给直播形式带来新的互动场景,比如：虚拟会场，人机互动；其中早期培养起来的打赏送礼行为功能经常用于有主播的娱乐互动直播中，也是增值盈利的一部分；&lt;/p&gt;
&lt;p&gt;tips: 除了送礼功能，根据不同直播场景，还有语音视频连麦，电商带货商品，没有主播，节目直播/转播，会议直播，自习室，基本的点赞，计数，聊天基础服务功能；还有些抽奖功能，答题功能(教育类直播居多)，投票，红包这些功能服务可在开播时设置，是否启用；有用户基础的流量平台可能还会以竞价排名的方式推荐一波；这些功能可以作为一个可管理的插件，通过组合的方式应用于直播中，方便管理，后续可以添加新功能满足某类型直播场景。&lt;/p&gt;
&lt;h2 id=&#34;需求设计&#34;&gt;需求设计&lt;/h2&gt;
&lt;p&gt;设计一个简单礼物打赏功能: A用户(观众)赠送礼物给B用户(主播)，可以给多个主播赠送礼物；&lt;/p&gt;
&lt;h3 id=&#34;分析&#34;&gt;分析&lt;/h3&gt;
&lt;p&gt;礼物：直播平台通过虚拟币来统一等价交换的虚拟物品，而虚拟币是需要通过用户充值购买；发送礼物可以获得一些积分；&lt;/p&gt;
&lt;p&gt;A用户发送礼物给B用户，A的虚拟币扣除，B的虚拟币相应增加；需要保证赠送和收到的数量一致；&lt;/p&gt;
&lt;p&gt;需要考虑并发场景，对于热门主播高峰期的流量值100w观众用户在线互动，每秒送礼的请求数量也可能高于这个值，用户可能连击送出多次， 而且为了保证数据一致和吞吐，尽量减少锁的使用，或者说采用&lt;a href=&#34;https://en.wikipedia.org/wiki/Optimistic_concurrency_control&#34;&gt;OCC&lt;/a&gt;，乐观锁的方式来处理事务，交由业务服务程序来处理，尽量减少或减短数据库中心存储服务上的锁操作，原理就是：夯主后，就呆萌了，资源未释放，请求资源一增多，导致整个服务吞吐下降，一直持续下去随时都会down掉，而且锁是建立在索引数据之上的， 如果没有相关降级处理，弄不好整体服务就&lt;a href=&#34;https://www.youtube.com/watch?v=4m48GqaOz90&#34;&gt;galigeigei&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;100W 观众A向同一个主播B 赠送礼物，对于主播B的虚拟币累计写操作比较大，同一时间可能100W+的w 操作 主播B 虚拟币这条记录，如果直接同步操作在数据库层面会出现行锁，会等待夯主整个赠送流程，所以需要把这些集中写，通过消息队列异步去更新虚拟币数目，进而提高观众送礼接口的吞吐量，&lt;/p&gt;
&lt;p&gt;观众虽然操作自己的虚拟币数目行记录，但是直接操作数据库，即使对用户资产表进行分库分表操作，也会有大量的磁盘i/o，所以直播间的互动数据直接在缓存中操作，把观众的操作记录消息队列的方式异步落库；&lt;/p&gt;
&lt;p&gt;缓存的方式操作，需要把观众的用户资产信息前置预热至缓存中，直播中直接操作缓存， 操作缓存需要保证并发操作事务的原子性，保证观众的虚拟币不能多扣或者少扣；&lt;/p&gt;
&lt;p&gt;并发场景下，为了减少大量用户冲击底层数据库，减少磁盘io, 送礼物这些互动直接读写用户缓存数据，这些缓存数据的操作类型分为是/否更新频繁；&lt;/p&gt;
&lt;p&gt;更新不频繁数据：用户，直播间，物料详情等信息，这些缓存数据在进入直播间的时候直接从数据库以cacheAside pattern获取填充，填充的时候采用singleflight方式；物料信息还可以服务本地缓存一份；变更数据时，远端缓存数据可以通过CDC订阅数据库操作日志(比如：binlog)来主动异步更新缓存数据，或者使用延时双删来被动更新，本地缓存可根据通过控制平面配置下发来触发从远端缓存更新数据；&lt;/p&gt;
&lt;p&gt;更新频繁数据： 这个主要发生在用户直播互动，赠送礼物场景，多次并发操作，变更的实体数据 观众/主播虚拟资产扣除/增加，这些数据以writeThrough/Behind parttern方式直接更新缓存，队列异步落库；因为直播场景用户的数据都在缓存中，数据实时更新查看，不影响用户体验；直播监控后台从数据库里订阅近实时查看用户的虚拟资产，会有一个批量窗口的处理延迟；&lt;/p&gt;
&lt;p&gt;缓存数据初始化，可以在用户刚打开app的时候初始化，也可以在进入/创建好直播间的时候初始化好用户直播间缓存数据；&lt;/p&gt;
&lt;p&gt;以上可以将操作分2个关键步骤： 观众赠送礼物和异步更新观众和主播的资产信息；通过消息队列来解耦，提高送礼接口吞吐和请求响应延迟，以及以pull方式消费，缓解数据库实例的读写压力；&lt;/p&gt;
&lt;p&gt;观众赠送礼物： 礼物是通过虚拟货币进行等价交换的，通过礼物id获取到对应消费的虚拟资产，对中心远端缓存分片中的观众虚拟资产进行事务扣除处理，事务提交之后，发送事务消息；这里采用cas方式处理，一种是watch key(string 读写io是O(1), 不用hash是因为读取全部资产信息io是O(n))+事务方式，一种是lua的形式直接写业务提交脚本给redis核心主线程去处理；这里可能会想到直接用 hash incr原子操作，但是这里不行，因为需要读出key对应的虚拟资产，用于判断虚拟资源是否充足，读出来在扣除写入，需要一起执行，保证事务原子性；除了核心流程，还有发送礼物成功后，需要推送消息到直播间，根据产品礼品策略判断是否展示特效; 以及增加用户活动积分，增加互动积极性；&lt;/p&gt;
&lt;p&gt;异步更新观众和主播数据库落地资产信息：这里为了减少对数据库的行锁的并发压力，也采用CAS的方式来更新数据库的数据，&lt;/p&gt;
&lt;p&gt;消息队列：涉及到金钱，为了提高吞吐，需要保证数据准确，数据最终一致(&lt;a href=&#34;https://www.allthingsdistributed.com/2008/12/eventually_consistent.html&#34;&gt;&lt;strong&gt;BASE&lt;/strong&gt;&lt;/a&gt;)，采用支持事务消息的分布式消息队列，比如：&lt;a href=&#34;https://rocketmq.apache.org/zh/docs/featureBehavior/04transactionmessage/&#34;&gt;rocketMQ&lt;strong&gt;事务消息&lt;/strong&gt;&lt;/a&gt;，这里可能有个疑问如果刚开始发送事务消息就失败了，可能是网络抖动,或者服务负载告等原因，一般是启用failover权重&lt;a href=&#34;https://en.wikipedia.org/wiki/Exponential_backoff&#34;&gt;指数退避&lt;/a&gt;策略重试到不同机房的rocketMQ集群，可以查看&lt;a href=&#34;https://rocketmq.apache.org/zh/docs/featureBehavior/05sendretrypolicy#%E6%B6%88%E6%81%AF%E5%8F%91%E9%80%81%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6&#34;&gt;消息发送重试机制&lt;/a&gt; 和 &lt;a href=&#34;https://rocketmq.apache.org/zh/docs/bestPractice/15bestpractice&#34;&gt;最佳实践&lt;/a&gt;, &lt;a href=&#34;https://aws.amazon.com/cn/builders-library/timeouts-retries-and-backoff-with-jitter/&#34;&gt;timeouts-retries-and-backoff-with-jitter&lt;/a&gt;；如果重试还是失败打印错误日志记录发送详情，通过实时数据流将异常行为写入db中，以便后续补发；&lt;/p&gt;
&lt;p&gt;Tips: 如果使用阿里云rocketMQ, 需要注意支持版本提供的SDK，5.0 版本 &lt;a href=&#34;https://github.com/apache/rocketmq-clients&#34;&gt;client SDK&lt;/a&gt; ; 4.0相关版本有些开发语言不支持tcp方式，仅提供http的方式(会少了一些功能，比如批量发送普通消息)；选用新版的5.0版本的SDK开发; 如果有自建运维能力，直接使用开源方案来搭建一套，比如用&lt;a href=&#34;https://www.amazonaws.cn/solutions/apache-rocketmq-on-aws/&#34;&gt;rocketMQ on aws&lt;/a&gt;，并且使用5.0可以实现一层mq-proxy;&lt;/p&gt;
&lt;p&gt;题外话: 现在分布式消息队列&lt;a href=&#34;https://kafka.apache.org/33/documentation/streams/architecture&#34;&gt;kafka-streams&lt;/a&gt;, &lt;a href=&#34;https://github.com/apache/rocketmq-streams&#34;&gt;rocketmq-streams&lt;/a&gt; 支持数据流(stream)处理大数据实时场景，支持一些简单算子操作和SQL(&lt;a href=&#34;https://github.com/confluentinc/ksql&#34;&gt;ksql&lt;/a&gt;, &lt;a href=&#34;https://github.com/alibaba/rsqldb&#34;&gt;rsql&lt;/a&gt;)；这个和flink对应功能是重合了，flink也在往table store上发力满足数据堆积的能力; 一波流～&lt;/p&gt;
&lt;h3 id=&#34;调研&#34;&gt;调研&lt;/h3&gt;
&lt;p&gt;以pc端抓http包为例，手机端接口一样&lt;/p&gt;
&lt;h4 id=&#34;抖音接口&#34;&gt;抖音接口&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;curl &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;https://live.douyin.com/webcast/gift/send/?aid=6383&amp;amp;live_id=1&amp;amp;device_platform=web&amp;amp;language=zh-CN&amp;amp;enter_from=web_live&amp;amp;cookie_enabled=true&amp;amp;screen_width=2048&amp;amp;screen_height=1152&amp;amp;browser_language=zh-CN&amp;amp;browser_platform=MacIntel&amp;amp;browser_name=Chrome&amp;amp;browser_version=107.0.0.0&amp;amp;browser_online=true&amp;amp;engine_name=Blink&amp;amp;engine_version=107.0.0.0&amp;amp;os_name=Mac+OS&amp;amp;os_version=10.15.7&amp;amp;cpu_core_num=8&amp;amp;device_memory=8&amp;amp;platform=PC&amp;amp;downlink=10&amp;amp;effective_type=4g&amp;amp;round_trip_time=50&amp;amp;channel=channel_pc_web&amp;amp;app_name=douyin_web&amp;amp;webid=7167235205950047744&amp;amp;user_agent=Mozilla%2F5.0+(Macintosh%3B+Intel+Mac+OS+X+10_15_7)+AppleWebKit%2F537.36+(KHTML,+like+Gecko)+Chrome%2F107.0.0.0+Safari%2F537.36&amp;amp;fp=verify_lam4f5i1_plZJSYeB_iUgU_4z2o_9JHF_d7Z0Z60sLg33&amp;amp;did=0&amp;amp;referer=https:%2F%2Flive.douyin.com%2F444452144000%3Fcover_type%3D0%26enter_from_merge%3Dweb_live%26enter_method%3Dweb_card%26game_name%3D%26is_recommend%3D1%26live_type%3Dgame%26more_detail%3D%26request_id%3D2022111814283801020916816201004237%26room_id%3D7167220081737468683%26stream_type%3Dvertical%26title_type%3D1%26web_live_page%3Dhot_live%26web_live_tab%3Dall&amp;amp;target=&amp;amp;device_id=7167235205950047744&amp;amp;msToken=aOEoMNHAEI98H45Z0n-zUTffiNgv7HNkGU0lwFptk-JBg00tEs0I74G4sYXgG670cAdhSmXNcKlRU3-QaxW7Pflt-p8YAmyU5eC3EGJQfp7Mk7JpmP_P&amp;amp;X-Bogus=DFSzswVL0qCmAcoQS8MuBN7TlqS8&amp;amp;_signature=_02B4Z6wo00001Heu8JQAAIDD43irmgubdKx3rvQAAH6ktTtRdH7gtQJWp3SjldUkeBB51lpkXUQ700UnFEXODUicQ0r1ccxSxq4OwWIjvxuNe8Acl-gJzChe99W43SojHkPp9aa82Qzi9VoTd2&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;authority: live.douyin.com&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;accept: application/json, text/plain, */*&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;accept-language: zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;content-type: application/x-www-form-urlencoded&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;cookie: xgplayer_user_id=502915240928; csrf_session_id=f5161482adac52884f25a91fa758d7b0; ttcid=5cd5ff73751f4ab39911c85e57f9ca7479; passport_csrf_token=46e48d1e7b4df245f8caab8a34b64935; passport_csrf_token_default=46e48d1e7b4df245f8caab8a34b64935; home_can_add_dy_2_desktop=%220%22; n_mh=Qo43cptpX41bfwDmWyVyRUGMZnsucxhgcWJqKjjWkvI; sso_uid_tt=a84f8e3ae1f0c8301f5a882b05abe3f0; sso_uid_tt_ss=a84f8e3ae1f0c8301f5a882b05abe3f0; toutiao_sso_user=a28a6e92e7dc7d690b4f6b9a59077692; toutiao_sso_user_ss=a28a6e92e7dc7d690b4f6b9a59077692; passport_assist_user=Cjyr0IY04IJK-7Hxgl87vzPKZIfpFS29oAG2arITfMftUANM_d6SDxwAksiJEuVqZgZdE_BYyvcjLLGAQaYaSAo8zVwGiPnNM3S7eRNlXwMkuS7yNVm17pbNfKqXsXj3Rgk9Nm08DWh_PY0JRbH8FQeLxabRAoqM4bPJTzQ8EM_DoQ0Yia_WVCIBAxToQPk%3D; sid_ucp_sso_v1=1.0.0-KGIxM2FlNmE2MDdiNWE5MDA1YmIwZjg5OWVkNTUxMTBhMzdhYWE2OTIKHQjhrMGYrgIQt8vcmwYY7zEgDDDHuNHRBTgGQPQHGgJobCIgYTI4YTZlOTJlN2RjN2Q2OTBiNGY2YjlhNTkwNzc2OTI; ssid_ucp_sso_v1=1.0.0-KGIxM2FlNmE2MDdiNWE5MDA1YmIwZjg5OWVkNTUxMTBhMzdhYWE2OTIKHQjhrMGYrgIQt8vcmwYY7zEgDDDHuNHRBTgGQPQHGgJobCIgYTI4YTZlOTJlN2RjN2Q2OTBiNGY2YjlhNTkwNzc2OTI; passport_auth_status=ba24f5319c0f02c6232d484fd51c2187%2C; passport_auth_status_ss=ba24f5319c0f02c6232d484fd51c2187%2C; sid_guard=ea2e466c926c317f4f552f0d3982a458%7C1668752823%7C5184000%7CTue%2C+17-Jan-2023+06%3A27%3A03+GMT; uid_tt=23c596f546d448da13c0098152ef5d17; uid_tt_ss=23c596f546d448da13c0098152ef5d17; sid_tt=ea2e466c926c317f4f552f0d3982a458; sessionid=ea2e466c926c317f4f552f0d3982a458; sessionid_ss=ea2e466c926c317f4f552f0d3982a458; sid_ucp_v1=1.0.0-KDRiMzcyMDVkZmZhMWIxNjhjNDM4YjBiZDA4Y2E5ZTBmN2IxNTE1NjIKFwjhrMGYrgIQt8vcmwYY7zEgDDgGQPQHGgJsZiIgZWEyZTQ2NmM5MjZjMzE3ZjRmNTUyZjBkMzk4MmE0NTg; ssid_ucp_v1=1.0.0-KDRiMzcyMDVkZmZhMWIxNjhjNDM4YjBiZDA4Y2E5ZTBmN2IxNTE1NjIKFwjhrMGYrgIQt8vcmwYY7zEgDDgGQPQHGgJsZiIgZWEyZTQ2NmM5MjZjMzE3ZjRmNTUyZjBkMzk4MmE0NTg; FOLLOW_NUMBER_YELLOW_POINT_INFO=%22MS4wLjABAAAAt_v5oVMmcxuNnLLRzi6Ey1GKVQr_2XVFt2jPbkhZPI8%2F1668787200000%2F0%2F1668752826051%2F0%22; strategyABtestKey=%221668752909.101%22; __ac_nonce=06377261b0070042789c9; __ac_signature=_02B4Z6wo00f01JfP74gAAIDDAxm0hJMbmiiX7-sAAEaJTk9YXvYiEKlcYbhZnUTqyIVISJ6Z9uR3UEye00i7MfEP1dAywrmbnaQAIP3m1.7zOA8BmpqIWhyYJal-u6k6LMxVpsCtyakYsz3325; live_can_add_dy_2_desktop=%221%22; tt_scid=PpJHVbeNWnhY54EQ6vWraqXl5A8SZDtl3dn9JTaQQNLPo37ztPaJz.xoJHxyhNYScf8e; s_v_web_id=verify_lam4f5i1_plZJSYeB_iUgU_4z2o_9JHF_d7Z0Z60sLg33; ttwid=1%7C-XDacSDIgDIHmJqBxLj6Op91O91Ww4nvf96AveJpNeE%7C1668752951%7C0275ac24a410dd06b5f87dc4d84188f6eedaf20ed69cc9d0e979559df7df461e; download_guide=%223%2F20221118%22; odin_tt=3a02e4ad7a6c9042e1c42ece6d0d4a1aeeb37ed334f3450eb4adf57a6d0e09938523f8954816d90d557b27f5d3cbea85; msToken=1GTirdFSckP7H_txAPOKIMLWleKhlwccm-ts_3OviXegeQ2cr0B56jMAqfB3SqEGnxPEBjXRWsmg-sxVW3okb1s-acOAnBkIVDA_47g5aZFOqMKEzI-N; msToken=aOEoMNHAEI98H45Z0n-zUTffiNgv7HNkGU0lwFptk-JBg00tEs0I74G4sYXgG670cAdhSmXNcKlRU3-QaxW7Pflt-p8YAmyU5eC3EGJQfp7Mk7JpmP_P&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;origin: https://live.douyin.com&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;referer: https://live.douyin.com/444452144000&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-ch-ua: &amp;#34;Google Chrome&amp;#34;;v=&amp;#34;107&amp;#34;, &amp;#34;Chromium&amp;#34;;v=&amp;#34;107&amp;#34;, &amp;#34;Not=A?Brand&amp;#34;;v=&amp;#34;24&amp;#34;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-ch-ua-mobile: ?0&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-ch-ua-platform: &amp;#34;macOS&amp;#34;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-fetch-dest: empty&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-fetch-mode: cors&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-fetch-site: same-origin&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;user-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;x-secsdk-csrf-token: 000100000001c39118162052c6b50f6dadb067cc07c073c9b93f035ea22242c67c43f5951903172899f1bc355042&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  --data-raw &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;room_id=7167220081737468683&amp;amp;to_room_id=7167220081737468683&amp;amp;sec_to_user_id=MS4wLjABAAAAOgGR5D9qmmPglgaT08-30j8vnjeeAdmgXhJY_8Q7oLk&amp;amp;to_episode_id=0&amp;amp;send_type=4&amp;amp;send_scene=1&amp;amp;gift_source=0&amp;amp;buff_level=0&amp;amp;count=1&amp;amp;price=2&amp;amp;gift_id=2002&amp;amp;is_first_combo=true&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  --compressed -iv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;响应&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
 &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;: {
   &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;message&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;Insufficient Fund&amp;#34;&lt;/span&gt;,
   &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;prompts&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;余额不足&amp;#34;&lt;/span&gt;
 },
 &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;extra&amp;#34;&lt;/span&gt;: {
   &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;now&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#099&#34;&gt;1668755929438&lt;/span&gt;
 },
 &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;status_code&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#099&#34;&gt;40001&lt;/span&gt;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;快手接口&#34;&gt;快手接口&lt;/h4&gt;
&lt;p&gt;请求&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;curl &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;https://live.kuaishou.com/live_graphql&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;Connection: keep-alive&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;Cookie: clientid=3; did=web_0d47b6546f1fd39fe4d1236703ae2b16; kuaishou.live.bfb1s=9b8f70844293bed778aade6e0a8f9942; client_key=65890b29; kpn=GAME_ZONE; userId=553458447; kuaishou.live.web_st=ChRrdWFpc2hvdS5saXZlLndlYi5zdBKgAV6EW8_dkcqveTyN6yy6uaMZd7O2c9rYOi19Fb3FhhOTPjtHtkb7lPQxQ4QaygTV0J-_Z0E7-4E5lFUZ2MRRzwjNAgbEEeSbf5duEVRtpGJnR_EEjJeZ3yyPMWPsJelIVcpSHGX02esKljXrWSXcbMWU709r4hxtaNHdMQtnvmLt1nijHxRE7lio0ZRYM5n-EK65VJq2EUpFqHFY_jFqxm0aEhrHsWfESUHgv806qk-5eqStgCIgOVwse70J74NPwA2TbGfOv-Ze0M-TVQJ0kHcHOHiTkKooBTAB; kuaishou.live.web_ph=75bafd83e69f9caf80b760c47f7b9c976d31; userId=553458447; ksliveShowClipTip=true&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;Origin: https://live.kuaishou.com&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;Referer: https://live.kuaishou.com/u/YiGe6666&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;Sec-Fetch-Dest: empty&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;Sec-Fetch-Mode: cors&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;Sec-Fetch-Site: same-origin&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;accept: */*&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;content-type: application/json&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-ch-ua: &amp;#34;Google Chrome&amp;#34;;v=&amp;#34;107&amp;#34;, &amp;#34;Chromium&amp;#34;;v=&amp;#34;107&amp;#34;, &amp;#34;Not=A?Brand&amp;#34;;v=&amp;#34;24&amp;#34;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-ch-ua-mobile: ?0&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  -H &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;sec-ch-ua-platform: &amp;#34;macOS&amp;#34;&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  --data-raw &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;{&amp;#34;operationName&amp;#34;:&amp;#34;SendTokenGift&amp;#34;,&amp;#34;variables&amp;#34;:{&amp;#34;e&amp;#34;:&amp;#34;UJfUx05OooLVLeaLzurAD7t0ycf7qHV57YPA64hWOh5Nslk4cNv5GCO5UIhUfygGimZNaBMDaQF7CWigSoxuOG4KmX6PBg7Nw/BxK3lCQ/MeVM8H3VRD7RIv7A9H4Zt+z/43c25jpTuaQrjLpxrWXzNYORIKJRjga9ZUGPCbNwatxYFMuVGEJcn8SZxFdd2rr1HMsQV2HXhl1PcILcXZ5fcnu7+VARIIj26snB4TOiQ=&amp;#34;,&amp;#34;iv&amp;#34;:&amp;#34;yLelD2PBybOSK8LM&amp;#34;,&amp;#34;giftId&amp;#34;:114,&amp;#34;liveStreamId&amp;#34;:&amp;#34;sOuGkqrHrOs&amp;#34;,&amp;#34;count&amp;#34;:1,&amp;#34;comboKey&amp;#34;:&amp;#34;IZLFwC_9lDBi2YL6_1668754497884&amp;#34;,&amp;#34;giftToken&amp;#34;:&amp;#34;CkMQj7b0hwIaNIECAoICgwLHAgmLAowCjQIOENsBnAGfAt8B4AEhoQLhAakCKXFysgLyAfYBtwL3AfgB+QEgNCi36OokEIzc0szIMBqQARbIi9FshY8J3yb72Pi3Kf3b4VlRZ8dHHr2d64OWA545YQ6SBsTaqA6ERQ9DQbGDCXK3L5MoVtVL/wy4cLlD+XTMYIYjEYUU/0IwTbvhrTXWdll64SIP1APvRQXCjDugMBShDAqlMCBPqREhchX0t8tXHhYO2h+h6k3+kwe3yAdSioapP7i5NxtuLxCFTYPiVA==&amp;#34;},&amp;#34;query&amp;#34;:&amp;#34;mutation SendTokenGift($e: String, $iv: String, $giftId: Int, $liveStreamId: ID, $count: Int, $comboKey: String, $giftToken: String) {\n  sendTokenGift(e: $e, iv: $iv, giftId: $giftId, liveStreamId: $liveStreamId, count: $count, comboKey: $comboKey, giftToken: $giftToken) {\n    result\n    ksCoin\n    styleType\n    __typename\n  }\n}\n&amp;#34;}&amp;#39;&lt;/span&gt; &lt;span style=&#34;color:#a50&#34;&gt;\
&lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&lt;/span&gt;  --compressed -iv
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;响应&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-json&#34; data-lang=&#34;json&#34;&gt;{
  &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;data&amp;#34;&lt;/span&gt;: {
    &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;sendTokenGift&amp;#34;&lt;/span&gt;: {
      &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;result&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;,&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;//成功&lt;/span&gt;
      &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;ksCoin&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#099&#34;&gt;0&lt;/span&gt;,
      &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;styleType&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#00a&#34;&gt;null&lt;/span&gt;,
      &lt;span style=&#34;color:#1e90ff;font-weight:bold&#34;&gt;&amp;#34;__typename&amp;#34;&lt;/span&gt;: &lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;SendGiftResult&amp;#34;&lt;/span&gt;
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;快手给端上的接口使用的&lt;a href=&#34;https://spec.graphql.org/draft/&#34;&gt;graphql&lt;/a&gt;统一中心化了入口，方便后续规范化管理接口；整体交互也有些差别，一个是后置判断，一个是前置判断礼物是否可以赠送，但是对于赠送礼物接口还是需要判断是否满足赠送的金额；前置对于用户体验会好些，少了些交互吧; 接口数据都有token加密验证，防止三方黑产中途拦截，后者对整体赠送数据也是压缩加密了(用户行为打点数据也是压缩上报的)；&lt;/p&gt;
&lt;p&gt;Tips: 貌似礼物的价格在各个直播平台都一样的，不像商品价格有相对波动，只是会有些直播场景定制化的礼物，有种非理性情感冲动消费的感觉，搞直播类用户产品，心理学貌似挺重要的，老铁带一波 666～&lt;/p&gt;
&lt;h3 id=&#34;设计&#34;&gt;设计&lt;/h3&gt;
&lt;h4 id=&#34;整体设计服务模块流程&#34;&gt;整体设计服务模块流程&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/%E7%9B%B4%E6%92%AD%E4%BA%92%E5%8A%A8-%E8%B5%A0%E9%80%81%E7%A4%BC%E7%89%A9%E8%AE%BE%E8%AE%A1.drawio.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;db&#34;&gt;DB&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;gift 礼物表&lt;/strong&gt;：有限集，这个物料数目是固定的，没有SKU这一概念，可以直接定义好配置之后，直接存放在数据库中；便于后续缓存至远端或者服务本地；&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;giftId&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;UK  唯一键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;name&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;礼物名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;currencyCn&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;价格：虚拟货币数目&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;unit&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;虚拟货币度量单位，对应资产类型：金币/钻石/X币&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;giftCategory&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;礼物类别&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;iconUrl&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;礼物icon地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sendRule&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;赠送规则&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;effectsUrl&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;礼物特效地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;createdAt&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;updatedAt&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;strong&gt;user_asset 用户拥有的虚拟资产表&lt;/strong&gt;：  用户当前拥有的虚拟币余额&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;userId&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;用户id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;assetCn&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;资产数量&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;assetType&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;资产类型 1. 金币 2.钻石 3. X币 &lt;del&gt;4. X优惠卷&lt;/del&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;更新版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;createdAt&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;updatedAt&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;对于&lt;strong&gt;单个用户资产修改&lt;/strong&gt;；如果存在 &lt;strong&gt;select 资产，然后根据不同产品策略进行业务逻辑计算出更新后资产，最后update 更新&lt;/strong&gt; 场景，在并发场景下，三种方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;服务直接通过分布式锁来处理，这种方式不能防住其他其他服务或者脚本直接操作数据库的情况，除非在操作之前也去获取一次锁，而且引入外部依赖；可以考虑自举方式，服务资源实例自己来上锁；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;悲观锁 select for update事务实现&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color:#00a&#34;&gt;SET&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;AUTOCOMMIT=&lt;span style=&#34;color:#099&#34;&gt;0&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt; 
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;BEGIN&lt;/span&gt;&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;；&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;   &lt;/span&gt;a&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetCn&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;user_asset&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;WHERE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;userId=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;userId&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetType=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;assetType&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;FOR&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;UPDATE&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;  
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;   &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;update&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;user_asset&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;set&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetCn=a.assetCn+&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;incrCn&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;where&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;userId=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;userId&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetType=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;assetType&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt; 
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;COMMIT&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;乐观锁 CAS的方式，没有更新继续循环，直到更新ok&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;a&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetCn&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;user_asset&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;WHERE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;userId=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;userId&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetType=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;assetType&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;#&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;oldAssetCn&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;a.assetCn&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;#&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;newAssetCn&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;a.assetCn+&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;incrCn&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;#&lt;span style=&#34;color:#00a&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;newAssetCn&amp;gt;=&lt;span style=&#34;color:#099&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;-&amp;gt;&lt;span style=&#34;color:#00a&#34;&gt;update&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;update&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;user_asset&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;set&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetCn=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;newAssetCn&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;where&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;userId=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;userId&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetType=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;assetType&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetCn&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;oldAssetCn&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; 
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;存在ABA问题：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;考虑如下操作：&lt;/p&gt;
&lt;p&gt;并发1（上）：获取出数据的初始值是A，后续计划实施CAS乐观锁，期望数据仍是A的时候，修改才能成功&lt;/p&gt;
&lt;p&gt;并发2：将数据修改成B&lt;/p&gt;
&lt;p&gt;并发3：将数据修改回A&lt;/p&gt;
&lt;p&gt;并发1（下）：CAS乐观锁，检测发现初始值还是A，进行数据修改&lt;/p&gt;
&lt;p&gt;并发1在修改数据时，虽然还是A，但已经不是初始条件的A了，中间发生了A变B，B又变A的变化，此A已经非彼A，数据却成功修改，可能导致错误&lt;/p&gt;
&lt;p&gt;ABA问题导致的原因，是CAS过程中只简单进行了“值”的校验，再有些情况下，“值”相同不会引入错误的业务逻辑（例如库存），有些情况下，“值”虽然相同，却已经不是原来的数据了。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;加上版本字段version, 对版本进行CAS更新&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;a&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetCn,&lt;span style=&#34;color:#00a&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;user_asset&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;WHERE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;userId=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;userId&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetType=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;assetType&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;#&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;oldAssetCn&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;a.assetCn&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;#&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;oldVersion&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;a.&lt;span style=&#34;color:#00a&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;#&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;newAssetCn&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;a.assetCn+&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;incrCn&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;#&lt;span style=&#34;color:#00a&#34;&gt;if&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;newAssetCn&amp;gt;=&lt;span style=&#34;color:#099&#34;&gt;0&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;-&amp;gt;&lt;span style=&#34;color:#00a&#34;&gt;update&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;#&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;newVersion&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;$&lt;/span&gt;oldVersion+&lt;span style=&#34;color:#099&#34;&gt;1&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;update&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;user_asset&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;set&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetCn=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;newAssetCn&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;version&lt;/span&gt;=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;newVersion&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;where&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;userId=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;userId&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;assetType=&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;assetType&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;and&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;version&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;{$&lt;/span&gt;oldVersion&lt;span style=&#34;color:#f00;background-color:#faa&#34;&gt;}&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; 
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;想一想：mysql为了高可用和读写分离，生产环境部署的实例集群是主从架构，存在主从延迟，其实这个是不影响的，最终都是CAS的update更新，更新成功会返回affect rows为1，没有更新则为0；&lt;/p&gt;
&lt;p&gt;Notice:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;select for update 加排斥锁和所建的索引有关(间隔(gap)锁，临键(next-key)锁，锁行/表)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果使用mongodb来存放，直接使用findAndModify incr 来操作即可，当然防止重复数据，需要加唯一索引&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;user_asset_record 用户虚拟币交易流水表&lt;/strong&gt;：记录虚拟币增加和减少数据详情，这个提供后台查看，用于重复请求幂等处理， 建库建表按照userId进行parttion 分库分表；&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;recordId&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;PK  用户资产流水记录id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;userId&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;用户id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;recUserId&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;接收者用户id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;roomId&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;房间id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;giftId&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;礼物id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;eventId&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;事件Id: 直播互动场景下，互动ID 用于贯彻整个送礼物流水链路,进行幂等处理，互动中台生成； 用户充值场景下，订单id，支付中台生成；&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;record&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;记录行为&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;recordOp&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;操作记录 虚拟币增加和减少&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;createdAt&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;updatedAt&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;资源评估：&lt;/p&gt;
&lt;p&gt;在支付中台，某个互动涉及到多个用户资产的变更，需要把多个写操作关联到一个本地事务进行处理，保证数据扣减和增减一致，需要开启本地事务来处理多表数据；以下gist为并发mysql本地事务处理测试demo&lt;/p&gt;
&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/weedge/1700dd7053a87a4ab35ba4fce0ebea6a.js&#34;&gt;&lt;/script&gt;

&lt;script type=&#34;application/javascript&#34; src=&#34;https://gist.github.com/weedge/fd731ce8549cd99ccfc9491f6025ae8e.js&#34;&gt;&lt;/script&gt;

&lt;h4 id=&#34;cache&#34;&gt;Cache&lt;/h4&gt;
&lt;p&gt;key设计：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;key&lt;/th&gt;
&lt;th&gt;value&lt;/th&gt;
&lt;th&gt;ex&lt;/th&gt;
&lt;th&gt;是否频繁更新&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;用户虚拟资产信息&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;Y&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;礼物信息&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;用户信息&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;直播间信息&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;N&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;资源评估：&lt;/p&gt;
&lt;p&gt;并发场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;缓存从db中获取&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;频繁增/减用户虚拟资产缓存存量数据&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;热key:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;用户维度的用户虚拟资产信息，通过userId进行分散即可， 如果多用户/租户 对 共享缓存资源频繁操作(比如 优惠卷/商卷)，突破了单redis实例的读写瓶颈，需要对key进行再次切分；如果是读多场景，更新不频繁缓存可以缓存在本地服务进程中；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;大key:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;存放的value值比较大，一般是list, set，zset, hash这些集合结构，存储的item/field数目一般在5000个左右，需要按比例切分，读放大的问题可以并发控制读取；&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;消息队列&#34;&gt;消息队列&lt;/h4&gt;
&lt;p&gt;topic&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;名称&lt;/th&gt;
&lt;th&gt;消息类型&lt;/th&gt;
&lt;th&gt;消息key&lt;/th&gt;
&lt;th&gt;消息tag&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;/table&gt;
&lt;h4 id=&#34;api&#34;&gt;API&lt;/h4&gt;
&lt;p&gt;前台统一入口接口参数安全验证&lt;/p&gt;
&lt;p&gt;互动中台：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;赠送礼物接口&lt;/li&gt;
&lt;li&gt;获取直播间礼物列表接口&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;支付中台：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;变更用户虚拟资产接口&lt;/li&gt;
&lt;li&gt;获取用户虚拟资产接口&lt;/li&gt;
&lt;li&gt;获取用户资产变更流水接口&lt;/li&gt;
&lt;li&gt;更新数据库中的用户资产 消费逻辑&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;消息服务： &lt;a href=&#34;https://weedge.github.io/post/jxzbim/&#34;&gt;https://weedge.github.io/post/jxzbim/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;开发&#34;&gt;开发&lt;/h3&gt;
&lt;p&gt;按服务模块进行并行开发，联调；给出对应排期&lt;/p&gt;
&lt;h5 id=&#34;开源开发框架和组件选择&#34;&gt;开源开发框架和组件选择&lt;/h5&gt;
&lt;ol&gt;
&lt;li&gt;开发语言：golang + lua + shell&lt;/li&gt;
&lt;li&gt;开发框架：gin&lt;/li&gt;
&lt;li&gt;DB：mysql, 高可用集群方案：不推荐自建sharding+proxy的方式；推荐使用支持mysql协议的分布式数据库，且无需在业务中考虑分库分表操作，以及分库分表的分布式事务；比如：开源方案 &lt;a href=&#34;https://docs.pingcap.com/zh/&#34;&gt;tidb&lt;/a&gt;(shared nothing,scale out)，云厂商：&lt;a href=&#34;https://polardbx.com/document&#34;&gt;polardb-x&lt;/a&gt; (shared nothing, scale out)/&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/AmazonRDS/latest/AuroraUserGuide/Aurora.AuroraMySQL.html&#34;&gt;aurora mysql&lt;/a&gt; (shared disk, scale up),   &lt;a href=&#34;https://gorm.io/&#34;&gt;gorm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Cache:  redis, 高可用集群方案 &lt;a href=&#34;https://redis.io/docs/management/scaling/&#34;&gt;redis-cluster&lt;/a&gt;   &lt;a href=&#34;https://redis.uptrace.dev/guide/&#34;&gt;go-redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;MQ: rocketMQ, &lt;a href=&#34;https://github.com/apache/rocketmq-client-go&#34;&gt;rocketmq-client-go&lt;/a&gt;,  如果使用阿里云rocketMQ使用对应&lt;a href=&#34;https://github.com/apache/rocketmq-clients/tree/master/golang&#34;&gt;client SDK&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;测试&#34;&gt;测试&lt;/h3&gt;
&lt;p&gt;基本功能逻辑测试，并发场景下的扣减和新增数据一致；然后加上 业务/基础服务/中间件服务监控，日志，在开始压测，给出性能报告，调优；最终给出接口/整体服务吞吐和延时上限，采用服务流控对服务接口加上接口/服务限流，以及超时重试，服务相关降级策略；然后模拟线上场景继续压测，触发对应报警和限流，降级策略；&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;模块测试&lt;/li&gt;
&lt;li&gt;加上服务监控，日志，报警，重点关注核心链路指标&lt;/li&gt;
&lt;li&gt;接口压测&lt;/li&gt;
&lt;li&gt;核心前端接口整体压测&lt;/li&gt;
&lt;li&gt;调优：耗时，内存，cpu，I/O(网络，磁盘)&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;面对大量并发请求的用户交互场景，整体思路是预热快速路径响应用户的交互请求行为，然后异步队列解耦，执行慢路径，快/慢路径上通过并发批量处理提高吞吐，快路径尽量使用乐观锁，减少block；需要考虑到数据一致，资产更改准确；本地事务(多表更新)，分布式事务场景(多服务对应表更新)；服务异常时的降级措施，以及服务过载时的限流，以及消息数据流的反压措施。&lt;/p&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/Cmw3QExqCfBAz9V0AlsS9A&#34;&gt;https://mp.weixin.qq.com/s/Cmw3QExqCfBAz9V0AlsS9A&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/cn/builders-library/timeouts-retries-and-backoff-with-jitter/&#34;&gt;https://aws.amazon.com/cn/builders-library/timeouts-retries-and-backoff-with-jitter/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/jznfR9Jc-U-uCXioHXjeew&#34;&gt;https://mp.weixin.qq.com/s/jznfR9Jc-U-uCXioHXjeew&lt;/a&gt; , &lt;a href=&#34;https://mp.weixin.qq.com/s/AV4E0Y9d4k5VYTL7n2TNug&#34;&gt;https://mp.weixin.qq.com/s/AV4E0Y9d4k5VYTL7n2TNug&lt;/a&gt; , &lt;a href=&#34;https://mp.weixin.qq.com/s/cT9b2GDsUinVNoA6gyqs_g&#34;&gt;https://mp.weixin.qq.com/s/cT9b2GDsUinVNoA6gyqs_g&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.52im.net/thread-3515-1-1.html#26&#34;&gt;http://www.52im.net/thread-3515-1-1.html#26&lt;/a&gt; , &lt;a href=&#34;http://www.52im.net/thread-3994-1-1.html&#34;&gt;http://www.52im.net/thread-3994-1-1.html&lt;/a&gt; , &lt;a href=&#34;http://www.52im.net/thread-3376-1-1.html&#34;&gt;http://www.52im.net/thread-3376-1-1.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://coolshell.cn/articles/8239.html&#34;&gt;https://coolshell.cn/articles/8239.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://redis.com/blog/redis-clustering-best-practices-with-keys/&#34;&gt;https://redis.com/blog/redis-clustering-best-practices-with-keys/&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>让ML跑起来</title>
      <link>https://weedge.github.io/post/let-ml-go/</link>
      <pubDate>Tue, 08 Nov 2022 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/let-ml-go/</guid>
      
        <description>&lt;h3 id=&#34;介绍&#34;&gt;介绍&lt;/h3&gt;
&lt;p&gt;上文提到通过用户的行为数据存放在S3中，这些数据包括结构化和非结构化数据，怎么让这些数据变得有价值呢？一种是人为进行数据挖掘，对相关指标转化率进行评估；还有一种是通过这些数据来训练模型，然后将预测模型用于生产环境中进行A/B测试，选出适合的模型，这个模型需要不断更新迭代，并且自动化半自动化运行起来；&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/images/ml-concepts-10.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据准备&#34;&gt;数据准备&lt;/h3&gt;
&lt;h4 id=&#34;特征工程&#34;&gt;特征工程&lt;/h4&gt;
&lt;h3 id=&#34;模型训练&#34;&gt;模型训练&lt;/h3&gt;
&lt;p&gt;相关库：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://xgboost.ai/&#34;&gt;XGBoost&lt;/a&gt;,  &lt;a href=&#34;https://en.wikipedia.org/wiki/Gradient_boosting&#34;&gt;Gradient Boosting&lt;/a&gt;框架下实现机器学习算法。XGBoost 提供了一种并行树提升（也称为 &lt;a href=&#34;https://developers.google.com/machine-learning/decision-forests/intro-to-gbdt&#34;&gt;GBDT&lt;/a&gt;、GBM），可以快速准确地解决许多数据科学问题。支持在多台机器上进行分布式训练，包括 AWS、GCE、Azure 和 Yarn 集群；可与 Flink、Spark 等云数据流系统集成。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;如果说把机器学习问题分成，常规机器学习（conventional machine learning）和深度学习（deep learning）的话，那么XGBoost就是在常规ML竞赛获奖最多的算法。&lt;a href=&#34;https://github.com/dmlc/xgboost&#34;&gt;XGBoost&lt;/a&gt; 的全称是 Extreme Gradient Boosting，是gradient boosting的一种开源实现。gradient boosting 把若干弱模型通过决策树的方式聚合（ensemble）在一起， 形成一个最终的模型，这个过程是一个持续的、不断迭代优化过程，每次迭代优化的方向通过计算loss function的梯度来实现，然后采取梯度下降的方式不断的降低loss function，从而得到一个最终的模型。&lt;/p&gt;
&lt;p&gt;XGBoost最常用来解决常规ML中的分类（regression）和回归（classification）问题。回归问题，举例来说：根据一个人的年龄、职业、居住环境等个人信息推算出这个人的收入，这种推理的结果是一个连续的值（收入）的情况就是一个回归问题；分类问题，比如在欺诈检测中，根据有关交易的信息，来判断交易是不是欺诈，这里的判断是或者否就是一个二分类问题。通常这两类问题都是给出一个表格类型数据，表格中的每列数据都是跟推理的目标（属于某个分类或者推理值）有着潜在关系的数据，XGBoost特别擅长处理这类的表格数据（tabular data），并据此作出推断。对于表格数据，无非由行、列来组成，在ML中对于表格数据中的行和列，我们有很多约定俗称的称谓，在各种关于ML的文章中这些称谓会经常出现，为了便于大家理解，在这里对这些叫法做一个梳理：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;行（row），叫做一个观察（observation），或者一个样本（sample）&lt;/li&gt;
&lt;li&gt;列（column） ，也叫字段（field），属性（attribute），或者特征（feature）&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://keras.io/zh/&#34;&gt;keras&lt;/a&gt;: 深度学习模型库，高级神经网络,同时支持卷积神经网络和循环神经网络，以及两者的组合。&lt;/p&gt;
&lt;h3 id=&#34;模型评估&#34;&gt;模型评估&lt;/h3&gt;
&lt;h3 id=&#34;模型部署&#34;&gt;模型部署&lt;/h3&gt;
&lt;p&gt;如果使用&lt;a href=&#34;https://www.tensorflow.org/&#34;&gt;TF&lt;/a&gt;(tensorflow)框架, 使用TF &lt;a href=&#34;https://github.com/tensorflow/serving&#34;&gt;serving&lt;/a&gt;来支持加载训练好的模型发布到生产环境，并且可以进行A/B测试；&lt;/p&gt;
&lt;p&gt;操作demo参考：https://www.tensorflow.org/tfx/tutorials/serving/rest_simple&lt;/p&gt;
&lt;h3 id=&#34;用于生产环境需要考虑的问题&#34;&gt;用于生产环境需要考虑的问题&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;训练模型的数据来源，以及采集存放(格式和压缩)；这些数据根据使用场景而定，比如demo中的电商场景，识别物品，需要大量的非结构化图片数据，这些用户上传的原始图片和加工后的图片存放于对象存储中比如S3，OSS，COS；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;特征数据清洗过滤存放；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据如何快速训练；数据量一般很大，PB级别，单机肯定是加载不了这么多数据训练，即使分割成多个小文件，单机处理需要大量中间结果存放，处理效率非常低；所以模型训练需要考虑集群模式，进行&lt;a href=&#34;https://openmlsys.github.io/chapter_distributed_training/index.html&#34;&gt;分布式训练模型&lt;/a&gt;，需要一个训练平台来支持，充分调度计算资源(CPU,GPU,TPU,FPGA)，并行计算，并且根据数据量进行可伸缩扩展，保证训练中途中断的可用性(failover,checkpoint)；&lt;/p&gt;
&lt;p&gt;开源框架：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;uber &lt;a href=&#34;https://github.com/horovod/horovod&#34;&gt;https://github.com/horovod/horovod&lt;/a&gt;  &lt;a href=&#34;https://arxiv.org/pdf/1802.05799.pdf&#34;&gt;Horovod: fast and easy distributed deep learning in TensorFlow&lt;/a&gt; 大部分云平台基于horovod做了定制化的改造&lt;/li&gt;
&lt;li&gt;Bytedance: &lt;a href=&#34;https://github.com/bytedance/byteps&#34;&gt;https://github.com/bytedance/byteps&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;将训练好的模型导出序列化pb格式，存放到文件系统中(&lt;a href=&#34;https://www.tensorflow.org/guide/saved_model#save_and_restore_models&#34;&gt;SavedModel&lt;/a&gt;)；然后TF serving启动服务加载模型，对外以 HTTP &lt;a href=&#34;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/api_rest.md&#34;&gt;REST API&lt;/a&gt;或 &lt;a href=&#34;https://github.com/tensorflow/serving/tree/master/tensorflow_serving/apis&#34;&gt;gRPC API&lt;/a&gt;的方式提供模型服务；正式用于线上，需要考虑服务性能问题(高并发场景，延迟和吞吐量，模型&lt;a href=&#34;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/saved_model_warmup.md&#34;&gt;预热&lt;/a&gt;(warmup)，&lt;a href=&#34;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/batching/README.md&#34;&gt;批处理&lt;/a&gt;(batching)等&lt;a href=&#34;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/performance.md&#34;&gt;性能&lt;/a&gt;优化点)，生产环境模型更新(构建，无损服务切换，流量A/B测试)，容器化部署(&lt;a href=&#34;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/serving_kubernetes.md&#34;&gt;serving on K8S&lt;/a&gt;)(扩缩容，流控，容错等高可用设计)，服务监控等工程上的问题；本地demo可参考: &lt;a href=&#34;https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/serving_basic.md&#34;&gt;Serving a TensorFlow Model&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;监控模型数据，如何对其进行评估；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;模型迭代更新速度快，需要引入CI/CD pipelines 来自动化支持模型闭环迭代；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;计算资源机器成本预估；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;开源方案&#34;&gt;开源方案&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://www.kubeflow.org/docs/started/introduction/&#34;&gt;Kubeflow&lt;/a&gt; 在 Kubernetes 上部署机器学习 (ML) 工作流变得简单、可移植和可扩展。提供一种直接的方式来将用于 ML 的同类最佳开源系统部署到不同的基础设施；在任何运行 Kubernetes 的地方，都应该能够运行 Kubeflow。&lt;/p&gt;
&lt;h3 id=&#34;tfx-with-kubeflow-on-gke&#34;&gt;TFX with kubeflow on GKE&lt;/h3&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/tensorflow/tfx&#34;&gt;https://github.com/tensorflow/tfx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;文档：&lt;a href=&#34;https://www.tensorflow.org/tfx/tutorials&#34;&gt;TFX tutorials&lt;/a&gt;&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/17l3VR2MIeg&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h3 id=&#34;ml-on--amazon-sagemakerhttpsawsamazoncomsagemaker&#34;&gt;ML on  &lt;a href=&#34;https://aws.amazon.com/sagemaker/&#34;&gt;Amazon SageMaker&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;分布式训练： &lt;a href=&#34;https://aws.amazon.com/cn/sagemaker/distributed-training/&#34;&gt;https://aws.amazon.com/cn/sagemaker/distributed-training/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;文档：&lt;a href=&#34;https://sagemaker-examples.readthedocs.io/en/latest/index.html&#34;&gt;Amazon SageMaker Example Notebooks&lt;/a&gt;， &lt;a href=&#34;https://sagemaker-workshop.com/&#34;&gt;Amazon SageMaker Workshop&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;SageMaker框架直接集成了多种机器学习框架，一条龙服务，也可以集成Kubeflow方案；机器学习整体生命周期包括训练数据准备，模型训练，模型评估，评估ok之后部署上线提供在线预测推理服务，通过监控搜集数据，重复迭代模型；整体生命周期如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://s3.cn-north-1.amazonaws.com.cn/awschinablog/use-xgboost-in-amazon-sagemaker-for-commercial-empowerment1.jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;将数据处理准备到模型上线整个过程可以自动化，通过sageMaker平台直接组合成工作流pipeline进行自动化处理，demo请参考：&lt;a href=&#34;https://aws.amazon.com/cn/getting-started/hands-on/machine-learning-tutorial-mlops-automate-ml-workflows/&#34;&gt;自动化机器学习工作流 sagemaker tutorial&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://d1.awsstatic.com/sagemaker-tutorial-5-1-step-3-1-pipeline-diagram.90a11a1a83636b6d56c8ce8d43829571b506ae11.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Tips: 这里只是整体概括下机器学习工程化的过程；机器学习以及深度学习相关的算法知识待深入边动手边学习；待续～ :)&lt;/p&gt;
&lt;h3 id=&#34;参考&#34;&gt;参考&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://developers.google.com/machine-learning&#34;&gt;google-developers-ml&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/tfx/&#34;&gt;TFX&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://xgboost.readthedocs.io/en/latest/index.html&#34;&gt;XGBoost文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tensorflow.org/tfx/guide/serving&#34;&gt;TF Serving&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/303430&#34;&gt;深度学习推荐系统实战&lt;/a&gt; &lt;a href=&#34;https://github.com/wzhe06/SparrowRecSys&#34;&gt;SparrowRecSys&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://zh.d2l.ai/index.html&#34;&gt;动手学深度学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.mikulskibartosz.name/how-to-ab-test-tensorflow-models-using-sagemaker-endpoints/&#34;&gt;How to A/B test Tensorflow models using Sagemaker Endpoints&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/cn/blogs/china/use-xgboost-in-amazon-sagemaker-for-commercial-empowerment/&#34;&gt;在 Amazon SageMaker 中使用 XGBoost 来实现商业赋能&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/cn/getting-started/hands-on/machine-learning-tutorial-mlops-automate-ml-workflows/&#34;&gt;自动化机器学习工作流 sagemaker tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/79030485&#34;&gt;AllReduce算法的前世今生&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>用户行为分析方案设计</title>
      <link>https://weedge.github.io/post/user-behavior-analytics-solution/</link>
      <pubDate>Wed, 02 Nov 2022 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/user-behavior-analytics-solution/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;用户在手机和pc端使用客户业务产品，比如浏览网页，购买商品，查看文档，观看视频，直播，IOT场景；会产生大量的用户行为数据，主要包括：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;非结构化数据：日志(前端事件埋点日志，服务端处理事件日志)，还有些非结构化的图片，音视频数据等等，主要存放在文件存储系统中；&lt;/li&gt;
&lt;li&gt;结构化和半结构化数据： 用户操作产品写入的结构化数据存放于数据库表中，将文档型半结构化的数据放入文档数据库中；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;需要分析用户的行为数据，进行决策；分为实时流式处理和离线批处理：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;实时流处理，主要用于实时展现客户端看板，后台BI实时分析，实时风控/推荐，异常报警等场景；&lt;/li&gt;
&lt;li&gt;离线批处理，分析用户历史数据，进行推荐算法等机器学习算法模型训练使用，数据仓库中根据不同维度对数据过滤聚合，进行上卷下钻分析，比如计算DAU,WAU,MAU，转化率(购买率，注册率)分析等，通常对数据建设投入多的话， 会把用户产生的结构化非结构化的数据都存下，放在一个大的池子里待使用时进行分析，即所谓的数据湖，围湖而建挖掘数据价值；而数仓相对精细化的分析，前置建模建表分析；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;对此进行方案分析，本文将介绍一种实时离线处理分析用户行为数据方案，即能帮助企业低成本地使用海量数据，又能更快速地响应业务需求，同时借助亚马逊云科技的托管服务，能够快速实施和轻松运维。&lt;/p&gt;
&lt;h3 id=&#34;操作概括&#34;&gt;操作概括&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;权限设置：根据公司业务组织，分配对应服务资源权限，比如系统管理员OP, 开发人员DEV, 还有业务管理员OP；组织架构权限建设；&lt;/li&gt;
&lt;li&gt;服务基础架构：首先需要搭好基础服务框架，结合云厂商服务，进行可水平垂直自动扩展，高容错性，低成本，可观测监控，易于维护，持续集成发布的稳定性架构建设；&lt;/li&gt;
&lt;li&gt;业务迭代数据建设开发：架子搭好之后，需要对特定的业务场景进行数据建模，AI模型训练，挖掘出数据的价值，进行决策；服务代码质量，框架建设；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;解决方案&#34;&gt;解决方案&lt;/h2&gt;
&lt;p&gt;使用aws 现有产品服务组件进行搭建，主要分为三个阶段，数据采集，数据处理存储，数据分析，整体架构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/user-behavior-analytics-cdk/blob/master/docs/aws-user-behavior-analytics.drawio.png?raw=true&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据源采集&#34;&gt;数据源采集&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;访问日志和请求事件：用户在手机端通访CloudFront 内容分发服务, 会生成用户行为&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html&#34;&gt;访问日志&lt;/a&gt;，这些&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/AmazonCloudFront/latest/DeveloperGuide/real-time-logs.html&#34;&gt;实时日志&lt;/a&gt;中会有产品中定义的行为分析埋点记录事件，存放在S3中，通过Lambda无服务函数写入kinesis data streams中；如果需要实时处理，需要开启&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/AmazonCloudFront/latest/DeveloperGuide/real-time-logs.html&#34;&gt;CloudFront实时日志功能&lt;/a&gt;，将数据写入Kinesis Data Streams中，会有几秒的处理延时；还有一种方式是服务端在线实时通过使用aws SDK方式直接写入记录事件数据，可通过无服务部署的lambda函数写入或者API gateway配置写入(参考:&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/apigateway/latest/developerguide/integrating-api-with-aws-services-kinesis.html&#34;&gt;在 API Gateway 中创建 REST API 作为 Amazon Kinesis 代理&lt;/a&gt;)，常用于实时异常报警和统计；&lt;/li&gt;
&lt;li&gt;数据库数据： 存放在数据库中的数据，需要将数据同步存放在数仓和数据湖中，进行离线分析; 数据库的数据可以通过&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Introduction.html&#34;&gt;aws DMS&lt;/a&gt;服务来支持存量增量数据同步至Kinesis Data Streams中，具体方案可以参考**&lt;a href=&#34;https://aws.amazon.com/cn/blogs/big-data/stream-change-data-to-amazon-kinesis-data-streams-with-aws-dms/&#34;&gt;使用 AWS DMS 将更改数据流式传输到 Amazon Kinesis Data Streams&lt;/a&gt;**；也可以使用&lt;a href=&#34;https://ververica.github.io/flink-cdc-connectors/master/&#34;&gt;flink CDC connector&lt;/a&gt;  &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/emr/latest/ReleaseGuide/emr-flink.html&#34;&gt;on aws EMR&lt;/a&gt;支持同步(需要理解反压机制，以便触发时看是否增大下游消费能力提高吞吐), 可参考&lt;a href=&#34;https://aws.amazon.com/cn/blogs/china/best-practice-of-using-amazon-emr-cdc-to-enter-the-lake-in-real-time-in-a-multi-database-multi-table-scenario/&#34;&gt;多库多表场景下使用Amazon EMR CDC实时入湖最佳实践&lt;/a&gt;，注意数据库表中的数据字段需要规范，需要一个更新时间字段方便数据顺序同步，比如mysql &lt;code&gt;update_time timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP&lt;/code&gt;；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;您可以参阅 AWS 白皮书&lt;a href=&#34;https://d1.awsstatic.com/whitepapers/aws-cloud-data-ingestion-patterns-practices.pdf&#34;&gt;AWS Cloud Data Ingestion Patterns and Practices&lt;/a&gt;，了解有关数据采集模式的更多详细信息；&lt;/p&gt;
&lt;p&gt;将数据采集写入消息队列中主要是方便多个消费方来处理流，以及服务之间的整体解耦，可作为数据流缓存层，数据流量突增时，增加分片数，提高吞吐，当然整体吞吐量也取决于下游数据的消费能力，引入消息队列，以pull方式进行消费(主动消费)，不至于将下游服务打挂，而且方便下游异常消费重启时，继续在未消费点开始消费；这里提供两种方案，一种将数据写入Kinesis Data Streams中，一种将数据写入&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/msk&#34;&gt;MSK&lt;/a&gt;(aws 托管的kafka集群服务，如果直接自己搭建维护，成本比较高，对接其他aws服务相对复杂些) 中；&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;数据写入Kinesis Data Streams中主要是方便多个消费方来处理流，以及服务之间的整体解耦，数据流缓存层，更重要的是方便使用aws Kinesis方案，减少运维成本，对接也丰富，主要是方便对接内部Kinesis相关服务组件;&lt;/li&gt;
&lt;li&gt;数据写入MSK中，使用的开源解决方案对接；下游对接kinesis Data Analytics 服务需要通过flink 计算引擎加载对应kafka connector包，从kafka中获取数据源进行分析；如果下游对接其他服务，比如：Kinesis Data Firehose，将数据传输转化写入数据湖S3中存储，写入Redshift数仓中分析；使用SNS 进行报警等； 需要引入无服务框架lambda函数，通过使用&lt;a href=&#34;https://docs.confluent.io/platform/current/clients/index.html&#34;&gt;kafka client SDK库&lt;/a&gt;来进行生产/消费处理；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;具体使用结合公司实际场景而定，如果想想通过kafka对接更多的开源大数据服务框架， 可以选择MSK方案，额外需要开发维护lambda函数服务；使用Kinesis Data streams 很方便接入aws相关服务，减少额外的开发维护成本，不过如果对接其他开源大数据服务框架，同样需要引入lambda函数服务；本文采用将数据写入Kinesis Data streams 服务，提供给下游对接。&lt;/p&gt;
&lt;h3 id=&#34;数据处理存储&#34;&gt;数据处理存储&lt;/h3&gt;
&lt;p&gt;数据处理分析，分为实时处理的&lt;a href=&#34;https://aws.amazon.com/cn/streaming-data/&#34;&gt;流数据&lt;/a&gt;和离线处理批数据处理存放；&lt;/p&gt;
&lt;p&gt;实时处理使用AWS Kinesisi Data Analytics(KDA)进行分析，支持三种分析方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;使用老的方式&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/dev/what-is.html&#34;&gt;SQL 应用程序&lt;/a&gt;进行分析处理，不能使用编程语言python/Scala来调用api来进行精细化操作(需要定义UDF包提供使用),以及即席查询；&lt;/li&gt;
&lt;li&gt;使用基于 &lt;a href=&#34;https://flink.apache.org/&#34;&gt;Apache Flink&lt;/a&gt; 的开源库在 Kinesis Data Analytics 中构建 Java ,Scala 和Python 应用程序,Apache Flink 是处理数据流的常用框架和引擎，Kinesis Data Analytics现使用flink支持最高版本是&lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/learn-flink/overview/&#34;&gt;1.13&lt;/a&gt;；在开发应用时，需要打印日志，以便使用CloudWatch 日志监控应用程序的性能和错误状况；如果应用程序出现bug或者服务异常中断可以使用检查点(&lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/ops/state/checkpoints/&#34;&gt;CheckPoints&lt;/a&gt;)和保存点(&lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/ops/state/savepoints/&#34;&gt;SavePoints&lt;/a&gt; 生成&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/java/how-fault-snapshot.html&#34;&gt;快照&lt;/a&gt;)在 Kinesis Data Analytics 应用程序中实现容错功能; 同时Kinesis Data Analytics &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/java/how-scaling.html&#34;&gt;&lt;strong&gt;可弹性扩缩&lt;/strong&gt;&lt;/a&gt;应用程序的并行度，以适应大多数场景下的源数据吞吐量和操作复杂性，Kinesis Data Analytics 监控应用程序的资源 (CPU) 使用情况，并相应地弹性地向上或向下扩展应用程序的并行度; 使用算子(&lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/datastream/operators/overview/#operators&#34;&gt;operators&lt;/a&gt;)进行数据流拓扑计算；同时通过&lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/datastream/overview/&#34;&gt;connector&lt;/a&gt;可直接引入jar包接入数据源或者sink到下游服务，可以在mvn库中找到，比如&lt;a href=&#34;https://mvnrepository.com/artifact/org.apache.flink/flink-sql-connector-kinesis&#34;&gt;kinesis stream connector&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;在基于 &lt;a href=&#34;https://flink.apache.org/&#34;&gt;Apache Flink&lt;/a&gt; 的开源库构建应用程序的基础上，结合&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/glue/latest/dg/how-it-works.html&#34;&gt;Glue&lt;/a&gt;定义数据库表存放数据catalog元数据，通过&lt;a href=&#34;https://zeppelin.apache.org/&#34;&gt;zeppelin&lt;/a&gt;增加了可视化即席查询, 直接可以在notebook上编写flink 流/批**&lt;a href=&#34;https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/overview/&#34;&gt;SQL&lt;/a&gt;**(notice: *flinkSQL和KDA SQL有所不同，特别是在window上有些区别*), 以及编写调用flink API的Scala,Python程序, 具体见&lt;a href=&#34;https://zeppelin.apache.org/docs/0.9.0/interpreter/flink.html&#34;&gt;zeppelin flink解释器&lt;/a&gt;; 这种方式是相对于第二种方式，在方便运维管理的基础上更加容易上手，直接在notebook上就可以进行即席查询, 查询会话还可以保留或存放本地，还可以作为测试开发调试的平台，构建好处理程序，可直接转化成&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/java/how-notebook-durable.html&#34;&gt;持久化的应用程序部署&lt;/a&gt;；当然这部分费用相比前面的分析方式相对多些，启动的studio notebook 费用，Kinesis 处理单元(KPU)将按小时收费；可参考&lt;a href=&#34;https://docs.aws.amazon.com/kinesisanalytics/latest/java/how-zeppelin-examples.html&#34;&gt;实例教程&lt;/a&gt;，&lt;a href=&#34;https://aws.amazon.com/cn/blogs/big-data/query-your-data-streams-interactively-using-kinesis-data-analytics-studio-and-python/&#34;&gt;使用 Kinesis Data Analytics Studio 和 Python 以交互方式查询数据流&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;整体来说： &lt;a href=&#34;https://aws.amazon.com/kinesis/data-analytics/&#34;&gt;Amazon Kinesis Data Analytics&lt;/a&gt; 可以轻松地实时分析流数据，并使用标准 SQL、Python 和 Scala 构建由 Apache Flink 提供支持的流处理应用程序。特别是notebook功能只需在AWS 管理控制台中单击几下，写下分析SQL，就可以启动无服务器笔记本来查询数据流并在几秒钟内获得结果。Kinesis Data Analytics 降低了构建和管理 Apache Flink 应用程序的复杂性。&lt;/p&gt;
&lt;p&gt;离线处理的数据主要是通过&lt;a href=&#34;&#34;&gt;AWS Kinesis Data Firehose&lt;/a&gt; 传输流写入下游服务存储，将数据写入湖仓系统中, 用于后续的数据分析，以及前期规划好的数据分析；选用firehose的原因是有原始备份机制存放于S3中，即使数据传输错误时，数据传输中不会丢失数据，同时内置lambd函数在传输之前将数据转化处理，同时也支持用Glue定义表来转换大数据相关的记录格式;&lt;/p&gt;
&lt;p&gt;原始分析数据直接存放于&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/Welcome.html&#34;&gt;S3&lt;/a&gt;中，11个9的保障可以非常可靠保证数据不丢失，通过&lt;a href=&#34;https://aws.amazon.com/cn/s3/storage-classes/glacier/&#34;&gt;Glacier&lt;/a&gt;持久冷热存放，降低成本，方便后面追查数据，以及通过Athena查询引擎结合Glue来定义表从S3中挖掘出更有价值的数据；数据存放下来之后，结合大数据相关平台，&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/emr/latest/ManagementGuide/emr-what-is-emr.html&#34;&gt;EMR&lt;/a&gt;进行海量数据处理(PB级别)；同时结合&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/glue/latest/dg/what-is-glue.html&#34;&gt;Glue&lt;/a&gt; 进行ETL 数据处理，集成编排成DAG工作流，可视化管理这些ETL任务作业，也可以迁移调度平台比如Azkaban的工作流迁移至Glue ETL工作流,参考&lt;a href=&#34;https://aws.amazon.com/cn/blogs/china/preliminary-study-on-selection-of-aws-glue-scheduling-tool/&#34;&gt;Amazon Glue ETL作业调度工具选型初探&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;提前业务场景数据分析建模，使用&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/redshift/latest/gsg/concepts-diagrams.html&#34;&gt;Redshift&lt;/a&gt;来存放不同维度(DIM)的表，分层(ODS-&amp;gt;&lt;strong&gt;DWD-&amp;gt;DWM-&amp;gt;DWS&lt;/strong&gt;)建设数据仓库； 选用redshift性价比比较高，开箱即用，存放结构化，半结构化数据，数据列式存储，分片存放，计算和存储分离，很方便无服务化，在数秒内轻松运行和扩展分析，而无需调配和管理数据仓库; 和数据湖打通，可以使用 &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/redshift/latest/gsg/data-lake.html&#34;&gt;Redshift Spectrum&lt;/a&gt; 在 Amazon S3 文件中查询数据，而不必将数据加载到 Amazon Redshift 表中，提高关联查询；还可以对接机器学习&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/machine_learning.html&#34;&gt;ML&lt;/a&gt;，通过CREATE MODEL DDL语句下推到Amazon &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/whatis.html&#34;&gt;SageMaker&lt;/a&gt;，从S3中加载数据进行训练；&lt;/p&gt;
&lt;h3 id=&#34;数据分析&#34;&gt;数据分析&lt;/h3&gt;
&lt;p&gt;主要是通过分析引擎从数据存储获取数据，根据维度展现看板，进行实时数据查看，离线分析，以及可视化即席分析：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;实时结果数据查看：通过&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/amazondynamodb/latest/developerguide/Introduction.html&#34;&gt;DynamoDB&lt;/a&gt;获取实时结果数据，主要是Key/Value数据，同时查询速度很快，利用&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/amazondynamodb/latest/developerguide/DAX.html&#34;&gt;DAX&lt;/a&gt;实现内存中加速；通过&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/lambda/latest/dg/welcome.html&#34;&gt;lambda&lt;/a&gt;对接&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/apigateway/latest/developerguide/welcome.html&#34;&gt;API Gateway&lt;/a&gt;提供数据接口，方便业务场景实时展现，比如监控查看异常数据，访问计数等结果展现；这些结果数据可以直接通过&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/sns/latest/dg/welcome.html&#34;&gt;SNS&lt;/a&gt;发送邮件或者短信进行通知；&lt;/li&gt;
&lt;li&gt;通过&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/opensearch-service/latest/developerguide/what-is.html&#34;&gt;OpenSearch&lt;/a&gt;提供实时搜索服务，比如日志搜索实时定位追查问题，通过KDA实时分析写入；在线检索商品，这些数据主要来源于数据库，异构成OpenSearch索引数据进行检索，可通过&lt;a href=&#34;https://ververica.github.io/flink-cdc-connectors/master/&#34;&gt;flink CDC&lt;/a&gt; on &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/emr/latest/ReleaseGuide/emr-flink.html&#34;&gt;EMR&lt;/a&gt;来同步数据到OpenSearch中；&lt;/li&gt;
&lt;li&gt;S3中的数据通过&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/what-is.html&#34;&gt;Athena&lt;/a&gt;在Glue/Hive上建表元数据，使用&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/athena/latest/ug/ddl-sql-reference.html&#34;&gt;SQL&lt;/a&gt;查询，几分钟内可以查询到结果;&lt;/li&gt;
&lt;li&gt;存放在&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/redshift/latest/gsg/concepts-diagrams.html&#34;&gt;Redshift&lt;/a&gt;数据仓库中的数据，通过Amazon &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/quicksight/latest/user/welcome.html&#34;&gt;QuickSight&lt;/a&gt;接入进行BI分析，响应时间在秒级别，只需要在界面上选择图表组合成一个仪表盘展现即可，方便快速决策；&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/quicksight/latest/user/regions.html&#34;&gt;支持AWS区域接入IP范围&lt;/a&gt;;&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;组织用户角色权限管理&#34;&gt;组织用户角色权限管理&lt;/h3&gt;
&lt;p&gt;以上这些谈到的服务需要进行安全访问，通过&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/iam/&#34;&gt;IAM&lt;/a&gt;定义策略角色分配权限进行&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/service-authorization/latest/reference/reference.html&#34;&gt;服务授权&lt;/a&gt;，来进行安全访问，有两种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;服务资源之间的访问，需要分配读写权限，需要把这些策略赋予莫个角色，然后资源通过这个赋予资源权限的角色来访问对应资源；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还有就是操作者访问服务资源，需要分配不同资源的读写权限，可以根据公司组织架构来管理每个员工的权限使用范围，非常方便；&lt;/p&gt;
&lt;p&gt;角色权限设置规则如下：&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/IAM/latest/UserGuide/id.html&#34;&gt;IAM身份&lt;/a&gt;设置用户组 dev, op, biz user，后续 细分在按组织部门进行建组；&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;op: 理论上构建完一组资源可以分配对应权限策略角色Role，给予服务资源的运维管理操作；&lt;/li&gt;
&lt;li&gt;dev: 只有使用开发资源权限，比如lambda编辑发布权限，数据库读写权限，而非管理删除权限策略Role；&lt;/li&gt;
&lt;li&gt;bizUser: 业务操作者，大部分只有读权限策略Role，没有写操作权限；&lt;/li&gt;
&lt;li&gt;admin: 管理员，Administrator权限，可以访问任何资源&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;还有是创建的应用是给外部服务用户使用，比如Web,移动端用户，通过Amazon &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/cognito/&#34;&gt;Cognito&lt;/a&gt;来注册登录管理用户，也可以通过第三方登录进行身份验证；两个主要组件是用户池和身份池：用户池是为应用程序提供注册和登录选项的用户目录，身份池授予用户访问其他 AWS 服务的权限。请参考&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/cognito/latest/developerguide/cognito-scenarios.html&#34;&gt;Amazon Cognito常见场景&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;场景&#34;&gt;场景&lt;/h2&gt;
&lt;h3 id=&#34;case-实时异常事件报警展现&#34;&gt;CASE 实时异常事件报警展现&lt;/h3&gt;
&lt;p&gt;打点事件数据：（实体数据，通过同步实体表数据流进行关联jion操作）&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;field&lt;/th&gt;
&lt;th&gt;type&lt;/th&gt;
&lt;th&gt;desc&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;eventId&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;用户行为事件id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;action&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;统一定义的事件动作，比如 浏览文档：viewDoc&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;userId&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;触发事件的用户id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;createdAt&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;触发事件时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;objectId&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;操作对象id, 比如文档id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;bizId&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;所属业务id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;errorMsg&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;错误信息&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;实时过滤出异常事件KDA SQL&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- ** Continuous Filter ** 
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- Performs a continuous filter based on a WHERE condition.
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;--          .----------.   .----------.   .----------.              
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;--          |  SOURCE  |   |  INSERT  |   |  DESTIN. |              
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- Source--&amp;gt;|  STREAM  |--&amp;gt;| &amp;amp; SELECT |--&amp;gt;|  STREAM  |--&amp;gt;Destination
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;--          |          |   |  (PUMP)  |   |          |              
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;--          &amp;#39;----------&amp;#39;   &amp;#39;----------&amp;#39;   &amp;#39;----------&amp;#39;               
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- STREAM (in-application): a continuously updated entity that you can SELECT from and INSERT into like a TABLE
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- PUMP: an entity used to continuously &amp;#39;SELECT ... FROM&amp;#39; a source STREAM, and INSERT SQL results into an output STREAM
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- Create output stream, which can be used to send to a destination
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- reference: 
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/sqlref/analytics-sql-reference.html
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/dev/streaming-sql-concepts.html
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/sqlref/kinesis-analytics-sqlref.pdf
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- abnormality event stream
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;CREATE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;OR&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;REPLACE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;STREAM&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;DESTINATION_SQL_STREAM&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; 
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;(&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;eventId&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;       &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;64&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;action&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;256&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;userId&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;64&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;objectId&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;64&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;bizId&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;         &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;64&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;1024&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;createdAt&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;32&lt;/span&gt;)&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;);&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- Filter errorMsg like panic/error pump
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;CREATE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;OR&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;REPLACE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;PUMP&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;ERROR_PANIC_STREAM_PUMP&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;AS&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;INSERT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;INTO&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;DESTINATION_SQL_STREAM&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;STREAM&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;eventId&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;action&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;userId&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;objectId&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;bizId&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;createdAt&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;WHERE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;LIKE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;%[PANIC]%&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;or&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;LIKE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;%[panic]%&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; 
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;or&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;LIKE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;%[ERROR]%&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; 
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;or&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;LIKE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;%[error]%&amp;#39;&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;每1分钟warn数目超过10次的SQL(滚动窗口)&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-sql&#34; data-lang=&#34;sql&#34;&gt;&lt;span style=&#34;color:#00a&#34;&gt;CREATE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;OR&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;REPLACE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;STREAM&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;DESTINATION_SQL_STREAM&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; 
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;(&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;eventId&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;       &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;64&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;action&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;256&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;userId&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;64&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;objectId&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;64&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;bizId&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;         &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;64&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;1024&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;createAt&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;32&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;INGREST_ROW_TIME&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;32&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;APPROXIMATE_ARRIVAL_TIME&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;      &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;varchar&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;32&lt;/span&gt;)&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;);&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- Filter errorMsg like warning pump
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- Aggregation with time window(u can use stagger windows,tumbling windows, sliding windows)
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- use tumbling windows for this case
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;CREATE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;OR&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;REPLACE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;PUMP&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;STREAM_PUMP&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;AS&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;INSERT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;INTO&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;DESTINATION_SQL_STREAM&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SELECT&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;STREAM&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;eventId&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;userId&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;objectId&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;bizId&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;createAt&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;action&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;STEP(&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;&lt;/span&gt;.ROWTIME&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;BY&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;INTERVAL&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;60&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SECOND&lt;/span&gt;)&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;AS&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;INGREST_ROW_TIME&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;STEP(&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;&lt;/span&gt;.APPROXIMATE_ARRIVAL_TIME&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;BY&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;INTERVAL&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;60&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SECOND&lt;/span&gt;)&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;AS&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;APPROXIMATE_ARRIVAL_TIME&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- STEP(&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;.EVENT_TIME BY INTERVAL &amp;#39;60&amp;#39; SECOND) AS &amp;#34;EVENT_TIME&amp;#34;,
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;COUNT&lt;/span&gt;(*)&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;AS&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;action_warn_count&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;FROM&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;WHERE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;LIKE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;% WARNNING %&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;or&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;errorMsg&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;LIKE&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;% warnning %&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;GROUP&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;BY&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;action&amp;#34;&lt;/span&gt;,&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;STEP(&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;&lt;/span&gt;.ROWTIME&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;BY&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;INTERVAL&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;60&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SECOND&lt;/span&gt;),&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;STEP(&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;&lt;/span&gt;.APPROXIMATE_ARRIVAL_TIME&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;BY&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#0aa&#34;&gt;INTERVAL&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;60&amp;#39;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;SECOND&lt;/span&gt;)&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;        &lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;-- STEP(&amp;#34;SOURCE_SQL_STREAM_001&amp;#34;.EVENT_TIME BY INTERVAL &amp;#39;60&amp;#39; SECOND) 
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt;    &lt;/span&gt;&lt;span style=&#34;color:#00a&#34;&gt;Having&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;action_warn_count&amp;#34;&lt;/span&gt;&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&amp;gt;=&lt;span style=&#34;color:#bbb&#34;&gt; &lt;/span&gt;&lt;span style=&#34;color:#099&#34;&gt;10&lt;/span&gt;;&lt;span style=&#34;color:#bbb&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;服务构建&#34;&gt;服务构建&lt;/h2&gt;
&lt;p&gt;基于以上服务搭建，需要用户去aws云平台上点击，配置使用， 特别是构建表，以及数据传输，属性和安全访问权限角色的管理，随着业务复杂度变高，基础服务也随之增多，可配置化的东西越来越多，会带来灾难性的后果，最终变得不可控，人力管理运维成本增加；aws平台提供了AWS CloudFormation 允许您通过将基础设施视为代码来建模、预置和管理 AWS 和第三方资源。即IaC，也是Devops经常所做的事情，可以使用相关IaC工具来自动化构建一个系统，常用的场景是CI/CD支持快速变化的业务需求开发；AWS一直提供基础服务的配置API，有相关的SDK可供使用，也有&lt;code&gt;aws&lt;/code&gt; 工具来操作这些基础服务资源； 后面提供了一种开源软件开发框架AWS Cloud Development Kit (AWS &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/cdk/v2/guide/home.html&#34;&gt;CDK&lt;/a&gt;)，可使用熟悉的编程语言来定义云应用程序资源；将云上硬件资源可编程化，可以很方便的实现自动化运维管理，充分利用云上的资源来组装construct成一个模块栈stack, 各个模块栈最终合成一个落地解决方案，方便开箱即用(安装软件一样)，降低云构建的复杂性；cdk construct分3个层次的封装，L1是最低级别初始封装，直接对应CloudFormation配置模版文件映射，称之为CFN 资源，必须配置每一项属性，需要深入了解资源模型的详细信息；L2是是对了L1的组合封装，使用资源属性默认值，比如new VPC；L3则是一种模式(pattern)，通过多种资源组合成一个常见资源架构，比如 new Fargate无服务化容器集群；具体参考见：&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/cdk/v2/guide/constructs.html&#34;&gt;constructs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;通过&lt;a href=&#34;https://cdkworkshop.com&#34;&gt;cdk workshop&lt;/a&gt; 大概花半天时间学习这里的demo就可以试着搭建相关的服务， 也有更多的&lt;a href=&#34;https://awesome-aws-workshops.com/&#34;&gt;awesome workshop&lt;/a&gt;可供参考和学习的，并且 &lt;a href=&#34;https://aws.amazon.com/blogs&#34;&gt;aws blog&lt;/a&gt;  &lt;a href=&#34;https://aws.amazon.com/cn/builders-library&#34;&gt;builders&#39; lib&lt;/a&gt;也会有很多相关的解决方案提供学习；当然需要很好的架构aws服务，需要多落地实践，深入服务细节(查看帮助文档&lt;a href=&#34;https://docs.aws.amazon.com/&#34;&gt;docs&lt;/a&gt;)，结合需求，才能构建一个相对完美的解决方案；当然前期生产落地需要使用CDK来进行架构推理。&lt;/p&gt;
&lt;p&gt;这里结合上述需求，使用CDK来搭建一些stack, 方便数据流分析管道的组装，后续也方便与其他contstucts进行组装；主要是分为以下stack:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;CDK-Workshop-Lambda-KDS-stack&lt;/strong&gt;：&lt;/p&gt;
&lt;p&gt;APIGateway-&amp;gt;lambda(put KDS record &amp;amp; hit counter in dynamodb)-&amp;gt;lambda(hello)  dynamotableviewer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DMS-KDS-stack&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;KDS-KDA-sql-Lambda-Dynamodb-stack&lt;/strong&gt;: KDS-&amp;gt;KDA-&amp;gt;lambda-&amp;gt;dynamodb dynamotableviewer&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;KDS-KDF-S3-stack&lt;/strong&gt;: KDS-&amp;gt;KDF-&amp;gt;S3&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;KDS-KDA-flink-OpenSearch-stack&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;KDS-KDA-flink-KDS-stack: eg: for near-realtime-warehouse, make a pipeline (ODS-&amp;gt;&lt;strong&gt;DWD-&amp;gt;DWM-&amp;gt;DWS&lt;/strong&gt;) sink to Redshift; like this &lt;a href=&#34;https://cloud.tencent.com/developer/article/1919594&#34;&gt;tencent news Pipeline pattern&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;KDS-KDF-Redshift-stack:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Redshift-QuickSight-stack&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;S3-Glue-Athena-stack&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里主要部署CDK-Workshop-Lambda-KDS-stack, KDS-KDA-sql-Lambda-Dynamodb-stack 和KDS-KDF-S3-stack 搭建SQL流式处理用户行为数据,具体见&lt;a href=&#34;https://github.com/weedge/user-behavior-analytics-cdk&#34;&gt;代码&lt;/a&gt;；其他stack可以后续进行扩展进行构建，推理整体基础设施架构。&lt;/p&gt;
&lt;h3 id=&#34;构建&#34;&gt;构建&lt;/h3&gt;
&lt;p&gt;首先需要安装CDK, 具体查看&lt;a href=&#34;https://aws.amazon.com/cn/getting-started/guides/setup-cdk/&#34;&gt;入门教程&lt;/a&gt;，执行如下命令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# download code to start&lt;/span&gt;
git clone https://github.com/weedge/user-behavior-analytics-cdk.git &amp;amp;&amp;amp; &lt;span style=&#34;color:#0aa&#34;&gt;cd&lt;/span&gt; user-behavior-analytics-cdk
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# tips: cdk load cdk.json + cdk.context.json to run by js on node&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# list stacks&lt;/span&gt;
cdk ls
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# deploy KDS-KDA-sql-Lambda-DynamoDB-stack with KDS-KDF-S3-stack(need created kinesis data stream)&lt;/span&gt;
cdk deploy KDS-KDA-sql-Lambda-DynamoDB-stack
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# deploy CDK-Workshop-Lambda-KDS-stack for hit event stream; lambda func put record to KDS, dependcy KDS&lt;/span&gt;
cdk deploy CDK-Workshop-Lambda-KDS-stack
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;部署完之后，会输出kinesis数据流的名称以及用于查看数据结果地址；&lt;/p&gt;
&lt;p&gt;开始写入测试数据，需要使用python3, 使用pip3 安装依赖包&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# init python virtural env&lt;/span&gt;
python3 -m venv .venv &amp;amp;&amp;amp; &lt;span style=&#34;color:#0aa&#34;&gt;source&lt;/span&gt; .venv/bin/activate 
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# install boto3  faker&lt;/span&gt;
pip3 install boto3 faker
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# run test script, wait KDA run, put record to KDS&lt;/span&gt;
python3 src/scripts/producer-kds-test.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;运行测试脚本，输入region地域名称,比如us-east-1, 等待启动后，输入数据流名称，开始发送数据；&lt;/p&gt;
&lt;p&gt;每1秒发一次数据写入KDS中，发了10次含有错误事件，发了10次随机事件，总共20条；&lt;/p&gt;
&lt;p&gt;也可以使用aws提供KDS数据生成器：https://github.com/awslabs/amazon-kinesis-data-generator&lt;/p&gt;
&lt;p&gt;从刚才部署输出结果地址查看含有错误的数据已经有10条展现出来(数据获取式前端每隔几秒轮训获取api数据，实时展现可通过&lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/apigateway/latest/developerguide/apigateway-websocket-api.html&#34;&gt;API Gateway WebSocket&lt;/a&gt; 来支持)；历史数据可以在KDF配置的S3目标中点击查看，原始数据可以下载gz包进行解压查看;&lt;/p&gt;
&lt;p&gt;通过使用提供给前端访问的事件api(api地址在部署CDK-Workshop-Lambda-KDS-stack后输出的访问地址)来写入异常&lt;code&gt;[error]&lt;/code&gt; 数据&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;curl -XPOST -iv https://{APIGateway}.execute-api.{region}.amazonaws.com/prod/event -d &lt;span style=&#34;color:#a50&#34;&gt;&amp;#39;{&amp;#34;eventId&amp;#34;:&amp;#34;1-1-1&amp;#34;,&amp;#34;bizId&amp;#34;:&amp;#34;123123&amp;#34;,&amp;#34;objectId&amp;#34;:&amp;#34;123&amp;#34;,&amp;#34;action&amp;#34;:&amp;#34;test&amp;#34;,&amp;#34;errorMsg&amp;#34;:&amp;#34;[error]&amp;#34;,&amp;#34;userId&amp;#34;:&amp;#34;1231321&amp;#34;}&amp;#39;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过刚才部署KDS-KDA-sql-Lambda-DynamoDB-stack的结果地址可以 查看异常数据已经实时写入。&lt;/p&gt;
&lt;p&gt;最后将部署资源清除，依赖删除(和卸载软件一样)。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# destroy resources with dependent resources&lt;/span&gt;
cdk destroy KDS-KDF-S3-stack
cdk destroy KDS-KDA-sql-Lambda-DynamoDB-stack
cdk destroy CDK-Workshop-Lambda-KDS-stack
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# or cdk destroy --all&lt;/span&gt;
cdk destroy --all
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;代码结构&#34;&gt;代码结构&lt;/h3&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;├── cmd                              -- golang cmd bin dir
├── docs                             -- help doc
├── infra                            -- infrastructures stack
│   └── lib                          -- cdk constuct in stack
├── src                              -- source code to run
│   ├── kinesis-analytics-pyflink    -- KDA python scripts use flink python api 
│   ├── kinesis-analytics-sql        -- KDA sql
│   ├── lambda                       -- js,python,golang lambda func 
│   ├── redshift-sql                 -- redshift sql 
│   └── scripts                      -- local run test code by use aws sdk
├── test                             -- test cdk logic
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
&lt;p&gt;sam cli &lt;a href=&#34;https://docs.aws.amazon.com/zh_cn/serverless-application-model/latest/developerguide/serverless-sam-cli-using-invoke.html&#34;&gt;local debug lambda&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;streaming cdk: &lt;a href=&#34;https://github.com/aws-samples/streaming-solution-aws-cdk&#34;&gt;https://github.com/aws-samples/streaming-solution-aws-cdk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;kds and msk cdk: &lt;a href=&#34;https://github.com/aws-solutions/streaming-data-solution-for-amazon-kinesis-and-amazon-msk&#34;&gt;https://github.com/aws-solutions/streaming-data-solution-for-amazon-kinesis-and-amazon-msk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Redshift cdk : &lt;a href=&#34;https://github.com/miztiik/redshift-demo&#34;&gt;https://github.com/miztiik/redshift-demo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Glue cdk: &lt;a href=&#34;https://github.com/aws-samples/glue-workflow-aws-cdk&#34;&gt;https://github.com/aws-samples/glue-workflow-aws-cdk&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;opensearch cdk: &lt;a href=&#34;https://www.luminis.eu/blog/cloud-en/deploying-a-secure-aws-elasticsearch-cluster-using-cdk/&#34;&gt;https://www.luminis.eu/blog/cloud-en/deploying-a-secure-aws-elasticsearch-cluster-using-cdk/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;mysql cdk: &lt;a href=&#34;https://aws.amazon.com/cn/blogs/infrastructure-and-automation/use-aws-cdk-to-initialize-amazon-rds-instances/&#34;&gt;https://aws.amazon.com/cn/blogs/infrastructure-and-automation/use-aws-cdk-to-initialize-amazon-rds-instances/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;mysql dms cdk: &lt;a href=&#34;https://aws.amazon.com/cn/blogs/database/accelerate-data-migration-using-aws-dms-and-aws-cdk/&#34;&gt;https://aws.amazon.com/cn/blogs/database/accelerate-data-migration-using-aws-dms-and-aws-cdk/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;aurora mysql dms kds opensearch cdk: &lt;a href=&#34;https://github.com/aws-samples/aws-dms-cdc-data-pipeline.git&#34;&gt;https://github.com/aws-samples/aws-dms-cdc-data-pipeline.git&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;kda-flink-py: &lt;a href=&#34;https://aws.amazon.com/cn/blogs/china/python-stream-data-processing-and-analysis-using-pyflink-in-amazon-kinesis-data-analytics/&#34;&gt;https://aws.amazon.com/cn/blogs/china/python-stream-data-processing-and-analysis-using-pyflink-in-amazon-kinesis-data-analytics/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;kda-zeppelin-flink-py: &lt;a href=&#34;https://aws.amazon.com/cn/blogs/big-data/query-your-data-streams-interactively-using-kinesis-data-analytics-studio-and-python/&#34;&gt;https://aws.amazon.com/cn/blogs/big-data/query-your-data-streams-interactively-using-kinesis-data-analytics-studio-and-python/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://docs.aws.amazon.com/pdfs/whitepapers/latest/microservices-on-aws/microservices-on-aws.pdf&#34;&gt;Implementing Microservices on AWS&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://d1.awsstatic.com/whitepapers/aws-cloud-data-ingestion-patterns-practices.pdf&#34;&gt;AWS Cloud Data Ingestion Patterns and Practices&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://catalog.us-east-1.prod.workshops.aws/workshops/c342c6d1-2baf-4827-ba42-52ef9eb173f6/en-US/flink-on-kda&#34;&gt;Flink-on-KDS Workshop&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://catalog.us-east-1.prod.workshops.aws/workshops/2300137e-f2ac-4eb9-a4ac-3d25026b235f/en-US&#34;&gt;Real time streaming with kinesis Workshop&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>全栈开发</title>
      <link>https://weedge.github.io/post/shop/</link>
      <pubDate>Sun, 02 Jan 2022 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/shop/</guid>
      
        <description>&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;以前工作中有过前端的开发经验，使用后端模版Smarty(主要是外部需求，现在新项目中应该很少使用这个了)，前端模版Mustache，页面中使用 js jquery交互逻辑，直接服用一些开源的UI组件Bootstrap，开源的后台UI系统，主要是建设内部后台的时候使用，自动生成CRUD页面；前端的技术栈更新迭代相对后端快些，通过以全栈技术栈为切入点，通过一个简单的系统，学习下最新技术栈工具，主要目的如下：&lt;/p&gt;
&lt;p&gt;根据需求，实现一个简单功能的购物系统，目的是为了学习ts-&amp;gt;js on node.js全栈开发，了解整体开发构建工具，熟悉下工具开发流程，主要还是了解前端框架工具的使用，以及熟悉通过js运行时环境运行在后端服务上的应用开发工具，以便在后续开发后台系统的时候可以熟练使用这些技术进行开发，这些工具的设计思想可以借鉴到其他后端业务开发语言中。&lt;/p&gt;
&lt;h2 id=&#34;功能要求&#34;&gt;功能要求&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;⽤户可以浏览商品，提供按商品名字搜索功能。&lt;/li&gt;
&lt;li&gt;⽤户可以下单购买某样商品（⽀付过程可以省略），购买成功后系统需要异步通知下游系统（如仓库 系统、物流系统等，下游系统可简单实现）。&lt;/li&gt;
&lt;li&gt;提供后台管理⻚⾯录⼊商品，包括商品名称、商品描述、商品价格、库存等。&lt;/li&gt;
&lt;li&gt;要求记录⽤户访问⽇志，供审计使⽤。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;实现要求&#34;&gt;实现要求&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;前端使⽤Vue.js + elementUI，后台使⽤ AdonisJS 框架（AdonisJS 版本要求5.0以上）。&lt;/li&gt;
&lt;li&gt;数据库使⽤ mysql，结合 AdonisJS 的 ORM 能⼒。&lt;/li&gt;
&lt;li&gt;设计时需要考虑必要的系统安全性。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;设计实现&#34;&gt;设计实现&lt;/h2&gt;
&lt;h3 id=&#34;需求分析&#34;&gt;需求分析&lt;/h3&gt;
&lt;p&gt;整体交互主要是实现购买系统，以及用户购买商品的访问日志，以及用户行为日志，给审计系统，进行漏洞分析等，考虑到前期用户比较少，交互使用，5天设计开发时间，先提供v1简单版本，满足商家和买家用户的基本购买功能&lt;/p&gt;
&lt;p&gt;买家基本需求：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;通过页面查看上架商品列表；查看商品详情页；通过商品名关键字搜索商品；&lt;/li&gt;
&lt;li&gt;购买商品，查看订单(为了简化需求，无购物车功能，假设用户订单只能购买一件商品，及用户和订单是一对多，订单和商品是多对一)；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;卖家基本需求：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;后台录入查看修改删除商品(一个用户编辑多个商品项，一个商品项也可以给多个用户编辑，及用户和商品是多对多，为了简单考虑，不考虑协同的情况)；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;后台需求：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;记录访问日志，审计需求；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;功能设计&#34;&gt;功能设计&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;Shop-frontend  数据页面展现，满足商品列表展现；通过商品名搜索；详情页查看；&lt;/li&gt;
&lt;li&gt;Shop-backend  商品后台，提供http RESTful api ，满足页面需求，以及相应auth权限验证，日志记录，购买订单发送；&lt;/li&gt;
&lt;li&gt;Shop-admin-frontend 商品数据管理页面展现，操作商品增删查改功能页面；&lt;/li&gt;
&lt;li&gt;Shop-admin-backend 商品数据管理后台，提供http RESTful api， 满足页面CRUD功能；&lt;/li&gt;
&lt;li&gt;Shop-backend  记录用户访问日志， 适用pb格式记录日志，产生日志实时写入消息队列中，提供给审计系统使用&lt;/li&gt;
&lt;li&gt;其他服务；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;整体架构设计如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/shop-system.drawio.png&#34; alt=&#34;simple-shop-system&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据库设计&#34;&gt;数据库设计&lt;/h3&gt;
&lt;p&gt;单独数据库实例shop, 简单实现，未根据未来几年的数据量来评估表的容量，分库分表的情况等。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;商品表  tbl_shop_items&lt;/p&gt;
&lt;p&gt;(Tips: 这里为了简化，没有定义复杂业务实体关系了，比如产品单元(CPU), 商品单元(SKU)，产品容器(Container) 等，不要脱离业务耍流氓)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;商品id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;name&lt;/td&gt;
&lt;td&gt;varchar(32)&lt;/td&gt;
&lt;td&gt;商品名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;desc&lt;/td&gt;
&lt;td&gt;varchar(1024)&lt;/td&gt;
&lt;td&gt;商品描述&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;price&lt;/td&gt;
&lt;td&gt;unsigned int&lt;/td&gt;
&lt;td&gt;价格（分）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;stock&lt;/td&gt;
&lt;td&gt;unsigned int&lt;/td&gt;
&lt;td&gt;库存数目&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;sell_cn&lt;/td&gt;
&lt;td&gt;unsigned int&lt;/td&gt;
&lt;td&gt;售卖数目&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_released&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;是否上架&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_soldout&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;是否售匿&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_del&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;是否删除&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;owner_id&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;添加者用户id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_at&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_at&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;修改时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ext&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;扩展字段&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;用户商品操作表 tbl_user_items&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;操作id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;商品管理后台用户id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;item_id&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;商品id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_at&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_at&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;修改时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ext&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;扩展字段&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;用户订单表  tbl_user_orders （为了简化，一个用户只能选一个商品直接下单购买，无购物车）&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;user_id&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;用户id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;item_id&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;商品id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;order_id&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;订单id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pay_amount&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;支付金额&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_at&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_at&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;修改时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;ext&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;扩展字段&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;用户表 tbl_users (users)&lt;/li&gt;
&lt;/ol&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;unsigned int64&lt;/td&gt;
&lt;td&gt;用户id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;name&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;用户名&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;email&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;邮件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;password&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;加密密码&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;remember_me_token&lt;/td&gt;
&lt;td&gt;varchar&lt;/td&gt;
&lt;td&gt;api Opaque Access Token&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_admin&lt;/td&gt;
&lt;td&gt;bool&lt;/td&gt;
&lt;td&gt;是否是管理员&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;created_at&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;updated_at&lt;/td&gt;
&lt;td&gt;timestamp&lt;/td&gt;
&lt;td&gt;修改时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;ER关系：&lt;/p&gt;
&lt;p&gt;[tbl_shop_items] &amp;lt;-N&amp;mdash;1-&amp;gt; (create) [tbl_users]&lt;/p&gt;
&lt;p&gt;[tbl_shop_items] &amp;lt;-1&amp;mdash;N-&amp;gt; [tbl_user_items] (record)   &amp;lt;-M&amp;mdash;1-&amp;gt; [tbl_users]&lt;/p&gt;
&lt;p&gt;[tbl_shop_items] &amp;lt;-1&amp;mdash;N-&amp;gt; [tbl_user_orders] (order) &amp;lt;-M&amp;mdash;1-&amp;gt; [users]&lt;/p&gt;
&lt;h3 id=&#34;消息设计&#34;&gt;消息设计&lt;/h3&gt;
&lt;p&gt;订单生成后，通知下游系统，订阅消息，暂不考虑。&lt;/p&gt;
&lt;h3 id=&#34;后端接口设计&#34;&gt;后端接口设计&lt;/h3&gt;
&lt;p&gt;因为逻辑简单，就没有画出接口功能的时序图和流程图。&lt;/p&gt;
&lt;h4 id=&#34;shop-backend--服务端口2021&#34;&gt;Shop-backend  服务端口：2021&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;GET /shop/api/v1/itmes  商品列表&lt;/li&gt;
&lt;li&gt;GET /shop/api/v1/items/:id 商品详情&lt;/li&gt;
&lt;li&gt;GET /shop/api/v1/items/search?q=** 更具名称搜索商品&lt;/li&gt;
&lt;li&gt;POST /shop/api/v1/order  商品下单&lt;/li&gt;
&lt;li&gt;GET  /shop/api/v1/orders/:orderId  获取订单详情&lt;/li&gt;
&lt;li&gt;GET /shop/api/v1/users/:uid/orders 用户商品订单列表&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;shop-admin-backend-服务端口2022&#34;&gt;Shop-admin-backend 服务端口：2022&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;shop items CRUD RESTful api  for resource methods (&lt;a href=&#34;https://docs.adonisjs.com/guides/controllers#resourceful-routes-and-controllers&#34;&gt;route RESTful resource&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;POST /shopadmin/api/v1/items/:id/check 商品审核&lt;/li&gt;
&lt;li&gt;GET /shopadmin/api/v1/items/:uid  获取用户创建的商品&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;前端页面交互设计&#34;&gt;前端页面交互设计&lt;/h3&gt;
&lt;p&gt;前端页面调试，本地起页面服务端口进行本地调试&lt;/p&gt;
&lt;h4 id=&#34;shop-frontend-vue-route-component-page&#34;&gt;Shop-frontend (vue route component page)&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;/     主页面/搜索结构页，列表页面 ，展示搜索框&lt;/li&gt;
&lt;li&gt;/items/:id   详细页面， 展示购买按钮&lt;/li&gt;
&lt;li&gt;/user/:id/orders 用户商品订单列表页面&lt;/li&gt;
&lt;li&gt;/error  访问不到的页面&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;shop-admin-frontend-crud-edge-template-layout-page&#34;&gt;Shop-admin-frontend (CRUD edge template layout page)&lt;/h4&gt;
&lt;p&gt;CRUD RESTful api  for resource methods to render edge page&lt;/p&gt;
&lt;h2 id=&#34;开发&#34;&gt;开发&lt;/h2&gt;
&lt;p&gt;初期整体使用前端js全栈开发技术栈；Typescript 静态语言，通过 tsc 将ts编译成js 减少错误；通过npm管理依赖包(vim vundle/python pip/php composer/go module/rust cargo)；使用VS Code IDE开发神器编码(All in ONE，可远程ssh连接安装了linux 内核虚拟服务调试学习，查看源码很方便)，安装所需插件。&lt;/p&gt;
&lt;p&gt;具体开发工具如下：&lt;/p&gt;
&lt;p&gt;Typescript 编程语言(JavaScript超级 tsc 4.5.4 ts-&amp;gt;js) + Node.js 运行时环境(v17.2 V8 JavaScript 引擎 from Google Chrome 的内核) + Adonis.js MVC后端框架(v5.0+) + Vue.js前端框架(v3.0+)  + Element-plus UI 前端页面UI模版(v1.3)&lt;/p&gt;
&lt;p&gt;tips：业务模块设计尽量满足SOLID原则，最终满足&lt;strong&gt;高内聚，低耦合&lt;/strong&gt;, 尽量让开发框架来满足。&lt;/p&gt;
&lt;h3 id=&#34;后端服务开发&#34;&gt;后端服务开发&lt;/h3&gt;
&lt;p&gt;shop-backend, shop-admin-backend 服务逻辑， 使用ts语言，AdonisJS (MVC+IoC开发框架,适合后台开发框架) 5.0+开发环境：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/database/introduction&#34;&gt;Model&lt;/a&gt;: app ER(entity relationship) data model -&amp;gt; table schema by migration -&amp;gt; create table -&amp;gt; make  table model&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/controllers&#34;&gt;Controller&lt;/a&gt;: make controller for api logic&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/routing&#34;&gt;Routing&lt;/a&gt;: http RESTful api router (start preload routes)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/views/introduction&#34;&gt;View&lt;/a&gt;: view  edge template reander frontend page&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/validator/introduction&#34;&gt;Validator&lt;/a&gt;: validate data schema&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/validator/custom-rules&#34;&gt;Rules&lt;/a&gt;: validate rules(common &amp;amp; DIY  start preload rules)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/middleware&#34;&gt;Middleware&lt;/a&gt;:  Middleware are a series of functions that are executed during an HTTP request before it reaches the route handler. Every function in the chain has the ability to end the request or forward it to the &lt;code&gt;next&lt;/code&gt; function. &lt;strong&gt;&lt;del&gt;server&lt;/del&gt;&lt;/strong&gt; Middleware, &lt;strong&gt;Global&lt;/strong&gt; Middleware, &lt;strong&gt;Naming&lt;/strong&gt; Middleware&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/auth/introduction&#34;&gt;Authentication&lt;/a&gt;: using &lt;strong&gt;sessions&lt;/strong&gt;, &lt;strong&gt;basic auth&lt;/strong&gt; or &lt;strong&gt;API tokens(JWT, OAT)&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://docs.adonisjs.com/guides/events&#34;&gt;Events&lt;/a&gt;: define evens listener  to listen async event on(eventName,callback) , then emit event to tigger regist event&amp;rsquo;s callback; eg: new user to emit event callback to send email (DIY events Listenner, start preload events)&lt;/p&gt;
&lt;p&gt;通过adonis-ts-app demo 初始化一个app:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#new project&lt;/span&gt;
npm init adonis-ts-app@latest shop-backend
npm init adonis-ts-app@latest shop-admin-backend
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#install package for mysql &lt;/span&gt;
npm i @adonisjs/lucid@alpha
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#invoke package to select mysql for ace make:model and migration table&lt;/span&gt;
node ace configure(invoke) @adonisjs/lucid
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#install mysql2&lt;/span&gt;
npm install mysql2
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#modify config/database.ts use mysql client: mysql2&lt;/span&gt;

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#install auth middleware&lt;/span&gt;
npm i @adonisjs/auth@alpha
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#install Argon2 password hashing algorithm following the PHC string format&lt;/span&gt;
npm install phc-argon2
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#invoke package to select lucid and api tokens&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# https://docs.adonisjs.com/guides/auth/introduction&lt;/span&gt;
node ace invoke @adonisjs/auth
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# rigister auth naming middleware in start/kernel.js  auth: &amp;#39;App/Middleware/Auth&amp;#39;,&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# add auth middleware for router in start/router.js  &lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# use database-backed opaque access token&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# demo: https://dev.to/tngeene/adonisjs-understanding-user-registration-and-authentication-2ojl&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# for session auth&lt;/span&gt;
npm i @adonisjs/session 
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# for CSRF token protection&lt;/span&gt;
npm i @adonisjs/shield 
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#invoke add fhield global middleware in start/kernel.js () =&amp;gt; import(&amp;#39;@ioc:Adonis/Addons/Shield&amp;#39;)&lt;/span&gt;
node ace invoke @adonisjs/shield

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#change .env modify mysql conf&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#migration table&lt;/span&gt;
node ace make:migration {table}
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#migration create/rollback table&lt;/span&gt;
node ace migration:run / node ace migration:rollback

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#then u can use ace to make a new model app/Models/***.ts&lt;/span&gt;
node ace make:model ***
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#then u can use ace to make a new app/Controllers/Http/***Controller.ts&lt;/span&gt;
node ace make:controller ***
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#if use edge tpl, u can use ace to make a new view to render tpl&lt;/span&gt;
node ace make:view ***
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#if valide request param, u can use ace to make a new volidator&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#https://docs.adonisjs.com/guides/validator/introduction&lt;/span&gt;
node ace make:validator ***
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#or diy validate rules&lt;/span&gt;
node ace make:prldfile validator

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#make events to gen start/events.ts for listen on(eventName,callback)&lt;/span&gt;
node ace make:prldfile events
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#or make listener to listen on eventsList &lt;/span&gt;
node ace make:listener ***


&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#make a middleware like auth middleware;&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#transmit by ctx, ctx-&amp;gt;ctx-&amp;gt;ctx to next()&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#eg: u can make a user action log middleware to analyse or A/B test for recommended system&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#https://docs.adonisjs.com/guides/middleware&lt;/span&gt;
node ace make:middleware ***

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# https://github.com/luin/ioredis/blob/master/API.md&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# https://docs.adonisjs.com/guides/redis&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#install redis&lt;/span&gt;
npm i @adonisjs/redis
node ace configure @adonisjs/redis

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# https://www.npmjs.com/package/@elastic/elasticsearch&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# https://www.elastic.co/guide/en/elasticsearch/client/javascript-api/current/typescript.html&lt;/span&gt;
npm i @elastic/elasticsearch


&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# watch run &lt;/span&gt;
node ace serve --watch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;前端开发&#34;&gt;前端开发&lt;/h3&gt;
&lt;p&gt;Shop-frontend, shop-admin-frontend 前端页面逻辑，使用TypeScript+ Vue.js(前端开发框架) + ElementUI组件 通过vite构建本地开发(CI过程通过webpack打包生成静态资源，通过CD部署到边缘CDN节点)，开发环境具体操作如下：&lt;/p&gt;
&lt;p&gt;Vue.js 3 + TypeScript + Vite + ElementUI-plus&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://next.router.vuejs.org/zh/&#34;&gt;vue router&lt;/a&gt;: 通过 Vue.js，用组件组成应用；通过 Vue Router 将组件映射到路由上，让 Vue Router 知道在哪里渲染它们;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://axios-http.com/zh/docs/intro&#34;&gt;axios&lt;/a&gt;: HTTP 网络client请求库;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://next.vuex.vuejs.org/zh/index.html&#34;&gt;vuex&lt;/a&gt;: state management pattern + library stat/view/actions like MVC;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://vee-validate.logaretm.com/v4/guide/overview&#34;&gt;vee-validate&lt;/a&gt;: form validation;  &lt;a href=&#34;https://www.npmjs.com/package/yup&#34;&gt;yup&lt;/a&gt;:  data schema validation;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# install vue cli&lt;/span&gt;
npm install -g @vue/cli
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# u can use vue create app use vue.js v3&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# vue create vue-app &amp;amp; cd vue-app&lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# vue add element-plus&lt;/span&gt;

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# or use vite build vue.js v3 project app&lt;/span&gt;
npm init @vitejs/app shop-frontend 
npm init @vitejs/app shop-admin-frontend

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# eg: shop-frontend&lt;/span&gt;
&lt;span style=&#34;color:#0aa&#34;&gt;cd&lt;/span&gt; shop-frontend (shop-admin-frontend)
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# choose vue-ts when install&lt;/span&gt;
npm install

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# install vue-router4, https://next.router.vuejs.org/zh/&lt;/span&gt;
npm install vue-router@4

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# install axios https://axios-http.com/zh/docs/intro&lt;/span&gt;
npm install axios

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# install vuex, nice design(state management pattern + library stat/view/actions like MVC)  &lt;/span&gt;
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# https://next.vuex.vuejs.org/zh/index.html&lt;/span&gt;
npm install vuex@next --save

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# install vee-validate, https://vee-validate.logaretm.com/v4/guide/overview&lt;/span&gt;
npm i vee-validate@next --save


&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#install element-plus ui&lt;/span&gt;
npm install element-plus --save
npm i -D sass
&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;#auto import &lt;/span&gt;
npm install -D unplugin-vue-components unplugin-auto-import

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;# run local vue dev runtime app service (vite --port 5000 --host)&lt;/span&gt;
npm run dev

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;附具体代码(Monolith版本, 后端状态存储数据读写使用同一个数据源)：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/weedge/backend-adonisjs-api/tree/main/shop-admin-backend&#34;&gt;Shop-admin-backend&lt;/a&gt; : 后台管理系统，为了方便后续根据数据库表一键生成CURD代码，采用后端模版edge template；用户管理可以采用内部公司用户平台SSO单点登录获取ticket的方式，或者使用框架本身的身份认证功能进行后台模块的权限管理(web authentication)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/weedge/backend-adonisjs-api/tree/main/adonisjs-shop-backend-api&#34;&gt;Shop-backend-api&lt;/a&gt;：后端接口，获取接口数据，需要登录验证，和token鉴权，记录用户行为日志，读写操作数据库和缓存等；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/weedge/frontend-vue/tree/main/vue-shop-frontend&#34;&gt;Shop-frontend-vue&lt;/a&gt;：前端页面，使用vue框架开发，访问后端API使用axios，状态管理使用vuex，页面路由使vue-router，表单验证和数据验证分别使用vee-valdate和yup，组件的使用需要结合文档使用；首页/搜索结果页展示商品列表，点击更多进入商品详细页面进行购买，购买需要登录/注册，登录后进入订单列表页，具体需求推动；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;整体联调&#34;&gt;整体联调&lt;/h3&gt;
&lt;p&gt;这里前后端统一技术栈采用js on node  by (AdonisJS 5 + Vue 3 + Element-plus UI)， 如果熟悉node js  很方便调试，开发1人工全栈搞定就行，至于外部需求UI的调整美化由PM和设计师确定好，尽量通过工具自动化， 降低沟通成本；&lt;/p&gt;
&lt;p&gt;当然当后续系统切成微服务，把1人工全栈的活分成多个人来维护，从公司和组织架构层面来说，虽然增加了开发沟通成本，但是对公司来说是有利的，人员离职对系统影响会降低很多吧(from: 郭老师的架构课,以心理学+认知等方面)；&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;前端的技术迭代速度是快于后端的，主要是前端有大量的需求开发，不管是外部业务还是内部需求开发，所以需要满足业务场景下的高效迭代速度，衍生出高效的开发框架工具和UI组件复用，同时需要保持工具在项目中的迭代升级，而且在基于前端技术发展触及到后端开发，演变出前后技术栈统一的全栈开发，但是需求增多，需要更多的资源来承载用户请求，对于后端一些基础组件服务和性能优化的场景，还是需要根据&lt;strong&gt;语言特性，人力，组织结构&lt;/strong&gt;等因素考虑；前端技术底层引擎和原理性基础知识是不易变的，可以在关注变化的过程中，深入浅出共性的底层逻辑，以不变应万变；工欲善其事，必先利其器；(不管是前端/后端开发，DevOps, 以及大数据开发，甚至AI，&lt;strong&gt;熟练&lt;/strong&gt;利用好工具，工具是在应用场景下沉淀下来的，&lt;strong&gt;理解&lt;/strong&gt;基础原理和工具设计原理，结合使用场景，快速定位(文档，问题)，输出最大化，技术工具没有银弹，应用在适用场景达到事半功倍效果，学会在巨人的肩膀上考虑问题，搞事情)。&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;ECMAScript: &lt;a href=&#34;https://tc39.es/ecma262/&#34;&gt;https://tc39.es/ecma262/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ts: &lt;a href=&#34;https://www.typescriptlang.org/&#34;&gt;https://www.typescriptlang.org/&lt;/a&gt;      &lt;a href=&#34;https://typescript.bootcss.com/&#34;&gt;https://typescript.bootcss.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;why-ts: &lt;a href=&#34;https://serokell.io/blog/why-typescript&#34;&gt;https://serokell.io/blog/why-typescript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Node.js: &lt;a href=&#34;http://nodejs.cn/learn&#34;&gt;http://nodejs.cn/learn&lt;/a&gt;  &lt;strong&gt;&lt;a href=&#34;https://nodejs.org/dist/latest-v17.x/docs/api/&#34;&gt;https://nodejs.org/dist/latest-v17.x/docs/api/&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;V8 JavaScript/&lt;a href=&#34;https://developer.mozilla.org/zh-CN/docs/WebAssembly/Concepts&#34;&gt;WebAssembly&lt;/a&gt; Engine: &lt;strong&gt;&lt;a href=&#34;https://chromium.googlesource.com/v8/v8.git&#34;&gt;https://chromium.googlesource.com/v8/v8.git&lt;/a&gt;&lt;/strong&gt; &lt;strong&gt;&lt;a href=&#34;https://v8.dev/docs&#34;&gt;https://v8.dev/docs&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Adonis.js5: &lt;a href=&#34;https://adonisjs.com/&#34;&gt;https://adonisjs.com/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adonis.js5 + Edge template demo: &lt;a href=&#34;https://masteringbackend.com/posts/adonisjs-tutorial-the-ultimate-guide&#34;&gt;https://masteringbackend.com/posts/adonisjs-tutorial-the-ultimate-guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Adonis.js5 + Vue.js3 demo: &lt;a href=&#34;https://www.section.io/engineering-education/build-a-ticketing-app-with-adonisjs-and-vuejs/&#34;&gt;https://www.section.io/engineering-education/build-a-ticketing-app-with-adonisjs-and-vuejs/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vue.js3: &lt;a href=&#34;https://v3.cn.vuejs.org/guide/introduction.html&#34;&gt;https://v3.cn.vuejs.org/guide/introduction.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vite: &lt;a href=&#34;https://cn.vitejs.dev/guide/&#34;&gt;https://cn.vitejs.dev/guide/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Vue CLI: &lt;a href=&#34;https://cli.vuejs.org/zh/guide/&#34;&gt;https://cli.vuejs.org/zh/guide/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Element-Plus UI: &lt;a href=&#34;https://element-plus.gitee.io/zh-CN/guide/installation.html&#34;&gt;https://element-plus.gitee.io/zh-CN/guide/installation.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;webpack: &lt;a href=&#34;https://webpack.docschina.org/concepts/&#34;&gt;https://webpack.docschina.org/concepts/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;web开发: &lt;strong&gt;&lt;a href=&#34;https://developer.mozilla.org/zh-CN/docs/Web&#34;&gt;https://developer.mozilla.org/zh-CN/docs/Web&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>CRDT</title>
      <link>https://weedge.github.io/post/crdt/</link>
      <pubDate>Tue, 28 Dec 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/crdt/</guid>
      
        <description>&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;无冲突复制数据类型&lt;/strong&gt;(CRDT: &lt;strong&gt;conflict-free replicated data type&lt;/strong&gt;) 是一种简化分布式数据存储系统和多用户应用程序的数据结构。&lt;/p&gt;
&lt;p&gt;在许多系统中，某些数据的副本需要存储在多台计算机上。此类系统的示例包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在本地设备上存储数据，并且需要将该数据同步到属于同一用户的其他设备（同一用户多端设备同步，例如日历、笔记、联系人或提醒）的移动应用程序；&lt;/li&gt;
&lt;li&gt;分布式数据库，维护数据的多个副本（在同一数据中心或不同位置,一般是不同数据中心的多活场景），以便在某些副本离线时系统继续正常工作；&lt;/li&gt;
&lt;li&gt;协作软件，例如 Google Docs、Trello、Figma 或许多其他软件，其中多个用户可以同时更改同一文件或数据；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.microsoft.com/en-us/shows/tech-exceptions/concordant-always-know-what-to-expect-from-your-data&#34;&gt;边缘计算场景&lt;/a&gt;，比如多个手机/车载app 在无信号的森林中，产生的本地离线协同数据，多个设备同步到云上处理;&lt;/li&gt;
&lt;li&gt;大规模数据存储和处理系统，复制数据以实现全球可扩展性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有此类系统都需要处理数据可能在不同副本上同时修改的事实。从广义上讲，有两种可能的方法来处理此类数据修改：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;强一致性复制：&lt;/p&gt;
&lt;p&gt;在这个模型中，副本相互协调以决定何时以及如何应用修改。这种方法支持强一致性模型，例如可序列化事务和可线性化。然而，等待这种协调会降低这些系统的性能；此外，CAP 定理告诉我们，当副本与系统的其余部分断开连接时（例如，由于网络分区，或者因为它是具有间歇性连接的移动设备），不可能对副本进行任何数据更改。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;乐观复制：&lt;/p&gt;
&lt;p&gt;在此模型中，用户可以独立于任何其他副本修改任何副本上的数据，即使该副本离线或与其他副本断开连接。这种方法可实现最大的性能和可用性，但当多个客户端或用户同时修改同一条数据时，它可能会导致冲突。当副本相互通信时，需要解决这些冲突。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;无冲突复制数据类型 (CRDT) 用于具有乐观复制的系统，它们负责解决冲突。CRDT 确保，无论在不同的副本上进行什么数据修改，数据始终可以合并到一致的状态。此合并由 CRDT 自动执行，无需任何特殊的冲突解决代码或用户干预。&lt;/p&gt;
&lt;h2 id=&#34;原理&#34;&gt;原理&lt;/h2&gt;
&lt;h2 id=&#34;实现&#34;&gt;实现&lt;/h2&gt;
&lt;h3 id=&#34;automergehttpsgithubcomautomergeautomerge&#34;&gt;&lt;a href=&#34;https://github.com/automerge/automerge&#34;&gt;automerge&lt;/a&gt;&lt;/h3&gt;
&lt;h3 id=&#34;yjshttpsgithubcomyjsyjs&#34;&gt;&lt;a href=&#34;https://github.com/yjs/yjs&#34;&gt;Yjs&lt;/a&gt;&lt;/h3&gt;
&lt;h3 id=&#34;redis-crdbhttpsrediscomredis-enterprisetechnologyactive-active-geo-distribution&#34;&gt;&lt;a href=&#34;https://redis.com/redis-enterprise/technology/active-active-geo-distribution/&#34;&gt;redis (CRDB)&lt;/a&gt;&lt;/h3&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type&#34;&gt;wiki: Conflict-free replicated data type&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/alangibson/awesome-crdt#know-before-you-go&#34;&gt;awesome-crdt#know-before-you-go&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://crdt.tech/resources&#34;&gt;crdt.tech-resources&lt;/a&gt;&lt;/strong&gt; &lt;strong&gt;&lt;a href=&#34;https://crdt.tech/implementations&#34;&gt;crdt.tech-implementations&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://hal.inria.fr/hal-00932836/file/CRDTs_SSS-2011.pdf&#34;&gt;Conflict-free Replicated Data Types.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://hal.inria.fr/file/index/docid/555588/filename/techreport.pdf?spm=a2c6h.12873639.0.0.a25177aaoVMJMH&amp;amp;file=techreport.pdf&#34;&gt;A comprehensive study of Convergent and Commutative Replicated Data Types.pdf&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://arxiv.org/pdf/1806.10254.pdf&#34;&gt;Conflict-free Replicated Data Types: An Overview.pdf&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.isa-afp.org/browser_info/current/AFP/CRDT/document.pdf&#34;&gt;A framework for establishing Strong Eventual Consistency for Conflict-free Replicated Data types.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://arxiv.org/pdf/1608.03960.pdf&#34;&gt;A Conflict-Free Replicated JSON Datatype.pdf&lt;/a&gt;&lt;/strong&gt; &lt;a href=&#34;https://cs.paperswithcode.com/paper/a-conflict-free-replicated-json-datatype&#34;&gt;code&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=TRvQzwDyVro&#34;&gt;vedio introduce&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GXJ0D2tfZCM&#34;&gt;Automerge: Making Servers Optional for Real-Time Collaboration&lt;/a&gt;&lt;/strong&gt; &lt;a href=&#34;https://speakerdeck.com/ept/automerge-making-servers-optional-for-real-time-collaboration&#34;&gt;slide&lt;/a&gt; &lt;a href=&#34;https://github.com/automerge&#34;&gt;github.com/automerge&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/publication/310212186_Near_Real-Time_Peer-to-Peer_Shared_Editing_on_Extensible_Data_Types&#34;&gt;Near Real-Time Peer-to-Peer Shared Editing on Extensible Data Types.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/S1877050921014101&#34;&gt;Toward Fast and Reliable Active-Active Geo-Replication for a Distributed Data Caching Service in the Mobile Cloud&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redis.com/redis-enterprise/technology/active-active-geo-distribution/&#34;&gt;redis: active-active-geo-distribution&lt;/a&gt; &lt;a href=&#34;https://docs.redis.com/latest/rs/references/developing-for-active-active/&#34;&gt;redis: Developing applications with Active-Active databases&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.riak.com/riak/kv/2.0.0/developing/data-types/?spm=a2c6h.12873639.0.0.a25177aaoVMJMH&#34;&gt;riak-kv:Data Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://developer.aliyun.com/article/635632&#34;&gt;阿里云redis：CRDT——解决最终一致问题的利器&lt;/a&gt;&lt;/strong&gt;  &lt;a href=&#34;https://developer.aliyun.com/article/781709?utm_content=g_1000239229&#34;&gt;多中心容灾实践：如何实现真正的异地多活？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.51cto.com/art/202107/674513.htm&#34;&gt;基于CRDT的数据最终一致性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://ddia.vonng.com/#/ch5?id=%E5%A4%9A%E4%B8%BB%E5%A4%8D%E5%88%B6&#34;&gt;多主复制&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>pool</title>
      <link>https://weedge.github.io/post/pool/</link>
      <pubDate>Thu, 02 Dec 2021 12:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/pool/</guid>
      
        <description>&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;平常想到不浪费资源的方法，是对资源进行复用，减少资源消耗和浪费(小时候大人经常在吃饭时说的那句话)；在计算机工程领域，存在大量消耗资源的场景，多路复用和池化是最常用的性能优化手段；多路复用存在系统调用，由系统内核层面去支持优化(I/O多路复用select/poll/epoll/kqueue)，而池化可以应用用户使用层面来优化；池化(&lt;a href=&#34;https://en.wikipedia.org/wiki/Pool_(computer_science)&#34;&gt;pool&lt;/a&gt;)是一种资源复用优化技术，减少资源回收处理，提高资源利用率，资源最好是固定大小，如果在复用资源过程中，资源在逐渐增大，一直复用，也会导致资源消耗过多，到了一定大小之后，通过系统释放掉；在程序启动的时候提前申请加载好资源放到池子中，运行时根据不同的调度管理资源策略从池子中获取准备好的资源，或者运行时新建资源放入池子中，用户程序中进行自定义处理操作，操作完之后将资源重新放入池子中复用，有些资源可以动态扩缩； 资源主要是程序运行时对象，当然这些操作资源实际都是分配在虚拟内存空间的内核空间和用户空间中，比如，&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B&#34;&gt;进程&lt;/a&gt;(process &lt;a href=&#34;https://en.wikipedia.org/wiki/Process_control_block&#34;&gt;PCB&lt;/a&gt; 内核态)、&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%9F%B7%E8%A1%8C%E7%B7%92&#34;&gt;线程&lt;/a&gt;(thread &lt;a href=&#34;https://en.wikipedia.org/wiki/Thread_control_block&#34;&gt;TCB &lt;/a&gt; 内核态)、&lt;a href=&#34;https://zh.wikipedia.org/zh-hans/%E5%8D%8F%E7%A8%8B&#34;&gt;协程&lt;/a&gt;(coroutine 用户态协作式调度,尽量减少内核调度)为载体的工作任务(work task 在用户态分配栈空间)；内存对象(heap object)，长链接(tcp connect) 等；主要对这些资源对象进行池化技术进行介绍，了解池化对应场景。&lt;/p&gt;
&lt;h2 id=&#34;工作任务池worker-pool&#34;&gt;工作任务池（worker pool)&lt;/h2&gt;
&lt;p&gt;程序中的工作任务是一些运行逻辑，通过进程，线程，或者协程为载体获取系统资源来运行；如果运行的资源对象特别多，这些资源对象在内存中分配空间，这就导致资源消耗过多，甚至可能导致OOM，同时处理任务完成之后，这些资源需要回收，也会消耗大量的cpu时间；所以在这些高耗进程/线程，或者协程资源的工作任务场景下(比如大量的请求任务)，需要用池化技术进行复用管理，提高利用率，减少请求耗时；对此分别介绍进程池，线程池，协程池，以及开源组件服务中的实现。&lt;/p&gt;
&lt;h3 id=&#34;进程池process-pool&#34;&gt;进程池(process pool)&lt;/h3&gt;
&lt;p&gt;早期的操作系统是以&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B&#34;&gt;进程&lt;/a&gt;作为资源分配和调度的基本单位，比如早期linux2.4以及之前的版本，进程是程序的基本执行实体；在面向线程设计的系统（如当代多数操作系统、&lt;a href=&#34;https://zh.wikipedia.org/wiki/Linux&#34;&gt;Linux&lt;/a&gt; 2.6及更新的版本）中，进程本身不是基本执行单位，而是&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%9F%B7%E8%A1%8C%E7%B7%92&#34;&gt;线程&lt;/a&gt;的容器，将资源分配和调度运行进行了分离设计；引入线程后，进程中可以有多个线程，并且共享线程资源；这里介绍进程池，一个进程中只有一个线程作为调度运行单位；在使用PHP语言进行web服务端开发的时候，常规操作用LAMP/LNMP组合，其中使用Apache/Nginx作为web服务器将请求路由到对应后端服务模块处理，然后将处理的响应结果返回；后端服务模块通过实现通用网关接口协议(CGI)应用(app)进程来处理请求, 如果仅仅是单个请求处理从路由模块转发的请求，吞吐量是很低的(一个请求一个进程的方式(fork-and-exec模式)，实现简单，甚至可以用shell脚本来作为CGI进程处理，早期90年之前互联网用户不多)；随着互联网的发展，fork-and-exec模式，进程创建和消除开销变大，成了诟病，&lt;a href=&#34;https://en.wikipedia.org/wiki/FastCGI&#34;&gt;FastCGI&lt;/a&gt;接口协议在90年代中期提出来，FastCGI服务器使用持久进程来处理一系列请求，及每个单独的 FastCGI 进程可以在其生命周期内处理许多请求，从而避免每个请求进程创建和终止的开销(另外还有SCGI,WSGI协议,都是定义通用的接口协议，将web服务器和应用服务器进行解耦，比如apache/nginx都有对应的协议模块和应用服务器php-fpm/uWSGI(python)相关接口协议进程进行交互，编写语言大多是解释性语言，进程运行时动态加载解释执行)。&lt;/p&gt;
&lt;h4 id=&#34;php-fpm-worker-process-pool&#34;&gt;php-fpm worker process pool&lt;/h4&gt;
&lt;p&gt;php解释性语言作为后端服务模块的开发语言，支持FastCGI，并且对支持FastCGI接口协议的进程进行管理，通过SAPI(Server Application Programme Interface)模块中的FPM(FastCGI Process Manager)实现；在初始启动php-fpm时，通过主进程监听不同服务端口，不同服务端口初始对应的FastCGI工作进程池；运行时，主进程(父进程)和工作进程(子进程)通过双向信号管道(pipe)进行通信，实现主进程对工作进程的控制管理，以及工作进程通过标准输出管道(stdout pipe)和标准错误管道(stderr pipe)，将结果和错误返回给主进程；主进程和工作进程通过共享内存的方式(内部记分板结构scoreboard)，实现工作进程运行时的监控(工作进程状态), 主进程会定时轮训检查工作进程数目，根据进程池管理策略来处理是否扩缩容，检查工作进程处理请求是否超时，整体流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/fpm-worker-pool.drawio.png&#34; alt=&#34;fpm-worker-pool&#34;&gt;&lt;/p&gt;
&lt;p&gt;具体代码见&lt;a href=&#34;https://github.com/php/php-src/tree/master/sapi/fpm&#34;&gt;php-fpm&lt;/a&gt;；php语言是线程安全的，使用 &lt;code&gt;TSRM&lt;/code&gt; 机制分配和使用变量时会有额外的损耗，所以一般不需要多线程的 PHP 环境；而且工作进程处理请求时加载php脚本解析成opcode, 然后通过ZendVM解释器调用opcode对应的机器指令，最终完成php脚本的运行，由于每次处理请求都需要解析成opcode,会有性能损耗，所以引入opcache来缓存解析后的opcode；php-fpm的运行机制是采用多进程方式来处理请求，每个woker进程处理请求时所占内存大小在10M+，可以通过&lt;code&gt;ps aux | grep php | grep -v grep | grep -v master | awk &#39;{sum+=$6; cn+=1} END {print sum/cn}&#39;&lt;/code&gt;获取worker进程消耗内存平均值，所以fpm引入工作进程池来防止过度消耗内存，而且可以服用工作进程来处理请求，内存资源紧的场景池中开启动态扩缩worker进程，反之采用静态方式池中一次初始pm.max_children 这么多worker进程，减少扩缩管理开销。&lt;/p&gt;
&lt;p&gt;php多进程(进程单个线程)编程相对多线程(进程多个线程)编程要简单些，多线程需要考虑共享所在进程资源同步的问题，处于安全隔离考虑，进程多线程中如果某个线程出错，整个进程就挂了，而多进程资源相互隔离，如果一个进程挂了，不影响其他进程处理任务；而且解释语言相对c/c++编译成机器码执行语言开发效率要高很多，运行时加载，无需重启服务(当然c/c++编译型语言也支持动态库加载至内存提供相关接口调用，进行热加载而无需重启服务，但是不可能每次新开发一个功能都以*.so动态库的形式提供吧，所以需求更新迭代快的场景，像游戏领域的服务器，网关服务器，甚至大数据任务算子，大多都是通过引入解释型脚本语言(lua/js/perl/python/php)编写业务逻辑，进行热加载)；&lt;/p&gt;
&lt;p&gt;但是多进程毕竟比多线程要消耗更多的系统资源；而且如果存在多进程单线程的&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8&#34;&gt;cpu&lt;/a&gt;切换，是从一个进程到另一个进程，而单进程多线程的&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8&#34;&gt;cpu&lt;/a&gt;切换则只在一个进程内，每个进程/线程都有自己的上下文堆栈保存，进程间的cpu切换消耗更大一些；多线程上下文的切换涉及程序计数器、堆栈指针和程序状态字等一系列的寄存器置换、程序堆栈重置甚至是 CPU 高速缓存、TLB 快表的汰换；进程间的上线文切换还涉及整个进程地址空间。&lt;/p&gt;
&lt;h3 id=&#34;线程池thread-poolhttpsenwikipediaorgwikithread_pool&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Thread_pool&#34;&gt;线程池(thread pool)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;线程是操作系统调度运行的最小单元，随着计算机&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8&#34;&gt;cpu&lt;/a&gt;核数的增加，多线程技术可以充分利用多个cpu核进行并行处理，提高吞吐；对于在单cpu单核的计算机上，使用多线程技术，也可以把进程中负责I/O处理、人机交互而常被阻塞的部分，与密集计算的部分分开来执行，编写专门的workhorse线程执行密集计算，虽然多任务比不上多核，但因为具备多线程的能力，从而提高了程序的执行效率。而多线程的频繁建立和销毁，以及多线程上下文的切换，会导致整体执行的延迟，对于高性能的服务组件，针对io密集型场景，引入线程池来进行优化；而业务场景，为了提高业务的接口吞吐量，也引入了线程池进行优化；&lt;/p&gt;
&lt;h4 id=&#34;nginx-thread-pool&#34;&gt;nginx thread pool&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&#34;&gt;nginx是多工作进程(cpu核数)+事件模型&lt;/a&gt;（如果是IO密集型 worker进程数在1.5-2倍cpu核数），通过工作进程单线程的事件模型(比喻成grandmaster😄)能够很快处理用户的请求(epoll事件机制)，但是为了解决重阻塞型IO密集型的工作任务问题，nginx 1.7.12引入了&lt;a href=&#34;https://www.nginx.com/blog/thread-pools-boost-performance-9x/&#34;&gt;thread pool 线程池技术&lt;/a&gt;，主要是针对linux系统，解决不支持异步IO的场景(FreeBSD系统的异步IO支持使用内存做为文件缓存)；&lt;/p&gt;
&lt;p&gt;比如产生磁盘io的系统调用read(),sendfile(),aio_write()(Linux上的在编写一些临时文件,在nginx1.9.13加入&lt;a href=&#34;https://github.com/nginx/nginx/commit/348f705c000bdbfbee74d6f0111a03697f8ffa4f&#34;&gt;commit 348f705&lt;/a&gt;)这些阻塞操作场景，工作进程处理这些操作的时候，将其放入线程池中来处理，常见的直播/点播回放场景中，会有拉流操作，从最近CDN服务节点上获取视频流进行播放；像视频流文件，或者其他大文件，这些请求资源是没法放入系统内存&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35448479&#34;&gt;页面缓存&lt;/a&gt;中，导致事件模型被文件操作卡住，没法正常的响应链接，引入 thread pool 来缓解这个问题；流程如下：&lt;/p&gt;
&lt;p&gt;工作进程中的主线程决定要发起文件系统操作时，将会建立一个特殊的任务，并将该任务丢到任务队列中；而线程池中的空闲线程会不断的执行该队列的文件任务，而后将执行好的结果返回，主线程监听到通知事件就绪调用回调函数处理结果，继续后续操作。经过这个优化，主线程不会再被阻塞在系统调用上(多分出了通知事件，不影响读写事件)，如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/nginx-thread-pool.drawio.png&#34; alt=&#34;thread-pools-worker-process-event-cycle&#34;&gt;&lt;/p&gt;
&lt;p&gt;thread pool整体实现代码见&lt;a href=&#34;https://github.com/nginx/nginx/commit/305fc021db799c87d751f0f1f5e99afee7bb2b3b&#34;&gt;thread pool commit 305fc02&lt;/a&gt; , &lt;a href=&#34;https://github.com/nginx/nginx/commit/e10e7a4831cfaf6a41824da7c35819fc7f58f8ee&#34;&gt;epoll notify mechanism&lt;/a&gt;, &lt;a href=&#34;https://github.com/nginx/nginx/commit/2b3c01e9953b3985e05a46e56a01078b37caeb18&#34;&gt;kqueue notify mechanism&lt;/a&gt;；最近有个&lt;a href=&#34;https://github.com/nginx/nginx/commit/83e92a2edd6bf7c6867b653284ac44962c4e33c9&#34;&gt;commit 83e92a2&lt;/a&gt; 解决http2 等待 sendfile 完成 请求hang住的情况，就是利用线程池的异步方式(aio)来处理的（ps: nginx 作者也）。&lt;/p&gt;
&lt;h4 id=&#34;redis-thread-pool&#34;&gt;redis thread pool&lt;/h4&gt;
&lt;p&gt;redis处理命令核心逻辑是单进程单线程模式，redis关注的是网络IO，以及内存操作，如果是单进程多线程处理必然会有同一个内存结构会有多个线程处理，加锁处理，线程等待以及多线程上下文切换开销的问题，执行效率不如单线程高效；网络IO事件直接通过IO多路复用事件模型(AE)来解决, 而且逻辑简单可维护；&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为了提高处理性能，Redis v4.0 将磁盘io和内存释放free工作采用几个线程异步处理bio(3个)；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;fsync内存异步持久落盘操作和close异步关闭文件操作；&lt;/p&gt;
&lt;p&gt;由于内存中大ke同步删除会耗时高从而阻塞核心逻辑，所以将这些内存释放采用lazyfree机制优化异步化处理，包括两类：一类是主动释放&lt;code&gt;unlink&lt;/code&gt; &lt;code&gt;flushall async&lt;/code&gt; ；一类是被动释放, 分为4种场景，按需求场景进行打开优化(默认是关闭的)：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
slave-lazy-flush no
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;​	lazyfree-lazy-eviction：针对redis内存使用达到maxmeory，并设置有淘汰策略时；在被动淘汰键时，是否采用lazy free机制； 具体流程见&lt;a href=&#34;https://weedge.github.io/post/lru/#%E8%BF%91%E4%BC%BClru%E7%AE%97%E6%B3%95&#34;&gt;redis 近似lru算法&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;​	lazyfree-lazy-expire：针对设置有TTL的键，达到过期后，被redis清理删除时是否采用lazy free机制；可开启&lt;/p&gt;
&lt;p&gt;​	lazyfree-lazy-server-del：针对有些指令在处理已存在的键时，会带有一个隐式的DEL键的操作，比如&lt;code&gt;rename&lt;/code&gt;操作，如果key存在会先删除这个key/value, 如果是大key场景会阻塞；可开启&lt;/p&gt;
&lt;p&gt;​	slave-lazy-flush：针对slave进行全量数据同步，slave在加载master的RDB文件前，会运行flushall来清理自己的数据场景，开启可减少全量同步耗时，从而减少主库因输出缓冲区爆涨引起的内存使用增长；可开启&lt;/p&gt;
&lt;p&gt;​	还有一个配置 &lt;code&gt;lazyfree-lazy-user-del no&lt;/code&gt;， 针对老用户/代码使用&lt;code&gt;del&lt;/code&gt;主动删除是否异步处理，开启和&lt;code&gt;unlink&lt;/code&gt;一样；&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;为了提高处理IO能力，Redis v6.0 正式在网络模型中实现 I/O 多线程，流程如下：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	客户端和主线程建立连接，主线程将请求封装成client结构放入LIFO读入队列(clients_pending_read)，主线程然后把LIFO读入队列中的client数据RR均匀分配给主线程和I/O多线程的本地队列(io_threads_list[id])；&lt;/p&gt;
&lt;p&gt;​	主线程和I/O多线程解析命令，写入查询缓存区(querybuf)；&lt;/p&gt;
&lt;p&gt;​	主线程忙轮训等待I/O多线程全部解析处理完之后，遍历LIFO读入队列(clients_pending_read)中的client, 处理执行命令核心逻辑(processCommand)，注意这里并不是I/O多线程来处理；主线程处理完命令后，将响应数据写入client写出缓存区(buf/reply)，然后把client放入LIFO 写出队列(clients_pending_write)，同样主线程然后把LIFO写出队列(clients_pending_write)中的client数据RR均匀分配给主线程和I/O多线程的本地队列(io_threads_list[id])；&lt;/p&gt;
&lt;p&gt;​	主线程和I/O多线程回写响应数据给客户端；&lt;/p&gt;
&lt;p&gt;​	主线程忙轮训等待I/O多线程全部回写响应数据给客户端 处理完之后，最后在遍历LIFO写出队列(clients_pending_write)，检查是否还有 client 的写出缓冲区(buf/reply)中有残留数据，如果有，为 client 注册一个命令回复器 sendReplyToClient，等待client可写之后在事件循环中继续回写残余的响应数据。&lt;/p&gt;
&lt;p&gt;处理流程和以前的单线程reactor模式差不多，主要区别是对读写IO优化(异步多线程处理)； 读入请求命令读取解析和写出响应数据给客户端，增加了I/O多线程来处理，以前的主线程处理的核心逻辑没有变，增加了和I/O多线程交互的读写LIFO队列(clients_pending_read / clients_pending_write)，有点像扇入扇出模式；尽量保持 &lt;strong&gt;less is more&lt;/strong&gt; 原则；&lt;/p&gt;
&lt;p&gt;而且redis v6.0为了高性能，网络IO多线程场景，和nginx一样也对多核CPU NUMA架构进行了亲和性处理(见setcpuaffinity.c中逻辑，&lt;a href=&#34;https://github.com/redis/redis/commit/1a0deab2a548fa306171f03439e858c00836fe69&#34;&gt;commit 1a0deab2&lt;/a&gt;)，充分利用CPU本地缓存，并行处理；另外redis v6.0还有一些性能优化骚操作，无锁化处理，看代码时会发现用到了mutex lock，通过 pthread_mutex_lock 给 io_threads_mutex[i] (0&amp;lt;=i&amp;lt;128) 上锁，其实目的是主线程用来通知I/O线程使用的，最终还是通过io_threads_pending[i] 原子化操作(atomic_load_explicit)获取判读是否等待；每个处理I/O线程都有自己的本地队列io_threads_list[i] 用于处理封装的client结构，I/O线程之间互不干涉；而且主线程和I/O子线程处理本地队列 io_threads_list[i] 以及io_threads_op 通过控制主线程和 I/O 线程交错访问来规避共享数据竞争(data race)问题。&lt;/p&gt;
&lt;p&gt;THREADED I/O 核心操作变量如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;/* ==========================================================================
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt; * Threaded I/O
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt; * ========================================================================== */&lt;/span&gt;

&lt;span style=&#34;color:#4c8317&#34;&gt;#define IO_THREADS_MAX_NUM 128
&lt;/span&gt;&lt;span style=&#34;color:#4c8317&#34;&gt;#define IO_THREADS_OP_READ 0
&lt;/span&gt;&lt;span style=&#34;color:#4c8317&#34;&gt;#define IO_THREADS_OP_WRITE 1
&lt;/span&gt;&lt;span style=&#34;color:#4c8317&#34;&gt;&lt;/span&gt;
pthread_t io_threads[IO_THREADS_MAX_NUM];
pthread_mutex_t io_threads_mutex[IO_THREADS_MAX_NUM];
redisAtomic &lt;span style=&#34;color:#0aa&#34;&gt;unsigned&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;long&lt;/span&gt; io_threads_pending[IO_THREADS_MAX_NUM];
&lt;span style=&#34;color:#0aa&#34;&gt;int&lt;/span&gt; io_threads_op;      &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;/* IO_THREADS_OP_WRITE or IO_THREADS_OP_READ. */&lt;/span&gt;

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;/* This is the list of clients each thread will serve when threaded I/O is
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt; * used. We spawn io_threads_num-1 threads, since one is the main thread
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt; * itself. */&lt;/span&gt;
list *io_threads_list[IO_THREADS_MAX_NUM];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上通过引入多线程来改善redis中I/O处理性能，这些优化都可以根据需求场景进行配置，也有具体说明 见: &lt;a href=&#34;https://github.com/redis/redis/blob/unstable/redis.conf&#34;&gt;redis.conf&lt;/a&gt; (LAZY FREEING, THREADED I/O)；功能按需配置，&lt;strong&gt;可配置功能说明&lt;/strong&gt; 配置文档原则 (开源软件配置文件一般都会有详细说明可了解)；&lt;/p&gt;
&lt;h4 id=&#34;java-thread-pool&#34;&gt;java thread pool&lt;/h4&gt;
&lt;p&gt;java多线程编程，也有相关的线程池(ThreadPoolExecutor，子类ScheduledThreadPoolExecutor - 利用延迟工作队列(最小堆)实现定时任务线程池)提供使用；使用ThreadPoolExecutor可以满足两种场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;并行执行子任务，提高响应速度。这种情况下，应该使用同步队列，没有什么任务应该被缓存下来，而是应该立即执行;&lt;/li&gt;
&lt;li&gt;并行执行大批次任务，提升吞吐量。这种情况下，应该使用有界队列，使用队列去缓冲大批量的任务，队列容量必须声明，防止任务无限制堆积；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/77441586f6b312a54264e3fcf5eebe2663494.png&#34; alt=&#34;ThreadPoolExecutor运行流程&#34;&gt;&lt;/p&gt;
&lt;p&gt;ThreadPoolExecutor具体的使用介绍可以参考美团的这片文章：&lt;a href=&#34;https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html&#34;&gt;Java线程池实现原理及其在美团业务中的实践&lt;/a&gt;，引用 ThreadPoolExecutor 运行流程如上图；文中有有实际的案例和参数配置解决方案，可以借鉴；在使用java线程池对接口吞吐量进行优化时，如果参数使用不当，线程池最大线程数过小，可能导致接口服务降级；消费线程过小任务队列过长，积压任务，可能导致请求超时的情况；针对这些场景，提出解决方案：增加线程池监控，通过配置中心，手动来调整java线程池参数, 进行动态配置化管理，这个思路其实也是服务基础稳定性的常用思路，做好监控报警，配置化及时人工响应。(美团的&lt;a href=&#34;https://mp.weixin.qq.com/s/C81f0_arbs23KGcaIwi56w&#34;&gt;复盘机制&lt;/a&gt;值得学习)&lt;/p&gt;
&lt;h4 id=&#34;thread-pool-小结&#34;&gt;thread pool 小结&lt;/h4&gt;
&lt;p&gt;引入线程池其实本质上还是对多线程的有效管理，充分利用多核进行并行处理，减少线程间的上下文切换开销(&lt;strong&gt;上下文切换时间在&lt;a href=&#34;https://eli.thegreenplace.net/2018/measuring-context-switching-and-memory-overheads-for-linux-threads/&#34;&gt;~1000 到 ~1500 纳秒&lt;/a&gt;，（平均）每核心&lt;a href=&#34;https://www.youtube.com/watch?v=jEG4Qyo_4Bc&amp;amp;feature=youtu.be&amp;amp;t=266&#34;&gt;每纳秒 12 条指令&lt;/a&gt;，上下文切换可能会花费大约 12k 到大约 18k 条指令的延迟&lt;/strong&gt;)；以上实现的线程池本质上都是通过多线程异步优化IO任务，通过线程池来管理线程，通过参数进行调优，充分利用多核cpu硬件资源，并行处理，吞吐最大化(ps: redis和nginx的源码值得一撸)。 但是用户应用层使用线程池需要对线程数目进行调整，那可否从用户应用层面来封装一层进行调度管理呢？ 答案是有的，像GO语言，现在的内部运行时runtime 通过G-P-M调度模型来有效管理，Go 语言的调度模型通过使用与 CPU 数量相等的线程减少线程频繁切换的内存开销(如果是在容器环境中，可以通过&lt;a href=&#34;https://github.com/uber-go/automaxprocs&#34;&gt;uber-go/automaxprocs&lt;/a&gt; 运行时自动适配分配给容器cpu核数)，同时在每一个线程上执行额外开销更低的 Goroutine 协程来降低操作系统和硬件的负载，用户应用层面不需要考虑多线程编程的细节，重点关注Goroutine 协程的使用优化，了解G-P-M模型，运行时&lt;a href=&#34;http://www1.cs.columbia.edu/~aho/cs6998/reports/12-12-11_DeshpandeSponslerWeiss_GO.pdf&#34;&gt;调度机制&lt;/a&gt;。(享受一波语言,工具福利时，&lt;strong&gt;注意系统阻塞调用时的线程泄露,以及异步阻塞时的协程泄漏, race检查,性能测试,pprof/trace分析,逃逸分析,GC&lt;/strong&gt;等)&lt;/p&gt;
&lt;h3 id=&#34;协程池coroutine-pool&#34;&gt;协程池(coroutine pool)&lt;/h3&gt;
&lt;p&gt;协程是运行在用户态的轻量线程，可以认为是用户应用层面的线程， 比线程分配的虚拟内存栈空间要小；创建一个线程所占虚拟内存栈空间大小，在linux下通过&lt;code&gt;pmap &lt;/code&gt;+pid 查看stack大小， 在macOS下通过&lt;code&gt;vmmap -interleaved&lt;/code&gt;+pid 查看stack大小，大小由&lt;code&gt;ulimit -s&lt;/code&gt; 控制，线程栈空间一般在8M~10M左右，如果使用不当会栈溢出；而协程分配空间是由实现协程语言来决定，像GO实现的goroutine协程初始创建栈空间大小是2k(go 1.4+ 采用连续堆栈策略，以前是分段栈策略)，最大限制的默认值在64位系统上是1GB（&lt;a href=&#34;https://github.com/golang/go/blob/f296b7a6f045325a230f77e9bda1470b1270f817/src/runtime/proc.go#L120&#34;&gt;不同的架构最大数会不同&lt;/a&gt;）；编译期间插入检查，调用时如果满足了扩容条件(根据被调用函数栈帧的大小来判断是否需要扩容，通过 stackguard0 来判断是否要进行栈增长)，扩容两倍空间，如果协程所使用的栈空间小于1/4时，缩容成一半空间；(具体细节见：&lt;a href=&#34;https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-stack-management/&#34;&gt;栈空间管理&lt;/a&gt; &lt;a href=&#34;https://kirk91.github.io/posts/2d571d09/&#34;&gt;推送场景: 聊一聊goroutine stack&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;尽管goroutine协程比线程分配栈空间小，但是 大量的 goroutine 还是很耗资源的，而且大量的 goroutine 对于调度和垃圾回收的耗时还是会有影响的，因此，goroutine 并不是越多越好，所以使用协程池来优化；&lt;/p&gt;
&lt;p&gt;GO中管理协程池的开发方案还是比较多的，大都是和线程池任务工作模型差不多，任务队列用的是GO中的runtime/channel,  池化管理用的是GO中的sync.Pool, 比如&lt;a href=&#34;https://github.com/valyala/fasthttp/blob/9f11af296864153ee45341d3f2fe0f5178fd6210/workerpool.go#L16&#34;&gt;fasthttp workerpool&lt;/a&gt; 针对自身场景的多个连接通道池化复用 -&amp;gt; &lt;a href=&#34;https://github.com/panjf2000/ants&#34;&gt;panjf2000/ants&lt;/a&gt; 通用化了多个任务通道池化复用 -&amp;gt; &lt;a href=&#34;https://github.com/bytedance/gopkg/tree/develop/util/gopool&#34;&gt;bytedance/gopool&lt;/a&gt; 任务tasker和工作worker池化复用；相对线程池thread pool的实现要简单些，因为底层GO runtime的&lt;a href=&#34;https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html&#34;&gt;调度器&lt;/a&gt;以及sync库已经做了大部分的优化(无锁或最小化锁粒度)。&lt;a href=&#34;https://time.geekbang.org/column/article/301716&#34;&gt;Pool：性能提升大杀器&lt;/a&gt; 中介绍了GO中sync.Pool的实现，以及协程池的三方开源方案实现；&lt;/p&gt;
&lt;p&gt;这里介绍一个实现的 &lt;a href=&#34;https://github.com/weedge/lib/tree/main/pool/workerpool&#34;&gt;workerpool&lt;/a&gt;   通过channel 存放任务，多个 Worker 共享同一个任务 Channel，通过多个协程来消费池中的任务执行，协程根据提交的任务数动态扩缩协程；任务可以定义输入，输出，超时时间；通过channel 返回是否超时; 可用于批量任务并发执行场景，适用于大量批量耗时相对比较高的任务；在实际工作中，比如组织引擎中树中组织节点的生成，有些任务超时了，使用方可以重新放入队列中，或者出错报警等操作。 执行流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/lib/main/pool/workerpool/workerpool.png&#34; alt=&#34;workerpool&#34;&gt;&lt;/p&gt;
&lt;p&gt;还有协程池的实现方式，主要是为了应对突发流量(场景：处理大量连接请求)，如下几个：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/gammazero/workerpool.git&#34;&gt;gammazero/workerpool&lt;/a&gt;  实现用到3个队列，一个用于提交任务的任务队列(buffer channel length 1，发送任务非阻塞)、一个等待队列（buf[] interface{} head,tail，为了应对突发流量设置的buff,无限制)、 一个工作队列(block channel，用阻塞chan是为了让消费的worker先启动)；未使用sync.Pool；通过dispatch协程来管理工作协程， 定时(idleTimeout)检查工作队列是否有任务(idle), 以及有工作协程(workerCount&amp;gt;1)，发送空任务(nil) 结束工作协程；这个检查是否有空闲工作协程机制比较简单，每到定时时间操作一次，回收频率可以调整，idleTimeout默认2秒；通过发送暂停任务 (Context/stopSignal) 来暂停worker工作以及整个workerpool，还有提交等待执行完成的任务，通过Pacer提交限速任务，使用方也可以提交超时任务；使用goroutine+channel+sync+context整体实现workerpool就300行左右，这个和ThreadPoolExecutor有些类似，流程如下：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/go-workerpool.drawio.png&#34; alt=&#34;go-workerpool&#34;&gt;&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/valyala/fasthttp/blob/9f11af296864153ee45341d3f2fe0f5178fd6210/workerpool.go#L16&#34;&gt;fasthttp workerpool&lt;/a&gt; 针对自身场景的多个连接通道池化复用； -&amp;gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/panjf2000/ants&#34;&gt;panjf2000/ants&lt;/a&gt; 通用化了多个任务通道池化复用（一次任务G用完生命周期还可以复用(按空闲时间长短回收), 可用worker放入自定义的池中(stack/loopQueue) , 如果工作池没有可用worker, 根据配置是否等待，等待则等有可用worker时通过条件变量(Cond)唤醒,使用自旋锁; 定时从自定义的工作池中获取空闲时间大于配置阈值的worker进行回收）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/bytedance/gopkg/tree/develop/util/gopool&#34;&gt;bytedance/gopool&lt;/a&gt; 任务task和工作worker池化复用(一次任务G用完生命周期可以复用，复用栈空间，尽量减少协程调度消耗) -&amp;gt; (尽量无锁化队列);针对&lt;strong&gt;优化栈扩张场景&lt;/strong&gt;使用(RPC 服务常见问题,比如：&lt;a href=&#34;https://kirk91.github.io/posts/2d571d09/&#34;&gt;推送场景: 聊一聊goroutine stack&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Tips: 1有等待全部任务结束；2，3，4 这些协程池没有等待，因为使用场景大多是多个协程处理完任务之后无需等待结果处理，可以自己的任务中定义；1,2,3都使用了channel, 1是在消费侧启动goroutine，2,3是在生产侧启动goroutine，通过channel单向通信task；4 未使用channel来通信，直接通过FIFO单向task链表，上锁头出尾入task，在生产侧启动goroutine；&lt;/p&gt;
&lt;p&gt;满足协程复用的前提下，在生产侧task，队列，消费侧worker 上尽量优化结构，结合调度特性。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上的workerpool 都有缓冲队列，如果服务进程重启，需要平滑停止服务，就是在收到TERM信号时，需要调用workerpool提供的Wait接口, 对于未等待的协程池，使用sync.WaitGroup来等待剩余的任务执行完成，这种任务如果是用户请求任务，一般都是短任务，处理时间不会很长，像Pod 中的 docker container销毁的时候都会等待一段时间才会回收掉；如果是长时间任务，比如cron job 取决于任务的重要程度，则需要落库存放任务状态，在任务提交之前通过任务表来记录，因为进程本地记录是不可行的，如果容器化部署在Pod中，每次部署的Node会不同；请根据需求场景选择合适的workerpool。&lt;/p&gt;
&lt;h3 id=&#34;小结&#34;&gt;小结&lt;/h3&gt;
&lt;p&gt;线程作为cpu执行调度的最小单元，而进程作为资源分配最小单元，进程中有多个线程，共享其进程资源，作为线程的容器，相互隔离不同进程之间的线程，所以nginx/fpm 都是多进程(单线程)+reactor多路复用的方式处理网络IO请求； php-fpm 为了有效控制请求进程所占资源过多消耗内存的情况，引入工作进程池来防止过度消耗内存，而且可以复用工作进程来处理请求；nginx 为了优化系统调用时阻塞io，使用线程池来异步化处理处理阻塞io事件；redis 引入多线程来解决磁盘IO,释放内存空间，以及网络IO读写的性能问题，nginx和redis 引入多线程都需要编译配置，其中nginx和redis中的网络IO优化细节值得学习的；协程创建分配栈空间比线程更小，Golang中通过可增长栈空间，运行时runtime 通过G-P-M调度模型来将 goroutine 多路复用到线程，如果协程过多，也会影响调度以及GC标记清除效率，所以在消耗大量协程的场景下，引入协程池来复用，因为golang runtime调度模型以及channel机制，使用&lt;a href=&#34;https://go.dev/blog/pipelines&#34;&gt;Go Concurrency Patterns&lt;/a&gt; 实现协程池方案很多，golang社区活跃，最好结合需求场景来分析。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial&#34;&gt;Introduction to Parallel Computing Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.akkadia.org/drepper/nptl-design.pdf&#34;&gt;nptl-design.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sourceware.org/git/?p=glibc.git;a=blob;f=nptl/pthread_create.c;hb=627f5ede70d70c77bdaf857db07404e8bf7f60af#l619&#34;&gt;glibc pthread_create&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/torvalds/linux/blob/master/kernel/fork.c&#34;&gt;linux v2.6.38+ fork.c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://makelinux.github.io/kernel/map/&#34;&gt;Linux 2.6.36 kernel map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nginx.com/blog/thread-pools-boost-performance-9x/&#34;&gt;nginx-thread-pools-boost-performance-9x&lt;/a&gt; &lt;a href=&#34;https://segmentfault.com/a/1190000010008012&#34;&gt;翻译&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&#34;&gt;inside-nginx-how-we-designed-for-performance-scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.aosabook.org/en/nginx.html&#34;&gt;AOSA-nginx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://antirez.com/news/93&#34;&gt;Lazy Redis is better Redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redis.io/topics/benchmarks&#34;&gt;How fast is Redis?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html&#34;&gt;Java线程池实现原理及其在美团业务中的实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www1.cs.columbia.edu/~aho/cs6998/reports/12-12-11_DeshpandeSponslerWeiss_GO.pdf&#34;&gt;Analysis of the Go runtime scheduler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Bq4y1q7Pi&#34;&gt;Golang操作系统调度原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part1.html&#34;&gt;Scheduling In Go : Part I - OS Scheduler&lt;/a&gt; &lt;a href=&#34;https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html&#34;&gt;Part II - Go Scheduler&lt;/a&gt; &lt;a href=&#34;https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html&#34;&gt;Part III - Concurrency&lt;/a&gt;  &lt;a href=&#34;https://github.com/ardanlabs/gotraining&#34;&gt;gotraining&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=f6kdp27TYZs&#34;&gt;Google I/O 2012 - Go Concurrency Patterns &lt;/a&gt; &lt;a href=&#34;https://talks.golang.org/2012/concurrency.slide#1&#34;&gt;「slide」&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=QDDwwePbDtw&#34;&gt;Google I/O 2013 - Advanced Go Concurrency Patterns&lt;/a&gt;  &lt;a href=&#34;https://talks.golang.org/2013/advconc.slide#1&#34;&gt;「slide」&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=5zXAHh5tJqQ&#34;&gt;Rethinking Classical Concurrency Patterns&lt;/a&gt;  &lt;strong&gt;&lt;a href=&#34;https://drive.google.com/file/d/1nPdvhB0PutEJzdCq5ms6UI58dp50fcAN/view&#34;&gt;「slide」&lt;/a&gt;&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1ETuA2IOmnaQ4j81AtTGT40Y4_Jr6_IDASEKg0t0dBR8/edit&#34;&gt;Go Preemptive Scheduler Design Doc&lt;/a&gt;  &lt;a href=&#34;https://rakyll.org/scheduler/&#34;&gt;Go&amp;rsquo;s work-stealing scheduler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tonybai.com/2017/06/27/an-intro-about-go-portability/&#34;&gt;也谈Go的可移植性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=KINIAgRpkDA&#34;&gt;The Design of the Go Assembler&lt;/a&gt; &lt;a href=&#34;https://9p.io/sys/doc/asm.html&#34;&gt;A Manual for the Plan 9 assembler&lt;/a&gt; &lt;a href=&#34;https://github.com/cch123/golang-notes/blob/master/assembly.md&#34;&gt;plan9 assembly 完全解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/301716&#34;&gt;Pool：性能提升大杀器&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>深入理解Linux的Page Cache 「转载的哦」</title>
      <link>https://weedge.github.io/%E8%BD%AC%E8%BD%BD/page-cache/</link>
      <pubDate>Fri, 26 Nov 2021 11:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/%E8%BD%AC%E8%BD%BD/page-cache/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;from: 互联网，了解下备个份而已啦～！unix 请看个 man&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;1page-cache&#34;&gt;1、Page Cache&lt;/h2&gt;
&lt;h3 id=&#34;11-page-cache-是什么&#34;&gt;1.1 Page Cache 是什么？&lt;/h3&gt;
&lt;p&gt;为了理解 Page Cache，我们不妨先看一下 Linux 的文件 I/O 系统，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2F2654c391j00r32mky000qc000hs00f6g.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;linux-io&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，红色部分为 Page Cache。可见 Page Cache 的本质是由 Linux 内核管理的内存区域。我们通过 mmap 以及 buffered I/O 将文件读取到内存空间实际上都是读取到 Page Cache 中。&lt;/p&gt;
&lt;h3 id=&#34;12-如何查看系统的-page-cache&#34;&gt;1.2 如何查看系统的 Page Cache？&lt;/h3&gt;
&lt;p&gt;通过读取 /proc/meminfo 文件，能够实时获取系统内存情况：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ cat /proc/meminfo  
...  
Buffers:            1224 kB  
Cached:           111472 kB  
SwapCached:        36364 kB  
Active:          6224232 kB  
Inactive:         979432 kB  
Active(anon):    6173036 kB  
Inactive(anon):   927932 kB  
Active(file):      51196 kB  
Inactive(file):    51500 kB  
...  
Shmem:             10000 kB  
... 
SReclaimable:      43532 kB  
... 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据上面的数据，你可以简单得出这样的公式（等式两边之和都是 112696 KB）：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Buffers + Cached + SwapCached = Active(file) + Inactive(file) + Shmem + SwapCached 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;两边等式都是 Page Cache，即：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Page Cache = Buffers + Cached + SwapCached 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过阅读 1.4 以及 1.5 小节，就能够理解为什么 SwapCached 与 Buffers 也是 Page Cache 的一部分。&lt;/p&gt;
&lt;p&gt;题外话，小伙伴答案：&lt;/p&gt;
&lt;p&gt;内核计算源码（linux 2.6.19）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2F419841c3j00r32mky000mc000hs009jg.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;内核算法：Cached = files - SwapCached - Buffers；&lt;/p&gt;
&lt;p&gt;Buffers + Cached + SwapCached = Active(file) + Inactive(file) + Shmem + SwapCached&lt;/p&gt;
&lt;p&gt;公式推出来的&lt;/p&gt;
&lt;p&gt;Cached = Active(file) + Inactive(file) + Shmem - Buffers ；&lt;/p&gt;
&lt;p&gt;由此可见，这个Cached 并不等于Active(file) + Inactive(file) ；&lt;/p&gt;
&lt;p&gt;这个cache包含很多 ：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;含有普通文件数据的页‘；&lt;/li&gt;
&lt;li&gt;含有目录的页；&lt;/li&gt;
&lt;li&gt;含有直接从块设备文件(跳过文件系统)读出的数据的页；&lt;/li&gt;
&lt;li&gt;含有用户态进程数据的页；&lt;/li&gt;
&lt;li&gt;属于特殊文件系统文件的页，如shm；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;13-page-与-page-cache&#34;&gt;1.3 page 与 Page Cache&lt;/h3&gt;
&lt;p&gt;page 是内存管理分配的基本单位， Page Cache 由多个 page 构成。page 在操作系统中通常为 4KB 大小（32bits/64bits），而 Page Cache 的大小则为 4KB 的整数倍。&lt;/p&gt;
&lt;p&gt;另一方面，并不是所有 page 都被组织为 Page Cache。&lt;/p&gt;
&lt;p&gt;Linux 系统上供用户可访问的内存分为两个类型[2]，即：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File-backed pages：文件备份页也就是 Page Cache 中的 page，对应于磁盘上的若干数据块；对于这些页最大的问题是脏页回盘；&lt;/li&gt;
&lt;li&gt;Anonymous pages：匿名页不对应磁盘上的任何磁盘数据块，它们是进程的运行是内存空间（例如方法栈、局部变量表等属性）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为什么 Linux 不把 Page Cache 称为 block cache，这不是更好吗？&lt;/p&gt;
&lt;p&gt;这是因为从磁盘中加载到内存的数据不仅仅放在 Page Cache 中，还放在 buffer cache 中。例如通过 Direct I/O 技术的磁盘文件就不会进入 Page Cache 中。当然，这个问题也有 Linux 历史设计的原因，毕竟这只是一个称呼，含义随着 Linux 系统的演进也逐渐不同。&lt;/p&gt;
&lt;p&gt;下面比较一下 File-backed pages 与 Anonymous pages 在 Swap 机制下的性能。&lt;/p&gt;
&lt;p&gt;内存是一种珍惜资源，当内存不够用时，内存管理单元（Memory Mangament Unit）需要提供调度算法来回收相关内存空间。内存空间回收的方式通常就是 swap，即交换到持久化存储设备上。&lt;/p&gt;
&lt;p&gt;File-backed pages（Page Cache）的内存回收代价较低。Page Cache 通常对应于一个文件上的若干顺序块，因此可以通过顺序 I/O 的方式落盘。另一方面，如果 Page Cache 上没有进行写操作（所谓的没有脏页），甚至不会将 Page Cache 回盘，因为数据的内容完全可以通过再次读取磁盘文件得到。&lt;/p&gt;
&lt;p&gt;Page Cache 的主要难点在于脏页回盘，这个内容会在第二节进行详细说明。&lt;/p&gt;
&lt;p&gt;Anonymous pages 的内存回收代价较高。这是因为 Anonymous pages 通常随机地写入持久化交换设备。另一方面，无论是否有更操作，为了确保数据不丢失，Anonymous pages 在 swap 时必须持久化到磁盘。&lt;/p&gt;
&lt;h3 id=&#34;14-swap-与缺页中断&#34;&gt;1.4 Swap 与缺页中断&lt;/h3&gt;
&lt;p&gt;Swap 机制指的是当物理内存不够用，内存管理单元（Memory Mangament Unit）需要提供调度算法来回收相关内存空间，然后将清理出来的内存空间给当前内存申请方。&lt;/p&gt;
&lt;p&gt;Swap 机制存在的本质原因是 Linux 系统提供了虚拟内存管理机制，每一个进程认为其独占内存空间，因此所有进程的内存空间之和远远大于物理内存。所有进程的内存空间之和超过物理内存的部分就需要交换到磁盘上。&lt;/p&gt;
&lt;p&gt;操作系统以 page 为单位管理内存，当进程发现需要访问的数据不在内存时，操作系统可能会将数据以页的方式加载到内存中。上述过程被称为缺页中断，当操作系统发生缺页中断时，就会通过系统调用将 page 再次读到内存中。&lt;/p&gt;
&lt;p&gt;但主内存的空间是有限的，当主内存中不包含可以使用的空间时，操作系统会从选择合适的物理内存页驱逐回磁盘，为新的内存页让出位置，选择待驱逐页的过程在操作系统中叫做页面替换（Page Replacement），替换操作又会触发 swap 机制。&lt;/p&gt;
&lt;p&gt;如果物理内存足够大，那么可能不需要 Swap 机制，但是 Swap 在这种情况下还是有一定优势：对于有发生内存泄漏几率的应用程序（进程），Swap 交换分区更是重要，这可以确保内存泄露不至于导致物理内存不够用，最终导致系统崩溃。但内存泄露会引起频繁的 swap，此时非常影响操作系统的性能。&lt;/p&gt;
&lt;p&gt;Linux 通过一个 swappiness 参数来控制 Swap 机制[2]：这个参数值可为 0-100，控制系统 swap 的优先级：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高数值：较高频率的 swap，进程不活跃时主动将其转换出物理内存。&lt;/li&gt;
&lt;li&gt;低数值：较低频率的 swap，这可以确保交互式不因为内存空间频繁地交换到磁盘而提高响应延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最后，为什么 Buffers 也是 Page Cache 的一部分？&lt;/p&gt;
&lt;p&gt;这是因为当匿名页（Inactive(anon) 以及 Active(anon)）先被交换（swap out）到磁盘上后，然后再加载回（swap in）内存中，由于读入到内存后原来的 Swap File 还在，所以 SwapCached 也可以认为是 File-backed page，即属于 Page Cache。这个过程如图所示：(匿名页的被交换后也是 Page Cache)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2F3c3bdceej00r32mkz000ac000hs0064g.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;15-page-cache-与-buffer-cache&#34;&gt;1.5 Page Cache 与 buffer cache&lt;/h3&gt;
&lt;p&gt;执行 free 命令，注意到会有两列名为 buffers 和 cached，也有一行名为 “-/+ buffers/cache”。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;~ free -m  
             total       used       free     shared    buffers     cached  
Mem:        128956      96440      32515          0       5368      39900  
-/+ buffers/cache:      51172      77784  
Swap:        16002          0      16001 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，cached 列表示当前的页缓存（Page Cache）占用量，buffers 列表示当前的块缓存（buffer cache）占用量。用一句话来解释：Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。&lt;/p&gt;
&lt;p&gt;Page Cache）占用量，buffers 列表示当前的块缓存（buffer cache）占用量。用一句话来解释：Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。&lt;/p&gt;
&lt;p&gt;Page Cache 与 buffer cache 的共同目的都是加速数据 I/O：写数据时首先写到缓存，将写入的页标记为 dirty，然后向外部存储 flush，也就是缓存写机制中的 write-back（另一种是 write-through，Linux 默认情况下不采用）；读数据时首先读取缓存，如果未命中，再去外部存储读取，并且将读取来的数据也加入缓存。操作系统总是积极地将所有空闲内存都用作 Page Cache 和 buffer cache，当内存不够用时也会用 LRU 等算法淘汰缓存页。&lt;/p&gt;
&lt;p&gt;在 Linux 2.4 版本的内核之前，Page Cache 与 buffer cache 是完全分离的。但是，块设备大多是磁盘，磁盘上的数据又大多通过文件系统来组织，这种设计导致很多数据被缓存了两次，浪费内存。所以在 2.4 版本内核之后，两块缓存近似融合在了一起：如果一个文件的页加载到了 Page Cache，那么同时 buffer cache 只需要维护块指向页的指针就可以了。只有那些没有文件表示的块，或者绕过了文件系统直接操作（如dd命令）的块，才会真正放到 buffer cache 里。因此，我们现在提起 Page Cache，基本上都同时指 Page Cache 和 buffer cache 两者，本文之后也不再区分，直接统称为 Page Cache。&lt;/p&gt;
&lt;p&gt;下图近似地示出 32-bit Linux 系统中可能的一种 Page Cache 结构，其中 block size 大小为 1KB，page size 大小为 4KB。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2F49a9a869j00r32mkz000nc000hs00cag.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Page Cache 中的每个文件都是一棵基数树（radix tree，本质上是多叉搜索树），树的每个节点都是一个页。根据文件内的偏移量就可以快速定位到所在的页，如下图所示。关于基数树的原理可以参见英文维基，这里就不细说了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2Fb103f4edj00r32mkz000pc000hs00axg.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;16-page-cache-与预读&#34;&gt;1.6 Page Cache 与预读&lt;/h3&gt;
&lt;p&gt;操作系统为基于 Page Cache 的读缓存机制提供预读机制（PAGE_READAHEAD），一个例子是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户线程仅仅请求读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。&lt;/li&gt;
&lt;li&gt;但是操作系统出于局部性原理会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图代表了操作系统的预读机制：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2Fb5460636j00r32mkz0013c0010q00ayg.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，应用程序利用 read 系统调动读取 4KB 数据，实际上内核使用 readahead 机制完成了 16KB 数据的读取。&lt;/p&gt;
&lt;h2 id=&#34;2page-cache-与文件持久化的一致性可靠性&#34;&gt;2、Page Cache 与文件持久化的一致性&amp;amp;可靠性&lt;/h2&gt;
&lt;p&gt;现代 Linux 的 Page Cache 正如其名，是对磁盘上 page（页）的内存缓存，同时可以用于读/写操作。一切内存缓存都存在一致性问题：内存中的数据与磁盘中的数据不一致，例如用作分布式中间件缓存的 Redis 就与 MySQL 等数据库中的数据存在不一致。&lt;/p&gt;
&lt;p&gt;Linux 提供多种机制来保证数据一致性，但无论是单机上的内存与磁盘一致性，还是分布式组件中节点 1 与节点 2 、节点 3 的数据一致性问题，理解的关键是 trade-off：吞吐量与数据一致性保证是一对矛盾。&lt;/p&gt;
&lt;p&gt;首先，需要我们理解一下文件的数据。文件 = 数据 + 元数据。元数据用来描述文件的各种属性，也必须存储在磁盘上。因此，我们说保证文件一致性其实包含了两个方面：数据一致+元数据一致。&lt;/p&gt;
&lt;p&gt;文件的元数据包括：文件大小、创建时间、访问时间、属主属组等信息。&lt;/p&gt;
&lt;p&gt;我们考虑如下一致性问题：如果发生写操作并且对应的数据在 Page Cache 中，那么写操作就会直接作用于 Page Cache 中，此时如果数据还没刷新到磁盘，那么内存中的数据就领先于磁盘，此时对应 page 就被称为 Dirty page。&lt;/p&gt;
&lt;p&gt;当前 Linux 下以两种方式实现文件一致性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write Through（写穿）：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；&lt;/li&gt;
&lt;li&gt;Write back（写回）：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述两种方式最终都依赖于系统调用，主要分为如下三种系统调用：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;方法&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;fsync(intfd)&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;fsync(fd)：将 fd 代表的文件的脏数据和脏元数据全部刷新至磁盘中。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;fdatasync (int fd)&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;fdatasync(fd)：将 fd 代表的文件的脏数据刷新至磁盘，同时对必要的元数据刷新至磁盘中，这里所说的必要的概念是指：对接下来访问文件有关键作用的信息，如文件大小，而文件修改时间等不属于必要信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;sync()&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;sync()：则是对系统中所有的脏的文件数据元数据刷新至磁盘中&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;上述三种系统调用可以分别由用户进程与内核进程发起。下面我们研究一下内核线程的相关特性。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;创建的针对回写任务的内核线程数由系统中持久存储设备决定，为每个存储设备创建单独的刷新线程；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;关于多线程的架构问题，Linux 内核采取了 Lighthttp 的做法，即系统中存在一个管理线程和多个刷新线程（每个持久存储设备对应一个刷新线程）。管理线程监控设备上的脏页面情况，若设备一段时间内没有产生脏页面，就销毁设备上的刷新线程；若监测到设备上有脏页面需要回写且尚未为该设备创建刷新线程，那么创建刷新线程处理脏页面回写。而刷新线程的任务较为单调，只负责将设备中的脏页面回写至持久存储设备中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;刷新线程刷新设备上脏页面大致设计如下：&lt;/p&gt;
&lt;p&gt;每个设备保存脏文件链表，保存的是该设备上存储的脏文件的 inode 节点。所谓的回写文件脏页面即回写该 inode 链表上的某些文件的脏页面；&lt;/p&gt;
&lt;p&gt;系统中存在多个回写时机，第一是应用程序主动调用回写接口（fsync，fdatasync 以及 sync 等），第二管理线程周期性地唤醒设备上的回写线程进行回写，第三是某些应用程序/内核任务发现内存不足时要回收部分缓存页面而事先进行脏页面回写，设计一个统一的框架来管理这些回写任务非常有必要。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Write Through 与 Write back 在持久化的可靠性上有所不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Write Through 以牺牲系统 I/O 吞吐量作为代价，向上层应用确保一旦写入，数据就已经落盘，不会丢失；&lt;/li&gt;
&lt;li&gt;Write back 在系统发生宕机的情况下无法确保数据已经落盘，因此存在数据丢失的问题。不过，在程序挂了，例如被 kill -9，Page Cache 中的数据操作系统还是会确保落盘；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3为什么使用-page-cache-与为什么不使用-page-cache&#34;&gt;3、为什么使用 Page Cache 与为什么不使用 Page Cache?&lt;/h2&gt;
&lt;h3 id=&#34;31-page-cache-的优势&#34;&gt;3.1 Page Cache 的优势&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1.加快数据访问&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果数据能够在内存中进行缓存，那么下一次访问就不需要通过磁盘 I/O 了，直接命中内存缓存即可。&lt;/p&gt;
&lt;p&gt;由于内存访问比磁盘访问快很多，因此加快数据访问是 Page Cache 的一大优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.减少 I/O 次数，提高系统磁盘 I/O 吞吐量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;得益于 Page Cache 的缓存以及预读能力，而程序又往往符合局部性原理，因此通过一次 I/O 将多个 page 装入 Page Cache 能够减少磁盘 I/O 次数， 进而提高系统磁盘 I/O 吞吐量。&lt;/p&gt;
&lt;h3 id=&#34;32-page-cache-的劣势&#34;&gt;3.2 Page Cache 的劣势&lt;/h3&gt;
&lt;p&gt;page cache 也有其劣势，最直接的缺点是需要占用额外物理内存空间，物理内存在比较紧俏的时候可能会导致频繁的 swap 操作，最终导致系统的磁盘 I/O 负载的上升。&lt;/p&gt;
&lt;p&gt;Page Cache 的另一个缺陷是对于应用层并没有提供很好的管理 API，几乎是透明管理。应用层即使想优化 Page Cache 的使用策略也很难进行。因此一些应用选择在用户空间实现自己的 page 管理，例如 MySQL InnoDB 存储引擎以 16KB 的页进行管理。&lt;/p&gt;
&lt;p&gt;Page Cache 最后一个缺陷是在某些应用场景下比 Direct I/O 多一次磁盘读 I/O 以及磁盘写 I/O。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>WAL</title>
      <link>https://weedge.github.io/post/wal/</link>
      <pubDate>Sun, 21 Nov 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/wal/</guid>
      
        <description>&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;p&gt;​	数据落地之前，如果出现持久化存储引擎实例重启，或者服务当机重启，如何进行故障恢复（Crash Recovery）呢？数据写操作增删改，这些操作状态数据，是如何保证事务中原子性和持久性的呢？ 这些问题数据大拿们提出了&lt;a href=&#34;https://en.wikipedia.org/wiki/Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics&#34;&gt;Algorithms for Recovery and Isolation Exploiting Semantics&lt;/a&gt; ，基于语义的恢复与隔离算法,现代数据库的基础理论；当前主流关系型数据在事务实现上都受到该理论的影响，其中有两种故障恢复的方法： 预写日志(write-ahead logging (WAL) ) 和shadow-page technique；shadow-page 方法简单介绍就是每次事务操作，以page为单位，写时复制的方式，分为Current和Shadow，类似主备的形式，如果commit成功，Current中的page合并到 Shadow中; 如果abort不成功丢弃Current的page; 如果Crash了，从Shadow中的page恢复，对所有未提交事务的回滚操作； 由于shadow-page技术的实现以page为单位，page内无法并发操作，commit/回滚时会有大量垃圾回收操作；本文主要介绍WAL，以及对应持久化存储引擎的实现机制介绍。&lt;/p&gt;
&lt;h2 id=&#34;wal&#34;&gt;WAL&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;预写日志&lt;/strong&gt;( &lt;strong&gt;WAL&lt;/strong&gt; ) 是一系列技术，用于在&lt;a href=&#34;https://en.wikipedia.org/wiki/Database_system&#34;&gt;数据库系统中&lt;/a&gt;提供&lt;a href=&#34;https://en.wikipedia.org/wiki/Atomicity_(database_systems)&#34;&gt;原子性&lt;/a&gt;和&lt;a href=&#34;https://en.wikipedia.org/wiki/Durability_(database_systems)&#34;&gt;持久性&lt;/a&gt;（两个&lt;a href=&#34;https://en.wikipedia.org/wiki/ACID&#34;&gt;ACID&lt;/a&gt;属性）。在将更改写入数据库之前，更改首先记录在日志中，日志必须写入&lt;a href=&#34;https://en.wikipedia.org/wiki/Stable_storage&#34;&gt;稳定存储&lt;/a&gt;（保证任何给定写入操作的原子性，并允许编写对某些硬件和电源故障具有&lt;a href=&#34;https://en.wikipedia.org/wiki/Robustness_(computer_science)&#34;&gt;鲁棒性的&lt;/a&gt;软件）。&lt;/p&gt;
&lt;p&gt;这样做的目的可以通过一个例子来说明。想象一下，当运行它的机器断电时，它正在执行某些操作。重新启动时，该程序可能需要知道它正在执行的操作是成功、部分成功还是失败。如果使用预写日志，程序可以检查此日志并将意外断电时应该执行的操作与实际执行的操作进行比较。在此比较的基础上，程序可以决定撤消已开始的内容、完成已开始的内容或保持原样。&lt;/p&gt;
&lt;p&gt;在使用 WAL 的系统中，所有修改在应用之前都会写入&lt;a href=&#34;https://en.wikipedia.org/wiki/Database_log&#34;&gt;日志&lt;/a&gt;。通常redo和undo信息都存储在日志中。&lt;/p&gt;
&lt;p&gt;注意：写不一定是顺序写，一般&lt;a href=&#34;https://en.wikipedia.org/wiki/Computer_data_storage&#34;&gt;计算机存储&lt;/a&gt; 非易失性的硬件结构对顺序写的性能高于随机写的性能，比如常用的磁盘HDD/SSD; 但是最近基于NVM技术(结合磁盘和内存的特性)的存储硬件PC-RAM(Phase Change Random Access Memory), STT-RAM( Spin Transfer Torque Random Access Memory),  R-RAM(Resistive Random Access Memory)，结合内存中随机访问，磁盘非易失性特性，随机写和顺序写没什么差别，&lt;a href=&#34;http://repository.bilkent.edu.tr/bitstream/handle/11693/37609/Implications%20of%20non-volatile%20memory%20as%20primary%20storage%20for%20database%20management%20systems.pdf&#34;&gt;Implications of Non-Volatile Memory as Primary Storage for Database Management Systems&lt;/a&gt; 这篇论文中提到Pg如果不部署内部的buffer cache，所有写直接写到NVM对应的存储硬件中，可以去掉redo日志，但是undo日志任然需要,在系统错误时复原; 一般学术方案要领先实际工程许多，真正落地在生产环境中，还是用躺过坑的成熟方案 （顺便想到现在一些k/v存储引擎考虑上云，支持云厂商的云盘，可以认为无限容量）。硬件结构决定上层软件存储引擎的设计的优化，以下都是以常用的磁盘HDD/SSD的硬件结构来介绍存储引擎实现WAL技术。&lt;/p&gt;
&lt;h2 id=&#34;mysql-innodb存储引擎&#34;&gt;mysql Innodb存储引擎&lt;/h2&gt;
&lt;p&gt;mysql Innodb存储引擎是通过 redo、undo 日志实现 WAL,主要用于crash 恢复和回滚，满足本地事务中的持久性和原子性，来保证数据一致性；当然innodb引擎为了提高并发读性能，undo log中加入了MVCC (多版本并发控制)相关信息； 另外，mysql server层执行器会写bin log，主要是用来恢复某个时间的点数据以及主从复制数据使用，bin log文件和存储引擎无关；分别简要介绍redo, undo, bin log 文件在mysql中的作用。&lt;/p&gt;
&lt;h3 id=&#34;redolog&#34;&gt;redolog&lt;/h3&gt;
&lt;h4 id=&#34;为什么需要redo-log&#34;&gt;为什么需要redo log？&lt;/h4&gt;
&lt;p&gt;我们都知道，事务的四大特性里面有一个是 &lt;strong&gt;持久性&lt;/strong&gt; ，具体来说就是&lt;strong&gt;只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态&lt;/strong&gt; 。那么mysql是如何保证一致性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因为 Innodb是以页为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！&lt;/li&gt;
&lt;li&gt;一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此 mysql设计了redolog ， &lt;strong&gt;具体来说就是只记录事务对数据页做了哪些修改&lt;/strong&gt;，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)。&lt;/p&gt;
&lt;h4 id=&#34;redo-log基本概念&#34;&gt;redo log基本概念&lt;/h4&gt;
&lt;p&gt;redo log包括两部分：一个是内存中的日志缓冲( redo log buffer )，另一个是磁盘上的日志文件(  redo log file )。 mysql 每执行一条 DML 修改写语句，操作的数据在内存中(如果没有会load到内存中)，首先会记修改操作的反操作逻辑数据记录写入undo log buffer中，然后会将修改哪个物理页面做了什么操作记录写入 redo log buffer ，后续某个时间点再一次性将多个操作记录写到 redo log file 和 undo log file。这种 &lt;strong&gt;先写日志，再写磁盘&lt;/strong&gt; 的技术就是 MySQL中的 WAL。&lt;/p&gt;
&lt;p&gt;在计算机操作系统中，用户空间( user space )下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间(kernel space )缓冲区( OS Buffer )。因此， redo/undo log buffer 写入 redo/undo log file; 实际上是先写入 OS Buffer ，然后再通过系统调用 fsync() 将其刷到 redo/undo log file 中，过程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://image-static.segmentfault.com/755/731/755731335-aec527828a1323b6_fix732&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;mysql 支持三种将 redo/undo log buffer 写入 redo/undo log file 的时机，可以通过 innodb_flush_log_at_trx_commit  参数配置，各参数值含义如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数值&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0（延迟写）&lt;/td&gt;
&lt;td&gt;事务提交时不会将 redo/undo log buffer 中日志写入到 os buffer ，而是每秒写入 os buffer 并调用 fsync() 写入到 redo/undo log file 中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1（实时写，实时刷）&lt;/td&gt;
&lt;td&gt;事务每次提交都会将 redo/undo log buffer 中的日志写入 os buffer 并调用 fsync() 刷到 redo/undo log file 中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。一般开启&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2（实时写，延迟刷）&lt;/td&gt;
&lt;td&gt;每次提交都仅写入到 os buffer ，然后是每秒调用 fsync() 将 os buffer 中的日志写入到 redo/undo log file 。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;https://image-static.segmentfault.com/706/634/706634199-04894beff4e7b54f_fix732&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;redo-log记录形式&#34;&gt;redo log记录形式&lt;/h4&gt;
&lt;p&gt;前面说过， redo log 实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。通过&lt;code&gt;show variables like &#39;innodb_log%&#39;; &lt;/code&gt; 查看参数；记录文件形式如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://image-static.segmentfault.com/390/444/3904443652-cc3225d69e1d0476_fix732&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;在innodb存储引擎中，既有 redo log 需要刷盘，还有 数据页 也需要刷盘， redo log 存在的意义主要就是降低对数据页刷盘的要求 。在上图中， write pos 表示 redo log 当前记录的 LSN (逻辑序列号)位置， check point 表示数据页更改记录刷盘后对应 redo log 所处的 LSN (逻辑序列号)位置。 write pos 到 check point 之间的部分是 redo log 空着的部分，用于记录新的记录； check point 到 write pos 之间是 redo log 待落盘的数据页更改记录。当 write pos 追上 check point 时，会先推动 check point 向前移动，空出位置再记录新的日志。&lt;/p&gt;
&lt;p&gt;启动 innodb 的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。因为 redo log 记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如 binlog )要快很多。 重启 innodb 时，首先会检查磁盘中数据页的 LSN ，如果数据页的 LSN 小于日志中的 LSN ，则会从 checkpoint 开始恢复。 还有一种情况，在宕机前正处于checkpoint 的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 LSN 大于日志中的 LSN，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。&lt;/p&gt;
&lt;p&gt;Mysql8.0 InnoDB存储引擎写操作，对redo log的写操作进行无锁全异步设计优化，增加；具体详细见官方文档：&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/optimizing-innodb-logging.html&#34;&gt;优化 InnoDB 重做日志&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;undolog&#34;&gt;undolog&lt;/h3&gt;
&lt;p&gt;数据库事务四大特性中有一个是 &lt;strong&gt;原子性&lt;/strong&gt; ，具体来说就是 &lt;strong&gt;原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况&lt;/strong&gt;。实际上， &lt;strong&gt;原子性&lt;/strong&gt; 底层就是通过 undo log 实现的。 undo log 主要记录了数据的逻辑变化，比如一条  INSERT 语句，对应一条 DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的undo log ，这样在发生错误时，就能回滚到事务之前的数据状态。同时， undo log 也是 MVCC (多版本并发控制)实现的关键；通过 &lt;code&gt;show variables like &#39;%undo%&#39;; &lt;/code&gt;查看参数。&lt;/p&gt;
&lt;h3 id=&#34;binlog&#34;&gt;binlog&lt;/h3&gt;
&lt;p&gt;binlog 用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。 binlog 是 mysql的逻辑日志，并且由 Server 层进行记录，使用任何存储引擎的 mysql 数据库都会记录 binlog 日志（&lt;code&gt;log_bin&lt;/code&gt; 打开的情况下）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;逻辑日志&lt;/strong&gt;： 可以简单理解为记录的就是sql语句 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;物理日志&lt;/strong&gt;： mysql 数据最终是保存在数据页中的，物理日志记录的就是数据页变更 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;binlog 是通过追加的方式进行写入的，可以通过 max_binlog_size 参数设置每个 binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。binlog相关参数通过&lt;code&gt;show variables like &amp;quot;%binlog%&amp;quot;;&lt;/code&gt; 查看；通过&lt;code&gt;show variables like &amp;quot;%log_bin%&amp;quot;;&lt;/code&gt;查看binlog是否开启,以及binlog日志目录，8.0版本默认时开启。&lt;/p&gt;
&lt;h4 id=&#34;binlog使用场景&#34;&gt;binlog使用场景&lt;/h4&gt;
&lt;p&gt;在实际应用中， binlog 的主要使用场景有两个，分别是 &lt;strong&gt;主从复制&lt;/strong&gt; 和 &lt;strong&gt;数据恢复&lt;/strong&gt; 。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;主从复制&lt;/strong&gt; ：在 Master 端开启 binlog ，然后将 binlog 发送到各个 Slave 端， Slave 端重放 binlog 从而达到主从数据一致。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据恢复&lt;/strong&gt; ：通过使用 mysqlbinlog 工具来恢复数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;binlog刷盘时机&#34;&gt;binlog刷盘时机&lt;/h4&gt;
&lt;p&gt;对于 InnoDB 存储引擎而言，只有在事务提交时才会记录 biglog ，此时记录还在内存中，那么 biglog是什么时候刷到磁盘中的呢？ mysql 通过 sync_binlog 参数控制 biglog 的刷盘时机，取值范围是 0-N：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;0：不去强制要求，由系统自行判断何时写入磁盘；&lt;/li&gt;
&lt;li&gt;1：每次 commit 的时候都要将 binlog 写入磁盘；一般开启&lt;/li&gt;
&lt;li&gt;N：每N个事务，才会将 binlog 写入磁盘。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从上面可以看出， sync_binlog 最安全的是设置是 1 ，这也是 MySQL 5.7.7之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。&lt;/p&gt;
&lt;h4 id=&#34;binlog日志格式&#34;&gt;binlog日志格式&lt;/h4&gt;
&lt;p&gt;binlog 日志有三种格式，分别为 STATMENT 、 ROW 和 MIXED 。在 MySQL 5.7.7 之前，默认的格式是 STATEMENT ， MySQL 5.7.7 之后，默认值是 ROW 。日志格式通过 binlog-format 指定; &lt;code&gt;show variables like &amp;quot;%binlog_format%&amp;quot;;&lt;/code&gt;查看&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;STATMENT ： 基于 SQL 语句的复制( statement-based replication, SBR )，每一条会修改数据的sql语句会记录到 binlog 中 。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点： 不需要记录每一行的变化，减少了 binlog  日志量，节约了  IO  , 从而提高了性能；&lt;/li&gt;
&lt;li&gt;缺点： 在某些情况下会导致主从数据不一致，比如执行本地时间操作； &lt;code&gt;SELECT NOW(),SYSDATE(),SLEEP(3),NOW(),SYSDATE();&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ROW ： 基于行的复制( row-based replication, RBR )，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了 。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点： 不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题 ；&lt;/li&gt;
&lt;li&gt;缺点： 会产生大量的日志，尤其是 alter table 的时候会让日志暴涨；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MIXED ： 基于 STATMENT 和 ROW 两种模式的混合复制( mixed-based replication, MBR )，一般的复制使用 STATEMENT 模式保存 binlog ，对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 binlog；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;binlog日志主要是用来主从同步复制数据以及数据恢复，是mysql server层执行器进行操作(主)写入和(从)读入(relaylog)；&lt;/p&gt;
&lt;p&gt;数据可以按天按周进行备份，顺序写入，没有大小限制(文件大小有限，但是整体没有限制，多个文件binlog.**可以通过binlog.index定位)；&lt;/p&gt;
&lt;h3 id=&#34;redo-log与binlog区别&#34;&gt;redo log与binlog区别&lt;/h3&gt;
&lt;p&gt;不同于redo log, 虽然两者都可以用来恢复数据，但是在mysql中innodb存储引擎的wal机制下生成的redolog有大小限制， redo log 实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志；而binlog主要是用来数据恢复，如果备份时间长，用户在某段时间有误操作，需要回滚操作，就可以同binlog来恢复到某个时间点的日志状态；对于redo log是做不到的；而且binlog 不是存储引擎特有的，所以可以在不同的存储引擎公用来恢复数据场景；区别如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;redo log&lt;/th&gt;
&lt;th&gt;binlog&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;文件大小&lt;/td&gt;
&lt;td&gt;redo log 的大小是固定的。&lt;/td&gt;
&lt;td&gt;binlog 可通过配置参数 max_binlog_size 设置每个 binlog 文件的大小。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;实现方式&lt;/td&gt;
&lt;td&gt;redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。&lt;/td&gt;
&lt;td&gt;binlog 是 Server 层实现的，MySQL 3.23.14 中引入的，所有引擎都可以使用 binlog 日志，服务器运行期间生成的服务器全局状态更改的跟踪日志&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;记录方式&lt;/td&gt;
&lt;td&gt;redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。&lt;/td&gt;
&lt;td&gt;binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;适用场景&lt;/td&gt;
&lt;td&gt;redo log 适用于崩溃恢复(crash-safe)，重启恢复的时候，通过check point和write pos 来恢复数据&lt;/td&gt;
&lt;td&gt;binlog 适用于主从复制和数据恢复，某个时间点的操作记录归档，可以按时间点进行恢复；以及主从之间的复制重放, 实现高可用的基础，以及订阅binlog进行不同分布式存储数据的同步&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;由 binlog 和 redo log 的区别可知：因为mysql 早期自带的MyISAM存储引擎设计用 binlog 日志只用于归档，进行数据恢复，只依靠 binlog 是没有 crash-safe 能力的。innodb存储引擎引入mysql之后，引入redo/undo log文件来支持事务持久性和原子性来保证写入数据的一致性；但只有 redo log 也不行，因为 redo log 是 InnoDB 特有的，循环写入，无法还原不在这个redo log中的记录，比如从服务启动或者记录数据落后很多(除非是shared storage架构机制的云厂商数据库，像&lt;a href=&#34;https://www.allthingsdistributed.com/files/p1041-verbitski.pdf&#34;&gt;Aurora&lt;/a&gt;,&lt;a href=&#34;https://www.vldb.org/pvldb/vol11/p1849-cao.pdf&#34;&gt;PolarDB&lt;/a&gt;)；因此需要 binlog 和 redo log二者同时记录，才能保证当数据库发生误删或者宕机重启时，数据不会丢失。&lt;/p&gt;
&lt;h3 id=&#34;两阶段提交&#34;&gt;两阶段提交&lt;/h3&gt;
&lt;p&gt;为了保证写入两份日志redo log, binlog 最终恢复数据是一致的，采用&lt;a href=&#34;https://en.wikipedia.org/wiki/Two-phase_commit_protocol&#34;&gt;两阶段提交(2pc)&lt;/a&gt;的机制(XA,内部/全局事务 innodb提供一样的操作)，mysql server 执行器 在调用innodb存储引擎接口进行写操作的时候，起到一个事务协调者的作用,通过TC_LOG(Transaction Coordinator Log)基类定义了事务日志需要实现的接口: open, prepare, commit, rollback, close；实现这些接口的类：TC_LOG_DUMMY(disable the logging), TC_LOG_MMAP(mmap logging), MYSQL_BIN_LOG(binlog)；主要是是查看MYSQL_BIN_LOG类中&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L7881&#34;&gt;prepare&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L7934&#34;&gt;commit&lt;/a&gt; 的实现；prepare 和 commit最终会调用存储引擎初始化时指向的handlerton对象对应函数；（这种接口隔离的常用设计，将调用方和实现方进行解耦，根据参数配置来绑定实现方，运行时动态调用）&lt;/p&gt;
&lt;p&gt;mysql是以plugin的方式管理存储引擎，replication(主从副本同步)插件和其他插件（通过&lt;code&gt;SHOW PLUGINS;&lt;/code&gt;查看)；具体的插件代码在&lt;a href=&#34;https://github.com/mysql/mysql-server/tree/8.0/plugin&#34;&gt;plugin&lt;/a&gt;文件中，简单的插件示例&lt;a href=&#34;https://github.com/mysql/mysql-server/tree/8.0/plugin/rewrite_example&#34;&gt;rewrite_example&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;mysqld 启动时通过配置初始的存储引擎(默认innodb)，调用&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/mysqld.cc#L5815&#34;&gt;init_server_components&lt;/a&gt; 调用innodb存储引擎的接口进行初始化ha_handler, 在&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/handler/ha_innodb.cc#L4935&#34;&gt;innodb_init&lt;/a&gt;中进行初始化, 比如刷盘操作 innobase_hton-&amp;gt;flush_logs = innobase_flush_logs; 然后在sql/handler中定义的相关接口调用, 比如&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/handler.cc#L2459&#34;&gt;ha_flush_logs&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;安装replication插件时会注册插件中相应的方法加入observer 列表中，运行触发的时候以AOP的方式RUN_HOOK 扫描observer列表Observer_info-&amp;gt;observer调用对应插件函数；replication插件需要实现以下&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/replication.h&#34;&gt;replication文件中&lt;/a&gt;相关结构体的方法(接口) 才能加载：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;struct Trans_observer /* Observes and extends transaction execution */
struct Server_state_observer /* Observer server state */
struct Binlog_transmit_observer /* Observe and extends the binlog dumping thread. */
struct Binlog_relay_IO_observer /* Observes and extends the service of slave IO thread. */
struct Binlog_storage_observer /* Observe binlog logging storage */
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里会有各种日志的刷新机制，可以通过&lt;code&gt;show variables like &#39;%innodb%flush%&#39;; show variables like &#39;sync_binlog&#39;;&lt;/code&gt;获取对应的参数，可以去官网&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html&#34;&gt;Server Option, System Variable, and Status Variable Reference&lt;/a&gt; 查找对应的详情进行配置优化；&lt;/p&gt;
&lt;p&gt;当开启binlog时, MySQL默认使用该隐式XA模式，开启自动提交事务autocommit。事务的提交流程相对比较复杂，执行简单的update操作，简述如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0. 执行器数据获取修改：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行器调用innodb存储引擎接口获取满足条件的数据，通过树索引查找/全表查找， 如果数据在buffer pool中查找到，返回数据；否则从磁盘表空间文件中读取数据page到buffer pool  clean page中，返回数据；无数据，流程终止返回；&lt;/li&gt;
&lt;li&gt;执行器修改找到的数据，将修改的数据 调用innodb存储引擎接口写入新数据，进行两阶段提交；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;事务的提交过程入口点位于 &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/handler.cc#L1592&#34;&gt;ha_commit_trans&lt;/a&gt;函数，以mysql binlog 为事务2pc协调者为例，事务提交的过程如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. mysql bin log 事务2pc协调者 处理 准备prepare阶段&lt;/strong&gt;：(tc_log-&amp;gt;prepare)&lt;/p&gt;
&lt;p&gt;MYSQL_BIN_LOG::prepare(THD *thd, bool all)  设置 thd-&amp;gt;durability_property = HA_IGNORE_DURABILITY; 用于在存储引擎准备阶段不刷新事务日志redo/undo log 到磁盘日志文件中；&lt;/p&gt;
&lt;p&gt;调用流程：ha_prepare_low → innobase_xa_prepare → trx_prepare_for_mysql →   &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/trx/trx0trx.cc#L2919&#34;&gt;static void trx_prepare(trx_t *trx)&lt;/a&gt;   → trx_prepare_low → trx_undo_set_state_at_prepare&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;p&gt;执行器调用innodb存储引擎接口进行修改操作，首先写入数据的旧值至undo log buffer中，更新InnoDB的undo回滚段，将其设置为Prepare状态（&lt;code&gt;TRX_UNDO_PREPARED&lt;/code&gt;）写入mlog中，返回 redo log 的LSN,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更新buffer pool中的数据(如果插入需要从free(free list)变成clean page(lru list)，free list 不够时需要从flush ist或者lru list淘汰一定的page变成free page 加入free list); 修改的clean page(lru list)变成 dirty page(lru list)(更新的数据页在缓存中，还未刷盘)；dirty page写入flush list； 为了提高写性能异步线程刷盘(刷盘时机可以在commit之后；MySQL 5.7引入了page cleaner线程)&lt;/p&gt;
&lt;p&gt;Tips: 在flush list上的页面一定在lru List上，但是反之则不成立。一个数据页可能会在不同的时刻被修改多次，在数据页上记录了最老(也就是第一次)的一次修改的LSN，即oldest_modification。不同数据页有不同的oldest_modification，flush list中的节点按照oldest_modification排序，链表尾是最小的，也就是最早被修改的数据页，当需要从flush list中淘汰页面时候，从链表尾部开始淘汰。加入flush list，需要使用flush_list_mutex保护，所以能保证flush list中节点的顺序。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同时将数据页的修改记录LSN写入redo log buffer中，准备提交事务，此时 redo log 处于 prepare 状态，如果thd-&amp;gt;durability_property = HA_IGNORE_DURABILITY, 将&lt;code&gt;LSN&lt;/code&gt; 写入redo log 磁盘文件中；原子化操作&lt;code&gt;trx_t&lt;/code&gt; 事务状态为 PREPARED (用于事务隔离操作)； 将&lt;code&gt;gtid_desc&lt;/code&gt;写入undolog 表空间中；然后告知执行器执行完成了，随时可以提交事务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tips: 这里会出现redo log file写满的情况，buffer 写入会hang住，MySQL就会停下手头的任务，先把脏页刷到磁盘里，才能继续干活，会导致MySQL的服务器的tps有明显的波动； 默认开启了innodb_adaptive_flushing 算法进行优化，在redo log file还没有满的时候，会根据redo log file生成的速度和刷新频率来将redo log file中的脏页刷入磁盘表空间文件中；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. mysql binlog 事务2pc协调者 处理 提交commit阶段：&lt;/strong&gt;(tc_log-&amp;gt;commit)&lt;/p&gt;
&lt;p&gt;调用流程：TC_LOG::enum_result MYSQL_BIN_LOG::commit(THD *thd, bool all) →&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L8717&#34;&gt;int MYSQL_BIN_LOG::ordered_commit(THD *thd, bool all, bool skip_commit)&lt;/a&gt;  , 如果没有开启log_bin，没有bin log文件，直接跳至commit阶段；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;组提交&lt;/strong&gt; (流程见代码中介绍 &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.h#L568-L641&#34;&gt;ordered_commit&lt;/a&gt; )：组提交第一眼看着有点懵逼，可以结合这片文章 &lt;a href=&#34;https://developer.aliyun.com/article/617776&#34;&gt;[图解MySQL]MySQL组提交(group commit)&lt;/a&gt; 了解；主要是为了提升事务吞吐量设计的方案(&lt;strong&gt;原则：尽量减少磁盘IO, 利用持久盘的特性顺序写&lt;/strong&gt;)；如同木桶效应一样，redo log 和 binlog 两者其中有一个没有组提交，都会降低事务吞吐量，所以最好的方式redo log 和 binlog 两者都组队提交; mysql设计者将组提交从flush阶段开始优化，将其分为几个阶段： flush 阶段、sync 阶段、(replication复制阶段) 、commit 阶段；其中replication复制阶段以HOOK的方式动态运行对于的replication复制策略，默认是异步复制。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;binlog_order_commits&lt;/code&gt;参数控制innodb commit顺序和binlog写入顺序是否一致，默认启用保证顺序一致，方便备份和快速恢复；和binlog组提交配合使用，这个参数来自官网的介绍：&lt;/p&gt;
&lt;p&gt;当在复制源服务器上启用此变量时（这是默认设置），发送给存储引擎的事务提交指令在单个leader线程上被序列化，因此事务总是按照写入binlog的相同顺序提交。禁用此变量允许使用多个线程发出事务提交指令。与binlog组提交结合使用，这可以防止单个事务的提交率成为吞吐量的瓶颈，因此可能会产生性能改进。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Flush阶段：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;调用流程：TC_LOG::enum_result MYSQL_BIN_LOG::commit(THD *thd, bool all) →&lt;a href=&#34;&#34;&gt;int MYSQL_BIN_LOG::ordered_commit(THD *thd, bool all, bool skip_commit)&lt;/a&gt;  →  &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L8301&#34;&gt;int MYSQL_BIN_LOG::process_flush_stage_queue&lt;/a&gt; ;&lt;/p&gt;
&lt;p&gt;RUN_HOOK 去获取加载的插件，rpl handler Binlog_storage_delegate::after_flush FOREACH_OBSERVER宏 遍历observer列表Observer_info-&amp;gt;observer调用对应replication插件函数&lt;/p&gt;
&lt;p&gt;最终调用&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/os/os0file.cc#L2847&#34;&gt;os_file_fsync_posix&lt;/a&gt; flush redolog to disk ; 根据不同的操作系统来调用，unix操作系统调用fsync/fdatasync函数刷盘, fsync会确保OS cache中的数据直到写磁盘操作结束才会返回，并且写入元数据，而fdatasync不会; 如果想不走OS cache直接写磁盘，对打开/创建的文件句柄加上O_DIRECT属性，一般用于写系统表空间数据落盘；&lt;/p&gt;
&lt;p&gt;此时process_flush_stage_queue处理会形成一组队列，由组leader(一个组中最早开始的事务)依次为别的线程写binlog文件 在准备写binlog前，会先调用ha_flush_logs -&amp;gt; innobase_flush_logs接口，将存储的日志写到最新的LSN；然后再写binlog到文件; 这样做的目的是为了提升组提交的效率。&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;执行器 调用innodb存储引擎innobase_flush_logs-&amp;gt;log_flush_low-&amp;gt;redo_space_flush-&amp;gt;os_file_flush-&amp;gt;&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/os/os0file.cc#L2847&#34;&gt;os_file_fsync_posix&lt;/a&gt; 接口 将 redo/undo log buffer中的数据写入redo/undo log file 磁盘中；&lt;/li&gt;
&lt;li&gt;执行器 调用 MYSQL_BIN_LOG::flush_thread_caches 将 thread caches binlog缓冲数据  写入 bin log(xid,GTID)中(还未刷盘),通过 &lt;code&gt;show variables like &#39;%binlog_cache%&#39;;&lt;/code&gt;查看缓冲大小； 并且设置好事务的写入位置m_trans_end_pos，当事务提交commit阶段的时候，直接获取位置提交；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Sync_binlog阶段：&lt;/strong&gt; &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L8506&#34;&gt;std::pair&amp;lt;bool, bool&amp;gt; MYSQL_BIN_LOG::sync_binlog_file(bool force)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RUN_HOOK 去获取加载的插件，rpl handler Binlog_storage_delegate::after_sync FOREACH_OBSERVER宏遍历observer列表Observer_info-&amp;gt;observer调用对应replication插件函数；&lt;/p&gt;
&lt;p&gt;最终调用 &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/mysys/my_sync.cc#L84&#34;&gt;int my_sync(File fd, myf my_flags)&lt;/a&gt;  Sync binlog data in file to disk&lt;/p&gt;
&lt;p&gt;如果&lt;code&gt;sync_binlog&lt;/code&gt;计数超过配置值，则进行一次文件fsync，n&amp;gt;1 开启组提交，参数&lt;code&gt;sync_binlog&lt;/code&gt;的含义不是指的这么多个事务之后做一次fsync，而是多个事务一组之后做一次fsync，&lt;code&gt;binlog_group_commit_sync_delay&lt;/code&gt;,&lt;code&gt;binlog_group_commit_sync_no_delay_count&lt;/code&gt; 这些参数见官网文档；&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;开始生成这个时间点的逻辑操作日志格式，通过&lt;code&gt;sync_binlog&lt;/code&gt; flush策略异步将thead caches中的数据批量写入到磁盘binlog文件binlog.**/binlog.index中； 通过 &lt;code&gt;show binlog events;&lt;/code&gt;来查看binlog文件相关的信息，也可以对单个文件查看；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Async/Semisync/Group 异步/半同步/组复制阶段：&lt;/strong&gt; (写操作都在主上)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异步复制&lt;/strong&gt;：主库在记录完binlog，执行完自己的事务之后就会直接返回，mysql主从模式默认是异步复制；异步复制流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/async-replication-diagram.png&#34; alt=&#34;async-replication-diagram&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;半同步复制&lt;/strong&gt;：主的事务需要等一台从同步binlog日志提交到Relay Log中(sync_relay=1)，返回ack，主库提交事务；半同步流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/semisync-replication-diagram.png&#34; alt=&#34;semisync-replication-diagram&#34;&gt;&lt;/p&gt;
&lt;p&gt;从MySQL5.5开始 以插件的形式支持半同步复制；如果需要支持，主从都需要安装半同步插件库；对应的代码在&lt;a href=&#34;https://github.com/mysql/mysql-server/tree/8.0/plugin/semisync&#34;&gt;plugin/semisync&lt;/a&gt;文件夹中。&lt;/p&gt;
&lt;p&gt;主 &lt;code&gt;install plugin rpl_semi_sync_master soname &#39;semisync_master.so&#39;;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;从 &lt;code&gt;install plugin rpl_semi_sync_slave soname &#39;semisync_slave.so&#39;;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;并且打开半同步复制，&lt;code&gt;set global rpl_semi_sync_master_enabled=1;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;其中通过参数&lt;code&gt;rpl_semi_sync_master_wait_point&lt;/code&gt;来决定什么时候提交事务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;after_sync&lt;/strong&gt; 主库先不提交事务，等待某一个从库返回了结果之后，再提交事务，在返回结构通知客户端。这样一来，如果从库在没有任何返回的情况下宕机了，master这边也无法提交事务。主从仍然是一致的，mysql5.7之后默认值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;after_commit&lt;/strong&gt; 主库先提交事务，等待从库返回结果再通知客户端。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;组复制&lt;/strong&gt;：基于原生复制及 paxos 协议，提供一致数据安全保证，一种可用于实现容错系统的技术；具体详情见官方文档：&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/group-replication.html&#34;&gt;MySQL8.0 Group Replication&lt;/a&gt;；组复制流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/gr-replication-diagram.png&#34; alt=&#34;gr-replication-diagram&#34;&gt;&lt;/p&gt;
&lt;p&gt;MySQL 5.7.17版本中引入MySQL 组复制，同样也是以插件的形式支持; 对应的代码在&lt;a href=&#34;https://github.com/mysql/mysql-server/tree/8.0/plugin/group_replication&#34;&gt;plugin/group_replication&lt;/a&gt;文件夹中。一组副本机器安装插件都是&lt;code&gt;INSTALL PLUGIN group_replication SONAME &#39;group_replication.so&#39;;&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;如果开启的主从复制(默认异步)1:n，主库会等待从库I/O线程建立连接之后，创建binlog dump线程，通知slave有数据更新，当I/O线程请求日志内容时，会将此时的binlog名称和当前更新的位置pos同时传给slave的I/O线程, 把binlog event发送给从库I/O线程，从库I/O线程获取到binlog event之后将其写入到自己的Relay Log中，然后从库启动SQL线程，将Relay中的数据进行重放，完成从库的数据更新；为了保证不重复更新，binlog/relaylog 中记录了GTID（mysql5.6加入）, 全局唯一, 如果relaylog中已有GTID, 则执行GTID自动跳过，意味着在源上提交的事务只能在副本上应用一次，这有助于保证一致性;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另外如果主从复制过程突然中断了，或者主从切换了，重启之后发现SQL线程实际执行到位置和数据库记录的不一致；mysql5.6之后将复制的进度放在系统的&lt;code&gt;mysql.slave_relay_log_info&lt;/code&gt;innodb表里，并且把更新进度、SQL线程执行用户事务绑定成一个事务执行。即使宕机了，可以通过MySQL内建的崩溃恢复机制来使实际执行的位置和数据库保存的进度恢复到一致。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Commit阶段:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;调用流程：int MYSQL_BIN_LOG::finish_commit(THD *thd) -&amp;gt; ha_commit_low -&amp;gt; innobase_commit -&amp;gt; &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/trx/trx0trx.cc#L2199&#34;&gt;void trx_commit(trx_t *trx)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RUN_HOOK 去获取加载的插件，rpl handler Trans_delegate::after_commit  FOREACH_OBSERVER宏遍历observer列表Observer_info-&amp;gt;observer调用对应replication插件函数；&lt;/p&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;
&lt;p&gt;只有binlog写入磁盘成功之后，执行器才会调用innodb存储引擎接口，从队列中获取事务组依次进行innodb commit 提交释放事务，将redo log中已经prepare的事务提交写入commit标记，并且写入binlog位点；最后调用MYSQL_BIN_LOG::rotate 是否切换binlog文件(在切换文件期间，使用一个防止新的提交组执行刷新阶段的锁，并等待直到准备好的事务的计数器变为0，然后才创建新文件)，如果切成新文件， 调用MYSQL_BIN_LOG::purge()刷盘；结束ordered_commit 组提交流程,返回提交；&lt;/p&gt;
&lt;p&gt;Tips: Commit阶段不用刷盘，Flush阶段中的redo log刷盘已经足够保证数据库崩溃时的数据安全了; Commit阶段队列的作用是承接Sync阶段的事务，完成最后的引擎提交，使得Sync可以尽早的处理下一组事务，最大化组提交的效率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;整体更新流程&#34;&gt;整体更新流程：&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/mysql-innodb-w.drawio.png&#34; alt=&#34;mysql-innodb-w&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;崩溃恢复&#34;&gt;崩溃恢复&lt;/h3&gt;
&lt;p&gt;更新流程中写入redo log的过程拆成了两个步骤prepare和commit 两个阶段；如果不使用两阶段提交，数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。在崩溃恢复中，&lt;!-- raw HTML omitted --&gt;是以 binlog 中的 xid 和 redolog 中的 xid 进行比较，xid 在 binlog 里存在则提交，不存在则回滚，以及判断redo log中是否有commit标识&lt;!-- raw HTML omitted --&gt;；崩溃恢复时具体的情况:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;binlog无记录，redolog无记录：在redolog写之前crash, 无prepare状态，无undo log 记录，恢复操作：无，无需关心；&lt;/li&gt;
&lt;li&gt;binlog无记录，redolog无记录：在redolog写之前crash, 无prepare状态，有undo log 记录，恢复操作：通过undo log回滚事务；&lt;/li&gt;
&lt;li&gt;binlog有记录，redolog有记录：redolog状态prepare， 则判断对应的事务是否存在完整的binlog，恢复操作：如果是, 则提交事务，否则, 通过undo log回滚事务;&lt;/li&gt;
&lt;li&gt;如果redo log里面的事务是完整的, 也就是有了commit标识, 恢复操作：直接提交事务；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;对于需要持久化的数据库系统，避免不了事务在处理过程中，突然中断的情况；WAL通过预写日志的方式在事务提交之前，需要把修改重放记录和撤销详细记录写入日志文件中，以便在故障后恢复数据；事务开始后，所有对数据库的修改在发送到缓冲池之前都被记录在内存中的WAL缓冲区中；事务提交之前，必须把WAL缓冲区刷新到磁盘。mysql innodb存储引擎引入redo/undo log文件来支持事务持久性和原子性，由于mysql binlog用来归档数据记录恢复和复制，为了保证写入两份日志redo log, binlog 最终恢复数据是一致的，采用两阶段提交机制，通过源码了解了些整体WAL的实现；以及崩溃时候需要用日志进行恢复。(其他持久化存储系统的WAL实现，待续)&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Write-ahead_logging&#34;&gt;Write-ahead_logging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics&#34;&gt;ARIES:Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cs.stanford.edu/people/chrismre/cs345/rl/aries.pdf&#34;&gt;aries.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OceanBase-Partner/lectures-on-dbms-implementation/blob/main/lecture-6.md#642-%E7%BC%93%E5%86%B2%E6%B1%A0%E7%AE%A1%E7%90%86%E7%AD%96%E7%95%A5&#34;&gt;缓冲池管理策略&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mesl.ucsd.edu/pubs/SOSP2013-MARS.pdf&#34;&gt;From ARIES to MARS: Transaction Support for Next-Generation, Solid-State Drives.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://repository.bilkent.edu.tr/bitstream/handle/11693/37609/Implications%20of%20non-volatile%20memory%20as%20primary%20storage%20for%20database%20management%20systems.pdf&#34;&gt;Implications of Non-Volatile Memory as Primary Storage for Database Management Systems.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://infoscience.epfl.ch/record/170505/files/aether-smpfulltext.pdf&#34;&gt;Scalability of write-ahead logging on multicore and multisocket hardware.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.vldb.org/pvldb/vol10/p337-arulraj.pdf&#34;&gt;WBL.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=S9nctHdkggk&#34;&gt;ARIES Overview, Types of Log Records, ARIES Helper Structures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4VGkRXVM5fk&#34;&gt;ARIES Database Recovery (CMU Databases Systems / Fall 2019)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/internals/en/binary-log.html&#34;&gt;mysql binary-log&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2021/10/01/&#34;&gt;MySQL · 引擎特性 · 庖丁解InnoDB之UNDO LOG&lt;/a&gt;  &lt;a href=&#34;http://catkang.github.io/2020/02/27/mysql-redo.html&#34;&gt;庖丁解InnoDB之REDO LOG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2020/05/09/&#34;&gt;MySQL · 引擎特性 · 基于GTID复制实现的工作原理&lt;/a&gt;  &lt;a href=&#34;http://mysql.taobao.org/monthly/2020/05/07/&#34;&gt;MySQL · 源码分析 · 内部 XA 和组提交&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/73161&#34;&gt;日志和索引相关问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.aliyun.com/article/617776&#34;&gt;[图解MySQL]MySQL组提交(group commit)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2018/07/01/&#34;&gt;MySQL · 引擎特性 · WAL那些事儿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/372300181&#34;&gt;无处不在的 MySQL XA 事务&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html&#34;&gt;Server Option, System Variable, and Status Variable Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://icyfenix.cn/architect-perspective/general-architecture/transaction/local.html&#34;&gt;凤凰架构-本地事务&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>设计-配置平台</title>
      <link>https://weedge.github.io/post/conf/</link>
      <pubDate>Thu, 18 Nov 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/conf/</guid>
      
        <description>&lt;h3 id=&#34;介绍&#34;&gt;介绍&lt;/h3&gt;
&lt;p&gt;业务服务在启动时加载配置，配置分为静态配置和动态配置，静态配置如服务监听的端口，日志路径，访问依赖服务单元不同云(region / zone) 域名地址等；动态配置包括业务配置，流程管理配置，策略配置等；静态配置服务启动之后不会更改，而动态配置在服务启动运行时可以动态热加载；将配置的内容和版本进行分离，关注配置的管理而无需关注配置的内容，配置内容用户可以自定义配置内容，使用json-schema进行校验，提供自定义配置内容json给后台ui前端进行单个整体配置的交互，配置后台只需加载json-schema进行校验提交内容，json-schema由用户上传提供地址即可。&lt;/p&gt;
&lt;h3 id=&#34;目标&#34;&gt;目标&lt;/h3&gt;
&lt;p&gt;通过配置后台，业务服务流程可控，可配置，可视化，隔离已有业务场景配置，提高人效；&lt;/p&gt;
&lt;h3 id=&#34;功能&#34;&gt;功能&lt;/h3&gt;
&lt;h4 id=&#34;后台基础功能&#34;&gt;后台基础功能&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;后台管理发布生产环境的动态配置，包括新增，修改，审核，发布，回滚等功能；&lt;/li&gt;
&lt;li&gt;多人发布的时候，检查当前的版本是否已经发布，并进行版本diff;&lt;/li&gt;
&lt;li&gt;配置是服务接口维度进行操作管理， 以服务粒度进行整体发布；&lt;/li&gt;
&lt;li&gt;提供获取当前已发布的服务配置接口，用于订阅端拉取；&lt;/li&gt;
&lt;li&gt;提供RBAC权限管理;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;动态配置热加载功能&#34;&gt;动态配置热加载功能&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;业务服务配置获取方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;服务配置修改发布，通过发布/订阅模式(Pub-Sub Pattern)通知业务服务进行加载；可用组件为支持pub/sub命令的redis协议kv服务，或者通过get(mget)/set(mset) incr(seq)命令进行模拟实现；&lt;/li&gt;
&lt;li&gt;服务配置修改发布，通过观察者模式(Observer Pattern) watch机制通知业务服务进行实时加载；可以使用etcdv3的watch机制实现;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两种方案都可以，看是否有对应的高可用组件服务支持；如果都有，建议使用etcdv3(client 3.4+)的watch机制，通过长链接来通知变更事件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;加载方式有两种实现方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;通过部署单独agent进程来获取配置进行解析写入指定配置路径文件中(重启时)和共享内存中(运行时)，先写文件，成功了，在写共享内存；然后由业务服务读取；&lt;/p&gt;
&lt;p&gt;优点：方便单独维护，无需业务方关心，只需关心加载配置的路径在后台维护，以及共享内存中的配置结构；&lt;/p&gt;
&lt;p&gt;缺点：多了一次进程之间的交互；业务方代码中需要有读取共享内存的逻辑考虑；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提供配置加载lib库，由业务方启动逻辑代码中调用；将获取配置进行解析写入指定配置路径文件中，加载到业务进程配置结构中使用即可；&lt;/p&gt;
&lt;p&gt;优点：业务方直接调用lib库中的方法，无需关心加载逻辑；&lt;/p&gt;
&lt;p&gt;缺点：假如业务方是不同的语言编写，需要提供不同语言版本的lib库方法；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总体来说，2种方案都可行，如果统一技术栈，比如使用golang进行开发，可以选用第二种方案；&lt;/p&gt;
&lt;p&gt;但是这样就可以了么？还有业务集群配置一致性需要考虑到，比如业务集群某台机器突然抽风，未加载最新的配置，打到这台机器的请求和其他正常加载配置的机器的请求逻辑会有所不同，导致整体服务接口不是幂等的，会出现不一致的情况；可以借鉴一下 &lt;a href=&#34;https://github.com/XiaoMi/Gaea/blob/master/docs/config-reloading.md&#34;&gt;gaea配置热加载设计与实现&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;配置一致性方案：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过两阶段提交的方式，由业务服务侧提供prepare接口和commit接口；&lt;/p&gt;
&lt;p&gt;准备阶段：conf-dashboard模块发布的时候获取业务服务的ip列表并发调用每个业务服务ip的prepare接口，开始触发业务服务本地配置的更新流程，首先通过conf-dashboard模块获取最新版本和当前版本比较，如果相同就无需比较了，否则从获取配置接口获取配置进行更新；更新流程不是直接替换线上正在使用的文件，而是生成一个准备文件进行提交时替换；每个prepare接口同步调用返回结果都ok了，进入下一步提交阶段，如果其中一个返回失败，发布失败，展现失败详情；&lt;/p&gt;
&lt;p&gt;提交阶段：prepare成功后；conf-dashboard模块继续并发调用的commit接口，开始文件替换，加载至缓存配置结构中；这个操作比较快，都提交成功之后，发布成功，否则发布失败，展现失败详情；&lt;/p&gt;
&lt;p&gt;失败处理：如果某台机器发布失败，可以排查下具体原因之后(原因应尽量在prepare和commit接口中详细给出)，看是否跳过继续发布还是会滚，重复发布不影响，有md5和版本比较；&lt;/p&gt;
&lt;p&gt;tips: 如果发布机器很多，并发力度根据conf-dashboard模块部署机器接口负载，可以自适应调整降低；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;兜底检查更新方案：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;配置发布成功后，调用业务服务机器的meta接口获取最新更新文件信息，进行兜底检查确认；&lt;/p&gt;
&lt;p&gt;业务服务开启兜底定时任务获取从conf-dashboard获取配置版本，配置信息进行兜底更新, 每隔10～30分钟执行一次；&lt;/p&gt;
&lt;p&gt;tips: 请求conf-dashboard获取配置信息的接口随机打散，防止并发流量对conf-dashboard模块的影响；&lt;/p&gt;
&lt;p&gt;定时任务流程图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/confmg.drawio.png&#34; alt=&#34;cron-confmg&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;整体交互框架&#34;&gt;整体交互框架&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/config-arch.drawio.png&#34; alt=&#34;config-arch&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据库核心动态配置表设计&#34;&gt;数据库核心动态配置表设计&lt;/h3&gt;
&lt;p&gt;当前服务版本和当前conf版本是1对多的场景，而历史服务快照版本和历史conf快照版本是多对多的场景；&lt;/p&gt;
&lt;p&gt;如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/config-version.png&#34; alt=&#34;config-version&#34;&gt;&lt;/p&gt;
&lt;p&gt;服务类型枚举表 service_type&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;枚举值&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;配置类型枚举表 conf_type&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;枚举值&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;枚举值由配置平台统一分配收敛管理&lt;/p&gt;
&lt;p&gt;当前服务版本表 tb_service_cur_ver&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型 比如：0.无 1.liveme 2.livestation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cluster_name&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务集群名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cur_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;服务当前版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;最大版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;当前conf版本表 tb_conf_cur_ver&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cur_service_ver_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;当前服务版本 id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;conf类型，比如：&lt;!-- raw HTML omitted --&gt;0.无 &lt;!-- raw HTML omitted --&gt;1.livemeDSL &lt;!-- raw HTML omitted --&gt;101.livestationAggrDSL 102.livestationSceneDSL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cur_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;conf当前版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;最大版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_name&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_target_path&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf生成的目标路径&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_val&lt;/td&gt;
&lt;td&gt;varchar(8192)&lt;/td&gt;
&lt;td&gt;conf当前内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;服务版本用户操作记录表 tb_service_op_record&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cluster_name&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务集群名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_status&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务配置审核状态: 0.待审核 1.审核不通过 2.审核通过&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;op_uid&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;操作者uid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;conf版本用户操作记录 tb_conf_op_record&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_op_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;服务版本操作 id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;conf类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_name&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_target_path&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf生成的目标路径&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_val&lt;/td&gt;
&lt;td&gt;varchar(8192)&lt;/td&gt;
&lt;td&gt;conf当前内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_del&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;是否删除，0.可用，1.不可用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;服务历史版本快照表 tb_service_ver_snapshot&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cluster_name&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务集群名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;history_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;服务历史版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;conf历史版本快照表 tb_conf_version_snapshot&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;conf类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_name&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;history_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;conf历史版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_target_path&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf生成的目标路径&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_val&lt;/td&gt;
&lt;td&gt;varchar(8192)&lt;/td&gt;
&lt;td&gt;conf历史快照内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;服务conf历史版本关联表 tb_service_conf_ver_snapshot&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_ver_snapshot_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;服务历史版本快照 id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_ver_snapshot_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;conf历史版本快照 id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;场景模拟&#34;&gt;场景模拟&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;新增版本保存更新删除&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;审核&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;发布&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;回滚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;获取当前服务conf版本配置&lt;/p&gt;
&lt;p&gt;服务粒度整体版本文件一次拉取下来，这里是接口形式提供， 后续可以提供将可用版本以服务粒度打个包提交；如果后续有多服务一起捆绑打包，需要考虑上线依赖顺序，暂时不提供&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;接口&#34;&gt;接口&lt;/h3&gt;
&lt;p&gt;线下内网域名访问需要配置router模块中的ngx proxy配置，新增一个location /confdashboard 进行路由跳转；或者指定ip端口访问路径；&lt;/p&gt;
&lt;p&gt;线上通过通过服务发现模块来获取confdashboard服务单元ip列表负载均衡进行访问；可以多机房部署，根据业务服务部署场景定；&lt;/p&gt;
&lt;h4 id=&#34;conf-dashboard-接口&#34;&gt;conf-dashboard 接口&lt;/h4&gt;
&lt;p&gt;提供给后台前端的CRUD接口不在这里描述，通过&lt;a href=&#34;https://github.com/smallnest/gen&#34;&gt;smallnest/gen&lt;/a&gt;生成RESTful接口提供给前端使用就行，修改操作，根据不同的conf_type加载不同的json_schema进行校验，以及审核，发布接口；主要是提供给业务服务调用的接口实现，如下：&lt;/p&gt;
&lt;p&gt;请求调用方式：http1.1 POST 或者 GRPC&lt;/p&gt;
&lt;p&gt;公共返回参数：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;字段&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;类型&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;errNo&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;int&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;错误号，默认为0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;errStr&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;string&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;错误描述&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;data&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;json&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;返回响应数据&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;获取当前服务配置文件版本   /confdashboard/v1/getcurversion&lt;/p&gt;
&lt;p&gt;请求：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;参数是否必须&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;serviceType&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型:0.无 1.liveme 2.livestation&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;响应：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;curVer&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;当前版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;maxVer&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;最大版本&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;获取当前服务文件配置内容   /confdashboard/v1/getcurserverconf&lt;/p&gt;
&lt;p&gt;(服务粒度整体版本文件一次拉取下来，这里是接口形式给出对应配置数据，兜底定时轮训获取）&lt;/p&gt;
&lt;p&gt;请求：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;字段&lt;/th&gt;
&lt;th&gt;参数是否必须&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;serviceType&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型:0.无 1.liveme 2.livestation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;confName&lt;/td&gt;
&lt;td&gt;可选&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务本地配置文件名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;confTargetPath&lt;/td&gt;
&lt;td&gt;可选&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务本地配置路径&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;响应data：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;downloadUrl&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务配置整体打包地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;confData&lt;/td&gt;
&lt;td&gt;map&lt;!-- raw HTML omitted --&gt;confData&lt;!-- raw HTML omitted --&gt;(map&amp;lt;{confTargetPath}/{confName}&amp;gt;{confData})&lt;/td&gt;
&lt;td&gt;服务配置列表&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;confData&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;文件当前版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;data&lt;/td&gt;
&lt;td&gt;[]byte&lt;/td&gt;
&lt;td&gt;文件当前版本内容&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;业务服务配置更新结果报告 /confdashboard/v1/reportBizServConf&lt;/p&gt;
&lt;p&gt;请求：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;参数是否必须&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;serviceType&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型:0.无 1.liveme 2.livestation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;reportInfos&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;map&lt;!-- raw HTML omitted --&gt;reportInfo&lt;/td&gt;
&lt;td&gt;业务服务配置更新结果报告列表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;clusterName&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;集群名称&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;reportInfo&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;confFilePath&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;业务配置文件路径（绝对路径）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;md5sum&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;文件MD5值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;confUpdateTime&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;业务配置文件更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;updateResultCode&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;0, 更新成功，1，更新失败&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;updateErrStr&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;更新失败原因&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;响应data：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;conf-agentlib-业务服务接口&#34;&gt;conf-agent/lib 业务服务接口&lt;/h4&gt;
&lt;p&gt;通过在业务服务机部署agent, 或者使用lib库封装函数的方式，最终都是需要提供获取配置的服务提供对应的接口，来保证整体服务配置的一致性，这里采用lib库封装函数提供给业务服务启动时调用这个函数的方式，是否启动单独启动端口是可选的，如果是在业务服务中启动，就用业务服务的端口，如果是单独agent方式启动，使用单独的端口；接口定义如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;获取配置开始准备替换工作 prepare接口 /{serviceType}/localconf/prepare&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提交本地替换工作 commit接口 /{serviceType}/localconf/commit&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;获取本地配置文件元数据，比如md5,路径,版本等，meta接口 /{serviceType}/localconf/meta&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;施工&#34;&gt;施工&lt;/h3&gt;
&lt;p&gt;可以进行模块划分，按人力进行分工，可以用Project或者trello这些工具来管理整个项目需求，开发，测试，上线周期；也可以内部整合jira 和 wiki 等平台工具进行管理;&lt;/p&gt;
&lt;p&gt;这个有点像建筑施工队，有了设计稿，推演几遍，满足整体需求和目标；剩下的是去实施了，实施的话需要，整体系统架构设计的建筑工程师👷，懂这行工具的专工👷，以及领队包工头👷，大项目可能还有项目监工👷‍♀️，监控进度，以及交互后的质量把控工程师👷；一起配合把事干好，让用户和老板满意。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;前期业务为了满足快速业务迭代，业务动态配置可能都是随着业务服务一起上线，或者通过单独的代码库进行管理分开单独上线；这个可能会因为代码上线了，但是配置忘记上线的情况；或者只需要修改配置上线，而不需要修改代码，也需要单独部署一次业务服务，如果涉及多个服务模块，不能及时响应了，不够KISS；为了满足业务集群配置化管理，配置平台需要管理业务动态配置来提高人效，保证业务集群上线配置的整体一致，通过后台页面来管理配置和历史配置，追踪配置的修改情况；需要注意的是，第一次上线的配置，可以先在测试环境配置平台上配置好，测试好之后，在到线上平台配置发布上线，然后在部署业务服务代码；发布配置也需要在线上未接入流量的机器上，测试之后才能上。&lt;/p&gt;
&lt;h3 id=&#34;qa&#34;&gt;Q&amp;amp;A&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;为什么不直接用etcd来管理配置呢？去掉mysql, 配置直接存etcd不行么？&lt;/p&gt;
&lt;p&gt;主要是因为mysql用来提供管理配置实体的关系，用于后台页面修改使用；如果是k8s中的场景，可以直接使用etcd来存放(100G以下的数据, 大厂多机房大集群会魔改etcd)；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果业务服务部署在Pod容器中, 怎么更新配置呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;agent通过DaemonSet容器化部署,单独升级, agent与业务Pod之间通过共享内存进行通信更新配置；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;以SideCar Container方式将agent与业务Container部署在同一Pod中，利用Pod的共享IPC特性及Memory Medium EmptyDir Volume方式共享内存进行通信更新配置，随业务容器化部署上线；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;agent通过&lt;a href=&#34;https://github.com/openkruise/kruise&#34;&gt;OpenKruise&lt;/a&gt; SidecarSet部署在SideCar容器中；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;references&#34;&gt;references&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Qihoo360/QConf/wiki&#34;&gt;QConf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.apolloconfig.com/#/zh/design/apollo-design&#34;&gt;apollo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://icyfenix.cn/distribution/connect/service-discovery.html&#34;&gt;凤凰架构-service-discovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/341060&#34;&gt;etcd-watch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redisbook.readthedocs.io/en/latest/feature/pubsub.html&#34;&gt;redis-pub/sub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzU4NzU0MDIzOQ==&amp;amp;mid=2247490475&amp;amp;idx=2&amp;amp;sn=83e79449b409c363239de1b37b96f8c8&#34;&gt;Service Mesh 在超大规模场景下的落地挑战&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>共享内存与内存映射(mmap)「转载的哦」</title>
      <link>https://weedge.github.io/%E8%BD%AC%E8%BD%BD/mmap/</link>
      <pubDate>Tue, 16 Nov 2021 11:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/%E8%BD%AC%E8%BD%BD/mmap/</guid>
      
        <description>&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;from: &lt;a href=&#34;https://www.cnblogs.com/huangfuyuan/p/9476951.html&#34;&gt;https://www.cnblogs.com/huangfuyuan/p/9476951.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先关于共享内存的链接：&lt;a href=&#34;http://blog.csdn.net/qq_26768741/article/details/56014845&#34;&gt;共享内存&lt;/a&gt;。&lt;strong&gt;里面包含了创建共享内存区域的函数，以及两个进程怎么挂载共享内存通信，分离、释放共享内存&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;共享内存的好处就是效率高，不需要太多次的进行数据的copy。可以直接进行读写内存。所以，相对来说在IPC进程间通信三大主题（消息队列，信号量，共享内存）里面，共享内存要比消息队列使用多，而且消息队列只在有血缘关系的进程间通信；但是，共享内存不保证同步，可以使用信号量来保证共享内存同步。&lt;strong&gt;Linux中的两种共享内存&lt;/strong&gt;。一种是我们的IPC通信System V版本的共享内存，另外的一种就是我们今天提到的存储映射I/O（mmap函数），当然还有一种POSIX的共享内存，它是在mmap基础之上构建的。&lt;/p&gt;
&lt;h2 id=&#34;mmap&#34;&gt;mmap&lt;/h2&gt;
&lt;p&gt;mmap I/O的描述符间接说明内存映射是对文件操作。另外，mmap另外可以在无亲缘的进程之间提供共享内存区。这样，类似的两个进程之间就是可以进行了通信。&lt;/p&gt;
&lt;p&gt;Linux提供了内存映射函数mmap, 它把文件内容映射到一段内存上(准确说是&lt;strong&gt;虚拟内存&lt;/strong&gt;上，运行着进程), &lt;strong&gt;通过对这段内存的读取和修改, 实现对文件的读取和修改&lt;/strong&gt;。mmap()系统调用使得进程之间可以通过映射一个普通的文件实现共享内存。&lt;strong&gt;普通文件映射到进程地址空间后，进程可以像访问内存的方式对文件进行访问，不需要其他内核态的系统调用(read,write)去操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里是讲设备或者硬盘存储的一块空间映射到物理内存，然后操作这块物理内存就是在操作实际的硬盘空间，不需要经过内核态传递。比如你的硬盘上有一个文件，你可以使用linux系统提供的mmap接口，将这个文件映射到进程一块虚拟地址空间，这块空间会对应一块物理内存，当你读写这块物理空间的时候，就是在读取实际的磁盘文件，就是这么直接高效。&lt;strong&gt;通常诸如共享库的加载都是通过内存映射的方式加载到物理内存的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;mmap系统调用并不完全是为了共享内存来设计的，它本身提供了不同于一般对&lt;strong&gt;普通文件&lt;/strong&gt;的访问的方式，进程可以像读写内存一样对普通文件进行操作（无需系统调用），IPC的共享内存是纯粹为了共享。&lt;/p&gt;
&lt;h3 id=&#34;mmap系统调用介绍&#34;&gt;mmap系统调用介绍&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这就是mmap系统调用的接口，mmap函数成功返回指向内存区域的指针，失败返回MAP_FAILED。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;addr，某个特定的地址作为起始地址，当被设置为NULL，标识系统自动分配地址。实实在在的物理区域。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;length说的是内存段的长度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;prot是用来设定内存段的访问权限。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;prot参数&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PROT_READ&lt;/td&gt;
&lt;td&gt;内存段可读&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PROT_WRITE&lt;/td&gt;
&lt;td&gt;内存段可写&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PROT_EXEC&lt;/td&gt;
&lt;td&gt;内存段可执行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PROT_NONE&lt;/td&gt;
&lt;td&gt;内存段不能被访问&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;fd参数是用来被映射文件对应的文件描述符。通过open系统调用得到。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;flags参数&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;MAP_SHARED&lt;/td&gt;
&lt;td&gt;进程间共享内存，对该内存段修改反映到映射文件中。提供了POSIX共享内存&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAP_PRIVATE&lt;/td&gt;
&lt;td&gt;内存段为调用进程所私有。对该内存段的修改不会反映到映射文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAP_ANNOYMOUS&lt;/td&gt;
&lt;td&gt;这段内存不是从文件映射而来的。内容被初始化为全0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAP_FIXED&lt;/td&gt;
&lt;td&gt;内存段必须位于start参数指定的地址处，start必须是页大小的整数倍（4K整数倍）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAP_HUGETLB&lt;/td&gt;
&lt;td&gt;按照大内存页面来分配内存空间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offset设定从何处进行映射。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mmap用于共享内存的方式&#34;&gt;mmap用于共享内存的方式&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;我们可以使用普通文件进行提供内存映射，例如，open系统调用打开一个文件，然后进行mmap操作，得到共享内存，这种方式适用于任何进程之间。&lt;/li&gt;
&lt;li&gt;以使用特殊文件进行匿名内存映射，这个相对的是具有血缘关系的进程之间，当父进程调用mmap，然后进行fork，这样父进程创建的子进程会继承父进程匿名映射后的地址空间，这样，父子进程之间就可以进行通信了。相当于是mmap的返回地址此时是父子进程同时来维护。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;另外&lt;a href=&#34;https://www.cnblogs.com/LubinLew/p/POSIX-shared_memory.html&#34;&gt;POSIX版本的共享内存&lt;/a&gt;底层也是使用了mmap。所以，共享内存在在posix上一定程度上就是指的内存映射了&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;mmap和system-v共享内存的比较&#34;&gt;mmap和System V共享内存的比较&lt;/h2&gt;
&lt;h3 id=&#34;system-v版本的共享内存以下我们统称为shm&#34;&gt;System V版本的共享内存（以下我们统称为shm）&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://gitee.com/lienhui68/picStore/raw/master/null/20200917180539.png&#34; alt=&#34;https://gitee.com/lienhui68/picStore/raw/master/null/20200917180539.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;mmap版本的共享内存&#34;&gt;mmap版本的共享内存&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://gitee.com/lienhui68/picStore/raw/master/null/20200917180729.png&#34; alt=&#34;https://gitee.com/lienhui68/picStore/raw/master/null/20200917180729.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;mmap是在磁盘上&lt;strong&gt;建立一个文件&lt;/strong&gt;，每个进程地址空间中开辟出一块空间进行映射。而shm共享内存，每个进程最终会&lt;strong&gt;映射到同一块物理内存&lt;/strong&gt;。shm保存在物理内存，这样读写的速度肯定要比磁盘要快，但是存储量不是特别大。&lt;/li&gt;
&lt;li&gt;相对于shm来说，mmap更加简单，调用更加方便，所以这也是大家都喜欢用的原因。&lt;/li&gt;
&lt;li&gt;另外mmap有一个好处是当机器重启，因为mmap把文件保存在磁盘上，这个文件还保存了操作系统同步的映像，所以mmap不会丢失，但是shmget在内存里面就会丢失。&lt;/li&gt;
&lt;li&gt;总之，shm是在内存中创建空间，每个进程映射到此处。内存映射是创建一个文件，并且映射到每个进程开辟的空间中。&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>工具盒子-ping/traceroute</title>
      <link>https://weedge.github.io/post/ping/</link>
      <pubDate>Mon, 15 Nov 2021 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/ping/</guid>
      
        <description>&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;p&gt;在访问网络是否ok, 通常喜欢用ping 命令来访问&lt;code&gt;ping www.baidu.com&lt;/code&gt; 看是否出现超时；ping在不同的操作系统平台实现方式差不多，底层都是用ICMP协议，每次发ICMP ECHO_REQUEST packet (IP地址/Host, ttl，icmp_seq序列号，&lt;a href=&#34;https://en.wikipedia.org/wiki/Round-trip_delay&#34;&gt;RTD/RTT&lt;/a&gt;(往返延时)记录 ),  运行结束后统计每个RTT, 最大RTT, 最小RTT, 平均RTT, &lt;a href=&#34;https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford&#34;&gt;标准偏差&lt;/a&gt;RTT, 发送/接受packets总数，丢包率 等数据，ping工具在PING(8)中的定义如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The ping utility uses the ICMP protocol&amp;rsquo;s mandatory ECHO_REQUEST datagram to elicit an ICMP ECHO_RESPONSE from a host or gateway.  ECHO_REQUEST datagrams  (&amp;ldquo;pings&#39;&#39;) have an IP and ICMP header, followed by a &amp;ldquo;struct timeval&#39;&#39; and then an arbitrary number of &amp;ldquo;pad&amp;rdquo; bytes used to fill out the packet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;icmphttpsenwikipediaorgwikiinternet_control_message_protocol&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol&#34;&gt;ICMP&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;互联网控制消息协议&lt;/strong&gt;（英语：&lt;strong&gt;I&lt;/strong&gt;nternet &lt;strong&gt;C&lt;/strong&gt;ontrol &lt;strong&gt;M&lt;/strong&gt;essage &lt;strong&gt;P&lt;/strong&gt;rotocol，缩写：&lt;strong&gt;ICMP&lt;/strong&gt;）是&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91&#34;&gt;互联网&lt;/a&gt;协议族的核心协议之一。它用于&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%BD%91%E9%99%85%E5%8D%8F%E8%AE%AE&#34;&gt;网际协议&lt;/a&gt;（IP）中发送控制消息，提供可能发生在通信环境中的各种问题反馈。通过这些信息，使管理者可以对所发生的问题作出诊断，然后采取适当的措施解决；使用在网络设备上，比如交换机，路由器&lt;/p&gt;
&lt;h3 id=&#34;为毛icmp设计在网络层呢&#34;&gt;为毛ICMP设计在网络层呢？&lt;/h3&gt;
&lt;p&gt;因为需要目的地址ip, 链路层无法通过ip socket编程，那为啥不用链路层的MAC地址呢？因为链路层的MAC地址只在局域网唯一，由交换机学习缓存策略决定(会缓存MAC地址，用于跳转)，如果广域网访问不同局域网，MAC地址可以不唯一(网络历史演变原因)，但是公网IP地址是全局唯一，相互转化通过NAT路由器(具体介绍看wiki: &lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_address_translation&#34;&gt;Network address translation&lt;/a&gt;&lt;/strong&gt;)； 如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/lib/main/net/NAT.png&#34; alt=&#34;NAT&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果在传输层的话，无需端口多了一次解包；ICMP与&lt;a href=&#34;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&#34;&gt;TCP&lt;/a&gt;、&lt;a href=&#34;https://en.wikipedia.org/wiki/User_Datagram_Protocol&#34;&gt;UDP&lt;/a&gt;等&lt;a href=&#34;https://en.wikipedia.org/wiki/Transport_protocol&#34;&gt;传输协议&lt;/a&gt;不同因为它通常不用于在系统之间交换数据，也不经常被最终用户网络应用程序使用（除了一些诊断工具，如&lt;a href=&#34;https://en.wikipedia.org/wiki/Ping_(networking_utility)&#34;&gt;ping&lt;/a&gt;和&lt;a href=&#34;https://en.wikipedia.org/wiki/Traceroute&#34;&gt;traceroute&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;ICMP 依靠ip来完成它的任务，它是ip的主要部分。它与传输协议（如&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE&#34;&gt;TCP&lt;/a&gt;和&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE&#34;&gt;UDP&lt;/a&gt;）显著不同：它一般不用于在两点间传输数据。它通常不由网络程序直接使用，除了 &lt;a href=&#34;https://zh.wikipedia.org/wiki/Ping&#34;&gt;ping&lt;/a&gt; 和 &lt;a href=&#34;https://zh.wikipedia.org/wiki/Traceroute&#34;&gt;traceroute&lt;/a&gt; 这两个特别的例子。 &lt;a href=&#34;https://zh.wikipedia.org/wiki/IPv4&#34;&gt;IPv4&lt;/a&gt;中的ICMP被称作ICMPv4，&lt;a href=&#34;https://zh.wikipedia.org/wiki/IPv6&#34;&gt;IPv6&lt;/a&gt;中的ICMP则被称作&lt;a href=&#34;https://zh.wikipedia.org/wiki/ICMPv6&#34;&gt;ICMPv6&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;pinghttpsenwikipediaorgwikiping_networking_utility&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Ping_(networking_utility)&#34;&gt;ping&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Ping (Packet Internet Grope)，因特网包探索器，用于测试网络连接量的程序。Ping发送一个ICMP回声请求消息给目的地并报告是否收到所希望的ICMP回声应答；具体流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/lib/main/net/ping-icmp.png&#34; alt=&#34;ping-icmp&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TTL&lt;/strong&gt;： 生存时间，指定&lt;!-- raw HTML omitted --&gt;数据包被路由器丢弃之前允许通过的网段数量&lt;!-- raw HTML omitted --&gt;；&lt;!-- raw HTML omitted --&gt;&lt;strong&gt;TTL 是由发送主机设置的，当其存活次数为0时，路由器便会取消数据包并发送一个ICMP TTL数据包给原数据包的发出者, 以防止数据包不断在 ip 互联网络上永不终止地循环, 而无法送达及耗尽网络资源&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;。转发 ip 数据包时，要求路由器至少将 TTL 减小 1；TTL 字段值不同操作系统类型对应的值不同，可以通过&lt;code&gt;ping 127.0.0.1&lt;/code&gt; 本地来查看初始值,或者&lt;code&gt;sysctl -a |grep ttl &lt;/code&gt;查看对应值(macOS Darwin下是net.inet.ip.ttl, linux下是net.ipv4.ip_default_ttl)；如果不修改这些值，linux系统一般是64，window系统一般是128。&lt;/p&gt;
&lt;h2 id=&#34;traceroutehttpsenwikipediaorgwikitraceroute&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Traceroute&#34;&gt;traceroute&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;traceroute是unix系统中，诊断&lt;a href=&#34;https://en.wikipedia.org/wiki/Computer_network&#34;&gt;计算机网络&lt;/a&gt;的命令程序(windos中对应tracert命令)；用于显示可能的路线（路径）和测量的传送延迟。路由的历史记录为从路由（路径）中每个连续主机（远程节点）接收到的数据包的往返次数；每&lt;a href=&#34;https://en.wikipedia.org/wiki/Hop_(networking)&#34;&gt;跳&lt;/a&gt;平均时间的总和是建立连接所花费的总时间的度量；如果所有（通常是三个）发送的数据包丢失两次以上，连接就会丢失并且无法评估路由，否则 Traceroute 会继续。&lt;/p&gt;
&lt;p&gt;主叫方首先发出 TTL=1 的数据包，第一个路由器将 TTL 减1得0后就不再继续转发此数据包，而是返回一个 ICMP 超时报文，主叫方从超时报文中即可提取出数据包所经过的第一个网关地址。然后又发出一个 TTL=2 的 ICMP 数据包，可获得第二个网关地址，依次递增 TTL 便获取了沿途所有网关地址。&lt;/p&gt;
&lt;p&gt;需要注意的是，并不是所有网关都会如实返回 ICMP 超时报文。出于安全性考虑，大多数防火墙以及启用了防火墙功能的路由器缺省配置为不返回各种 ICMP 报文，其余路由器或&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%A4%E6%8D%A2%E6%9C%BA&#34;&gt;交换机&lt;/a&gt;也可被管理员主动修改配置变为不返回 ICMP 报文。因此 Traceroute 程序不一定能拿全所有的沿途网关地址。所以，当某个 TTL 值的数据包得不到响应时，并不能停止这一追踪过程，程序仍然会把 TTL 递增而发出下一个数据包。一直达到默认或用参数指定的追踪限制（maximum_hops）才结束追踪（没有到达目标ip, 所以收不到目标ip的ICMP报文）。&lt;/p&gt;
&lt;p&gt;而ping工具只计算从目的地点的最终往返时间。&lt;/p&gt;
&lt;p&gt;当然ping/traceroute，不一定用网络层的ICMP协议来实现，也可以用传输层的&lt;a href=&#34;https://en.wikipedia.org/wiki/User_Datagram_Protocol&#34;&gt;UDP协议&lt;/a&gt;来实现(发送udp协议报文),默认主目的主机端口是33434开始)，这个端口是有讲究的；利用了 UDP 数据包的 traceroute 程序在数据包到达真正的目的主机时，就可能因为该主机没有提供 &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE&#34;&gt;UDP&lt;/a&gt; 服务而简单将数据包抛弃，并不返回任何信息。为了解决这个问题，traceroute 故意使用了一个大于 30000 的端口号(因 UDP 协议规定端口号必须小于 30000)，所以目标主机收到数据包后唯一能做的事就是返回一个“端口不可达(ICMP PORT_UNREACHABLE)”的 ICMP 报文，于是主叫方就将端口不可达报文当作跟踪结束的标志。&lt;/p&gt;
&lt;p&gt;甚至traceroute还用&lt;a href=&#34;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&#34;&gt;TCP协议&lt;/a&gt;来实现(发送tcp协议报文)，这个需要看场景下，需要获取的测试监控数据是哪些，是否有必要建立可靠连接。比如一些traceroute 实现使用TCP 数据包，例如&lt;em&gt;tcptraceroute&lt;/em&gt;和&lt;a href=&#34;https://en.wikipedia.org/wiki/Layer_four_traceroute&#34;&gt;第四层traceroute&lt;/a&gt; (LFT)。&lt;/p&gt;
&lt;p&gt;具体使用可以参考&lt;code&gt;man traceroute&lt;/code&gt; 中的介绍，以上说的，在man文档里都有介绍到；&lt;/p&gt;
&lt;p&gt;可以通过&lt;code&gt;traceroute -P ICMP  www.baidu.com&lt;/code&gt; 使用ICMP协议来追踪每一跳的路由情况；支持ICMP, UDP(默认发送方式), TCP协议，具体见文档；&lt;/p&gt;
&lt;p&gt;如果想查看ICMP协议包的内容可以通过&lt;a href=&#34;https://gitlab.com/wireshark/wireshark/-/wikis/home&#34;&gt;Wireshark/TShark(命令)&lt;/a&gt;来抓包，主要是通过&lt;strong&gt;协议报文&lt;/strong&gt;，来分析网络问题；你会发现ping 命令程序只用到了IP/ICMP协议(send Type: 8 (Echo (ping) request)；recv Type: 0 (Echo (ping) reply) from dst ip)， 而traceroute 命令程序会用到IP/ICMP(send Type: 8 (Echo (ping) request)；recv Type: 11 (Time-to-live exceeded) code:0 from 每个路由，recv Type: 0 (Echo (ping) reply) from dst ip), IP/UDP协议(如果用UDP发送，send udp 数据报文, recv Type: 11 (Time-to-live exceeded) code:0 from  每个路由， recv Type: 3 (Destination unreachable) code:3 from dst ip)。&lt;/p&gt;
&lt;p&gt;可以分析出，ping 和 traceroute 都使用IP/ICMP协议时，traceroute 是接收了每一跳路由的响应进行处理，然后展现的每一跳累计的总耗时。流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/lib/main/net/traceroute-icmp.png&#34; alt=&#34;traceroute-icmp&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;轮子&#34;&gt;轮子&lt;/h2&gt;
&lt;p&gt;为啥要用golang重新写一个工具呢？ （已有开源的 &lt;a href=&#34;https://github.com/go-ping/ping.git&#34;&gt;go-ping&lt;/a&gt;, 支持icmp, udp (icmp.ListenPacket &lt;a href=&#34;https://godoc.org/golang.org/x/net/icmp&#34;&gt;x/net/icmp&lt;/a&gt;) 直接查看源码吧）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;平时虽然用，但是具体实现想了解下，主要是&lt;a href=&#34;https://en.wikipedia.org/w/index.php?title=Internet_Control_Message_Protocol&#34;&gt;ICMP协议&lt;/a&gt;中的控制信息(&lt;a href=&#34;https://en.wikipedia.org/w/index.php?title=Internet_Control_Message_Protocol#Control_messages&#34;&gt;Control messages&lt;/a&gt;), 以便在次协议上DIY网络需求；&lt;/li&gt;
&lt;li&gt;golang是跨系统平台编译语言，同一份代码编译运行在不同平台；&lt;/li&gt;
&lt;li&gt;可以做一些扩展，运用在K8S的编排容器中测试网络环境；因为icmp定义在网络层，只需ip，无需服务端口，利用icmp协议做一些扩展功能；比如机器是否挂了，目的ip是否不可到达了，以及做一些网络层监控等。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;reference&#34;&gt;reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Ping_(networking_utility)&#34;&gt;PING&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol&#34;&gt;ICMP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.techtarget.com/searchnetworking/definition/time-to-live&#34;&gt;TTL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_address_translation&#34;&gt;NAT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=IIicPE38O-s&#34;&gt;PING Command - Troubleshooting&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>缓存淘汰策略-LRU</title>
      <link>https://weedge.github.io/post/lru/</link>
      <pubDate>Mon, 08 Nov 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/lru/</guid>
      
        <description>&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;p&gt;​	在计算机硬件中缓/内存设计是用来机器启动的时候加载程序，分配运行空间数据，停机，缓/内存中的数据会丢失；磁盘用来持久化存储，提供数据加载到内存中，内存的读写速度比磁盘快很多，以下是&lt;a href=&#34;https://research.google/people/jeff/&#34;&gt;Jeff Dean&lt;/a&gt;  &amp;ldquo;&lt;a href=&#34;http://brenocon.com/dean_perf.html&#34;&gt;Numbers Everyone Should Know&lt;/a&gt;&amp;rdquo; 中提供的数据(虽然过去10多年了)， 读取1MB数据，从内存中读比从磁盘中读取快100+倍；但是缓/内存的空间比磁盘空间少，为了加快数据的访问，减少缓存/磁盘io，大概分为三种：1. 可以提前将数据从磁盘加载到内/缓存中(page)、2. 内/缓存miss从下层存储获取数据(cache,pool,page)、3. 无需加载，直接内/缓存evict；如果提供给进程的最大内/缓存资源到了最大限制，需要对存储资源进行evict操作，常用的evict策略可以从&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_replacement_policies&#34;&gt;Cache_replacement_policies&lt;/a&gt;中了解；有关特定于分页的详细算法，请参阅&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm&#34;&gt;页面替换算法&lt;/a&gt;；有关特定于 CPU 和 RAM 之间缓存的详细算法，请参阅&lt;a href=&#34;https://en.wikipedia.org/wiki/CPU_cache&#34;&gt;CPU 缓存&lt;/a&gt;。这里主要关注LRU evict相关策略。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;OP(io)&lt;/th&gt;
&lt;th&gt;cost&lt;!-- raw HTML omitted --&gt;（1s= 10^9ns)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;L1 cache reference 读取CPU的一级缓存&lt;/td&gt;
&lt;td&gt;0.5 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Branch mispredict(转移、分支预测)&lt;/td&gt;
&lt;td&gt;5 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;L2 cache reference 读取CPU的二级缓存&lt;/td&gt;
&lt;td&gt;7 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mutex lock/unlock 互斥锁\解锁&lt;/td&gt;
&lt;td&gt;100 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Main memory reference 读取内存数据&lt;/td&gt;
&lt;td&gt;100 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Compress 1K bytes with Zippy 1k字节压缩&lt;/td&gt;
&lt;td&gt;10,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Send 2K bytes over 1 Gbps network 在1Gbps的网络上发送2k字节&lt;/td&gt;
&lt;td&gt;20,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read 1 MB sequentially from memory 从内存顺序读取1MB&lt;/td&gt;
&lt;td&gt;250,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Round trip within same datacenter 从一个数据中心往返一次，ping一下&lt;/td&gt;
&lt;td&gt;500,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Disk seek  磁盘搜索&lt;/td&gt;
&lt;td&gt;10,000,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read 1 MB sequentially from network 从网络上顺序读取1兆的数据&lt;/td&gt;
&lt;td&gt;10,000,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read 1 MB sequentially from disk 从磁盘里面读出1MB&lt;/td&gt;
&lt;td&gt;30,000,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Send packet CA-&amp;gt;Netherlands-&amp;gt;CA 一个包的一次远程访问&lt;/td&gt;
&lt;td&gt;150,000,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;lru算法&#34;&gt;LRU算法&lt;/h2&gt;
&lt;p&gt;​	LRU(least recently used)是一种缓存 evict 策略算法：在缓存有限的情况下，如果有新的数据需要加载进缓存，则需要将最不可能被继续访问的缓存剔除掉。这是一种提前预判假设的算法，因为缓存是否可能被访问到没法做预测的，所以假设 &lt;strong&gt;一个key经常被访问，那么该key的idle time应该是最小的。&lt;/strong&gt; (但这个假设也是基于概率，并不是充要条件,很明显,idle time最小的,甚至都不一定会被再次访问到)。&lt;/p&gt;
&lt;p&gt;​	LRU 的工作原理是一种时间局部性原理的假设，在过去的几条指令中使用最多的页面最有可能在接下来的几条指令中也被大量使用。&lt;/p&gt;
&lt;p&gt;​	实现方式可以采用wiki中的实现，每个缓存item中有序列号(每个新访问的增量为 1)，缓存满了将序列号最低的替换掉，这种实现需要找到最低的进行比较替换；还有种实现实现方式是通过hashMap+双向链表的方式实现，空间换时间的方式，&lt;a href=&#34;https://leetcode-cn.com/problems/lru-cache/&#34;&gt;leetcode上有这道题&lt;/a&gt;，一般面试会问到；&lt;/p&gt;
&lt;p&gt;实际工程实现中，由于实现成本，根据使用场景，考虑空间利用和时间的折中，使用的&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm#Variants_on_LRU&#34;&gt;LRU算法变体&lt;/a&gt;：(以下定义来自wiki)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm#cite_note-15&#34;&gt;LRU-K&lt;/a&gt; 驱逐过去第 K 次最近访问最远的页面。例如，LRU-1 只是 LRU，而 LRU-2 根据倒数第二次访问的时间驱逐页面。LRU-K 在时间上的局部性方面大大改进了 LRU。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm#cite_note-16&#34;&gt;ARC&lt;/a&gt; 算法通过保持最近驱逐页面的历史可LRU，并使用此选项可以更改的偏好近期或频繁访问。它对顺序扫描特别有抵抗力。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm#cite_note-17&#34;&gt;2Q&lt;/a&gt; 算法改进了 LRU 和 LRU/2 算法。通过具有两个队列，一个用于热路径项目，另一个用于慢路径项目，项目首先被放置在慢路径队列中，并且在第二次访问放置在热路径项目中的项目之后；由于对添加项的引用比 LRU 和 LRU/2 算法中的保留时间更长，因此它具有更好的热路径队列，从而提高了缓存的命中率。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_replacement_policies#Segmented_LRU_(SLRU)&#34;&gt;SLRU&lt;/a&gt; 缓存分为两个段，试用段和保护段。每个段中的行按从最近访问到最近最少访问的顺序排列。来自未命中的数据被添加到试用段最近访问的末端的缓存中。命中从它们当前所在的任何地方删除，并添加到受保护段的最近访问端。因此，受保护段中的行至少被访问了两次。&lt;/p&gt;
&lt;h2 id=&#34;本地缓存中的实现机制&#34;&gt;本地缓存中的实现机制&lt;/h2&gt;
&lt;p&gt;go语言实现的本地缓存策略中有开源方案&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/groupcache&#34;&gt;https://github.com/golang/groupcache&lt;/a&gt;  (LRU)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://github.com/dgryski/go-s4lru&#34;&gt;http://github.com/dgryski/go-s4lru&lt;/a&gt; (S4LRU)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dgryski/go-arc&#34;&gt;https://github.com/dgryski/go-arc&lt;/a&gt; (ARC)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/hashicorp/golang-lru&#34;&gt;https://github.com/hashicorp/golang-lru&lt;/a&gt; (LRU, ARC, TwoQueue)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vmihailenco/go-cache-benchmark&#34;&gt;https://github.com/vmihailenco/go-cache-benchmark&lt;/a&gt; 对不同的cache 淘汰策略的对比，引用结果：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;TinyLFU最适合少量的key(少于100k)。TinyLFU内存开销可以通过第二个参数进行调整。
Clock-pro有明显较小的内存使用大量的key(当key的数量超过 1m)。
分段LRU的内存使用量更小，但命中率不一致。
如果你需要它提供的额外功能，Ristretto仍然是一个不错的选择。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;存储组件中的实现机制&#34;&gt;存储组件中的实现机制&lt;/h2&gt;
&lt;h3 id=&#34;redis-dictsdsredisobject-lru-evict策略&#34;&gt;redis Dict(sds,redisObject) LRU evict策略&lt;/h3&gt;
&lt;p&gt;redis 是缓存数据库，缓存空间是有限的，可以指定最大内存使用空间；redis提供过期机制，给key制定过期时间，redis实现了删除这些过期key的删除策略（定期删除+惰性删除），但是还是存在问题，对于一些key没有设置过期时间，总会到最大内存使用空间，需要实现内存淘汰回收策略，其中策略就是LRU, 操作对象分为全部key (allkeys-lru) 和 过期key(volatile-lru)；这里整体介绍下redis缓存策略，然后单独介绍对应的redis LRU evict策略:&lt;/p&gt;
&lt;h4 id=&#34;最大内存配置选项&#34;&gt;最大内存配置选项&lt;/h4&gt;
&lt;p&gt;maxmemory 配置选项使用来配置 Redis 的存储数据所能使用的最大内存限制。可以通过在内置文件redis.conf中配置，也可在Redis运行时通过命令CONFIG SET来配置。例如，我们要配置内存上限是100M的Redis缓存，那么我们可以在 redis.conf 配置如下：maxmemory 100mb&lt;/p&gt;
&lt;p&gt;设置 maxmemory 为 0 表示没有内存限制。在 64-bit 系统中，默认是 0 无限制，但是在 32-bit 系统中默认是 3GB。当存储数据达到限制时，Redis 会根据情形选择不同策略，或者返回errors（这样会导致浪费更多的内存），或者清除一些旧数据回收内存来添加新数据。&lt;/p&gt;
&lt;h4 id=&#34;惰性释放的策略&#34;&gt;惰性释放的策略&lt;/h4&gt;
&lt;p&gt;应用这种策略的原因在于对于某些数据对象的释放需要消耗过多的系统资源，如果在&lt;em&gt;Redis&lt;/em&gt;的主线程中采用同步的方式去删除以及释放这样的&lt;em&gt;key-value&lt;/em&gt;数据，那么会导致系统长时间的阻塞在释放数据操作上，而无法处理其他的业务逻辑。对于这种情况，我们以惰性释放的策略，使用一个后台线程，通过异步的方式来对数据对象进行释放，无疑是一种较为合适的选择，可配置三种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;redisServer.lazyfree_lazy_eviction： 是否在淘汰某个&lt;em&gt;key&lt;/em&gt;时，使用惰性释放策略；这个在内存淘汰策略异步释放会用到；&lt;/li&gt;
&lt;li&gt;redisServer.lazyfree_lazy_expire：是否在过期某个&lt;em&gt;key&lt;/em&gt;时，使用惰性释放策略;&lt;/li&gt;
&lt;li&gt;redisServer.lazyfree_lazy_server_del: 服务器端删除某个&lt;em&gt;key&lt;/em&gt;时，是否使用惰性释放策略;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;过期删除缓存策略&#34;&gt;过期删除缓存策略&lt;/h4&gt;
&lt;p&gt;分为定期删除，惰性删除, 两种策略配合使用：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定期删除&lt;/strong&gt; 指的是Redis默认会每隔一定时间（默认100ms）就会&lt;!-- raw HTML omitted --&gt;抽取一批设置了过期时间的key&lt;!-- raw HTML omitted --&gt;来检测是否过期，过期就删除。&lt;/p&gt;
&lt;p&gt;在Redis2.6版本中，规定每秒运行10次，大概100ms运行一次。在Redis2.8版本后，可以通过修改配置文件redis.conf 的 &lt;strong&gt;hz&lt;/strong&gt; 选项来调整每秒次数(一般用默认值， 过高会的cpu造成一定压力)。由redis.c/activeExpireCycle 函数实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;惰性删除&lt;/strong&gt; 在获取某个Key时Redis会先检测一下，这个key是否设置了过期时间？如果设置了过期时间那么是否过期？过期就删除。由 db.c/expireIfNeeded 函数实现。&lt;/p&gt;
&lt;p&gt;如果定期抽取一批过期key删除, 以及没有对过期key访问了，这样会存在大量过期key未删除回收的情况，会导致内存使用率大大降低；所以redis内部提供了不同的内存淘汰回收策略。&lt;/p&gt;
&lt;h4 id=&#34;内存淘汰回收策略&#34;&gt;内存淘汰回收策略&lt;/h4&gt;
&lt;p&gt;当内存达到限制时，Redis 具体的回收策略是通过 maxmemory-policy 配置项配置的。&lt;/p&gt;
&lt;p&gt;以下的策略都是可用的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;noenviction：不清除数据，只是返回错误，这样会导致浪费掉更多的内存，对大多数写命令（DEL 命令和其他的少数命令例外）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allkeys-lru：从所有的数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰，以供新数据使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰，以供新数据使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allkeys-random：从所有数据集（server.db[i].dict）中任意选择数据淘汰，以供新数据使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰，以供新数据使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰，以供新数据使用&lt;/p&gt;
&lt;p&gt;从 Redis 4.0 版开始，引入了新的 LFU（最近最不常用）策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;volatile-lfu：从已设置过期时间的数据集（server.db[i].expires）中挑选近似 LFU 数据淘汰。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allkeys-lfu：从所有的数据集（server.db[i].dict）中挑选近似 LFU 数据淘汰。&lt;/p&gt;
&lt;p&gt;LFU 类似于 LRU：它使用一个概率计数器，称为&lt;a href=&#34;https://en.wikipedia.org/wiki/Approximate_counting_algorithm&#34;&gt;莫里斯计数器&lt;/a&gt;，以便仅使用每个对象的几位来估计对象访问频率，并结合衰减周期，以便计数器随着时间的推移而减少：在某些时候，我们不再希望将key视为经常访问的key，即使它们过去是这样，以便算法可以适应访问的转变。LFU具有可调参数:  （见：&lt;a href=&#34;http://antirez.com/news/109&#34;&gt;Random notes on improving the Redis LRU algorithm&lt;/a&gt; Least Frequently Used)&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;lfu-log-factor 10 //在大约一百万个请求时使计数器饱和因子，计数器对数因子会改变需要多少次命中才能使频率计数器饱和，这恰好在 0-255 的范围内。系数越高，需要越多的访问以达到最大值。系数越低，低访问计数器的分辨率越好，见redis示例redis.conf文件
lfu-decay-time 1 //每一分钟衰减一次计数器。
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当 cache 中没有符合清除条件的 key 时，回收策略 volatile-lru, volatile-random 和volatile-ttl 将会和 策略 noeviction 一样返回错误。选择正确的回收策略是很重要的，取决于你的应用程序的访问模式。但是，你可以在程序运行时重新配置策略，使用 INFO 输出来监控缓存命中和错过的次数，以调优你的设置。&lt;/p&gt;
&lt;p&gt;普适经验规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果期望用户请求呈现幂律分布(power-law distribution)，也就是，期望一部分子集元素被访问得远比其他元素多时，可以使用allkeys-lru策略。在你不确定时这是一个好的选择。&lt;/li&gt;
&lt;li&gt;如果期望是循环周期的访问，所有的键被连续扫描，或者期望请求符合平均分布(每个元素以相同的概率被访问)，可以使用allkeys-random策略。&lt;/li&gt;
&lt;li&gt;如果你期望能让 Redis 通过使用你创建缓存对象的时候设置的TTL值，确定哪些对象应该是较好的清除候选项，可以使用volatile-ttl策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当你想使用单个Redis实例来实现缓存和持久化一些键，allkeys-lru和volatile-random策略会很有用。但是，通常最好是运行两个Redis实例来解决这个问题。&lt;/p&gt;
&lt;p&gt;另外值得注意的是，为键设置过期时间需要消耗内存，所以使用像allkeys-lru这样的策略会更高效，因为在内存压力下没有必要为键的回收设置过期时间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;回收过程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;理解回收过程是运作流程非常的重要，回收过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个客户端运行一个新命令，添加了新数据。&lt;/li&gt;
&lt;li&gt;Redis检查内存使用情况，如果大于maxmemory限制，根据策略来回收键。&lt;/li&gt;
&lt;li&gt;一个新的命令被执行，如此等等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们添加数据时通过检查，然后回收键以返回到限制以下，来连续不断的穿越内存限制的边界。如果一个命令导致大量的内存被占用(比如一个很大的集合保存到一个新的键)，那么内存限制很快就会被这个明显的内存量所超越。&lt;/p&gt;
&lt;h4 id=&#34;近似lru算法&#34;&gt;近似LRU算法&lt;/h4&gt;
&lt;p&gt;Redis整体上是一个大的dict，如果实现一个双向链表需要在每个key上首先增加两个指针，需要16个字节，并且额外需要一个list结构体去存储该双向链表的头尾节点信息。Redis作者认为这样实现不仅内存占用太大，而且可能导致性能降低。具体详见作者博客文章：&lt;a href=&#34;http://antirez.com/news/109&#34;&gt;Random notes on improving the Redis LRU algorithm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  &lt;strong&gt;Redis为什么不使用原生LRU算法？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原生LRU算法需要 双向链表 来管理数据，需要&lt;strong&gt;额外内存&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;数据访问时涉及&lt;strong&gt;数据移动，有性能损耗&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;Redis现有&lt;strong&gt;数据结构需要改造&lt;/strong&gt;，dictEntry, key指向sds, val指向redisObject，dictEntry 是个单向链表；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Redis的LRU算法不是一个严格的LRU实现。这意味着Redis不能选择最佳候选键来回收，也就是最久未被访问的那些键。相反，Redis 会尝试执行一个近似的LRU算法，通过采样一小部分键，然后在采样键中回收最适合(拥有最久访问时间)的那个。然而，从Redis3.0开始，算法被改进为维护一个回收候选键池。这改善了算法的性能，使得更接近于真实的LRU算法的行为。Redis的LRU算法有一点很重要，你可以调整算法的精度，通过改变每次回收时检查的采样数量。这个参数可以通过如下配置指令：&lt;code&gt;maxmemory-samples 5&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Redis没有使用真实的LRU实现的原因，是因为这会消耗更多的内存。然而，近似值对使用Redis的应用来说基本上也是等价的。文章&lt;a href=&#34;https://redis.io/topics/lru-cache&#34;&gt;Using Redis as an LRU cache&lt;/a&gt;为Redis使用的LRU近似值和真实LRU之间的比较。&lt;/p&gt;
&lt;p&gt; 触发时机是在redis server执行新的写命令时, 当 mem_used &amp;gt; maxmemory 的时候，通过 &lt;a href=&#34;https://github.com/redis/redis/blob/c1718f9d862267bc44b2a326cdc8cb1ca5b81a39/src/evict.c#L531:5&#34;&gt;performEvictions&lt;/a&gt; 方法完成数据淘汰(所看的Redis6.2.6源码)。LRU策略淘汰核心逻辑在 &lt;a href=&#34;https://github.com/redis/redis/blob/c1718f9d862267bc44b2a326cdc8cb1ca5b81a39/src/evict.c#L145:6&#34;&gt;evictionPoolPopulate&lt;/a&gt;（淘汰数据集合填充） 方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Redis6.2.6 淘汰策略整体逻辑&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/lib/blob/main/client/redis/redis-lru.png?raw=true&#34; alt=&#34;redis-lru&#34;&gt;&lt;/p&gt;
&lt;p&gt;key访问变更策略值(用于计算idle)：&lt;/p&gt;
&lt;p&gt;在Redis的dict中每次按key获取一个值的时候，都会调用&lt;code&gt;lookupKey&lt;/code&gt;函数，前提是没有fork出来的saving子进程(会触发copy on write)
如果配置使用了LRU模式,该函数&lt;code&gt;LRU_CLOCK&lt;/code&gt;会更新val-&amp;gt;redisObject中的lru字段为当前秒级别的时间戳, 在估算idle time的时候，&lt;code&gt;estimateObjectIdleTime&lt;/code&gt;会再次调用&lt;code&gt;LRU_CLOCK&lt;/code&gt;获取时间戳和最近一次val-&amp;gt;redisObject中的lru相减获取idle；
为后面的样本池中获取bestKey来淘汰删除。&lt;/p&gt;
&lt;p&gt;采样方法：&lt;/p&gt;
&lt;p&gt;遍历数据库，根据淘汰策略从dict(没有过期时间的key)还是expires(有过期时间的key)中获取随机&lt;code&gt;maxmemory_samples&lt;/code&gt;个样本，放入&lt;code&gt;static struct evictionPoolEntry *EvictionPoolLRU&lt;/code&gt; pool样本池中。样本池中的样本idle值从低到高插入排序，数据淘汰策略每次选择idle最高数据进行淘汰释放(根据配置是否开启惰性淘汰策略释放异步释放还是同步释放)；样本池大小是&lt;code&gt;EVPOOL_SIZE 16&lt;/code&gt;，所以采集样本要根据自己的idle值大小或池中是否有空位来确定是否成功插入样本池中，如果池中没有空位，或者被插入样本的idle值都小于池子中的数据，那插入将会失败；这样样本池中一致存放idle最大，最大几率被淘汰的key(sds)样本(通过key找到dictEntry中的val-&amp;gt;redisObject 去释放)。&lt;/p&gt;
&lt;p&gt;Idle获取：&lt;/p&gt;
&lt;p&gt;如果是LRU策略：estimateObjectIdleTime(o)  获取redisObject 的 idle 时间，一个key经常被访问，那么该key的idle time应该是最小；
如果是LFU策略：255-LFUDecrAndReturn(o) 最大使用频率255减去redisObject的使用频率，所以最小使用频率，idle越大；
如果是已过期中淘汰策略： ULLONG_MAX - (long)dictGetVal(de);  过期越早越好；
pool中按idle从小到大插入排序，便于获取bestKey,用于删除。&lt;/p&gt;
&lt;p&gt;淘汰删除策略：&lt;/p&gt;
&lt;p&gt;如果开启惰性淘汰策略，则使用dbAsyncDelete 异步回收只释放key, 不会对主线程造成过大的负担，否则使用dbSyncDelete同步回收；
异步回收如果释放对象数目&amp;gt;64, 将对象创建job加入lazy free list；通知&lt;code&gt;signal type: bio_lazy_free&lt;/code&gt;回收处理线程进行回收；
这两种操作都是会将key从数据库的键空间中移除，唯一的区别就在于，对value数据的释放，是同步操作还是异步操作。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/redis/redis/blob/79ac57561f268814babe212c9216efe45cfdf937/src/server.c#L5330&#34;&gt;触发代码在server.c中&lt;/a&gt;：activeExpireCycle performEvictions 函数 在 &lt;a href=&#34;https://github.com/redis/redis/blob/b71c5849e3e5c040b029c6e25cec2069d70760c1/README.md#serverc&#34;&gt;server.c&lt;/a&gt; readme中有介绍什么时候触发。&lt;/p&gt;
&lt;h3 id=&#34;mysql80-innodb-page-buffer-pool-lru-evict策略&#34;&gt;Mysql8.0 InnoDB page buffer pool LRU evict策略&lt;/h3&gt;
&lt;h4 id=&#34;页page&#34;&gt;页Page&lt;/h4&gt;
&lt;p&gt;数据库的数据是放在磁盘空间以表空间存放的，加载的时候以页page为单位进行加载，页是InnoDB存储引擎磁盘管理的最小单位，每个页默认16KB；可以通过参数innodb_page_size设置(一个页内必须存储2行记录，否则就不是B+tree，而是链表了)，页面类型：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;数据页（B-tree Node）&lt;/p&gt;
&lt;p&gt;undo页（undo Log Page）&lt;/p&gt;
&lt;p&gt;系统页（System Page）&lt;/p&gt;
&lt;p&gt;事务数据页（Transaction system Page）&lt;/p&gt;
&lt;p&gt;插入缓冲位图页（Insert Buffer Page）&lt;/p&gt;
&lt;p&gt;插入缓冲空闲列表页（Insert Buffer Free List）&lt;/p&gt;
&lt;p&gt;未压缩的二进制大对象页（Uncompressd BLOB Page）&lt;/p&gt;
&lt;p&gt;压缩的二进制大对象页（Compressd BLOB Page）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://blogstatic.haohtml.com/uploads/2019/08/innodb_engine_struct.png&#34; alt=&#34;innodb_engine_struct&#34;&gt;&lt;/p&gt;
&lt;p&gt;从InnoDB存储引擎的逻辑结构看，所有数据都被逻辑地存放在一个空间内，称为表空间(tablespace)，而表空间由段（sengment）、区（extent）、页（page）组成。 在一些文档中extend又称块（block）。这里有几个概念简单介绍下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;表空间（Tablespace）&lt;/strong&gt; 是一个逻辑容器，表空间存储的对象是段，在一个表空间中可以有一个或多个段，但是一个段只能属于一个表空间。数据库由一个或多个表空间组成，表空间从管理上可以划分为&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-system-tablespace.html&#34;&gt;系统表空间&lt;/a&gt;、&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-file-per-table-tablespaces.html&#34;&gt;File-per-table 表空间&lt;/a&gt;、&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/general-tablespaces.html&#34;&gt;通用表空间&lt;/a&gt;、&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-undo-tablespaces.html&#34;&gt;撤销表空间&lt;/a&gt;、&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-temporary-tablespace.html&#34;&gt;临时表空间&lt;/a&gt;。(表空间文件可以通过xxd进行分析)&lt;/p&gt;
&lt;p&gt;在 InnoDB 中存在两种表空间的类型：共享表空间(例如系统表空间或通用表空间)和独立表空间(File-per-table 表空间)。如果是共享表空间就意味着多张表共用一个表空间。如果是独立表空间，就意味着每张表有一个独立的表空间，也就是数据和索引信息都会保存在自己的表空间中。独立的表空间可以在不同的数据库之间进行迁移。禁用&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_file_per_table&#34;&gt;&lt;code&gt;innodb_file_per_table&lt;/code&gt;&lt;/a&gt; 会在系统表空间中创建表。&lt;/p&gt;
&lt;p&gt;mysql8.0 InnoDB存储引擎对磁盘结构中的表空间操作有些改变：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;8.0版本中，系统表空间只是更改缓冲区的存储区域；以前版本是InnoDB数据字典、双写缓冲区、更改缓冲区和撤消日志的存储区域 。(如果表是在系统表空间中创建的，而不是在每个表文件或通用表空间中创建，则它还可能包含表和索引数据)&lt;/li&gt;
&lt;li&gt;在8.0以前的 MySQL 版本中，系统表空间包含InnoDB数据字典mysql.* 。在 MySQL 8.0 中InnoDB将元数据存储在 MySQL 数据字典表空间中，表结构等数据字典元数据都是通过InnoDB来管理(mysql.ibd或者独立表空间*.ibd文件中）。&lt;/li&gt;
&lt;li&gt;在 MySQL 8.0.20 之前，doublewrite 缓冲区存储区位于InnoDB系统表空间中；从 MySQL 8.0.20 开始，双写缓冲区存储区域位于双写文件中。附上官方mysql8.0 InnoDB存储引擎架构图(对比 &lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html&#34;&gt;5.7版本架构&lt;/a&gt;)：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/innodb-architecture.png&#34; alt=&#34;innodb-architecture&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;段（Segment）&lt;/strong&gt; 由一个或多个区组成，区在文件系统是一个连续分配的空间（在 InnoDB 中是连续的 64 个页），不过在段中不要求区与区之间是相邻的。段是数据库中的分配单位，不同类型的数据库对象以不同的段形式存在。当我们创建数据表、索引的时候，就会相应创建对应的段，比如创建一张表时会创建一个表段，创建一个索引时会创建一个索引段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;区（extent）&lt;/strong&gt; 在 InnoDB 存储引擎中，一个区会分配 64 个连续的页。因为 InnoDB 中的页大小默认是 16KB，所以一个区的大小是 64*16KB=1MB。在任何情况下每个区大小都为1MB，为了保证页的连续性，InnoDB存储引擎每次从磁盘一次申请4-5个区。默认情况下，InnoDB存储引擎的页大小为16KB，即一个区中有64个连续的页。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;页（page）&lt;/strong&gt; 是InnoDB存储引擎磁盘管理的最小单位，每个页默认16KB，页结构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blogstatic.haohtml.com/uploads/2019/08/1d49c975639e53fe92466f0b1ebe2b2a99672e8b-1024x828.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Page directory 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录，这样方便二分查找快速定位到记录；&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blogstatic.haohtml.com/uploads/2019/08/innodb-page-dir-1024x959.jpg&#34; alt=&#34;page-slot&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;行（row）&lt;/strong&gt; InnoDB存储引擎是按行进行存放的，每个页存放的行记录也是有硬性定义的，最多允许存放16KB/2-200，即7992行记录。&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-row-format.html&#34;&gt;InnoDB 行格式&lt;/a&gt;支持四名的格式：REDUNDANT，COMPACT， DYNAMIC，和COMPRESSED，默认DYNAMIC&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;B+ 树是如何进行记录检索的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果通过 B+ 树的索引查询行记录，首先是从 B+ 树的根开始，逐层检索，直到找到&lt;strong&gt;叶子节点&lt;/strong&gt;，也就是找到对应的&lt;strong&gt;数据页&lt;/strong&gt;为止，如果数据页没在缓冲池中，将数据页加载到内存 &lt;strong&gt;缓冲池(buffer pool)&lt;/strong&gt; 中，页目录中的 &lt;strong&gt;槽(slot)&lt;/strong&gt; 采用二分查找的方式先找到一个粗略的&lt;strong&gt;记录分组&lt;/strong&gt;，然后再在分组中通过链表遍历的方式查找&lt;strong&gt;记录&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;缓冲池buffer-pool--lruunzip_lru-链表&#34;&gt;缓冲池(buffer pool)  LRU/unzip_LRU 链表&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;缓冲池(buffer pool)&lt;/strong&gt; 是主内存中的一个区域，用于在 &lt;code&gt;InnoDB&lt;/code&gt;访问时缓存表和索引数据。缓冲池允许直接从内存访问经常使用的数据，从而加快处理速度。在专用服务器上，多达 80% 的物理内存通常分配给缓冲池。&lt;/p&gt;
&lt;p&gt;这里有个问题，比如有如下 场景，一个直播间id为1的观看人数上百万，假如运营后台需要查找全部数据，（这里假设没有通过CQRS模式将数据放入ES中，ES查询缓存也用到了LRU, 可以参考这篇&lt;a href=&#34;https://www.easyice.cn/archives/367&#34;&gt;Elasticsearch 的查询缓存&lt;/a&gt;）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from room_student_history where room_id=1  and id&amp;gt;=(select id from room_student_history where order by id limit 1000000,1) order by id limit 1000&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果room_student_history中有大量长尾用户数据并且读取之后不会继续使用,则LRU头部会被大量的room_student_history中的数据占据。这样会造成热点数据被逐出缓存从而导致大量的磁盘io ;&lt;/p&gt;
&lt;p&gt;mysql innodb的buffer pool使用了一种改进的LRU算法，大意是将LRU链表分成两部分，一部分为newlist,一部分为oldlist,newlist是头部热点数据，oldlist是非热点数据,oldlist默认占整个list长度的3/8.当初次加载一个page的时候，会首先放入oldlist的头部，只有满足一定条件后，才被移到new list上，主要是为了防止预读的数据页和全表扫描污染buffer pool。详细介绍见&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html&#34;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/innodb-buffer-pool-list.png&#34; alt=&#34;innodb-buffer-pool&#34;&gt;&lt;/p&gt;
&lt;p&gt;附mac下把玩操作：（单机实例，通过brew切换版本服务挺方便的；生产环境优化配置: 高可用，性能优化稳定等配置）&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;brew install &lt;a href=&#34;mailto:mysql@5.7&#34;&gt;mysql@5.7&lt;/a&gt; //安装5.7版本&lt;/li&gt;
&lt;li&gt;brew services start &lt;a href=&#34;mailto:mysql@5.7&#34;&gt;mysql@5.7&lt;/a&gt; //启动5.7版本mysqld,mysqld_safe&lt;/li&gt;
&lt;li&gt;建表，查看/usr/local/var/mysql 目录下的数据文件，可以对照 &lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html&#34;&gt;5.7版本架构&lt;/a&gt; 查看表空间文件；&lt;/li&gt;
&lt;li&gt;写些数据，查看相关数据文件的数据变化， 通过 xxd/hexdump 以十六进制的方式查看表空间二进制文件*.ibd等&lt;/li&gt;
&lt;li&gt;brew install mysql //安装最新版本8.0&lt;/li&gt;
&lt;li&gt;brew services stop &lt;a href=&#34;mailto:mysql@5.7&#34;&gt;mysql@5.7&lt;/a&gt;  //停止mysql@5.7服务&lt;/li&gt;
&lt;li&gt;brew services start mysql //启动8.0版本mysqld,mysqld_safe&lt;/li&gt;
&lt;li&gt;查看/usr/local/var/mysql 目录下的数据文件, 对比5.7版本的文件变化，新增了哪些文件分开管理, 以及对数据字典的变化&lt;/li&gt;
&lt;li&gt;/usr/local/opt/mysql/bin/ibd2sdi (utilities/ibd2sdi.cc文件)  查看ibd文件中的字典序列化信息,mysqlbinlog binlog.* 打印binlo g信息&lt;/li&gt;
&lt;li&gt;客户端命令执行show VARIABLES like &amp;ldquo;%Innodb%&amp;quot;; show status like &amp;ldquo;%Innodb%&amp;quot;; 查看Innodb参数和状态统计；&lt;/li&gt;
&lt;li&gt;客户端命令执行  SHOW ENGINE INNODB STATUS; 查看整体运行状态监控数据(io,thread, buffer pool memory, SEMAPHORES, TRANSACTIONS,INSERT BUFFER AND ADAPTIVE HASH INDEX,LOG,ROW OPERATIONS)&lt;/li&gt;
&lt;li&gt;客户端执行命令，通过dtruss -p  查看mysqld进程对应的系统调用&lt;/li&gt;
&lt;li&gt;相关的参数可以从官网查看介绍&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html&#34;&gt;Server Option, System Variable, and Status Variable Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;下载源码 &lt;a href=&#34;https://github.com/mysql/mysql-server&#34;&gt;https://github.com/mysql/mysql-server&lt;/a&gt; 8.0 版本分支，download zip文件，解压，编译，运行，gdb debug&lt;/li&gt;
&lt;li&gt;通过docker来部署： &lt;a href=&#34;https://hub.docker.com/_/mysql&#34;&gt;https://hub.docker.com/_/mysql&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;​	缓/内存io比磁盘io快许多，但是缓/内存空间有限，且无法持久化，所以需要提供缓/内存淘汰机制来保证缓/内存使用命中率，本文介绍常用的LRU算法；golang实现的开源方案，可以结合业务场景，进行使用，redis 为了节省空间，通过抽样将淘汰的数据放入待淘汰数据池(evictionPoolEntry) 进行淘汰，在 Redis 3.0 中使用 10 个样本大小，该近似值非常接近 Redis 3.0 的原始LRU理论性能。mysql 需要充分利用缓存池资源，减少磁盘io, 因为加载单元是page, 如果第一次加载放入LRU链表头，可能这些数据使用频率不高，导致缓存池命中率低，将LRU链表按3/8分成old list 和new list , 第一次加载放入oldList头，再次访问时才会移动到newlist。根据淘汰的结构，根据数据使用场景，将LRU算法优化, redis和mysql 都用到了pool, 但是是两种场景，redis是为了淘汰释放使用样本pool, 样本池中放入的是idle值，根据不同策略算出的值，用来淘汰最大的idle, 方便扩展优化算法； mysql 中的pool是buffer pool 缓冲池，主要是为了存放page, page 是innodb磁盘管理的最小单位，为了减少磁盘io, 尽量减少缓存miss, 增加hit率，提高读写操作方案。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)&#34;&gt;Cache_replacement_policies#Least_recently_used_(LRU)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Adaptive_replacement_cache&#34;&gt;Adaptive_replacement_cache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm&#34;&gt;Page_replacement_algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://antirez.com/news/109&#34;&gt;Random notes on improving the Redis LRU algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redis.io/topics/lru-cache&#34;&gt;Using Redis as an LRU cache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://brenocon.com/dean_perf.html&#34;&gt;Numbers Everyone Should Know&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://videolectures.net/wsdm09_dean_cblirs/&#34;&gt;Challenges in Building Large-Scale Information Retrieval Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html&#34;&gt;mysql8.0 innodb-buffer-pool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/dev/mysql-server/latest/buf0lru_8cc.html&#34;&gt;mysql8.0 source code buf0lru.cc File Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2017/11/05/&#34;&gt;MySQL · 源码分析 · InnoDB LRU List刷脏改进之路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2017/05/01/&#34;&gt;MySQL · 引擎特性 · InnoDB Buffer Pool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2021/01/06/&#34;&gt;MySQL · 源码阅读 · Innodb内存管理解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/internals/en/&#34;&gt;MySQL Internals Manual&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html&#34;&gt;Server Option, System Variable, and Status Variable Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>服务改造简述</title>
      <link>https://weedge.github.io/post/servicetransformation/</link>
      <pubDate>Tue, 26 Oct 2021 22:04:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/servicetransformation/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;随着前期业务迭代不断增多，会留下一些技术债务；用户不断累计增加，整体DAU,MAU,PV/UV的不断上升，为了符合根据组织结构和业务需求更加稳定健康的发展，需要对业务服务进行改造/重构；采用团队适合的语言开发，将服务进行分层，抽象底层模型，分离出不变/易变业务逻辑；业务改造和基础建设服务升级（整体系统认知的改变）&lt;/p&gt;
&lt;h2 id=&#34;过程&#34;&gt;过程&lt;/h2&gt;
&lt;p&gt;整体服务分为4个阶段进行简述：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;快速上线，需求多，迭代快，开发团队整体使用熟悉开发框架（效益：前期起步使用rd熟悉的开发脚本语言，支持需求快速迭代）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;后面功能复用， 建设业务中台， 直播中台，互动中台的建设，中台的请求大，采用golang进行开发，（效益：整体机器资源消耗减少, 高峰期机器负载降低)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;根据直播业务场景，抽象中台底层数据模型，（效益：减少人力，提高复用，增加整体研发效能）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;开发语言迁移， 服务模型从多进程脚本弱类型语言切到多协程强类型语言，需要适配接口&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需要梳理核心服务接口和非核心服务接口，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务上线，迁移老接口， 需要做流量的切分，新老接口的diff , 有两种方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在业务层面加上灰度策略，通过策略配置，对不同的业务id进行异步分流，一份请求数据，2份响应数据，只返回老的响应数据，新老响应数据进行diff处理；优点：业务改造方自己把控；缺点：对业务代码有侵入，如果改造灰度策略多的话，会降低业务代码逻辑稳定性；&lt;/li&gt;
&lt;li&gt;在新老服务之上加一层接口代理层，接口适配，灰度策略流量切分，新老接口diff功能 移至 接口代理层做，相当于提供一层网关服务来处理；优点： 对接口灰度进行统一管理，不会对业务代码有浸入操作；缺点：多了一层代理层，接口响应时间会有所增加，需要保证代理层的稳定性；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两种方案都可以，需要结合组织结构来考虑开发技术成本， 方案一：不需要额外的人力来支持维护代理层；方案二：需要单独的团队或者开发人员来维护代理层； 如果看整体收益的话，偏向于第二种方案，前者就是战术编程，后者就是战略编程，应该侧重战略编程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课中直播是流量突发的场景，对于服务优化改造，服务压力测试必不可少：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;接口压测，关注qps，接口响应时间，服务监控，负载等情况；&lt;/li&gt;
&lt;li&gt;全链路压侧，关注tps，整体链路调用接口响应时间耗时，总响应时间耗时，各服务监控，负载等情况；并且输出测试报表；为了不污染线上数据，需要对基础存储组件 单独部署一套影子系统，服务链路上需要加上压侧标签参数；可参考：&lt;a href=&#34;https://help.aliyun.com/document_detail/29337.html&#34;&gt;性能测试 PTS&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;保证切流过程中服务比较稳定，进行周期性引流，切流观察：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;旁路引流diff，覆盖到业务全场景的情况，diff在可接受范围内，进行下一步 流量切流&lt;/li&gt;
&lt;li&gt;为了保证服务稳定性，不出现p0,p1,p2事故，流量切换的周期一般比较长，按覆盖到的业务场景和整体服务监控情况而定，按1%、2%、10%、20%，40%，80%放量；查看客户端是否有异常以及用户的反馈工单，切流放量阶段diff还是正常进行，返回是否有问题，存放数据是否一致；没有问题，进入下一步  线上观察&lt;/li&gt;
&lt;li&gt;线上观察一段时间，会以月为单位，观察阶段主要服务流量是新改造的服务，如果发现有异动，还可以切回原来的服务；如果观察阶段没有问题，可以下掉原来的服务了；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务改造过程中，会有新的业务需求进来，如果是大的需求，开发周期比较长的项目，如果是紧急项目，只能在原有服务上进行开发，后续在迁移至新系统中；对于非紧急需求，可以暂缓压压，可以等新服务上线稳定之后，在使用新服务框架开发，上线部署，主要看需求中是否需要修改老接口，还是直接提供新接口就可以满足；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;容器化改造，上云（效益：整体测试，线上环节保持一致，节约开发测试时间；线上服务治理通过K8S+Istio,进行网格化治理, 以前部署在物理机或者虚拟机上，混部的情况，资源分配和隔离不合理，迁移后，可以充分合理利用宿主物理机/虚拟机资源，隔离，弹性扩缩容，部署上线前提条件是需要保证K8S可用性）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对不同语言服务进行容器化改造，有不同业务部门推进(主要是项目构建打包成镜像，docker的话需要编写Dockerfile)，基础的资源管理由devops提供CI(gitlab ci)/CD平台整合上线(可以部署物理机/虚拟机/部署(kubectl/istioctl)容器上云)&lt;/li&gt;
&lt;li&gt;在迁移至容器云(Kubernetes 集群中的应用)的过程中，会涉及到一部分服务容器化部署上线，一部分还是部署在物理机/虚拟机上，服务之间相互访问，容器云-&amp;gt;容器云，容器云-&amp;gt;物理机/虚拟机， 物理机/虚拟机-&amp;gt;容器云，需要业务梳理出服务之间的调用关系，然后对3种服务调用情况进行改造，其中可以使用sidecar模式进行流量输入输出&lt;/li&gt;
&lt;li&gt;通过K8S来编排服务，会出现服务治理的问题，需要可视化，监控，追查定位问题等相关平台来整合，对应的规范和开源工具整合进来，log: 采集日志，存储日志(热/冷)，查找日志；metric: 监控数据采集，监控指标，监控看板/大盘；trace: 服务请求访问链路追踪，服务调用响应时间，整体响应时间；以及k8s本身调度节点中pod资源监控&lt;/li&gt;
&lt;li&gt;部署至容器云后的整体测试，接口压侧，整体链路压侧&lt;/li&gt;
&lt;li&gt;上线后的切流方案&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;整体流程&#34;&gt;整体流程&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/cicd.png&#34; alt=&#34;cicd&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;随着业务的发展，服务不断迭代改造，涉及到业务层面抽象改造，以及基础平台服务的升级；最终目的都是为了满足日益增长的需求，缩短需求发布到上线的周期，复用，减少迭代对服务整体稳定性的影响。&lt;/p&gt;
&lt;h4 id=&#34;references&#34;&gt;References&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/practice/service-discovery-and-loadbalancing.html&#34;&gt;k8s-service-discovery-and-loadbalancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/practice/integration-registry.html&#34;&gt;istio集成服务注册中心&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/sidecar-injection.html&#34;&gt;Sidecar 模式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhaohuabing.com/post/2019-10-21-pilot-discovery-code-analysis/&#34;&gt;Istio Pilot 组件介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>工程师六大意识</title>
      <link>https://weedge.github.io/post/rd/</link>
      <pubDate>Sat, 02 Oct 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/rd/</guid>
      
        <description>&lt;h2 id=&#34;1时间意识&#34;&gt;&lt;strong&gt;1.时间意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    时间意识的终极目标是按时保质的完成工作。时间是一种宝贵的资源，由于每天工作时间的有限的而需要处理事情是复杂多变性的，为了按时保质的完成工作，我们首先需要有极强的时间意识，使用科学的时间管理策略。总的来说，时间管理就是让我们更有计划的知道需要做什么，什么时候做什么，而时间管理的难点为：事情具有突发性、完成时间难以预算性、执行力和预期不符合。&lt;/p&gt;
&lt;h3 id=&#34;11做明确计划&#34;&gt;1.1做明确计划&lt;/h3&gt;
&lt;p&gt;​    花一定的时间专门做计划，精确到小时，磨刀不误砍材工。为了做出精确的计划，提高时间的利用率，我们可以把个人时间和任务安排分块化，让同性质的任务部门分配同一段时间来处理，让零碎的时间处理细碎的问题，高效率的时间做大块重要困难的问题。&lt;/p&gt;
&lt;h3 id=&#34;12能尽快完成就尽快完成给以突发事情一定预算余地&#34;&gt;1.2能尽快完成就尽快完成，给以突发事情一定预算余地&lt;/h3&gt;
&lt;p&gt;​    即使每天计划的清清楚楚的工作安排，还是很大可能出现突发事情打乱计划，因为我们的工作性质就是这样的，需要随时待命解决突发的问题，并且很多事情是难以准确预算完成时间的，所以我们应该尽快的完成任务而不是拖到最后甚至拖到明天，这样才能最大限度的留给未知可能的处理空间。&lt;/p&gt;
&lt;p&gt;​    现在的社会处于互联网产业高速发展时期，到处充满着机遇，但是不管对企业还对个人来说又都面领着极大的竞争挑战。想要在这样的环境下生存并且前进，需要我们具有争分夺秒的意识，今天落后一步，就需要无数天的加速才能追上别人，更重要的是，身为团队的一员，很可能因为自己的一点懈怠而拖慢团队的脚步。&lt;/p&gt;
&lt;h3 id=&#34;13总结提高锻炼坚毅的性格提高执行力度&#34;&gt;1.3总结提高，锻炼坚毅的性格，提高执行力度&lt;/h3&gt;
&lt;p&gt;​    除了事情本身的多变性和竞争的激烈性，还有一点就是我们通常会高估自己的执行力，这需要我们我们进行自我管理自我约束，培养坚毅的性格，具有很强的责任心，高效率的执行力，主动的向别人汇报进度，树立起一个让自己和别人都信得过的形象。我们还需要不断的总结提高计划的准确性，看清自己，看清问题，将自己和问题准确的在时间维度上来对应起来。&lt;/p&gt;
&lt;h2 id=&#34;2质量意识&#34;&gt;&lt;strong&gt;2.质量意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    时间是宝贵的资源，但是不能为了节省时间而降低质量，时间是用来使用的，真正的节省时间就是合理高效的使用时间。欲速则不达，在复杂庞大的网络环境中，每一个小小的质量问题，都可能导致巨大的灾难，比如有可能这个灾难只是因为某一个进制转换精度损失引起的。如何保证质量，需要个人的责任心、需要团队的正确文化氛围、需要科学的质量保证流程。&lt;/p&gt;
&lt;p&gt;​    首先需要我们拥有一个保证质量的责任心，每一个人都要对质量负责，要有居安思危的意识，不能默认没问题，而是要反复核对自己的工作，不要等着别人来发现自己的问题，不要依赖流程，比如开发不能依赖测试，测试只是最后的质量检查而已，而不是保证，而且局限性小，即使测试出问题，修改也是费时费力。&lt;/p&gt;
&lt;p&gt;​    然后就是有一套科学的质量保证流程，比如需求的审核、开发的测试、上线过程评审等，质量保证工作存在于每一个环节，早发现早解决，因为越到后面挽救的代价越大。&lt;/p&gt;
&lt;h2 id=&#34;3沟通意识&#34;&gt;&lt;strong&gt;3.沟通意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    沟通的本质就是，了解他人的需要，表达自己的需要，沟通是项目成功的重要技巧之一。沟通无处不在，包括：文档、邮件、合同，更直接点的就是电话、口头。对于开发而言，代码本身就是用于沟通，所以我们要严格要求代码规范，要意识到代码是要用于沟通的，让人一看就懂的才是好代码。&lt;/p&gt;
&lt;h3 id=&#34;31沟通的态度&#34;&gt;3.1沟通的态度&lt;/h3&gt;
&lt;p&gt;​    沟通中的双发是代表各自角色的沟通，而不是个人间的沟通，也是通常我们说的 对事不对人 。因此，我们在沟通中不要忘记自己的职业角色，也不要忽视对方的职业角色。在沟通中我们要公开和坦诚地表达自己的意见，同时要有尊重别人的权利的态度，多用描述性语句，少用判断性语句，要有积极的态度。&lt;/p&gt;
&lt;h3 id=&#34;32主动沟通&#34;&gt;3.2主动沟通&lt;/h3&gt;
&lt;p&gt;​    看问题的角度不同，看法和观点会不一致，我们无法寄希望于对方主动来找我们沟通，所以为了得到好的结果，我们需要主动去沟通。所以要做好以下几点：&lt;/p&gt;
&lt;p&gt;（1）做好沟通前的准备，想好要表述的问题和想知道的问题&lt;/p&gt;
&lt;p&gt;（2）把握沟通时机，要在适当的时间、地点，同时考虑好沟通对象的状态。&lt;/p&gt;
&lt;p&gt;（3）选择好沟通方式，根据沟通紧急程度，具体问题的不同，选择合适的沟通方式，如：面谈、电话、书面（含即时通讯工具）等&lt;/p&gt;
&lt;h2 id=&#34;4团队意识&#34;&gt;&lt;strong&gt;4.团队意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    要实现目标，最重要的就是团队，我们让自己变得优秀的本质也是为了能够为团队做更大的贡献，通过团队实现个人，也通过个人贡献团队。听说这样一句话，一个中国人是一条龙，一群中国人是一群虫，这就是我们在国外人眼中缺少团队的意识。对于团队我们要有以下意识：&lt;/p&gt;
&lt;h3 id=&#34;41集体荣誉感&#34;&gt;4.1集体荣誉感&lt;/h3&gt;
&lt;p&gt;​    要有集体荣誉感，凡事看大局，每个人都是团队的一份子，不能有打酱油的心态。&lt;/p&gt;
&lt;h3 id=&#34;42建立完善的规则&#34;&gt;4.2建立完善的规则&lt;/h3&gt;
&lt;p&gt;​    没有规矩，不以成方圆，没有没有纪律的军队，不可能打胜仗。对于研发团队，统一的规则可以有效的减低沟通成本，集合整个团队的智慧，降低错误的可能性，规则要不断总结，不断优化。&lt;/p&gt;
&lt;h3 id=&#34;43团结互进&#34;&gt;4.3团结互进&lt;/h3&gt;
&lt;p&gt;​    团队之间要互相信任，乐于为别人提供帮助，乐于和善于从其他同事那里获得帮助，互相学习共同进步。开诚布公、相互尊重、相互理解，多站在对方的立场上考虑，对事不对人。团队意识不等于哥们义气、拉帮结派，也不等于好好先生，建立优秀的团队氛围。&lt;/p&gt;
&lt;h3 id=&#34;44建立强沟通&#34;&gt;4.4建立强沟通&lt;/h3&gt;
&lt;p&gt;​    团队要强调沟通意识，以各种方式建立起成员之间的联系。&lt;/p&gt;
&lt;h2 id=&#34;5进取意识&#34;&gt;&lt;strong&gt;5.进取意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    要有理想，有进取心，不断的追求更高的目标。在激烈竞争的环境，要有忧患意识，不断进步，否则迟早要淘汰。而进取意识最终要的是客服自己的心态，“破山中贼易，破心中贼难”，&lt;strong&gt;对自己的要求比别人对自己的要求更严格&lt;/strong&gt; ，客服自己的内心，加强计划性和执行力，这是见于所有能快速成长的优秀工程师所共有特质，而恰恰是那些不适应一个高速成长的团队而被淘汰掉的工程师身上所最缺乏的东西。&lt;/p&gt;
&lt;p&gt;​    要未雨绸缪，也要容忍失败。进取是为了未雨绸缪，但是进取不代表不会失败，而是指能在失败面前勇于剖析、勇于承担责任，又能自我总结经验教训、保持自己的进取心。 ¡&lt;/p&gt;
&lt;h2 id=&#34;6求实意识&#34;&gt;&lt;strong&gt;6.求实意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    实事求是，是《毛泽东思想》的精髓之一，也正是实事求是，不搞虚的，才能有高速发展的中国的今天。在实际项目中要注重事实，反对弄虚作假，大胆的假设小心地求证，一切以数据说话，用准确的数字和事实来论证，不能只有臆测的结论。&lt;/p&gt;
&lt;p&gt;​    以量化指标作为判断的依据，实际数据为王，没有量化，就没有绩效，通过这些指标衡量自己的成长和进步，通过这些指标知道工作的方向和重点。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;工程师，是从复杂的需求中，&lt;strong&gt;定义问题&lt;/strong&gt;，解决问题，给出具体方案而生的工种，不能单兵作战，需要通过高效的工具进行武装，对复杂重复通用的场景进行沉淀下移，方便其他工程师使用，所谓开源；在不断挖坑填坑中，解决特定任务，锻炼出皮实耐操的难得品格，需求虐我千百遍，我对需求如初恋；没有需求何来架构落地呢，何来量化指标，升值加薪呢～&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>组织引擎</title>
      <link>https://weedge.github.io/post/zborg/</link>
      <pubDate>Sun, 05 Sep 2021 21:04:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/zborg/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景：&lt;/h2&gt;
&lt;p&gt;教学直播间场景多样性，按年龄段区分辅导后台角色，构成整个教学课中直播和互动的多样性，为了快速支持业务发展，导致后端服务接口过多，不易维护，统一管理。&lt;/p&gt;
&lt;p&gt;主要分为如下场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;对接辅导侧后台的场景：&lt;/strong&gt; 辅导侧不同的辅导运营后台，比如：低幼辅导，班主任(班课)，督学服务，0转化督学服务等，后续可能还有小鹿编程，大师素养课对应的辅导侧；辅导侧会分班去带学生，不同的辅导侧会有单独的课中业务服务来对接辅导后台的接口，课中理解不同的业务组织形态，代码逻辑和存放数据冗余，不方便维护；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;业务前台对接直播接口场景&lt;/strong&gt;：直播业务服务多样；按照课程类型分为专题课，班课，短训班，素养课，编程课等；直播服务：班主任出镜（课前，课中，课后），小班，小组，大班，自习室等；服务的多样性，导致业务接口繁琐，前期快速开发上线，针对每个直播服务业务场景单独提供接口， 带来的问题不方便统一管理维护；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;课中互动中台互动聊天场景：&lt;/strong&gt; 大班，小班，小组直播间场景依赖售卖和辅导侧的组织结构进行聊天，答题，鼓励，PK，发红包等互动；导致课前需要对这些组织结构按照不同直播场景+不同辅导侧数据进行提前预热处理，逻辑重复；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;设计目标&#34;&gt;设计目标：&lt;/h2&gt;
&lt;p&gt;需要一个承上启下的模块来连接辅导侧支撑课中直播/回放互动场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对不同业务直播场景进行收敛，减少重复开发；&lt;/li&gt;
&lt;li&gt;隔离底层业务后台辅导侧，售卖侧数据，统一接入辅导/售卖侧全量数据，以及异动，减少数据冗余；&lt;/li&gt;
&lt;li&gt;隔离底层业务数据，抽象直播中台数据模型，中台面向这个数据模型进行编程，提供原子化接口；&lt;/li&gt;
&lt;li&gt;当天上课课前预热数据需要在0-6点尽量全部预热完成；预热加速，预热后的数据检查；&lt;/li&gt;
&lt;li&gt;复用中台数据模型已支持的直播场景能力，提供saas化服务，前台使用中台定义的dsl，根据业务场景进行组装，提高开发效率；&lt;/li&gt;
&lt;li&gt;提供可配置后台，管理服务接口；&lt;/li&gt;
&lt;li&gt;将读写io最小化，提高原子化接口响应时间RT&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;原则： 高内聚低耦合、空间换时间&lt;/p&gt;
&lt;h2 id=&#34;数据模型&#34;&gt;数据模型：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;一个章节会有多个直播间，比如辅导老师出镜(课前，课中，课后)，最多3n+1个直播间，n为课程章节下的辅导老师数目，liveRoom&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不同直播间，对应不同的直播间业务流程:  bizType&lt;/p&gt;
&lt;p&gt;三分屏直播间，进入教室→签到→直播/互动→离开(切直播间)&lt;/p&gt;
&lt;p&gt;小组直播间，进入教室→课件下载→分组→签到→直播/互动→离开(切直播间)&lt;/p&gt;
&lt;p&gt;小班直播间，进入直播间→ 课件下载→ 分班→ 直播/互动→离开(切直播间)&lt;/p&gt;
&lt;p&gt;自习室直播间，进入直播间→ 签到→直播&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不同直播间，对应不同的流媒体推拉流方案：streamPolicy&lt;/p&gt;
&lt;p&gt;三分屏直播间，rtmp + 长链接&lt;/p&gt;
&lt;p&gt;小组直播间，rtc + 长链接&lt;/p&gt;
&lt;p&gt;小班直播间，rtc + 长链接&lt;/p&gt;
&lt;p&gt;自习室直播间，rtmp + 长链接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不同组织关系对应聊天互动广播统计维度，抽象组织结构：orgPolicy, orgTree(node)&lt;/p&gt;
&lt;p&gt;一课三分屏：/课程章节,  无班主任，全员互动；课中自动生成；&lt;/p&gt;
&lt;p&gt;小英小数小语文小组直播间，/课程章节/辅导老师/{队/小组}，  辅导老师： 低幼辅导，班主任(班课)，督学服务，0转化督学服务等， 队/小组由课中学生选组自动生成；低幼辅导，班主任，督学服务，0转化督学服务提供数据；&lt;/p&gt;
&lt;p&gt;班主任小班直播间，/课程章节/辅导老师/小班，辅导老师： 低幼辅导，班主任(班课)，小班由辅导侧课前排灌班生成；低幼辅导，班主任服务提供数据；&lt;/p&gt;
&lt;p&gt;短训班，/课程章节/督学LPC/微信群，微信群有督学老师课前排灌班生产，督学服务提供数据；&lt;/p&gt;
&lt;p&gt;0转化服务，/课程章节/督学LPC , 0转化督学服务提供数据；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;lessonPolicy: (bizType,streamPolicy,orgPolicy)&lt;/p&gt;
&lt;p&gt;原则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;直播中台解耦业务属性，支持抽象业务场景，作为底层直播能力输出；&lt;/li&gt;
&lt;li&gt;可复用，直播功能，性能，稳定性的复用；比如三分屏，班课，小组，伪直播等不同维度业务属性解耦前置到预热阶段；&lt;/li&gt;
&lt;li&gt;可扩展，直播数据模型属性如有新增，不会影响原有属性；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;数据量&#34;&gt;数据量：&lt;/h2&gt;
&lt;p&gt;1天最高峰2w节课，总报名学生数量600w+， 在线学生100w+ ， 课中进入上课页面qps 120w+&lt;/p&gt;
&lt;p&gt;处理数据量：按一个课程章节来计算，最大的报名学生数目3w+  实际测试用60w+ 的报名学生，预热大概45多分钟&lt;/p&gt;
&lt;p&gt;3w 的报名学生， 小组直播间，班主任出镜，一个班主任最多带500学生，预热大概 1分钟30多秒&lt;/p&gt;
&lt;p&gt;策略数据： 一个章节对应一个策略，一个策略可以给多个章节使用，&lt;/p&gt;
&lt;p&gt;policy (id,conf,desc,name)&lt;/p&gt;
&lt;p&gt;lessonPolicy (keyId,keyType,bizType,partition,policyId)&lt;/p&gt;
&lt;p&gt;直播间数量： 3n+1 (n是班主任数目，出镜场景） 最多181个直播间 180*8*5(id,roomId,virturalRoomId,rootId,bizId,roomType,teacherUid,startTime,endTime,status) = 7.2KB&lt;/p&gt;
&lt;p&gt;组织节点数量：3w/6=5000个小组节点，5000/6 = 800多个队节点，60个辅导老师节点，总共6000个组织节点， 6000*8*7(id, nodeId,parentId,rootId,virturalNodeId,sourceId,path) =328KB&lt;/p&gt;
&lt;p&gt;用户数量： 3w+  每个班主任最多带500个学生，  3w/500 = 60  个班主任，最多 181 个直播间， 180*500 + 3w =12w条直播间用户数据， 按直播间维度协程任务分批处理; 12w*8*4(id,uid,nodeId,roomId) =3.7MB&lt;/p&gt;
&lt;p&gt;一天大概总共 2w * 4M =  78GB数据可能需要课前预热 （以一天最大2w节课程章节，每个章节报名人数3w计算, 报名学生2w*3w =6亿）&lt;/p&gt;
&lt;h2 id=&#34;依赖中间件基础服务&#34;&gt;依赖中间件基础服务&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;redis (stored k/v存储）  前期是哨兵模式架构， 后期采用proxy模式架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DB(mysql ) 主从架构，未使用proxy数据库中间件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MQ(NMQ, RocketMQ) 消息队列&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前期用的NMQ  消息以push的方式发送的消费方，通过groupKey来保证有序，以及消息积压报警，无限重试，消费方来保证幂等&lt;/p&gt;
&lt;p&gt;RMQ是为了兼容NMQ , 对rocketMQ进行来封装， 消息生成侧提供proxy, 兼容nmqproxy；消费侧rocketMQ是pull长轮训方式，为了兼容NMQ的push方式，提供pusher模块；数据存放用rocketMQ的broker&lt;/p&gt;
&lt;p&gt;rocketMQ : &lt;a href=&#34;https://github.com/apache/rocketmq/tree/master/docs/cn&#34;&gt;https://github.com/apache/rocketmq/tree/master/docs/cn&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;kafka : &lt;a href=&#34;https://kafka.apachecn.org/intro.html&#34;&gt;https://kafka.apachecn.org/intro.html&lt;/a&gt; 长链接心跳打点数据 → kafka → 计算引擎&lt;/p&gt;
&lt;h2 id=&#34;流程&#34;&gt;流程&lt;/h2&gt;
&lt;h3 id=&#34;数据对接方&#34;&gt;&lt;strong&gt;数据对接方&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;预热模块接入辅导侧三方数据：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;班主任侧（小班，辅导老师：班主任）&lt;/li&gt;
&lt;li&gt;督学服务侧（微信服务，辅导老师：督学）&lt;/li&gt;
&lt;li&gt;0转化督学服务侧（拉新转化，辅导老师：0转化督学）&lt;/li&gt;
&lt;li&gt;低幼服务侧（小班，辅导老师：班主任）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;场景直播间维度&#34;&gt;&lt;strong&gt;场景（直播间维度）&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;一个章节里一个主直播间一个组织树 （非出境）&lt;/li&gt;
&lt;li&gt;一个章节里多个主直播间一个组织树 （出境）&lt;/li&gt;
&lt;li&gt;一个章节里多个主直播间对应多个从直播间多个组织树 （旁听+出境）&lt;/li&gt;
&lt;li&gt;多个章节情况都转化成一个章节下的直播间情况 （共享）&lt;/li&gt;
&lt;li&gt;跟课场景：一个章节可能给不同的辅导侧在使用，辅导平台的数据源不同，一个组织树对应多个业务组织，一个直播间主讲推流，多个辅导侧后台拉流监控&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;流程-1&#34;&gt;流程&lt;/h3&gt;
&lt;p&gt;定义规范辅导侧数据接入 → 上课课程章节绑定对应策略(如不满足，新增支持）→ 分发任务前置预热 → 生成中台理解的属性 (liveRoom,lessonPolicy,orgTree 等)  →直播中台面向这些属性编程，提供原子化读写接口&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/%E7%9B%B4%E6%92%AD%E4%B8%AD%E5%8F%B0-%E7%BB%84%E7%BB%87%E5%BC%95%E6%93%8E%E6%B5%81%E7%A8%8B%E6%A1%86%E6%A1%86%E6%96%BD%E5%B7%A5%E5%9B%BE.jpg&#34; alt=&#34;直播中台-组织引擎流程框框施工图.jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;策略规则平台policy&#34;&gt;策略规则平台policy：&lt;/h2&gt;
&lt;p&gt;用于不同的业务直播间类型绑定组织策略，开发提供给运营产品团队使用&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;推拉流策略（rtc(udp),rtmp(tcp)+CDN 延迟较高，价格低； 学生，老师小组直播间互动场景用的rtc, 一课(三分屏)直播间用的rtmp; 辅导跟课后台，监控后台用的rtmp）；&lt;/li&gt;
&lt;li&gt;直播间策略(班主任课前/课中/课后出镜直播间，主讲直播间)；&lt;/li&gt;
&lt;li&gt;互动组织策略（基于组织树，学生，班主任，老师 通过长链接的聊天广播模式）;&lt;/li&gt;
&lt;li&gt;预热策略（极简，简单，全部预热）;&lt;/li&gt;
&lt;li&gt;预热时间计算预热时长(根据直播间数，组织节点数，用户数，计算预热时长）；用于分层时间轮来监控预热任务超时报警&lt;/li&gt;
&lt;li&gt;缓存设计中直播间的学生集合和在线学生集合 zset 分片策略（根据课程报名人数和商品库存数调权相加获取）；&lt;/li&gt;
&lt;li&gt;数据源定义（辅导侧数据：低幼，0转化督学，督学，班主任等，售卖侧数据）；&lt;/li&gt;
&lt;li&gt;异动数据通知定义 (学生更换班主任/小班，老师更换，课程章节上课时间更改，课程章节重开）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;组织数据生成引擎core&#34;&gt;组织数据生成引擎core：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;缓存设计：&lt;/p&gt;
&lt;p&gt;策略缓存/本地缓存，组织树缓存，直播间缓存，学生缓存，预热任务缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据库数据设计：&lt;/p&gt;
&lt;p&gt;业务策略表，组织节点表，直播间表，学生表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;直播中台组织引擎课中数据接口设计：&lt;/p&gt;
&lt;p&gt;直接从缓存中取，交互的数据通过write-behind 模式写入&lt;/p&gt;
&lt;p&gt;获取组织树节点信息，节点原始节点信息，子节点信息，学生所在直播间节点，选组/位置&lt;/p&gt;
&lt;p&gt;获取业务课程章节业务id的直播间信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;直播中台组织引擎回放数据接口设计：&lt;/p&gt;
&lt;p&gt;接口数据缓存，cache-aside 模式读取，课后回放数据都是读的场景&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;消息队列topic 消息体设计 ：异步落库，为了同步db,  同步db逻辑幂等，降低db的写压力&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;直播间，组织节点，学生数据&lt;/p&gt;
&lt;p&gt;内部优化设计：（原则：尽量减少读写io, 达到最优解）&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;异步缓冲buffer数据批量发送队列入库，减少网络io，降低db的写压力&lt;/li&gt;
&lt;li&gt;课中老师的课件信令记录，zset存缓存，学生高并发场景获取直播间信令记录，通过本地缓存来减少对zset 大key数据读取压力&lt;/li&gt;
&lt;li&gt;任务池化，并发批量处理任务，提高吞吐相应速度&lt;/li&gt;
&lt;li&gt;临时对象池化，高并发吞吐减少gc&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;配置平台conf-dashboard&#34;&gt;配置平台conf-dashboard：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;预热流程 DSL pipeline 配置,&lt;/li&gt;
&lt;li&gt;依赖缓存和数据配置 ，&lt;/li&gt;
&lt;li&gt;业务配置，&lt;/li&gt;
&lt;li&gt;预热报警通知配置,&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;预热数据监控平台monitor-dashboard&#34;&gt;预热数据监控平台monitor-dashboard:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;提供手动触发预热和预热数据检查；&lt;/li&gt;
&lt;li&gt;查看预热好的直播间，组织树，学生所在直播间的组织节点信息，以及课中直播间开始结束时间，直播间状态，学生在线状态，聊天状态（禁言/可聊天), 分组信息，到课时间&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;开发工具&#34;&gt;开发工具&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;线上/线下预热通知群&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预热报警通知群&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预热回归diff检查工具&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/%E9%A2%84%E7%83%AD%E6%A3%80%E6%9F%A5.jpg&#34; alt=&#34;预热检查&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/preload-diff.png&#34; alt=&#34;preload-diff&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;容错处理&#34;&gt;容错处理&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;分布式任务处理，如果一个机器挂了不影响任务处理，failover机制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任务执行失败会右报警机制，可以手动处理重新预热，还有自动轮训检查预热是否成功机制，如果预热失败，会在下个轮训周期出发预热， 轮训周期可调，默认是10分钟&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;技术难点和收益&#34;&gt;技术难点和收益&lt;/h2&gt;
&lt;h3 id=&#34;组织引擎&#34;&gt;组织引擎：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;业务数据源梳理，设计通用的模型，通过策略配置将不属于课中直播中台的业务属性进行隔离&lt;/strong&gt;，&lt;/p&gt;
&lt;p&gt;比如售卖平台和辅导侧运营平台 售卖的课程产品，分班排管班策略，以及课程中每一节大纲章节业务属性，都通过课前预热的时候进行解耦，生成课中理解的内聚模型，直播间，组织树；主讲，辅导老师和学生在直播间上课，通过组织树进行互动；课中学生老师进入教室获取课前绑定的策略，初始化直播间和组织树属性。这样能够服用已有沉淀下来的稳定功能；而且在支持新业务直播场景下，节省开发人力，加速产品迭代，将业务属性隔离，也有助于服务稳定运行&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;组织树在分布式缓存和数据库中的设计；&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如何在k/v存储中表示一颗组织树，以及在db数据库表中表示一颗组织树和学生，老师之间的关系；&lt;/p&gt;
&lt;p&gt;数据库需要考虑每天的数据容量，以及未来3年的数据容量(按一天2w节课，一节课3w+报名，估算78GB数据量)；&lt;/p&gt;
&lt;p&gt;为了方便课后问题排查，缓存数据过期时间7天（可调整），课中接口是直接和缓存交互，改变的数据状态通过Write behind模式异步刷盘写入db中，后台的接口数据通过Cache aside 课前预读提前加载至缓存中(延迟双删)。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;半夜0点～6点这段时间需要保证当天预热数据的高效性，准确性，以及可视化监控报警&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	1. &lt;strong&gt;预热框架的设计&lt;/strong&gt; ，业务数据和课中直播组织模型 策略绑定平台，生产预热任务，负载均衡分发至预热worker节点，记录预热，任务监控(预热和检查)，预热失败的容错，failover，报警；&lt;/p&gt;
&lt;p&gt;​	将业务属性和直播属性通过策略进行绑定，生成任务发送给消息队列，通过消息队列pusher到 预热模块, 利用内部的nmq工具属性，进行任务的负载均衡发布到每台worker协程来预热，考虑到可能会同时发多个相同的任务在不同的worker上执行，需要加锁；预热记录在预热记录表中，进行监控；&lt;/p&gt;
&lt;p&gt;​	每个预热worker会统计本机处理的章节，直播间，组织节点/树，学生数目，预热完之后，通过丁丁通知预热结果，也会同时触发数据检查流程；&lt;/p&gt;
&lt;p&gt;​	为了支持不同的预热场景，加入了极速预热，快速预热策略，满足新建一个课直接上课的场景(这些场景在内部老师的测试课会使用到), 秒级内完成；&lt;/p&gt;
&lt;p&gt;​&lt;/p&gt;
&lt;p&gt;​	2. &lt;strong&gt;预热数据检查&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​	检查预热数据的完整性，通过和数据源的对比，检查绑定的策略属性是否是好的；缓存和db中的直播间，组织数据，以及学生所在组织树，老师所在的直播间等数据的检查&lt;/p&gt;
&lt;p&gt;​	批量数据检查不能影响线上的稳定性，主要是读取线上缓存和db中的数据，也会像预热那样分发到集群机器上去并行处理；如果是业务高峰期进行检查，需要对检查流量进行限流，&lt;/p&gt;
&lt;p&gt;限流方案：对单机进行限流，对整体检查集群进行限流，都是以当前运行的检查任务数进行计数限流控制(redis hincr)；每个检查worker进程会统计当前正在运行的任务数，如果到了单机最大任务数，新的检查请求会直接返回检查容量已超限制错误，pusher会重试到另外一台机器上，&lt;/p&gt;
&lt;p&gt;​	3. &lt;strong&gt;预热数据监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​	课前 预热任务和检查任务的监控；&lt;/p&gt;
&lt;p&gt;​	课前 业务数据和课中直播组织模型 绑定策略， 老师直播间，组织树，学生等数据，在缓存，db中的监控；&lt;/p&gt;
&lt;p&gt;​	课中 直播间状态，所在组织树下的学生数据状态的监控；&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;需要考虑课前，课中的异动场景&lt;/strong&gt;，比如&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	课前，辅导侧给分好班的学生重新分班，需要订阅辅导测的异动，如果是同一时间批量修改，课中直播中台预热好的组织树需要考虑 并发异动修改学生所在的节点；&lt;/p&gt;
&lt;p&gt;​	课中，并发场景动态扩容，比如学生进入教室之前需要选组，如果初始小组节点不够，到了阈值，发送扩容任务，通过异步动态扩容协程进行扩容；&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;课中获取缓存数据的接口优化，分布式缓存中的大key和热key的优化&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	大key优化 通过分片处理，直播间的在线学生集合 和 报名学生集合，对key 进行partition分片，每个partition 5000个学生， partition的值是在课前预热的时候通过报名人数和课程的库存数量进行加权和预估的值；&lt;/p&gt;
&lt;p&gt;​	热key优化 通过加本地缓存，通过LRU进行evict，比如 一个老师上课时产生的信令列表(直播间维度，按时间顺序)，存放在zset中，提供学生进入教室时拉取，以及数据滞后时候的拉取，如果是一个热门直播间，会同时上万个学生获取这个老师产生的信令列表，会对分布式缓存中的slot带了压力，为了解决这个问题，将以获取的信令列表数据缓存到本地的有序列表中(sortedlist -&amp;gt; skiplist), 这些有序列表通过直播间维度hash分桶， 本地的有序列表数据只需维护 新增的数据，而不需要整段去获取缓存，减少获取热key的网络io； 这里会打点记录每个key的hit命中/miss未命中的数据量，数据日志采集接入基础监控平台，实时查看；&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;新业务接入，对新策略的增加，以及对老策略的修改，如何保证系统稳定性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;进行预热逻辑升级之后，上线之前都会在线下进行一轮未改策略的预热数据自动化diff，是拉取不同的版本，还未合入master的线上版本和修改了的版本，分布部署在两个容器中；根据不同的直播场景，从线上获取数据，预热写入线下缓存实例k/v和数据库实例表中，然后分别读取两份数据进行对比，比较为修改的策略是否有影响，有数据diff, 并报告diff的数据点，进行线下修复，再次进行自动化diff, 无diff之后，才能合并到master上线分支，上线；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;建设组织引擎课前预热整体收益&#34;&gt;建设组织引擎课前预热整体收益：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;节约了人力，加速产品开发迭代周期；以前如果接入新的业务辅导侧数据，以及提供相关的课中接口，从开发，测试上线，大概3～4个人力，需要2～3周的时间， 改造之后，开发，测试上线，大概1-2个人，需要1周的开发时间，节约了一半的成本；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;复用现有直播场景功能，将底层业务和直播属性进行隔离， 直播只关注直播属性，无需关注业务属性；保证直播服务的稳定性，将业务数据提供规范化接入后，可以将业务依赖进行反正，为后续saas化提供保障；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;直播接口性能有所提高，以前是有不同的业务方去把控，现在收敛整体把控，降低资源消耗（cpu, 内存，磁盘空间，网络io)，有些业务当时还是用php开发，php是多进程的方式处理业务请求逻辑，相对于go协程，占用资源更多；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;系统更加稳定，引入自动化工具检查预热数据，监控报警机制，修改策略线下检查机制，能保障系统稳定升级，减少线上出错率；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;qa&#34;&gt;Q&amp;amp;A&lt;/h2&gt;
&lt;p&gt;Q：课前预热直播间数据为什么选择先写缓存，然后在通过mq异步落db呢？&lt;/p&gt;
&lt;p&gt;A： 因为预热的过程是异步多台机器单机进程并行预热，进程中通过协程并发处理流程预热，为了预热提速；&lt;/p&gt;
&lt;p&gt;如果直接写db, 然后在更新缓存，因为mysql是主从架构，预热是写多读多场景， 写多是因为预热数据初始写入数据库，读多是因为数据入库之后，会通知接口缓存模块去请求读db接口缓存数据(接口数据为空，不会存储，都为insert操作成功之后，才通知接口缓存模块，不会出现不一致的情况)；读请求可以通过多个从来分担，但是写的话都是在主上，分库分表都是在单实例上, 单机抗大量写请求会成为整体预热的瓶颈；&lt;/p&gt;
&lt;p&gt;如果直接写入缓存，然后mq异步落db 的形式可以充分利用缓存比磁盘读写io速度快的优势，缓存的实例部署是以proxy的形式分布式部署，可以对slot分片进行读写 扩容，分散读写压力；不会成为预热的瓶颈；（以前是无中心化的形式通过业务使用方一致性hash 来访问分布式缓存slot分片, 后面改成proxy中心化的方式，统一管理方便运维，业务使用方直接通过redis协议请求，无需关心分片操作）&lt;/p&gt;
&lt;p&gt;通过mq异步落db，mq是通过push的方式直接发给后端接口入库的，降低mq的push的并发窗口，可以减少push频率，降低后端接口的请求量，但是会消费变慢，为了加快操作，对发送给mq的数据进行buffer 处理，批量发送，通过后端接口批量写入数据库，减少网络i/o, 提高写入吞吐量；&lt;/p&gt;
&lt;p&gt;Q: 预热过程中，如果有上线，预热中断了，怎么处理呢？&lt;/p&gt;
&lt;p&gt;A： 在预热的时候会上报预热的启动状态， 旁路脚本每半小时会检查一次预热的启动状态，如果一直处于运行中，则报警，根据阈值判断(比如报名人数估算处预热时间，报警次数) 触发自动预热重新预热上；预热监控后台也提供了手动触发预热；&lt;/p&gt;
&lt;p&gt;这里没有像数据库那样使用WAL机制（进程crash后，缓存中的数据没有了，可以通过WAL日志找回），业务场景可以回溯数据，按章节或者直播间重新预热&lt;/p&gt;
&lt;p&gt;Q: 组织树的作用是什么呢？&lt;/p&gt;
&lt;p&gt;A： 将业务组织关系进行解偶，如果接入其他业务组织关系，只需要提供原始数据，就可以服务用课中的组织关系能力，提供课中组织关系下的直播互动；课中组织树是可以动态扩展的，满足课中报名人数突增的情况；&lt;/p&gt;
&lt;p&gt;Q: 后续会提供用户维度的组织树操作接口吗？&lt;/p&gt;
&lt;p&gt;A： 现在是通过采集其他平台的组织数据进行一份转化生成提供给课中直播互动使用的组织树，后续提供相关的基础读写接口来初始/更改预热数据，使用方只需要在构造业务组织结构的时候调用写入缓存&lt;/p&gt;
&lt;p&gt;Q: 现在业务数据量有多大？&lt;/p&gt;
&lt;p&gt;A: 系统是按照最大量估算的，一天大概总共 2w * 4M =  78GB数据可能需要课前预热 （报名学生2w*3w =6亿）&lt;/p&gt;
&lt;p&gt;Q: 是否考虑用工作流任务调度的方式处理呢？&lt;/p&gt;
&lt;p&gt;A: 正在考虑中，现在方式是后台绑定好预热策略，把策略发到消息队列里，然后通过消息队列负载均衡推送给预热任务执行；&lt;/p&gt;
&lt;p&gt;后面会优化成工作流任务调度的方式，将整个预热流程拆分成可单独执行的任务，然后生成一个DAG工作流，通过任务调度模块，分发到预热执行机器上执行，入度为0的任务开始启动执行&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>网络模型</title>
      <link>https://weedge.github.io/post/poller/</link>
      <pubDate>Thu, 02 Sep 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/poller/</guid>
      
        <description>&lt;p&gt;看了一些开源的网络I/O模型框架库，尝试着按照理解简单实现一个相对简单的网络I/O模型框架，类似netty的reactor模型。&lt;/p&gt;
&lt;p&gt;Netty的NIO模型是Reactor反应堆模型（Reactor相当于有分发功能的多路复用器Selector）。每一个连接对应一个Channel（多路指多个Channel，复用指多个连接复用了一个线程或少量线程，在Netty指EventLoop），一个Channel对应唯一的ChannelPipeline，多个Handler串行的加入到Pipeline中，每个Handler关联唯一的ChannelHandlerContext。&lt;/p&gt;
&lt;p&gt;Reactor 模式的基本工作流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Server 端完成在 &lt;code&gt;bind&amp;amp;listen&lt;/code&gt; 之后，将 listenfd 注册到 epollfd 中，最后进入 event-loop 事件循环。循环过程中会调用 &lt;code&gt;select/poll/epoll_wait&lt;/code&gt; 阻塞等待，若有在 listenfd 上的新连接事件则解除阻塞返回，并调用 &lt;code&gt;socket.accept&lt;/code&gt; 接收新连接 connfd，并将 connfd 加入到 epollfd 的 I/O 复用（监听）队列。&lt;/li&gt;
&lt;li&gt;当 connfd 上发生可读/可写事件也会解除 &lt;code&gt;select/poll/epoll_wait&lt;/code&gt; 的阻塞等待，然后进行 I/O 读写操作，这里读写 I/O 都是非阻塞 I/O，这样才不会阻塞 event-loop 的下一个循环。然而，这样容易割裂业务逻辑，不易理解和维护。&lt;/li&gt;
&lt;li&gt;调用 &lt;code&gt;read&lt;/code&gt; 读取数据之后进行解码并放入队列中，等待工作线程处理。&lt;/li&gt;
&lt;li&gt;工作线程处理完数据之后，返回到 event-loop 线程，由这个线程负责调用 &lt;code&gt;write&lt;/code&gt; 把数据写回 client。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考这些网络模型，采用golang封装的底层epoll/kqueue系统调用方法，支持tcp协议，实现一个相对简单的网络模型，框架如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/im/main/go-epoll.png&#34; alt=&#34;go-epoll.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;代码实现：&lt;a href=&#34;https://github.com/weedge/lib/tree/main/poller&#34;&gt;https://github.com/weedge/lib/tree/main/poller&lt;/a&gt;  (对一个开源库进行的改造，codec编解码器待完善)&lt;/p&gt;
&lt;h4 id=&#34;参考&#34;&gt;参考：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/panjf2000/gnet&#34;&gt;gnet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudwego/netpoll&#34;&gt;netpoll&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tidwall/evio&#34;&gt;evio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/AlexStocks/getty&#34;&gt;getty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/netty/netty&#34;&gt;netty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/xinali/articles/issues/57&#34;&gt;Linux网络编程模型&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>教学直播概括</title>
      <link>https://weedge.github.io/post/jxzb/</link>
      <pubDate>Wed, 01 Sep 2021 22:04:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/jxzb/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景：&lt;/h2&gt;
&lt;p&gt;不同于常规的主播互动直播；教学直播，面向k12人群，&lt;/p&gt;
&lt;p&gt;前期会有课前的准备工作比如课程创建，学生购买数据，老师课件，试卷题目的准备；&lt;/p&gt;
&lt;p&gt;双师模式：学生会分配给不同的辅导老师，辅导老师会对学生进行分班处理，课中也会有学生选组上课互动的场景，辅导老师也可以给学生上课，也会在后台进行跟课，监督学生上课；&lt;/p&gt;
&lt;p&gt;相对于常规的主播互动，会模拟线下上课的场景到线上课中直播，形成一套线上教学直播间场景模式&lt;/p&gt;
&lt;h2 id=&#34;业务发展&#34;&gt;业务发展：&lt;/h2&gt;
&lt;p&gt;课中直播是按章节维度进行直播交互的，一个章节一个直播间；&lt;/p&gt;
&lt;p&gt;随着业务发展，出现了一个章节多个不同直播间的场景（出镜），多个章节共享一个章节直播间的场景(共享直播间）； 一个章节有2个相同课中主讲直播间的场景（旁听）; 后面根据业务需求衍生出其他组合玩法；&lt;/p&gt;
&lt;h2 id=&#34;上课业务流程介绍&#34;&gt;上课业务流程介绍：&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;售卖侧建课&lt;/strong&gt;：售卖老师在售卖后台新建课程章节，定义课程章节的属性，形成售卖商品上架；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;学生侧购买报名&lt;/strong&gt;：学生在售卖页面可以购买课程章节上课，或者0元课扫二维码直接购买报名上课；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;辅导侧&lt;/strong&gt;： 根据上课用户的年龄段进行分类：低幼，班主任，督学，0转化督学；对报名的用户课前排灌班，以大班/小班/小组的组织形式上课；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;教学直播课前预热：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将当天课前准备的课件，试卷题目，课程章节老师辅导相关的等非状态非易变接口数据在上课之前预热至缓存中；因为课中上课是突发流量场景，减少对后台接口db的并发压力； 对课中不会变的接口数据可以加上本地缓存，提高相应吞吐效率；(读多写少场景接口，cache-aside模式）&lt;/li&gt;
&lt;li&gt;课前对课中异动易变数据需要直播间缓存，业务组织缓存等初始化缓存数据；提供给课中互动场景使用；后面通过业务策略绑定，把业务组织数据抽象一个课中理解的数据模型，直播间缓存， 组织树节点缓存，学生所在直播间节点缓存等初始数据；（基于这个课中缓存数据模型，进行编码，隔离业务属性）&lt;/li&gt;
&lt;li&gt;对于异动状态易变更新频繁的接口直接课中缓存交互，异步落盘，降低相应延迟减少对后台接口的读写压力；（写多频繁场景接口，write-behind模式）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;教学直播课中互动：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不同用户角色直播链路
&lt;ol&gt;
&lt;li&gt;老师端：初始化直播间(配置加载，不同的互动ui, 互动功能是否可用，流媒体appid/token)→ 加载课件(cocos资源) →进入直播间 → 通过流媒体推流拉流/连麦/通过长链接发送聊天消息和信令→互动（发题目/答案/红包/奖励）→ 切换直播间(辅导出镜)/结束直播&lt;/li&gt;
&lt;li&gt;学生端：初始化直播间(配置加载，流媒体appid/token, 流程配置)→加载资源(cocos互动资源包/ai模型资源包)→签到/分组→进入直播间→通过流媒体拉流推流/连麦/通过长链接发送聊天消息→互动（发题目/答案/红包/奖励/pk）→ 退出直播间&lt;/li&gt;
&lt;li&gt;辅导跟课后台：进入跟课后台→ 进入直播间→通过流媒体拉流/通过长链接发送聊天消息→处理报警/遮盖/鉴黄/标记→直播结束获取计算好的学生到课时长，作答率，出勤率，完课率等&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;互动依赖长链接，答题，pk等场景，都有开始到结束的过程，对每个互动场景用互动id来管理生命周期，涉及金额的互动，需要考虑黑产的影响，需要对答案加密，以及金额的提前计算预热和防止多发少发，互动读写接口尽量细化，防止读写io多在同一个接口中；尽量把计算放在用户端来处理， 比如 答题是否成功，pk是否赢了等，分散服务端流量压力；(原则：统一管理互动类型，可配置化，细化io, 计算前置,分流)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;教学直播课后回放：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;建课后直接根据绑定的策略直接生成直播间，提供回放数据，比如素养课，伪直播&lt;/li&gt;
&lt;li&gt;课中的回放数据，会有直播间和用户互动最终状态数据落库&lt;/li&gt;
&lt;li&gt;回放数据是不会更改，读多写非常少的场景，缓存直接通过cache-aside的模式缓存db后台接口数据&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;教学整体概括架构&#34;&gt;教学整体概括架构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/zyb-jx.png&#34; alt=&#34;jxzb&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结思考&#34;&gt;总结思考&lt;/h2&gt;
&lt;p&gt;​	底层的基础建设比较重要(&lt;strong&gt;高效能&lt;/strong&gt;)；上层业务的发展离不开基础组件的稳定性(&lt;strong&gt;高可用&lt;/strong&gt;)；以及服务多了之后，如何高效快速迭代，上线之后保证整体服务性能的稳定性(&lt;strong&gt;高并发/低延迟/可监控/可配置&lt;/strong&gt;)； 以及服务模块之间的划分合理，细化出功能组件，异动业务代码的可维护性（&lt;strong&gt;低耦合高内聚&lt;/strong&gt;）；这些都需要理论知识加以指导(比如服务划分抽象原则DDD, 业务抽象设计原则SOLID)，以及实践场景中去平衡折中改进；没有永恒的银弹(内卷)，尚需不断迭代提高。一个字 &amp;ldquo;稳&amp;rdquo;。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/theme/119&#34;&gt;作业帮云原生探索和实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/9jn0qfcx2xq7h6xltwa9&#34;&gt;学而思网校直播课堂的架构演进之路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://insights.thoughtworks.cn/tag/domain-driven-design/&#34;&gt;Thoughtworks洞见-领域驱动设计&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.meituan.com/2020/03/19/design-pattern-practice-in-marketing.html&#34;&gt;设计模式在美团外卖营销业务中的实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.meituan.com/2017/12/22/ddd-in-practice.html&#34;&gt;领域驱动设计在互联网业务开发中的实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://read.douban.com/ebook/169386436/&#34;&gt;架构整洁之道&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sre.google/books/&#34;&gt;google-sre-book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://2012.33degree.org/pdf/JamesLewisMicroServices.pdf&#34;&gt;JamesLewisMicroServices.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://icyfenix.cn/&#34;&gt;凤凰架构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/6dlQZisMiXK3hzLIwEET&#34;&gt;微服务架构设计中的设计模式、原则及最佳实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/mojOSgEUaHWGU3H3j7WjlQ&#34;&gt;微服务拆分之道&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://book.douban.com/subject/26938710/&#34;&gt;系统架构-复杂系统的产品设计与开发&lt;/a&gt;: 理论知识，多读多思考多实践，&amp;lsquo;&amp;lsquo;虚实&#39;&amp;lsquo;结合&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;amp;mid=2247497722&amp;amp;idx=1&amp;amp;sn=33df39c492c508b2086a704612edf186&#34;&gt;架构指导原则&lt;/a&gt;&lt;/strong&gt;: 值得反复推敲，内化，回顾以往做过的项目，总结出底层原理&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>直播系列之消息模块演进</title>
      <link>https://weedge.github.io/post/jxzbim/</link>
      <pubDate>Mon, 02 Nov 2020 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/jxzbim/</guid>
      
        <description>&lt;h4 id=&#34;整体服务框架&#34;&gt;整体服务框架&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/im/blob/main/zbim.png?raw=true&#34; alt=&#34;zbim&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>policy worker</title>
      <link>https://weedge.github.io/todo/policyworker/</link>
      <pubDate>Wed, 10 Jun 2020 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/todo/policyworker/</guid>
      
        <description>&lt;h4 id=&#34;策略模型&#34;&gt;策略模型&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#00a&#34;&gt;package&lt;/span&gt; main

&lt;span style=&#34;color:#00a&#34;&gt;import&lt;/span&gt; (
  &lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;sync/atomic&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;time&amp;#34;&lt;/span&gt;
)

&lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#0a0&#34;&gt;loadConfig&lt;/span&gt;() &lt;span style=&#34;color:#00a&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt; {
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 从数据库或者文件系统中读取配置信息，然后以map的形式存放在内存里
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#00a&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;make&lt;/span&gt;(&lt;span style=&#34;color:#00a&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;)
}

&lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#0a0&#34;&gt;requests&lt;/span&gt;() &lt;span style=&#34;color:#00a&#34;&gt;chan&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;int&lt;/span&gt; {
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 将从外界中接受到的请求放入到channel里
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#00a&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;make&lt;/span&gt;(&lt;span style=&#34;color:#00a&#34;&gt;chan&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;int&lt;/span&gt;)
}

&lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#0a0&#34;&gt;main&lt;/span&gt;() {
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// config变量用来存放该服务的配置信息
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#00a&#34;&gt;var&lt;/span&gt; config atomic.Value
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 初始化时从别的地方加载配置文件，并存到config变量里
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  config.&lt;span style=&#34;color:#0a0&#34;&gt;Store&lt;/span&gt;(&lt;span style=&#34;color:#0a0&#34;&gt;loadConfig&lt;/span&gt;())
  &lt;span style=&#34;color:#00a&#34;&gt;go&lt;/span&gt; &lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt;() {
    &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 每10秒钟定时的拉取最新的配置信息，并且更新到config变量里
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#00a&#34;&gt;for&lt;/span&gt; {
      time.&lt;span style=&#34;color:#0a0&#34;&gt;Sleep&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;10&lt;/span&gt; * time.Second)
      &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 对应于赋值操作 config = loadConfig()
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;      config.&lt;span style=&#34;color:#0a0&#34;&gt;Store&lt;/span&gt;(&lt;span style=&#34;color:#0a0&#34;&gt;loadConfig&lt;/span&gt;())
    }
  }()
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 创建工作线程，每个工作线程都会根据它所读取到的最新的配置信息来处理请求
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#00a&#34;&gt;for&lt;/span&gt; i := &lt;span style=&#34;color:#099&#34;&gt;0&lt;/span&gt;; i &amp;lt; &lt;span style=&#34;color:#099&#34;&gt;10&lt;/span&gt;; i++ {
    &lt;span style=&#34;color:#00a&#34;&gt;go&lt;/span&gt; &lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt;() {
      &lt;span style=&#34;color:#00a&#34;&gt;for&lt;/span&gt; r := &lt;span style=&#34;color:#00a&#34;&gt;range&lt;/span&gt; &lt;span style=&#34;color:#0a0&#34;&gt;requests&lt;/span&gt;() {
        &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 对应于取值操作 c := config
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 由于Load()返回的是一个interface{}类型，所以我们要先强制转换一下
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;        c := config.&lt;span style=&#34;color:#0a0&#34;&gt;Load&lt;/span&gt;().(&lt;span style=&#34;color:#00a&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;)
        &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 这里是根据配置信息处理请求的逻辑...
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;        _, _ = r, c
      }
    }()
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;参考&#34;&gt;参考：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.betacat.io/post/golang-atomic-value-exploration/&#34;&gt;https://blog.betacat.io/post/golang-atomic-value-exploration/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
  </channel>
</rss>

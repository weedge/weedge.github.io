<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>时间飘过</title>
    <link>https://weedge.github.io/</link>
    <description>Recent content on 时间飘过</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 25 Sep 2023 15:26:23 +0800</lastBuildDate>
    
        <atom:link href="https://weedge.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://weedge.github.io/about/</link>
      <pubDate>Sun, 20 Jan 2013 21:38:52 +0800</pubDate>
      
      <guid>https://weedge.github.io/about/</guid>
      
        <description>
&lt;link rel=&#34;stylesheet&#34; href=&#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css&#34;&gt;
&lt;style type=&#34;text/css&#34;&gt;.dark-theme .aplayer{background:#212121}.dark-theme .aplayer.aplayer-withlist .aplayer-info{border-bottom-color:#5c5c5c}.dark-theme .aplayer.aplayer-fixed .aplayer-list{border-color:#5c5c5c}.dark-theme .aplayer .aplayer-body{background-color:#212121}.dark-theme .aplayer .aplayer-info{border-top-color:#212121}.dark-theme .aplayer .aplayer-info .aplayer-music .aplayer-title{color:#fff}.dark-theme .aplayer .aplayer-info .aplayer-music .aplayer-author{color:#fff}.dark-theme .aplayer .aplayer-info .aplayer-controller .aplayer-time{color:#eee}.dark-theme .aplayer .aplayer-info .aplayer-controller .aplayer-time .aplayer-icon path{fill:#eee}.dark-theme .aplayer .aplayer-list{background-color:#212121}.dark-theme .aplayer .aplayer-list::-webkit-scrollbar-thumb{background-color:#999}.dark-theme .aplayer .aplayer-list::-webkit-scrollbar-thumb:hover{background-color:#bbb}.dark-theme .aplayer .aplayer-list li{color:#fff;border-top-color:#666}.dark-theme .aplayer .aplayer-list li:hover{background:#4e4e4e}.dark-theme .aplayer .aplayer-list li.aplayer-list-light{background:#6c6c6c}.dark-theme .aplayer .aplayer-list li .aplayer-list-index{color:#ddd}.dark-theme .aplayer .aplayer-list li .aplayer-list-author{color:#ddd}.dark-theme .aplayer .aplayer-lrc{text-shadow:-1px -1px 0 #666}.dark-theme .aplayer .aplayer-lrc:before{background:-moz-linear-gradient(top, #212121 0%, rgba(33,33,33,0) 100%);background:-webkit-linear-gradient(top, #212121 0%, rgba(33,33,33,0) 100%);background:linear-gradient(to bottom, #212121 0%, rgba(33,33,33,0) 100%);filter:progid:DXImageTransform.Microsoft.gradient( startColorstr=&#39;#212121&#39;, endColorstr=&#39;#00212121&#39;,GradientType=0 )}.dark-theme .aplayer .aplayer-lrc:after{background:-moz-linear-gradient(top, rgba(33,33,33,0) 0%, rgba(33,33,33,0.8) 100%);background:-webkit-linear-gradient(top, rgba(33,33,33,0) 0%, rgba(33,33,33,0.8) 100%);background:linear-gradient(to bottom, rgba(33,33,33,0) 0%, rgba(33,33,33,0.8) 100%);filter:progid:DXImageTransform.Microsoft.gradient( startColorstr=&#39;#00212121&#39;, endColorstr=&#39;#cc212121&#39;,GradientType=0 )}.dark-theme .aplayer .aplayer-lrc p{color:#fff}.dark-theme .aplayer .aplayer-miniswitcher{background:#484848}.dark-theme .aplayer .aplayer-miniswitcher .aplayer-icon path{fill:#eee}&lt;/style&gt;
&lt;script src=&#34;https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.js&#34;&gt;&lt;/script&gt;

&lt;script src=&#34;https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js&#34;&gt;&lt;/script&gt;&lt;meting-js auto=&#34;https://music.163.com/#/playlist?id=451020859&#34; theme=&#34;#2980b9&#34;&gt;&lt;/meting-js&gt;
&lt;h4 id=&#34;人生&#34;&gt;人生&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;“物来顺应，未来不迎，当时不杂，既过不恋” &amp;ndash; 曾国藩&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&amp;ldquo;Yesterday is a history, tomorrow is a mystery, only today is a gift, that is why we call it present. &amp;quot; &amp;ndash; 功夫熊猫 (inner peace)&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;!-- raw HTML omitted --&gt;&lt;strong&gt;Hope is the good thing and maybe the best of things And no good things ever dies&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;
~ Andy Dufresne – Shawshank Redemption&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h4 id=&#34;规律&#34;&gt;规律&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;”路漫漫其修远兮，吾将上下而求索“ &amp;ndash; 屈原《离骚》&lt;/li&gt;
&lt;li&gt;&amp;ldquo;众里寻他千百度。蓦然回首，那人却在，灯火阑珊处&amp;rdquo; &amp;ndash; 辛弃疾《青玉案·元夕》&lt;/li&gt;
&lt;li&gt;&amp;ldquo;道生一，一生二，二生三，三生万物&amp;rdquo; &amp;ndash; 老子《&lt;a href=&#34;https://baike.baidu.com/item/%E9%81%93%E5%BE%B7%E7%BB%8F/327138&#34;&gt;道德经&lt;/a&gt;》&lt;/li&gt;
&lt;li&gt;&amp;ldquo;&lt;strong&gt;万物之始，大道至简，衍化至繁&lt;/strong&gt;&amp;rdquo; &amp;ndash; 老子《&lt;a href=&#34;https://baike.baidu.com/item/%E9%81%93%E5%BE%B7%E7%BB%8F/327138&#34;&gt;道德经&lt;/a&gt;》&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>译：相似性搜索，第 4 部分：分层可导航小世界 (HNSW)</title>
      <link>https://weedge.github.io/post/oneday/similarity-search/4.hierarchical-navigable-small-world-hnsw/</link>
      <pubDate>Mon, 25 Sep 2023 15:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/similarity-search/4.hierarchical-navigable-small-world-hnsw/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/0.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;介绍&#34;&gt;介绍&lt;/h1&gt;
&lt;p&gt;在数据科学中，相似性搜索经常出现在 NLP 领域、搜索引擎或推荐系统中，其中需要检索最相关的文档或项目以进行查询。有多种不同的方法可以提高海量数据的搜索性能。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1603.09320.pdf&#34;&gt;&lt;strong&gt;分层可导航小世界&lt;/strong&gt;&lt;/a&gt;(HNSW) 是一种用于近似搜索最近邻居的最先进算法。在底层，HNSW 构建了优化的图结构，使其与本系列文章前面部分中讨论的其他方法非常不同。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;HNSW 的主要思想是构建这样一个图，其中任何一对顶点之间的路径都可以通过少量步骤遍历。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;著名的&lt;a href=&#34;https://en.wikipedia.org/wiki/Six_degrees_of_separation&#34;&gt;六次握手规则&lt;/a&gt;的一个著名类比与此方法有关：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;所有人之间的社会关系距离不超过 6 个。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;在继续讨论 HNSW 的内部工作之前，让我们首先讨论跳跃列表和可导航小世界——HNSW 实现中使用的关键数据结构。&lt;/p&gt;
&lt;h1 id=&#34;跳过列表&#34;&gt;跳过列表&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Skip_list&#34;&gt;跳过列表&lt;/a&gt;是一种概率数据结构，允许在排序列表中插入和搜索元素*O(logn)*一般。跳跃列表由多层链表构成。最底层有原始链表，其中包含所有元素。当移动到更高级别时，跳过的元素数量会增加，从而减少连接数量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;在跳过列表中查找元素 20&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;某个值的搜索过程从最高级别开始，并将其下一个元素与该值进行比较。如果该值小于或等于该元素，则算法将继续处理下一个元素。否则，搜索过程下降到具有更多连接的较低层并重复相同的过程。最后，算法下降到最低层并找到所需的节点。&lt;/p&gt;
&lt;p&gt;根据&lt;a href=&#34;https://en.wikipedia.org/wiki/Skip_list&#34;&gt;维基百科&lt;/a&gt;的信息，跳过列表的主要参数&lt;em&gt;p&lt;/em&gt;定义了一个元素出现在多个列表中的概率。如果某个元素出现在&lt;em&gt;第 i层&lt;/em&gt;，那么它出现在第&lt;em&gt;i+1&lt;/em&gt;层的概率等于&lt;em&gt;p&lt;/em&gt;（&lt;em&gt;p&lt;/em&gt;通常设置为 0.5 或 0.25 ）。平均而言，每个元素都以*1 / (1 - p)*列表的形式呈现。&lt;/p&gt;
&lt;p&gt;我们可以看到，这个过程比链表中普通的线性搜索要快得多。事实上，HNSW 继承了相同的思想，但它使用的不是链表，而是图。&lt;/p&gt;
&lt;h1 id=&#34;可航行的小世界navigable-small-world&#34;&gt;可航行的小世界(Navigable Small World)&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Small-world_network&#34;&gt;&lt;strong&gt;可导航小世界&lt;/strong&gt;&lt;/a&gt;是一个具有多对数*T = O(logᵏn)*搜索复杂度的图，它使用贪婪路由。**路由(Routing)**是指从低度数顶点开始搜索过程，以高度数顶点结束的过程。由于低度顶点的连接很少，因此该算法可以在它们之间快速移动，以有效地导航到最近邻居可能所在的区域。然后算法逐渐放大并切换到高度顶点，以找到该区域顶点中的最近邻居。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;顶点&lt;em&gt;Vertex&lt;/em&gt;有时也称为&lt;strong&gt;节点Node&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;搜索&#34;&gt;搜索&lt;/h2&gt;
&lt;p&gt;首先，通过选择入口点来进行搜索。为了确定算法要移动到的下一个顶点（或多个顶点），它会计算从查询向量到当前顶点的邻居的距离，并移动到最近的顶点。在某些时候，当算法无法找到比当前节点本身更接近查询的邻居节点时，算法会终止搜索过程。该节点作为查询的响应返回。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;可导航的小世界中的贪婪搜索过程。节点 A 用作入口点。它有两个邻居 B 和 D。节点 D 比 B 更接近查询。因此，我们移动到 D。节点 D 有三个邻居 C、E 和 F。E 是距离查询最近的邻居，因此我们移动到 D。最后，搜索过程将导致节点 L。由于 L 的所有邻居都比 L 本身距离查询更远，因此我们停止算法并返回 L 作为查询的答案&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;这种贪婪策略不能保证它会找到精确的最近邻居，因为该方法仅使用当前步骤的本地信息来做出决策。&lt;strong&gt;提前停止Early stopping&lt;/strong&gt;是该算法的问题之一。它尤其发生在搜索过程开始时，当没有比当前节点更好的邻居节点时。在大多数情况下，当起始区域具有太多低度顶点时，可能会发生这种情况。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;提前停止，当前节点的两个邻居距离查询都较远。因此，算法返回当前节点作为响应，尽管存在距离查询更近的节点&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;通过&lt;strong&gt;使用多个入口点&lt;/strong&gt;可以提高搜索准确性。&lt;/p&gt;
&lt;h2 id=&#34;建造&#34;&gt;建造&lt;/h2&gt;
&lt;p&gt;NSW 图是通过打乱数据集点并将它们一一插入到当前图中来构建的。当插入一个新节点时，它会通过边链接到距离它最近的&lt;em&gt;M 个顶点。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/4.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;按 M = 2 顺序插入节点（从左到右）。每次迭代时，都会将一个新顶点添加到图中，并链接到其 M = 2 个最近邻居。蓝线表示与新插入节点的连接边。&lt;/p&gt;
&lt;p&gt;在大多数情况下，远程边可能会在图构建的开始阶段创建。它们在图形导航中发挥着重要作用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在构造开始时插入的元素的最近邻居的链接后来成为网络集线器之间的桥梁，保持整体图的连接性并允许在贪婪路由期间对跳数进行对数缩放。——于。A.马尔科夫，DA Yashunin&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;从上图中的例子我们可以看出一开始添加的远程边&lt;em&gt;AB&lt;/em&gt;的重要性。想象一下，一个查询需要从相对较远的节点&lt;em&gt;A&lt;/em&gt;和 I 遍历一条路径。有了边&lt;em&gt;AB&lt;/em&gt;，可以通过直接从图的一侧导航到另一侧来快速完成此操作。&lt;/p&gt;
&lt;p&gt;随着图中顶点数量的增加，新连接到新节点的边的长度变小的可能性也随之增加。&lt;/p&gt;
&lt;h1 id=&#34;hnsw&#34;&gt;HNSW&lt;/h1&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/1603.09320.pdf&#34;&gt;&lt;strong&gt;HNSW&lt;/strong&gt;&lt;/a&gt;基于与skiplist 调表和navigable small world (NSW) 可导航小世界相同的原理。它的结构代表了一个多层图，顶层的连接较少，底层的区域更密集。&lt;/p&gt;
&lt;h1 id=&#34;搜索search&#34;&gt;搜索(Search)&lt;/h1&gt;
&lt;p&gt;搜索从最高层开始，每次在各层节点中贪婪地找到局部最近邻时，都会向下一级进行搜索。最终，在最低层找到的最近邻居就是查询的答案。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/5.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;在HNSW中搜索&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;与 NSW 类似，HNSW 的搜索质量可以通过使用多个入口点来提高。不是在每一层上只找到一个最近邻居，而是找到与查询向量最接近的&lt;em&gt;efSearch&lt;/em&gt;（超参数） ，并将这些邻居中的每一个用作下一层的入口点。&lt;/p&gt;
&lt;h2 id=&#34;复杂度&#34;&gt;复杂度&lt;/h2&gt;
&lt;p&gt;[原论文中，在任何层上找到最近邻居所需的操作数量都受到一个常数的限制。考虑到图中所有层的数量是对数的，我们得到的总搜索复杂度为&lt;em&gt;O(logn)&lt;/em&gt;。&lt;/p&gt;
&lt;h1 id=&#34;建造construction&#34;&gt;建造(Construction)&lt;/h1&gt;
&lt;h2 id=&#34;选择最大层数&#34;&gt;选择最大层数&lt;/h2&gt;
&lt;p&gt;HNSW中的节点是按顺序一一插入的。每个节点都被随机分配一个整数&lt;em&gt;l&lt;/em&gt;，表示该节点可以出现在图中的最大层。例如，如果&lt;em&gt;l = 1&lt;/em&gt;，则只能在第 0 层和第 1 层上找到该节点。作者为每个节点随机选择&lt;em&gt;l&lt;/em&gt; ，其具有由非零乘数 mL 归一化的&lt;strong&gt;指数衰减概率分布(exponentially decaying probability distribution)&lt;/strong&gt;（&lt;em&gt;mL= 0&lt;/em&gt;导致HNSW 中的单层和未优化的搜索复杂度）。通常，大多数&lt;em&gt;l&lt;/em&gt;值应等于 0，因此大多数节点仅存在于最低级别。&lt;em&gt;mL&lt;/em&gt;的较大值增加节点出现在较高层的概率。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/6.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	每个节点的层数 &lt;em&gt;l&lt;/em&gt; 是按指数衰减概率分布随机选择的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/7.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;基于归一化因子 mL 的层数分布。水平轴表示均匀(0, 1) 分布的值&lt;/em&gt;。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;为了实现可控层次结构的最佳性能优势，不同层上的邻居之间的重叠（即也属于其他层的元素邻居的百分比）必须很小。— Yu. A. Malkov, D. A. Yashunin。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;减少重叠的方法之一是减少&lt;em&gt;mL&lt;/em&gt;。但重要的是要记住，减少&lt;em&gt;mL&lt;/em&gt;平均也会导致在每层的贪婪搜索期间进行更多的遍历。这就是为什么必须选择一个能够平衡重叠和遍历次数的&lt;em&gt;mL值。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;该论文的作者建议选择&lt;em&gt;mL&lt;/em&gt;的最佳值，即等于&lt;strong&gt;1 / ln(M)&lt;/strong&gt;。该值对应于跳跃列表的参数&lt;em&gt;p = 1 / M&lt;/em&gt;，即层之间的平均单个元素重叠。&lt;/p&gt;
&lt;h2 id=&#34;插入insertion&#34;&gt;插入(Insertion)&lt;/h2&gt;
&lt;p&gt;为节点分配值&lt;em&gt;l&lt;/em&gt;后，其插入有两个阶段：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;该算法从上层开始，贪婪地寻找最近的节点。然后找到的节点将用作下一层的入口点，并且搜索过程将继续。一旦到达第&lt;em&gt;l&lt;/em&gt;层*，*插入就进入第二步。&lt;/li&gt;
&lt;li&gt;从第&lt;em&gt;l&lt;/em&gt;层开始，算法在当前层插入新节点。然后它的行为与之前步骤 1 中的相同，但不是只查找一个最近邻居，而是贪婪地搜索&lt;em&gt;efConstruction&lt;/em&gt;（超参数）最近邻居。然后从&lt;em&gt;efConstruction&lt;/em&gt;邻居中选择&lt;em&gt;M&lt;/em&gt; 个，并构建从插入节点到它们的边。之后，算法下降到下一层，找到的每个&lt;em&gt;efConstruction&lt;/em&gt;节点都充当入口点。当新节点及其边被插入到最低层 0 后，算法终止。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/8.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;在 HNSW 中插入节点（蓝色）。新节点的最大层被随机选择为 l = 2。因此，该节点将被插入到第 2、1 和 0 层。在这些层的每一层上，该节点将连接到其 M = 2 个最近邻居&lt;/em&gt;。&lt;/p&gt;
&lt;h2 id=&#34;选择构造参数值choosing-values-for-construction-parameters&#34;&gt;选择构造参数值(Choosing values for construction parameters)&lt;/h2&gt;
&lt;p&gt;原始论文提供了关于如何选择超参数的一些有用的见解：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;根据模拟，&lt;em&gt;M&lt;/em&gt;的最佳值在 5 到 48 之间。较小的&lt;em&gt;M&lt;/em&gt;值往往更适合较低召回率或低维数据，而较高的 M 值更适合高召回率或高维数据。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;efConstruction&lt;/em&gt;的值越高，意味着随着探索的候选者越多，搜索就越深入。然而，它需要更多的计算。作者建议选择这样一个&lt;em&gt;efConstruction&lt;/em&gt;值，使训练期间的召回率接近&lt;em&gt;0.95-1&lt;/em&gt;。&lt;/li&gt;
&lt;li&gt;此外，还有一个重要参数&lt;em&gt;Mₘₐₓ&lt;/em&gt;——一个顶点可以拥有的最大边数。除此之外，还存在相同的参数&lt;em&gt;Mₘₐₓ₀&lt;/em&gt;，但对于最低层Lay 0是单独的。建议为&lt;em&gt;Mₘₐₓ&lt;/em&gt;选择接近&lt;em&gt;2 * M&lt;/em&gt;的值。大于&lt;em&gt;2 * M&lt;/em&gt;的值可能会导致性能下降和内存使用过多。同时，&lt;em&gt;Mₘₐₓ = M&lt;/em&gt;导致在高召回率下表现不佳。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;候选者启发式选择candidate-selection-heuristic&#34;&gt;候选者启发式选择(Candidate selection heuristic)&lt;/h2&gt;
&lt;p&gt;上面注意到，在节点插入期间，选择&lt;em&gt;efConstruction&lt;/em&gt;候选者中的&lt;em&gt;M&lt;/em&gt;个来为它们构建边。让我们讨论选择这&lt;em&gt;M&lt;/em&gt; 个节点的可能方法。&lt;/p&gt;
&lt;p&gt;朴素方法采用&lt;em&gt;M&lt;/em&gt;个最接近的候选者。然而，它并不总是最佳选择。下面是一个演示它的例子。&lt;/p&gt;
&lt;p&gt;想象一个具有下图结构的图表。如您所见，共有三个区域，其中两个区域未相互连接（左侧和顶部）。因此，例如，从&lt;em&gt;A&lt;/em&gt;点到&lt;em&gt;B&lt;/em&gt;点需要穿过另一个区域的很长的路径。以某种方式连接这两个区域以实现更好的导航是合乎逻辑的。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/9.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;节点 X 被插入到图中。目标是将其最佳地连接到其他 M = 2 点&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;然后将节点&lt;em&gt;X&lt;/em&gt;插入到图中，并且需要链接到&lt;em&gt;M&lt;/em&gt; &lt;em&gt;= 2 个&lt;/em&gt;其他 顶点。&lt;/p&gt;
&lt;p&gt;在这种情况下，朴素方法直接采用&lt;em&gt;M = 2 个&lt;/em&gt;最近邻居（&lt;em&gt;B&lt;/em&gt;和&lt;em&gt;C&lt;/em&gt;）并将&lt;em&gt;X&lt;/em&gt;连接到它们。尽管&lt;em&gt;X&lt;/em&gt;与其真正的最近邻居相连，但这并不能解决问题。让我们看看作者发明的启发式方法。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;启发式不仅考虑节点之间的最近距离，还考虑图上不同区域的连通性。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;启发式选择第一个最近邻居（在我们的例子中为&lt;em&gt;B&lt;/em&gt;）并将插入的节点 (&lt;em&gt;X&lt;/em&gt;) 连接到它。然后，该算法按顺序选取另一个最接近的最近邻居 (&lt;em&gt;C&lt;/em&gt;)，并仅当该邻居到新节点 (&lt;em&gt;X&lt;/em&gt;) 的距离小于从该邻居到所有已连接顶点的任何距离时，才为其构建一条边(&lt;em&gt;B&lt;/em&gt;) 到新节点 (&lt;em&gt;X&lt;/em&gt;)。之后，算法继续到下一个最近邻，直到建立&lt;em&gt;M&lt;/em&gt;条边&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;回到示例，启发式过程如下图所示。启发式选择&lt;em&gt;B&lt;/em&gt;作为 X 的最近邻并构建边&lt;em&gt;BX&lt;/em&gt;。然后算法选择&lt;em&gt;C&lt;/em&gt;作为下一个最近的最近邻。然而，这次&lt;em&gt;BC &amp;lt; CX&lt;/em&gt;。这表明将边&lt;em&gt;CX&lt;/em&gt;添加到图中并不是最佳的，因为已经存在边&lt;em&gt;BX&lt;/em&gt;并且节点&lt;em&gt;B&lt;/em&gt;和&lt;em&gt;C&lt;/em&gt;彼此非常接近。对于节点&lt;em&gt;D&lt;/em&gt;和&lt;em&gt;E&lt;/em&gt;进行相同的类比。之后，算法检查节点&lt;em&gt;A&lt;/em&gt;。&lt;em&gt;这次，它满足BA&lt;/em&gt; &lt;em&gt;&amp;gt; AX 的&lt;/em&gt;条件。结果，新边&lt;em&gt;AX&lt;/em&gt;和两个初始区域彼此连接。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/10.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;左边的例子使用了朴素方法。右侧的示例使用启发式选择，这会导致两个初始不相交区域相互连接&lt;/em&gt;。&lt;/p&gt;
&lt;h2 id=&#34;复杂度-1&#34;&gt;复杂度&lt;/h2&gt;
&lt;p&gt;与搜索过程相比，插入过程的工作方式非常相似，没有任何可能需要非常数操作的显着差异。因此，插入单个顶点需要&lt;em&gt;O(logn)&lt;em&gt;的时间。为了估计总复杂度，应考虑给定数据集中所有插入节点&lt;/em&gt;n&lt;/em&gt;的数量。最终，HNSW 构建需要O(n * logn)时间。&lt;/p&gt;
&lt;h1 id=&#34;将-hnsw-与其他方法相结合&#34;&gt;将 HNSW 与其他方法相结合&lt;/h1&gt;
&lt;p&gt;HNSW 可以与其他相似性搜索方法一起使用，以提供更好的性能。最流行的方法之一是将其与倒排文件索引和乘积量化 ( &lt;em&gt;IndexIVFPQ&lt;/em&gt; ) 结合起来，这在本系列文章的其他部分中进行了描述。&lt;/p&gt;
&lt;p&gt;在此范例中，HNSW 扮演IndexIVFPQ 粗量化器(&lt;strong&gt;coarse quantizer&lt;/strong&gt;)的角色，这意味着它将负责查找最近的 Voronoi 分区，因此可以缩小搜索范围。为此，必须在所有 Voronoi 质心上构建 HNSW 索引。当给出查询时，HNSW 用于查找最近的 Voronoi 质心（而不是像以前那样通过比较到每个质心的距离进行强力搜索）。之后，查询向量在相应的 Voronoi 分区内进行量化，并使用 PQ 码计算距离。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/11.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;通过查找建立在 Voronoi 质心之上的 HNSW 中的最近邻居来选择最近的 Voronoi 质心&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;当仅使用倒排文件索引时，最好将 Voronoi 分区的数量设置得不要太大（例如 256 或 1024），因为会执行强力搜索来找到最近的质心。通过选择少量的 Voronoi 分区，每个分区内的候选者数量会变得相对较多。因此，该算法可以快速识别查询的最近质心，并且其大部分运行时间都集中在查找 Voronoi 分区内的最近邻居上。&lt;/p&gt;
&lt;p&gt;然而，将 HNSW 引入工作流程需要进行调整。考虑仅在少量质心（256 或 1024）上运行 HNSW：HNSW 不会带来任何显著的好处，因为在向量数量较少的情况下，HNSW 在执行时间方面与朴素的暴力搜索相对相同。此外，HNSW 需要更多内存来存储图结构。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;这就是为什么在合并 HNSW 和倒排文件索引时，建议将 Voronoi 质心的数量设置得比平常大得多。通过这样做，每个 Voronoi 分区内的候选者数量变得少得多。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这种范式的转变导致了以下设置：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;HNSW 在对数时间内快速识别最近的 Voronoi 质心。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;之后，在各个 Voronoi 分区内执行穷举搜索。这应该不成问题，因为潜在候选人的数量很少。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;： 这种HNSW+IndexIVFPQ方式是最常用的方式，常结合场景数据结合硬件训练，调优，&lt;a href=&#34;https://github.com/harsha-simhadri/big-ann-benchmarks&#34;&gt;刷榜&lt;/a&gt;。来处理B级别以上的embedding向量数据；需要关注 &lt;strong&gt;recall 召回率&lt;/strong&gt;， &lt;strong&gt;内存使用率&lt;/strong&gt; 和 &lt;strong&gt;搜索速度&lt;/strong&gt;， 根据场景对这三方面进行取舍。（详情见： faiss复合索引 &lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_composite_indexes.ipynb&#34;&gt;&lt;strong&gt;faiss_composite_indexes.ipynb&lt;/strong&gt;&lt;/a&gt;）&lt;/p&gt;
&lt;h1 id=&#34;faiss实现&#34;&gt;FAISS实现&lt;/h1&gt;
&lt;p&gt;根据&lt;a href=&#34;https://faiss.ai/&#34;&gt;Faiss 文档&lt;/a&gt;中的信息，我们将了解如何利用 HNSW 并将其与倒排文件索引和乘积量化合并在一起。&lt;/p&gt;
&lt;h2 id=&#34;indexhnswflat&#34;&gt;IndexHNSWFlat&lt;/h2&gt;
&lt;p&gt;FAISS 有一个实现 HNSW 结构的&lt;em&gt;IndexHNSWFlat&lt;/em&gt;类。与往常一样，后缀“ &lt;em&gt;Flat&lt;/em&gt; ”表示数据集向量完全存储在索引中。构造函数接受 2 个参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;d&lt;/strong&gt;：数据维度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;M&lt;/strong&gt;：插入时每个新节点需要添加的边数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，通过&lt;strong&gt;hnsw&lt;/strong&gt;字段，&lt;em&gt;IndexHNSWFlat&lt;/em&gt;提供了几个有用的属性（可以修改）和方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;hnsw.efConstruction&lt;/strong&gt;：构建过程中要探索的最近邻居的数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hnsw.efSearch&lt;/strong&gt;：搜索期间要探索的最近邻居的数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hnsw.max_level&lt;/strong&gt;：返回最大层。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hnsw.entry_point&lt;/strong&gt;：返回入口点。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;faiss.vector_to_array(index.hnsw.levels)&lt;/strong&gt;：返回每个向量的最大层列表&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;hnsw.set_default_probas(M: int, level_mult: float)&lt;/strong&gt;：允许分别设置&lt;em&gt;M&lt;/em&gt;和&lt;em&gt;mL&lt;/em&gt;值。默认情况下，&lt;em&gt;level_mult&lt;/em&gt;设置为&lt;em&gt;1 / ln(M)&lt;/em&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/12.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IndexHNSWFlat 的 Faiss 实现&lt;/em&gt; (注：图中的efConstruction 和 efSearch 注释弄反了)&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IndexHNSWFlat&lt;/em&gt;设置&lt;em&gt;Mₘₐₓ = M&lt;/em&gt;和&lt;em&gt;Mₘₐₓ₀ = 2 * M&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;indexhnswflat--indexivfpq&#34;&gt;IndexHNSWFlat + IndexIVFPQ&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;IndexHNSWFlat&lt;/em&gt;也可以与其他索引组合。其中一个示例是上一部分中描述的&lt;em&gt;IndexIVFPQ&lt;/em&gt; 。该综合索引的创建分两个步骤进行：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;em&gt;IndexHNSWFlat&lt;/em&gt;被初始化为粗量化器。&lt;/li&gt;
&lt;li&gt;量化器作为参数传递给&lt;em&gt;IndexIVFPQ&lt;/em&gt;的构造函数。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;训练和添加可以通过使用不同或相同的数据来完成。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/hierarchical-navigable-small-world-hnsw/13.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IndexHNSWFlat + IndexIVFPQ 的 FAISS 实现&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;结论&#34;&gt;结论&lt;/h1&gt;
&lt;p&gt;在本文中，我们研究了一种鲁棒算法，该算法特别适用于大型数据集向量。通过使用多层图表示和候选启发式选择，其搜索速度可以有效扩展，同时保持良好的预测精度。还值得注意的是，HNSW 可以与其他相似性搜索算法结合使用，使其非常灵活。&lt;/p&gt;
&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Six_degrees_of_separation&#34;&gt;Six degrees of separation | Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Skip_list&#34;&gt;Skip List | Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1603.09320.pdf&#34;&gt;&lt;strong&gt;Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs&lt;/strong&gt;. Yu. A. Malkov, D. A. Yashunin&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://faiss.ai/&#34;&gt;Faiss documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss&#34;&gt;Faiss repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss/wiki/Faiss-indexes&#34;&gt;Summary of Faiss indexes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原文地址：&lt;a href=&#34;https://towardsdatascience.com/similarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&#34;&gt;https://towardsdatascience.com/similarity-search-part-4-hierarchical-navigable-small-world-hnsw-2aad4fe87d37&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;附操作笔记&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_hnsw.ipynb&#34;&gt;&lt;strong&gt;faiss_hnsw.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_vector_indexes.ipynb&#34;&gt;&lt;strong&gt;faiss_vector_indexes.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_composite_indexes.ipynb&#34;&gt;&lt;strong&gt;faiss_composite_indexes.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>译：相似性搜索，第 3 部分：混合倒排文件索引和乘积量化</title>
      <link>https://weedge.github.io/post/oneday/similarity-search/3.blending-inverted-file-index-and-product-quantization/</link>
      <pubDate>Mon, 25 Sep 2023 11:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/similarity-search/3.blending-inverted-file-index-and-product-quantization/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/0.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;介绍&#34;&gt;介绍&lt;/h1&gt;
&lt;p&gt;在数据科学中，相似性搜索经常出现在 NLP 领域、搜索引擎或推荐系统中，其中需要检索最相关的文档或项目以进行查询。有多种不同的方法可以提高海量数据的搜索性能。&lt;/p&gt;
&lt;p&gt;在本系列的前两部分中，我们讨论了信息检索中的两种基本算法：&lt;strong&gt;倒排文件索引&lt;/strong&gt;和&lt;strong&gt;乘积量化&lt;/strong&gt;。它们都优化了搜索性能，但侧重于不同的方面：第一个加速了搜索速度，而后者将向量压缩为更小的、节省内存的表示形式。&lt;/p&gt;
&lt;p&gt;由于两种算法侧重于不同的方面，自然出现的问题是是否可以将这两种算法合并为一种新算法&lt;/p&gt;
&lt;p&gt;在本文中，我们将结合这两种方法的优点来产生快速且内存高效的算法。作为参考，大多数讨论的想法都将基于&lt;a href=&#34;https://inria.hal.science/inria-00514462v2/document&#34;&gt;本文&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在深入研究细节之前，有必要了解残差向量(residual vectors)是什么，并对它们的有用属性有一个简单的直觉。稍后我们将在设计算法时使用它们。&lt;/p&gt;
&lt;h1 id=&#34;残差向量residual-vectors&#34;&gt;残差向量(Residual vectors)&lt;/h1&gt;
&lt;p&gt;想象一下执行了一个聚类算法并产生了多个聚类。每个簇都有一个质心和与其关联的点。&lt;strong&gt;残差residual&lt;/strong&gt;是点(向量)与其质心的偏移量。基本上，要找到特定向量的残差，必须从向量的质心中减去该向量。&lt;/p&gt;
&lt;p&gt;如果聚类是通过 k-means 算法构建的，则聚类质心是属于该聚类的所有点的平均值。因此，从任意点找到残差相当于从中减去簇的平均值。通过从属于特定簇的所有点中减去平均值，这些点将以 0 为中心。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;原始点簇显示在左侧。然后从所有聚类点中减去聚类质心。生成的残差向量显示在右侧。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;我们可以观察到一个有用的事实：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;用残差替换原始向量不会改变它们之间的相对位置。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;也就是说，向量之间的距离始终保持不变。让我们简单地看一下下面的两个方程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;减去平均值不会改变相对距离&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;第一个方程是一对向量之间的欧氏距离公式。在第二个方程中，从两个向量中减去簇平均值。我们可以看到均值项简单地被抵消了——整个表达式变得与第一个方程中的欧几里得距离相同！&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;我们通过使用 L2 度量（欧氏距离）公式证明了这一说法。重要的是要记住，此规则可能不适用于其他度量方法。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;因此，如果对于给定的查询，目标是找到最近的邻居，则可以仅从查询中减去簇均值，然后继续在残差中进行正常的搜索过程。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;从查询中减去平均值不会改变其与其他向量的相对位置&lt;/p&gt;
&lt;p&gt;现在让我们看一下下图中的另一个示例，其中有两个簇，其中每个簇向量的残差是单独计算的。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;从簇的每个向量中减去相应质心的平均值将使所有数据集向量以 0 为中心&lt;/em&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这是一个有用的观察结果，将来会用到。此外，对于给定的查询，我们可以计算所有集群的查询残差。查询残差允许我们计算到簇的原始残差的距离。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/4.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;从每个簇中减去平均值后，所有点都以 0 为中心。查询和查询残差与相应簇的其他点的相对位置不会改变。&lt;/p&gt;
&lt;h1 id=&#34;训练training&#34;&gt;训练(Training)&lt;/h1&gt;
&lt;p&gt;考虑到上一节中有用的观察结果后，我们可以开始设计算法。&lt;/p&gt;
&lt;p&gt;给定一个向量数据库，构建一个倒排文件索引，将向量集划分为&lt;em&gt;n&lt;/em&gt;个Voronoi 分区，从而减少推理查询过程中的搜索范围。&lt;/p&gt;
&lt;p&gt;在每个 Voronoi 分区内，从每个向量中减去质心的坐标。结果，来自所有分区的向量变得彼此更接近并且以 0 为中心。此时，不需要原始向量，因为我们存储它们的残差。&lt;/p&gt;
&lt;p&gt;之后，对来自所有分区的向量运行乘积量化算法。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;重要的方面&lt;/em&gt;：乘积量化不是&lt;strong&gt;针对&lt;/strong&gt;每个分区单独执行的——这会降低效率，因为分区的数量通常很高，这可能会导致需要大量内存来存储所有代码本。相反，&lt;strong&gt;该算法是同时对所有分区的所有残差执行的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;实际上，现在每个子空间都包含来自不同 Voronoi 分区的子向量。然后，对于每个子空间，像往常一样执行聚类算法并构建&lt;em&gt;k&lt;/em&gt;个聚类及其质心。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/5.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;训练流程&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;用向量的残差替换向量的重要性是什么&lt;/em&gt;？如果向量不被它们的残差替换，那么每个子空间将包含更多不同的子向量（因为子空间将存储来自不同的非相交 Voronoi 分区的子向量，这些分区在空间中可能彼此相距很远）。现在，来自不同分区的向量（残差）相互重叠。由于现在每个子空间的多样性较少，因此有效表示向量所需的再现值较少。换句话说：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在与之前使用的相同长度的PQ码的情况下，向量可以更准确地表示，因为它们具有较小的方差。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;推理查询inference&#34;&gt;推理查询(Inference)&lt;/h1&gt;
&lt;p&gt;对于给定的查询，找到 Voronoi 分区的&lt;em&gt;k&lt;/em&gt;个最近的质心。这些区域内的所有点都被视为候选点。由于原始向量最初被每个 Voronoi 区域中的残差替换，因此还需要计算查询向量的残差。在这种情况下，需要为每个 Voronoi 分区单独计算查询残差（因为每个区域具有不同的质心）。只有所选 Voronoi 分区的残差才会分配给候选者。&lt;/p&gt;
&lt;p&gt;然后将查询残差分割成子向量。与原始乘积量化算法一样，对于每个子空间，计算包含从子空间质心到查询子向量的距离的距离矩阵&lt;em&gt;d&lt;/em&gt;。 必须记住，每个 Voronoi 分区的查询残差都是不同的。基本上，这意味着需要为每个查询残差单独计算距离矩阵&lt;em&gt;d&lt;/em&gt;。这是所需优化的计算成本。&lt;/p&gt;
&lt;p&gt;最后，像之前在乘积量化算法中所做的那样，对部分距离进行求和。&lt;/p&gt;
&lt;h2 id=&#34;排序结果sorting-results&#34;&gt;排序结果(Sorting results)&lt;/h2&gt;
&lt;p&gt;计算完所有距离后，需要选择&lt;em&gt;k&lt;/em&gt;个最近邻。为了有效地做到这一点，作者建议维护&lt;a href=&#34;https://medium.com/@slavahead/heapify-with-heap-sort-5df23b5764c1&#34;&gt;MaxHeap&lt;/a&gt; (&lt;strong&gt;注&lt;/strong&gt;：容量为k 的大顶堆用于查最小最近的k个值，小顶堆则相反)数据结构。它的容量有限，为&lt;em&gt;k&lt;/em&gt;，并且在每一步中，它存储&lt;em&gt;k&lt;/em&gt;个当前最小距离。每当计算新距离时，仅当计算值小于 MaxHeap 中的最大值时，才会将其值添加到 MaxHeap 中。计算完所有距离后，查询的答案已存储在 MaxHeap 中。使用 MaxHeap 的优点是其快速构建时间，即&lt;em&gt;O(n)&lt;/em&gt; 。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/6.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;推理查询过程&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;性能performance&#34;&gt;性能(Performance)&lt;/h1&gt;
&lt;p&gt;该算法利用了倒排文件索引和乘积量化的优点。根据推理查询过程中 Voronoi 分区探测的数量，需要计算相同数量的子向量到质心矩阵&lt;em&gt;d&lt;/em&gt;并将其存储在内存中。这可能看起来像是一个缺点，但与整体优势相比，这是一个相当不错的权衡。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/7.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;该算法继承了倒排文件索引良好的搜索速度和乘积量化的压缩效率&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;faiss实现&#34;&gt;FAISS实现&lt;/h1&gt;
&lt;p&gt;根据&lt;a href=&#34;https://faiss.ai/&#34;&gt;Faiss 文档&lt;/a&gt;中的信息，我们将看到如何将倒排文件和产品量化索引组合在一起形成新的索引。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Faiss 在IndexIVFPQ&lt;/em&gt;类中实现所描述的算法，该类接受以下参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;quantizer&lt;/strong&gt;：指定如何计算向量之间的距离。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;d&lt;/strong&gt;：数据维度。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nlist&lt;/strong&gt;：Voronoi 分区的数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;M&lt;/strong&gt;：子空间的数量。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nbits&lt;/strong&gt;：编码单个簇 ID 所需的位数。这意味着单个子空间中的总簇数将等于&lt;em&gt;k = 2^nbits&lt;/em&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此外，还可以调整&lt;strong&gt;nprobe&lt;/strong&gt;属性，该属性指定在推理查询期间必须使用多少个 Voronoi 分区来搜索候选者。更改此参数不需要重新训练。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/8.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​	&lt;em&gt;IndexIVFPQ 的 Faiss 实现&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;存储单个向量所需的内存与原始乘积量化方法相同，只是现在我们添加了 8 个字节来存储有关倒排文件索引中向量的信息。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/9.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;结论&#34;&gt;结论&lt;/h1&gt;
&lt;p&gt;利用前面文章部分的知识，我们已经完成了最先进的算法的实现，该算法实现了高内存压缩和加速的搜索速度。该算法广泛应用于处理海量数据的信息检索系统中。&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://inria.hal.science/inria-00514462v2/document&#34;&gt;paper: &lt;strong&gt;Product quantization for nearest neighbour search&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://faiss.ai/&#34;&gt;Faiss document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss&#34;&gt;Faiss repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss/wiki&#34;&gt;&lt;strong&gt;Faiss wiki&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/facebookresearch/faiss/wiki/Faiss-indexes&#34;&gt;Summary of Faiss indexes&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;除非另有说明，所有图片均由作者提供&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;原文地址：&lt;a href=&#34;https://towardsdatascience.com/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa&#34;&gt;https://towardsdatascience.com/similarity-search-blending-inverted-file-index-and-product-quantization-a8e508c765fa&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;附操作笔记&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_vector_indexes.ipynb&#34;&gt;&lt;strong&gt;faiss_vector_indexes.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_composite_indexes.ipynb&#34;&gt;&lt;strong&gt;faiss_composite_indexes.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>译：相似性搜索，第 2 部分：乘积量化</title>
      <link>https://weedge.github.io/post/oneday/similarity-search/2.product-quantization/</link>
      <pubDate>Mon, 25 Sep 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/similarity-search/2.product-quantization/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/0.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;介绍&#34;&gt;介绍&lt;/h1&gt;
&lt;p&gt;在数据科学中，相似性搜索经常出现在 NLP 领域、搜索引擎或推荐系统中，其中需要检索最相关的文档或项目以进行查询。有多种不同的方法可以提高海量数据的搜索性能。&lt;/p&gt;
&lt;p&gt;在本系列文章的&lt;a href=&#34;https://weedge.github.io/post/oneday/similarity-search/1.knn-inverted-file-index/&#34;&gt;第一部分&lt;/a&gt;中，我们研究了用于执行相似性搜索的 kNN 和倒排文件索引结构。正如我们所知，kNN 是最直接的方法，而倒排文件索引则在其之上发挥作用，建议在速度加速和准确性之间进行权衡。然而，这两种方法都不使用数据压缩技术，这可能会导致内存问题，特别是在数据集较大且 RAM 有限的情况下。在本文中，我们将尝试通过研究另一种称为“&lt;strong&gt;乘积量化(Product Quantization)&lt;/strong&gt;”的方法来解决此问题。&lt;/p&gt;
&lt;h1 id=&#34;定义&#34;&gt;定义&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;乘积量化&lt;/strong&gt;是将每个数据集向量转换为短的内存高效表示形式（称为&lt;strong&gt;PQ code&lt;/strong&gt;）的过程。不是完全保留所有向量，而是存储它们的短表示。同时，乘积量化是一种有损压缩方法，预测精度较低，但在实践中，该算法效果很好。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;一般来说，量化是将无限值映射到离散值的过程。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;训练training&#34;&gt;训练(Training)&lt;/h1&gt;
&lt;p&gt;首先，该算法将每个向量分为几个相等的部分——&lt;strong&gt;子向量&lt;/strong&gt;。所有数据集向量的各个部分形成独立的&lt;strong&gt;子空间&lt;/strong&gt;并单独处理。然后对每个向量子空间执行聚类算法。通过这样做，在每个子空间中创建了几个质心。每个子向量都用它所属的质心的 ID 进行编码。此外，所有质心的坐标都会被存储以供以后使用。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;子空间质心也称为&lt;strong&gt;量化向量(quantized vectors)&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;在乘积量化中，簇ID通常被称为&lt;strong&gt;再现值(reproduction value)&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note: 在下图中，矩形表示包含多个值的向量，而正方形表示单个数字。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​											&lt;em&gt;使用量化进行编码&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;因此，如果一个原始向量被分为&lt;em&gt;n&lt;/em&gt;个部分，那么它可以由&lt;em&gt;n&lt;/em&gt;个数字——每个子向量各自质心的 ID 来编码。通常，为了更有效地使用内存，创建的质心&lt;em&gt;k&lt;/em&gt;的数量通常选择为 2 的幂。这样，存储编码向量所需的内存为n * log(k)位。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;子空间内所有质心的集合称为&lt;strong&gt;码本&lt;/strong&gt;。对所有子空间运行 n 个聚类算法会产生 n 个独立的码本。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;压缩示例compression-example&#34;&gt;压缩示例(Compression example)&lt;/h2&gt;
&lt;p&gt;想象一下，存储浮点数（32 位）的大小为 1024 的原始向量被分为&lt;em&gt;n = 8&lt;/em&gt;个子向量，其中每个子向量由&lt;em&gt;k = 256&lt;/em&gt;个簇之一进行编码。因此，对单个簇的 ID 进行编码需要&lt;em&gt;log(256) = 8&lt;/em&gt;位。让我们比较两种情况下向量表示的内存大小：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原始向量：1024 * 32 位 = 4096 字节。&lt;/li&gt;
&lt;li&gt;编码向量：8 * 8 位 = 8 字节。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最终压缩512倍！这就是产品量化的真正力量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​					&lt;em&gt;量化示例(向量中的数字显示它存储了多少个数字)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;以下是一些重要的注意事项：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;该算法可以在一个向量子集上进行训练（例如，以创建聚类）并用于另一个向量子集：训练完算法后，将传递另一个向量数据集，其中通过使用每个子空间已构造的质心对新向量进行编码。&lt;/li&gt;
&lt;li&gt;通常，选择 k-means 作为聚类算法。它的优点之一是簇的数量&lt;em&gt;k&lt;/em&gt;是一个超参数，可以根据内存使用需求手动定义。&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;推理查询inference&#34;&gt;推理查询(Inference)&lt;/h1&gt;
&lt;p&gt;为了更好地理解，让我们首先看一下几种简单的方法并找出它们的缺点。这也将帮助我们了解为什么它们不应该被正常使用。&lt;/p&gt;
&lt;h2 id=&#34;朴素方法naive-approaches&#34;&gt;朴素方法(Naive approaches)&lt;/h2&gt;
&lt;p&gt;第一种简单方法包括通过连接每个向量相应的质心来解压缩所有向量。之后，可以计算从查询向量到所有数据集向量的&lt;em&gt;L2&lt;/em&gt;距离（或其他度量）。显然，这种方法是可行的，但是非常耗时，因为要对高维解压向量进行暴力搜索和距离计算。&lt;/p&gt;
&lt;p&gt;另一种可能的方式是将查询向量分割成子向量，并基于其PQ码计算从每个查询子向量到数据库向量的相应量化向量的距离之和。因此，再次使用暴力搜索技术，并且这里的距离计算仍然需要原始向量维数的线性时间，如前一情况所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​						&lt;em&gt;使用朴素方法计算近似距离（该示例以欧氏距离作为度量）&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;另一种可能的方法是将查询向量编码成PQ码。然后直接利用该 PQ 代码来计算到所有其他 PQ 代码的距离。然后，具有最短距离的相应 PQ 代码的数据集向量被视为查询的最近邻居。这种方法比前两种方法更快，因为距离始终是在低维 PQ 代码之间计算的。然而，PQ码由簇ID组成，没有太多语义，可以被视为明确用作实数变量的分类变量。显然，这是一种不好的做法，并且这种方法可能会导致预测质量较差。&lt;/p&gt;
&lt;h2 id=&#34;优化方法&#34;&gt;优化方法&lt;/h2&gt;
&lt;p&gt;查询向量被划分为子向量。对于每个子向量，计算到相应子空间的所有质心的距离。最终，该信息存储在表&lt;em&gt;d&lt;/em&gt;中。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/4.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​							&lt;em&gt;获取存储部分查询子向量到质心距离的表 d&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;计算出的子向量到质心的距离通常称为&lt;strong&gt;部分距离(partial distances)&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;通过使用这个子向量到质心距离表&lt;em&gt;d&lt;/em&gt;，可以通过其 PQ 代码轻松获得从查询到任何数据库向量的近似距离：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对于数据库向量的每个子向量，找到最近的质心&lt;em&gt;j&lt;/em&gt;（通过使用 PQ 代码的映射值）以及从该质心到查询子向量&lt;em&gt;i&lt;/em&gt;的部分距离&lt;em&gt;d[i][j]&lt;/em&gt;（通过使用计算的矩阵&lt;em&gt;d&lt;/em&gt;）被获取。&lt;/li&gt;
&lt;li&gt;所有部分距离均被平方并求和。通过对该值求平方根，即可获得近似的欧氏距离。如果还想了解如何获得其他度量的近似结果，见&lt;a href=&#34;http://weedge.github.io/post/oneday/similarity-search/2.product-quantization/#%E5%85%B6%E4%BB%96%E8%B7%9D%E7%A6%BB%E5%BA%A6%E9%87%8F%E7%9A%84%E8%BF%91%E4%BC%BC%E5%80%BCapproximation-of-other-distance-metrics&#34;&gt;&lt;em&gt;其他距离度量的近似值&lt;/em&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/5.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​						&lt;em&gt;使用 PQ 代码和距离表计算从查询到数据库向量的距离&lt;/em&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;使用此方法计算近似距离假设：部分距离&lt;strong&gt;d&lt;/strong&gt;非常接近查询和数据库子向量之间的实际距离&lt;strong&gt;a 。&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;然而，这个条件可能不被满足，特别是当数据库子向量与其质心之间的距离*c很大时。*在这种情况下，计算会导致精度降低。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/6.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;左边的例子展示了当实际距离非常接近部分距离（c 很小）时的近似情况。在右侧，我们可以观察到一个糟糕的场景，因为部分距离比实际距离长得多（c很大）。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;在获得所有数据库行的近似距离后，我们搜索具有最小值的向量。这些向量将是查询的最近邻。&lt;/p&gt;
&lt;h2 id=&#34;其他距离度量的近似值approximation-of-other-distance-metrics&#34;&gt;其他距离度量的近似值（Approximation of other distance metrics）&lt;/h2&gt;
&lt;p&gt;到目前为止，我们已经了解了如何使用部分距离来近似欧氏距离。让我们也将这一规则推广到其他度量方式。&lt;/p&gt;
&lt;p&gt;想象一下我们想要计算一对向量之间的距离度量。如果我们知道度量的公式，我们可以直接应用它来得到结果。但有时我们可以通过以下方式分部分完成：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;两个向量都分为&lt;em&gt;n&lt;/em&gt;个子向量。&lt;/li&gt;
&lt;li&gt;对于每对相应的子向量，计算距离度量。&lt;/li&gt;
&lt;li&gt;然后将计算出的&lt;em&gt;n 个&lt;/em&gt;度量组合起来，生成原始向量之间的实际距离。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/7.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;该图显示了计算度量的两种方法。在左侧，度量公式直接应用于两个向量。在右侧，计算每对相应子向量的部分距离。然后使用聚合函数 h、g 和 f 将它们组合起来。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;欧几里德距离是可以按部分计算度量的。根据上图，我们可以选择聚合函数为&lt;em&gt;h(z) = z²&lt;/em&gt;、&lt;em&gt;g(z₀, z₁, …, zₙ) = sum(z₀, z₁, …, zₙ)&lt;em&gt;和&lt;/em&gt;f(z) = √z&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/8.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​								&lt;em&gt;欧氏距离可以分部分计算&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;内积(IP-Inner product )是此类度量的另一个示例，具有聚合函数&lt;em&gt;h(z) = z、g(z₀, z₁, …, zₙ) = sum(z₀, z₁, …, zₙ) 和 f(z) = z&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;在乘积量化的背景下，这是一个非常重要的属性，因为在推理查询过程中，算法按部分计算距离。这意味着使用不具有此属性的度量进行乘积量化会出现更多问题。余弦距离是此类度量的一个示例。&lt;/p&gt;
&lt;p&gt;如果仍然需要使用没有此属性的度量，则需要应用额外的启发式方法来聚合具有一定误差的部分距离。&lt;/p&gt;
&lt;h2 id=&#34;性能performance&#34;&gt;性能(Performance)&lt;/h2&gt;
&lt;p&gt;乘积量化的主要优点是对存储为短 PQ 代码的数据库向量进行大规模压缩。对于某些应用来说，这样的压缩率甚至可能高于95%！然而，除了PQ码之外，还需要存储包含每个子空间的量化向量的大小为&lt;em&gt;k x n&lt;/em&gt;的矩阵&lt;em&gt;d&lt;/em&gt; 。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;乘积量化是一种有损压缩方法，因此压缩率越高，预测精度就越有可能下降。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;构建有效表示的系统需要训练多种聚类算法。除此之外，在推理查询过程中，需要以暴力方式计算&lt;em&gt;k * n&lt;/em&gt;个部分距离，并对每个数据库向量求和，这可能需要一些时间。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/9.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​											&lt;em&gt;产品量化性能&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;faiss-实现&#34;&gt;FAISS 实现&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss&#34;&gt;&lt;strong&gt;Faiss&lt;/strong&gt;&lt;/a&gt;（Facebook AI Search Comparison）是一个用 C++ 编写, binding Python使用的faiss库, 提供c api 库方便FFI交互，用于优化相似性搜索。该库提供了不同类型的索引，这些索引是用于有效存储数据和执行查询的数据结构。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;根据&lt;a href=&#34;https://faiss.ai/&#34;&gt;Faiss 文档&lt;/a&gt;中的信息，我们将了解如何利用乘积量化。&lt;/p&gt;
&lt;p&gt;乘积量化在&lt;em&gt;IndexPQ&lt;/em&gt;类中实现。为了初始化，我们需要为其提供 3 个参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;d&lt;/strong&gt;：数据的维度数。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;M&lt;/strong&gt; ：每个向量的分割数（与上面使用的&lt;em&gt;n&lt;/em&gt;参数相同）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nbits&lt;/strong&gt;：编码单个簇 ID 所需的位数。这意味着单个子空间中的总簇数将等于&lt;em&gt;k = 2^nbits&lt;/em&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于相等的子空间维度分裂，参数&lt;em&gt;d&lt;/em&gt;必须能被&lt;em&gt;M&lt;/em&gt;整除。&lt;/p&gt;
&lt;p&gt;存储单个向量所需的总字节数等于：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/10.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;正如我们在上面的公式中看到的，为了更有效地使用内存，M * nbits 的值应该能被&lt;em&gt;8&lt;/em&gt;整除。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/11.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;​												&lt;em&gt;IndexPQ 的 Faiss 实现&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&#34;结论&#34;&gt;结论&lt;/h1&gt;
&lt;p&gt;我们研究了信息检索系统中非常流行的算法，该算法可以有效地压缩大量数据。它的主要缺点是推理查询速度慢。尽管如此，该算法仍广泛应用于现代大数据应用中，特别是与其他相似性搜索技术结合使用。&lt;/p&gt;
&lt;p&gt;在本系列文章的第一部分中，我们描述了倒排文件索引的工作流程。事实上，我们可以将这两种算法合并成一种更高效的算法，从而兼具两者的优点！这正是我们在本系列的下一部分中要做的事情。&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://inria.hal.science/inria-00514462v2/document&#34;&gt;paper: &lt;strong&gt;Product quantization for nearest neighbour search&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://faiss.ai/&#34;&gt;Faiss document&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss&#34;&gt;Faiss repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss/wiki&#34;&gt;&lt;strong&gt;Faiss wiki&lt;/strong&gt;&lt;/a&gt; &lt;a href=&#34;https://github.com/facebookresearch/faiss/wiki/Faiss-indexes&#34;&gt;Summary of Faiss indexes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pinecone.io/learn/series/faiss/product-quantization/&#34;&gt;https://www.pinecone.io/learn/series/faiss/product-quantization/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;原文地址： &lt;a href=&#34;https://towardsdatascience.com/similarity-search-product-quantization-b2a1a6397701&#34;&gt;https://towardsdatascience.com/similarity-search-product-quantization-b2a1a6397701&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;附操作笔记&lt;/strong&gt;: &lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_product_quantization.ipynb&#34;&gt;&lt;strong&gt;faiss_product_quantization.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>译：相似性搜索，第 1 部分：kNN 和倒排文件索引</title>
      <link>https://weedge.github.io/post/oneday/similarity-search/1.knn-inverted-file-index/</link>
      <pubDate>Sun, 24 Sep 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/similarity-search/1.knn-inverted-file-index/</guid>
      
        <description>&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/0.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;相似性搜索&lt;/strong&gt;(similarity-search)是给定一个查询，目标是在所有数据库文档中找到与其最相似的文档。本章介绍 kNN 的相似性搜索及其使用倒排文件的加速。&lt;/p&gt;
&lt;h1 id=&#34;介绍&#34;&gt;介绍&lt;/h1&gt;
&lt;p&gt;在数据科学中，相似性搜索经常出现在 NLP 领域、搜索引擎或推荐系统中，其中需要检索最相关的文档或项目以进行查询。通常，文档或项目以文本或图像的形式表示。然而，机器学习算法不能直接处理原始文本或图像，这就是为什么文档和项目通常被预处理并存储为数字向量的原因。&lt;/p&gt;
&lt;p&gt;有时向量的每个分量都可以存储语义。在这种情况下，这些表示也称为&lt;strong&gt;嵌入&lt;/strong&gt;。这样的嵌入可以有数百个维度，数量可以达到数百万个！由于数量如此庞大，任何信息检索系统都必须能够快速检测相关文档。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;在机器学习中，向量也称为&lt;strong&gt;对象&lt;/strong&gt;或&lt;strong&gt;点&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;指数&#34;&gt;指数&lt;/h1&gt;
&lt;p&gt;为了加速搜索性能，在数据集嵌入之上构建了特殊的数据结构。这样的数据结构称为&lt;strong&gt;索引&lt;/strong&gt;。该领域已经进行了大量的研究，并演化出了多种类型的指标。在选择索引来应用特定任务之前，有必要了解它的幕后运作方式，因为每个索引都有不同的目的，并且都有自己的优点和缺点。&lt;/p&gt;
&lt;p&gt;在本文中，我们将看看最简单的方法:&lt;strong&gt;kNN&lt;/strong&gt;。基于 kNN，我们将切换到&lt;strong&gt;倒排文件&lt;/strong&gt;:一种用于更具可扩展性的搜索的索引，可以将搜索过程加速数倍。&lt;/p&gt;
&lt;h1 id=&#34;knn&#34;&gt;kNN&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;kNN&lt;/strong&gt;是最简单、最朴素的相似性搜索算法。考虑向量数据集和新的查询向量&lt;em&gt;Q&lt;/em&gt;。我们希望找到与&lt;em&gt;Q&lt;/em&gt;最相似的前&lt;em&gt;k 个&lt;/em&gt;数据集向量。首先要考虑的方面是如何测量两个向量之间的相似性（距离）。事实上，有几个相似性指标可以做到这一点。其中一些如下图所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;相似度指标&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&#34;训练&#34;&gt;训练&lt;/h2&gt;
&lt;p&gt;kNN 是机器学习中少数不需要训练阶段的算法之一。选择合适的指标后，我们可以直接进行预测。&lt;/p&gt;
&lt;h2 id=&#34;推理&#34;&gt;推理&lt;/h2&gt;
&lt;p&gt;对于一个新对象，该算法会详尽地计算到所有其他对象的距离。之后，它找到距离最小的&lt;em&gt;k&lt;/em&gt;个对象并将它们作为响应返回。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;kNN工作流程&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;显然，通过检查到所有数据集向量的距离，kNN 保证了 100% 准确的结果。然而，这种蛮力方法在时间性能方面非常低效。如果数据集由&lt;em&gt;m&lt;/em&gt;个维度的&lt;em&gt;n&lt;/em&gt;个向量组成，则对于每个&lt;em&gt;n&lt;/em&gt;个向量，需要&lt;em&gt;O(m)&lt;em&gt;时间来计算从查询&lt;/em&gt;Q&lt;/em&gt;到它的距离，这导致总时间复杂度为&lt;em&gt;O(mn)&lt;/em&gt;。正如我们稍后将看到的，存在更有效的方法。&lt;/p&gt;
&lt;p&gt;而且，原始向量没有压缩机制。想象一个包含数十亿个对象的数据集。将它们全部存储在 RAM 中是不可能的！&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;kNN 性能。具有 100% 的准确度且无需训练阶段，可在向量的推理和无内存压缩期间进行详尽的搜索。注：此类图显示了不同算法的相对比较。根据情况和选择的超参数，性能可能会有所不同。&lt;/p&gt;
&lt;h2 id=&#34;应用&#34;&gt;应用&lt;/h2&gt;
&lt;p&gt;kNN 的应用范围有限，仅应在以下场景之一使用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据集大小或嵌入维数相对较小。这方面确保了算法仍然能够快速执行。&lt;/li&gt;
&lt;li&gt;算法要求的准确度必须是100%。在准确性方面，没有其他最近邻算法可以超越 kNN。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;根据指纹检测人员就是需要 100% 准确度的问题的一个例子。如果此人犯罪并留下了指纹，则仅检索正确的结果至关重要。否则，如果系统不是 100% 可靠，那么另一个人可能会被判有罪，这是一个非常严重的错误。&lt;/p&gt;
&lt;p&gt;基本上，改进 kNN 的方法主要有两种（我们稍后会讨论）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缩小搜索范围。&lt;/li&gt;
&lt;li&gt;降低向量的维数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当使用这两种方法之一时，我们将不会再次执行详尽的搜索。此类算法称为**近似最近邻 (ANN)，**因为它们不能保证 100% 准确的结果。&lt;/p&gt;
&lt;h1 id=&#34;倒排文件索引&#34;&gt;倒排文件索引&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;“倒排索引&lt;/strong&gt;（也称为&lt;strong&gt;倒排列表&lt;/strong&gt;postings list/file、&lt;strong&gt;倒排文件&lt;/strong&gt;inverted file）是一种数据库索引，存储从内容（例如单词或数字）到其在表、文档或一组数据中的位置的映射”——维基百科&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;执行查询时，会计算查询的哈希函数并从哈希表中获取映射值。这些映射值中的每一个都包含其自己的一组潜在候选值，然后根据条件对其进行全面检查，使其成为查询的最近邻居。通过这样做，缩小了所有数据库向量的搜索范围。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/4.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;倒排文件索引工作流程&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;根据哈希函数的计算方式，该索引有不同的实现方式。我们将要看到的实现是使用&lt;strong&gt;Voronoi 图&lt;/strong&gt;（或&lt;strong&gt;Dirichlet tessellation&lt;/strong&gt;）的实现。&lt;/p&gt;
&lt;h2 id=&#34;训练-1&#34;&gt;训练&lt;/h2&gt;
&lt;p&gt;该算法的思想是创建每个数据集点所属的几个不相交的区域。每个区域都有自己的质心，指向该区域的中心。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有时&lt;strong&gt;Voronoi 区域&lt;/strong&gt;被称为&lt;strong&gt;单元&lt;/strong&gt;或&lt;strong&gt;分区&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/5.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Voronoi 图的示例。白点是包含一组候选的各个分区的中心。&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Voronoi 图的主要属性是从一个质心到其区域内任意点的距离小于从该点到另一个质心的距离。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;推理-1&#34;&gt;推理&lt;/h2&gt;
&lt;p&gt;当给定一个新对象时，将计算到所有 Voronoi 分区质心的距离。然后选择距离最小的质心，并将该分区中包含的向量作为候选向量。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/6.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;通过给定的查询，我们搜索最近的质心（位于绿色区域）&lt;/p&gt;
&lt;p&gt;最终，通过计算到候选者的距离并选择其中最接近的前&lt;em&gt;k&lt;/em&gt;个，返回最终答案。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/7.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;查找所选区域中的最近邻居&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;正如您所看到的，这种方法比前一种方法快得多，因为我们不必查看所有数据集向量。&lt;/p&gt;
&lt;h2 id=&#34;边缘问题&#34;&gt;边缘问题&lt;/h2&gt;
&lt;p&gt;随着搜索速度的提高，倒排文件也有一个缺点：它不能保证找到的对象始终是最近的。&lt;/p&gt;
&lt;p&gt;在下图中，我们可以看到这样的场景：实际的最近邻居位于红色区域，但我们仅从绿色区域中选择候选者。这种情况称为&lt;strong&gt;边缘问题&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/8.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;边缘问题&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;当查询的对象位于与另一个区域的边界附近时，通常会发生这种情况。为了减少这种情况下的错误数量，我们可以扩大搜索范围，并根据与对象最接近的前&lt;em&gt;m个质心选择几个区域来搜索候选区域。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/9.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;搜索多个区域内的最近邻居 (m = 3)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;探索的区域越多，结果就越准确，计算结果所需的时间也就越多。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;注：这个类似geohash搜索中的边缘问题&lt;/p&gt;
&lt;h2 id=&#34;应用-1&#34;&gt;应用&lt;/h2&gt;
&lt;p&gt;尽管存在边缘问题，基于训练的倒排文件在实践中仍显示出不错的结果。当我们想要以稍微降低精度来实现速度数倍增长的情况下，它是完美的选择。&lt;/p&gt;
&lt;p&gt;用例示例之一是基于内容的推荐系统。想象一下，它根据用户过去看过的其他电影向他推荐一部电影。该数据库包含一百万部电影可供选择。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;通过使用 kNN，系统确实为用户选择了最相关的电影并推荐。然而，执行查询所需的时间非常长。&lt;/li&gt;
&lt;li&gt;让我们假设通过倒排文件索引，系统推荐第五个最相关的电影，这可能是现实生活中的情况。搜索时间比 kNN 快 20 倍。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从用户体验来看，很难区分这两个推荐的质量结果：第一个和第五个最相关的结果都是来自一百万个可能的电影的良好推荐。用户可能会对这些建议中的任何一个感到满意。从时间角度来看，倒排文件显然是赢家。这就是为什么在这种情况下最好使用后一种方法。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/10.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;倒排文件索引性能。这里我们稍微降低精度以在推理过程中获得更高的速度。&lt;/p&gt;
&lt;h1 id=&#34;faiss实现&#34;&gt;FAISS实现&lt;/h1&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss&#34;&gt;&lt;strong&gt;Faiss&lt;/strong&gt;&lt;/a&gt;（Facebook AI Search Comparison）是一个用 C++ 编写, binding Python使用的faiss库, 提供c api 库方便FFI交互，用于优化相似性搜索。该库提供了不同类型的索引，这些索引是用于有效存储数据和执行查询的数据结构。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href=&#34;https://faiss.ai/&#34;&gt;根据Faiss 文档&lt;/a&gt;中的信息，我们将了解索引是如何创建和参数化的。&lt;/p&gt;
&lt;h2 id=&#34;knn-1&#34;&gt;kNN&lt;/h2&gt;
&lt;p&gt;实现 kNN 方法的索引在 Faiss 中被称为&lt;strong&gt;扁平索引(flat index)&lt;/strong&gt;，因为它们不压缩任何信息。它们是保证正确搜索结果的唯一索引。实际上Faiss中存在两种类型的扁平索引：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;IndexFlatL2&lt;/em&gt;。相似度计算为欧几里得距离。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;IndexFlatIP&lt;/em&gt;。相似度计算为内积。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这两个索引在其构造函数中都需要一个参数&lt;strong&gt;d&lt;/strong&gt;：数据维度。这些索引没有任何可调参数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/11.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IndexFlatL2 和 IndexFlatIP 的 Faiss 实现&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;存储向量的单个分量需要 4 个字节。因此，要存储维度为 d 的&lt;strong&gt;单个向量&lt;/strong&gt;，需要&lt;em&gt;4 * d字节。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/12.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;倒排文件索引-1&#34;&gt;倒排文件索引&lt;/h2&gt;
&lt;p&gt;对于所描述的倒排文件，Faiss 实现了类&lt;em&gt;IndexIVFFlat&lt;/em&gt;。与 kNN 的情况一样，“ &lt;em&gt;Flat&lt;/em&gt; ”一词表示原始向量没有解压缩并且它们被完全存储。&lt;/p&gt;
&lt;p&gt;要创建此索引，我们首先需要传递一个量化器 - 一个将确定如何存储和比较数据库向量的对象。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IndexIVFFlat&lt;/em&gt;有2个重要参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;nlist&lt;/strong&gt;：定义在训练期间创建的多个区域（Voronoi 单元）。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;nprobe&lt;/strong&gt;：确定要搜索候选区域的区域数。更改 nprobe 参数不需要重新训练。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/13.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;IndexIVFFlat 的 Faiss 实现&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;与前面的情况一样，我们需要&lt;em&gt;4 * d&lt;/em&gt;字节来存储单个向量。但现在我们还必须存储数据集向量所属的 Voronoi 区域的信息。在 Faiss 实现中，此信息每个向量占用 8 个字节(可调整)。因此，存储&lt;strong&gt;单个向量&lt;/strong&gt;所需的内存为：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/knn-inverted-file-index/14.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h1 id=&#34;结论&#34;&gt;结论&lt;/h1&gt;
&lt;p&gt;我们已经了解了相似性搜索中的两种基本算法。实际上，朴素 kNN 几乎不应该用于机器学习应用，因为除了特定情况外，它的可扩展性很差。另一方面，倒排文件为加速搜索提供了良好的启发式方法，其质量可以通过调整其超参数来提高。搜索性能仍然可以从不同的角度来提高。在本系列文章的下一部分中，我们将了解一种旨在压缩数据集向量的方法。&lt;/p&gt;
&lt;h1 id=&#34;reference&#34;&gt;Reference&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Inverted_index&#34;&gt;Inverted Index | Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Voronoi_diagram&#34;&gt;Voronoi diagram | Wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://faiss.ai/&#34;&gt;Faiss documentation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss&#34;&gt;Faiss repository&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss/wiki/Faiss-indexes&#34;&gt;Summary of Faiss indexes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/facebookresearch/faiss/wiki/Guidelines-to-choose-an-index&#34;&gt;Guideline for choosing an index&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pinecone.io/learn/series/faiss/faiss-tutorial/&#34;&gt;faiss-tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/cn/what-is/hyperparameter-tuning/&#34;&gt;https://aws.amazon.com/cn/what-is/hyperparameter-tuning/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注：&lt;em&gt;除非另有说明，所有图片均由原作者提供。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;原文：https://towardsdatascience.com/similarity-search-knn-inverted-file-index-7cab80cc0e79&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;附操作笔记&lt;/strong&gt;:&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_tutorial.ipynb&#34;&gt;&lt;strong&gt;faiss_tutorial.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/faiss_vector_indexes.ipynb&#34;&gt;&lt;strong&gt;faiss_vector_indexes.ipynb&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>译：FANN：200行Rust实现的向量搜索</title>
      <link>https://weedge.github.io/post/oneday/vector-search-in-200-lines-of-rust/</link>
      <pubDate>Wed, 20 Sep 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/vector-search-in-200-lines-of-rust/</guid>
      
        <description>&lt;p&gt;由于 AI/ML 采用的快速进展，向量数据库无处不在。虽然它们支持复杂的人工智能/机器学习应用，但向量搜索本身从概念上来说并不难。在这篇文章中，我们将描述向量数据库如何工作，并用不到 200 行 Rust 代码构建一个简单的向量搜索库。&lt;a href=&#34;https://github.com/fennel-ai/fann&#34;&gt;所有代码都可以在此 Github 存储库&lt;/a&gt;中找到。我们这里使用的方法基于流行库Spotify &lt;a href=&#34;https://github.com/spotify/annoy&#34;&gt;annoy&lt;/a&gt;中使用的一系列称为“&lt;a href=&#34;https://en.wikipedia.org/wiki/Locality-sensitive_hashing&#34;&gt;局部敏感散列(Locality-sensitive_hashing)&lt;/a&gt;”的算法。本文的目标不是介绍新的算法库，而是描述向量搜索如何使用真实的代码片段工作。首先了解下什么是向量搜索。&lt;/p&gt;
&lt;h2 id=&#34;向量简介又名嵌入embedding&#34;&gt;向量简介（又名嵌入embedding）&lt;/h2&gt;
&lt;p&gt;文档、图像、视频等复杂的非结构化数据很难在传统数据库中表示和查询，特别是如果查询意图是查找“相似”项目。那么 Youtube 如何才能选择接下来播放的最佳视频呢？或者Spotify根据您当前的歌曲自定义音乐队列？&lt;/p&gt;
&lt;p&gt;2010 年代初人工智能的进步（从&lt;a href=&#34;https://en.wikipedia.org/wiki/Word2vec&#34;&gt;Word2Vec&lt;/a&gt; 和 &lt;a href=&#34;https://en.wikipedia.org/wiki/GloVe&#34;&gt;GloVe&lt;/a&gt; &lt;a href=&#34;https://github.com/stanfordnlp/GloVe&#34;&gt;stanfordnlp-GloVe&lt;/a&gt; 开始）使我们能够构建这些对象的语义表示，其中它们被表示为笛卡尔空间中的点。假设一个视频映射到点 [0.1, -5.1, 7.55]，另一个视频映射到点 [5.3, -0.1, 2.7]。这些机器学习算法的神奇之处在于，这些表示的选择能够维护语义信息——两个视频越相似，它们的向量之间的距离就越小。&lt;/p&gt;
&lt;p&gt;请注意，这些向量（或更专业地称为嵌入）不必是 3 维的 - 它们可以并且通常位于更高维的空间中（例如 128 维或 750 维）。而且距离也不需要是欧几里德距离 - 其他形式的距离（例如点积）也可以。无论哪种方式，重要的是它们之间的距离与其相似性相对应。&lt;/p&gt;
&lt;p&gt;现在想象一下，我们可以访问所有 Youtube 视频的此类向量。我们如何找到与给定起始视频最相似的视频？简单的。循环遍历所有视频，计算它们之间的距离并选择距离最小的视频 - 也称为查找查询视频的“最近邻居”。这实际上会起作用。不过，正如您所猜测的，线性 O(N) 扫描的成本可能太高。因此，我们需要一种更快的亚线性方法来找到任何查询视频的最近邻居。这通常是不可能的——必须付出一些代价。&lt;/p&gt;
&lt;p&gt;事实证明，在实际情况中，我们不需要找到最近的视频- 找到足够近的视频也可以。这就是近似最近邻搜索算法（也称为向量搜索）的用武之地。目标是亚线性（理想情况下以对数时间）找到空间中任何点的足够近的最近邻。那么如何解决呢？&lt;/p&gt;
&lt;h2 id=&#34;如何找到近似最近邻居&#34;&gt;如何找到近似最近邻居？&lt;/h2&gt;
&lt;p&gt;所有向量搜索算法背后的基本思想都是相同的——进行一些预处理来识别彼此足够接近的点（有点类似于构建索引）。在查询时，使用这个“索引”来排除大片点。并在不被排除的少量点内进行线性扫描。&lt;/p&gt;
&lt;p&gt;然而，有很多方法可以实现这个简单的想法。存在几种最先进的向量搜索算法，例如&lt;a href=&#34;https://github.com/nmslib/hnswlib&#34;&gt;HNSW&lt;/a&gt;（一种连接邻近顶点并通过固定入口点维护长距离边的分层图，类似skiplist）。目前存在诸如 Facebook 的&lt;a href=&#34;https://github.com/facebookresearch/faiss&#34;&gt;FAISS&lt;/a&gt;之类的开源项目，以及诸如&lt;a href=&#34;https://www.pinecone.io/&#34;&gt;Pinecone&lt;/a&gt;，&lt;a href=&#34;https://weaviate.io/&#34;&gt;Weaviate&lt;/a&gt;，&lt;a href=&#34;https://github.com/zilliztech/knowhere&#34;&gt;zilliz-Milvus-knowhere&lt;/a&gt;等高可用性向量数据库的 PaaS 产品中。&lt;/p&gt;
&lt;p&gt;在这篇文章中，我们将在给定的“N”点上构建一个简化的向量搜索索引，如下所示：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;随机取 2 个任意可用向量 A 和 B。&lt;/li&gt;
&lt;li&gt;计算这两个向量之间的中点，称为 C。&lt;/li&gt;
&lt;li&gt;构建一个穿过 C 并垂直于连接 A 和 B 的线段的超平面（类似于高维中的“线”）。&lt;/li&gt;
&lt;li&gt;将所有向量分类为超平面“上方”或“下方”，将可用向量分为 2 组。&lt;/li&gt;
&lt;li&gt;对于两个组中的每一个：如果组的大小高于可配置参数“最大节点大小”，则在该组上递归调用此过程以构建子树。否则，使用所有向量（或其唯一的 ID）构建单个叶节点&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此，我们使用这个随机过程来构建一棵树，其中每个内部节点都是超平面定义，左子树是超平面“下方”的所有向量，右子树是超平面“上方”的所有向量。向量集被连续递归地分割，直到叶节点包含不超过“最大节点大小”向量。考虑下图的例子，有五点：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/vector-search-in-200-lines-of-rust/1.png&#34; alt=&#34;img&#34;&gt;图 1：用随机超平面分割空间&lt;/p&gt;
&lt;p&gt;我们随机选择向量A1=(4,2)，B1=(5,7)。它们的中点是 (4.5,4.5)，我们通过中点构建一条垂直于线 (A1, B1) 的线。该线是 x + 5y=27（用蓝色绘制），这给了我们一组 2 个向量和一组 4 个向量。假设“最大节点大小”配置为 2。我们不进一步拆分第一组，而是选择后者构建新的（A2，B2）红色超平面等等。对大型数据集进行重复分割会将超空间分割成几个不同的区域，如下所示。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/vector-search-in-200-lines-of-rust/2.png&#34; alt=&#34;img&#34;&gt;图 2：许多超平面后的分段空间（来自 &lt;a href=&#34;https://t.co/K0Xlht8GwQ&#34;&gt;https://t.co/K0Xlht8GwQ&lt;/a&gt;，作者：&lt;a href=&#34;https://twitter.com/bernhardsson&#34;&gt;&lt;strong&gt;Erik Bernhardsson&lt;/strong&gt;&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;这里的每个区域代表一个叶节点，并且这里的直觉是足够接近的点很可能最终出现在同一个叶节点中。因此，给定一个查询点，我们可以在对数时间内遍历树以找到它所属的叶子，并对该叶子中的所有（少量）点运行线性扫描。这显然不是万无一失的——实际上足够近的点完全有可能被超平面分开并最终彼此相距很远。但是这个问题可以通过构建不是一棵而是许多独立的树来解决 - 这样，如果两个点足够接近，它们更有可能位于至少某些树中的同一叶节点中。在查询时，我们遍历所有树以找到相关的叶节点，对所有叶节点的所有候选节点进行并集，&lt;/p&gt;
&lt;p&gt;好吧，理论已经足够了。让我们开始编写一些代码，首先为下面的 Rust 中的 Vector 类型定义一些实用程序，用于点积、平均、散列和平方 L2 距离。感谢 Rust 良好的类型系统，我们传播泛型类型参数 N 来强制索引中的所有向量在编译时具有相同的维度。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;cp&#34;&gt;#[derive(Eq, PartialEq, Hash)]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;HashKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;u32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;cp&#34;&gt;#[derive(Copy, Clone)]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;f32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;impl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;subtract_from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mapped&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coords&lt;/span&gt;: &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;f32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mapped&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;try_into&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unwrap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mapped&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;2.0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coords&lt;/span&gt;: &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;f32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;mapped&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;try_into&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unwrap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coords&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;dot_product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;kt&#34;&gt;f32&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zipped_iter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zipped_iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;f32&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;to_hashkey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;HashKey&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// f32 in Rust doesn&amp;#39;t implement hash. We use bytes to dedup. While it
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// can&amp;#39;t differentiate ~16M ways NaN is written, it&amp;#39;s safe for us
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bit_iter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_bits&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;: &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;u32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;bit_iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;try_into&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unwrap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashKey&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sq_euc_dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;kt&#34;&gt;f32&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zipped_iter&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vector&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;zipped_iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;powi&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;构建完这些核心实用程序后，我们还可以定义超平面的外观：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;HyperPlane&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coefficients&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;constant&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;f32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;impl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HyperPlane&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;point_is_above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;point&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;kt&#34;&gt;bool&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coefficients&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dot_product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;point&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;constant&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.0&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;接下来，让我们重点关注生成随机超平面并构建最近邻树森林。我们应该如何表示树中的点？&lt;/p&gt;
&lt;p&gt;我们可以直接将 D 维向量存储在叶节点内。但这会显着增加大 D 的内存碎片（主要性能损失），并且当多棵树引用相同的向量时，还会在森林中创建重复的内存。相反，我们将向量存储在全局连续位置，并在叶节点处保存“usize”大小的索引（在 64 位系统上为 8 字节，而不是 4D，其中 f32 占用 4 字节）。以下是用于表示树的内部节点和叶节点的数据类型。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;k&#34;&gt;enum&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Box&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;InnerNode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Leaf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Box&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LeafNode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;LeafNode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;InnerNode&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hyperplane&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;HyperPlane&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;left_node&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;right_node&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;nc&#34;&gt;ANNIndex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;trees&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;我们如何真正找到正确的超平面？&lt;/p&gt;
&lt;p&gt;我们对向量 A 和 B 的两个唯一索引进行采样，计算 n = A - B，并找到 A 和 B 的中点 (point_on_plane)。超平面通过系数（向量 n）和常数（n 和 point_on_plane 的点积）结构有效存储为 n(x-x0) = nx - nx0。我们可以在任何向量和 n 之间执行点积，并减去常数以将向量放置在超平面“上方”或“下方”。由于树中的内部节点保存超平面定义，而叶节点保存向量 ID，因此我们可以使用 ADT 对树进行类型检查：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;k&#34;&gt;impl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ANNIndex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;build_hyperplane&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;indexes&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HyperPlane&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;indexes&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;choose_multiple&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;rand&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;thread_rng&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// cartesian eq for hyperplane n * (x - x_0) = 0
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// n (normal vector) is the coefs x_1 to x_n
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sample&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coefficients&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;subtract_from&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;point_on_plane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;avg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;constant&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coefficients&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dot_product&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;point_on_plane&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hyperplane&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HyperPlane&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;coefficients&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;constant&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;below&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;vec!&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;vec!&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;indexes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hyperplane&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;point_is_above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;else&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;below&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;id&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hyperplane&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;below&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;因此，我们可以定义递归过程来基于索引时间“最大节点大小”构建树：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;k&#34;&gt;impl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ANNIndex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;build_a_tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_size&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;indexes&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;indexes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_size&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Node&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;Leaf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Box&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;LeafNode&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;indexes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;clone&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;plane&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;below&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;build_hyperplane&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;indexes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;node_above&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;build_a_tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;node_below&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;build_a_tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;below&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Node&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;Inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Box&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;InnerNode&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hyperplane&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;plane&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;left_node&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;node_below&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;right_node&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;node_above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}));&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;   
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;请注意，在两点之间构建超平面要求这两个点是唯一的 - 即我们必须在索引之前对向量集进行重复数据删除，因为该算法不允许重复。&lt;/p&gt;
&lt;p&gt;因此整个索引（树木的森林）可以这样构建：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;k&#34;&gt;impl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ANNIndex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;deduplicate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vectors&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dedup_vectors&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids_of_dedup_vectors&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hashes_seen&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashSet&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hash_key&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;to_hashkey&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hashes_seen&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;contains&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hash_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hashes_seen&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;insert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hash_key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dedup_vectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids_of_dedup_vectors&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;push&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;build_index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_trees&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_size&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vecs&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vec_ids&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nc&#34;&gt;ANNIndex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;vec!&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;fm&#34;&gt;vec!&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;deduplicate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;vec_ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// Trees hold an index into the [unique_vecs] list which is not
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// necessarily its id, if duplicates existed
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_indexes&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;trees&lt;/span&gt;: &lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_trees&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;build_a_tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;max_size&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;all_indexes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unique_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ANNIndex&lt;/span&gt;::&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;trees&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;unique_vecs&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;查询时间&#34;&gt;查询时间&lt;/h3&gt;
&lt;p&gt;一旦建立了索引，我们如何使用它来搜索单个树上输入向量的 K 个近似最近邻？在非叶节点，我们存储超平面，因此我们可以从树的根开始并询问：“这个向量是在这个超平面之上还是之下？”。这可以通过 O(D) 和点积来计算。根据响应，我们可以递归搜索左子树或右子树，直到找到叶节点。请记住，叶节点最多存储“最大节点大小”向量，这些向量位于输入向量的近似邻域中（因为它们落在所有超平面下的超空间的同一分区中，见图 1(b)）。如果该叶节点处的向量索引数量超过 K，我们现在可以按与输入向量的 L2 距离对所有这些向量进行排序，并返回最接近的 K！&lt;/p&gt;
&lt;p&gt;假设我们的索引导致平衡树，对于维度 D、向量数量 N 和最大节点大小 M &amp;laquo; N，搜索需要 O(Dlog(N) + DM + Mlog(M)) - 这构成了平均最差情况 log(N)  次比较超平面以查找叶节点（即树的高度）；其中每次比较都会花费 O(D) 点积，计算 O(DM) 中叶节点中所有候选向量的 L2 度量；最后对它们进行排序以返回 O(Mlog(M)) 中的前 K 个。&lt;/p&gt;
&lt;p&gt;但是，如果我们找到的叶节点的向量少于 K 个，会发生什么情况？如果最大节点大小太小或者超平面分割相对不均匀，子树中留下的向量很少，则这是可能的。为了解决这个问题，我们可以在树搜索中添加一些简单的回溯功能。例如，如果返回的候选数不够，我们可以在内部节点进行额外的递归调用来访问另一个分支。它可能是这样的：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;k&#34;&gt;impl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ANNIndex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;tree_result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;Node&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;candidates&lt;/span&gt;: &lt;span class=&#34;kp&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nc&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashSet&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// take everything in node, if still needed, take from alternate subtree
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Node&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;Leaf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;box_leaf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;leaf_values&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;box_leaf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_candidates_found&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;min&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;leaf_values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;());&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;..&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_candidates_found&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;candidates&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;insert&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;leaf_values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;num_candidates_found&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;Node&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;Inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;above&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;hyperplane&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;point_is_above&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;above&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                    &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;right_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;left_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                    &lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;false&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;left_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;inner&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;right_node&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)),&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;};&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;match&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;tree_result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;candidates&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;tree_result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;backup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;candidates&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                    &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;                &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;请注意，我们可以通过在子树中存储向量总数，以及直接指向每个内部节点的所有叶节点的指针列表来进一步优化递归调用，但为了简单起见，这里不这样做。&lt;/p&gt;
&lt;p&gt;将此搜索扩展到树木森林很简单 - 只需从所有树中独立收集前 K 个候选者，按距离对它们进行排序，然后返回总体前 K 个匹配项。请注意，更多数量的树将具有线性高的内存占用和线性缩放的搜索时间，但可以导致更好的“更接近”的邻居，因为我们跨不同的树收集候选者。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-rust&#34; data-lang=&#34;rust&#34;&gt;&lt;span class=&#34;k&#34;&gt;impl&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;const&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ANNIndex&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;pub&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;fn&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;search_approximate&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;: &lt;span class=&#34;nc&#34;&gt;Vector&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;N&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;top_k&lt;/span&gt;: &lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;-&amp;gt; &lt;span class=&#34;nb&#34;&gt;Vec&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;i32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;f32&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;gt;&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;let&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;candidates&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;HashSet&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;new&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;in&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;trees&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;Self&lt;/span&gt;::&lt;span class=&#34;n&#34;&gt;tree_result&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;top_k&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;tree&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;k&#34;&gt;mut&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;candidates&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;);&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;        &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;candidates&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;into_iter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;values&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;].&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sq_euc_dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;query&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;sorted_by&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;partial_cmp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;).&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;unwrap&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;take&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;top_k&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;k&#34;&gt;as&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;usize&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;|&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;bp&#34;&gt;self&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;ids&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;idx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt;&lt;span class=&#34;w&#34;&gt; &lt;/span&gt;&lt;span class=&#34;n&#34;&gt;dis&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;            &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;n&#34;&gt;collect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;    &lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;&lt;span class=&#34;w&#34;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这为我们提供了 200 行 Rust 的简单向量搜索索引！&lt;/p&gt;
&lt;p&gt;为了说明的目的，这个实现相当简单——事实上，它是如此简单，以至于我们怀疑它一定比最先进的算法差得多（尽管在更广泛的方法中是相似的）。让我们做一些基准测试来证实我们的怀疑。&lt;/p&gt;
&lt;p&gt;可以评估算法的延迟和质量。质量通常通过召回率来衡量 - 实际最近邻（从线性扫描获得）的百分比，也是通过近似最近邻搜索获得的。有时，返回的结果在技术上并不在前 K 中，但它们非常接近实际的前 K，因此并不重要 - 为了量化这一点，我们还可以查看邻居的平均欧几里德距离，并将其与暴力平均距离进行比较强制搜索。&lt;/p&gt;
&lt;p&gt;测量延迟很简单 - 我们可以查看执行查询所需的时间（我们通常对索引构建延迟不太感兴趣）。&lt;/p&gt;
&lt;p&gt;所有基准测试结果均在配备 2.3 GHz 四核 Intel Core i5 处理器的单设备 CPU 上运行，使用 999,994 个 Wiki 数据 FastText 嵌入 ( &lt;a href=&#34;https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip&#34;&gt;https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news -300d-1M.vec.zip&lt;/a&gt; ) 300 维。我们将所有查询的“top K”设置为 20。&lt;/p&gt;
&lt;p&gt;作为参考，我们将 FAISS HNSW 索引 (ef_search=16、ef_construction=40、max_node_size=15) 与 Rust 索引的小版本 (num_trees=3、max_node_size=15) 进行比较。我们在 Rust 中实现了详尽的搜索，而 FAISS 库有 HNSW 的 C++ 源代码。原始延迟数低，增强了近似搜索的优势：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;算法&lt;/th&gt;
&lt;th&gt;延迟 Latency&lt;/th&gt;
&lt;th&gt;QPS&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Exhaustive Search&lt;/td&gt;
&lt;td&gt;675.25ms&lt;/td&gt;
&lt;td&gt;1.48&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;FAISS HNSW Index&lt;/td&gt;
&lt;td&gt;355.36μs&lt;/td&gt;
&lt;td&gt;2814.05&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Custom Rust Index&lt;/td&gt;
&lt;td&gt;112.02μs&lt;/td&gt;
&lt;td&gt;8926.98&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;两种近似最近邻方法的速度都快了三个数量级，这很好。与 HNSW 相比，我们的 Rust 实现在这个微基准测试中速度快了 3 倍。分析质量时，直观地考虑 prompt “river” 返回的前 10 个最近邻。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Exhaustive Search&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;FAISS HNSW Index&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Custom Rust Index&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Word&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Euclidean Distance&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Word&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Euclidean Distance&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Word&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Euclidean Distance&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;river&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;river&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;river&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;River&lt;/td&gt;
&lt;td&gt;1.39122&lt;/td&gt;
&lt;td&gt;River&lt;/td&gt;
&lt;td&gt;1.39122&lt;/td&gt;
&lt;td&gt;creek&lt;/td&gt;
&lt;td&gt;1.63744&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;rivers&lt;/td&gt;
&lt;td&gt;1.47646&lt;/td&gt;
&lt;td&gt;river-&lt;/td&gt;
&lt;td&gt;1.58342&lt;/td&gt;
&lt;td&gt;river.&lt;/td&gt;
&lt;td&gt;1.73224&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;river-&lt;/td&gt;
&lt;td&gt;1.58342&lt;/td&gt;
&lt;td&gt;swift-flowing&lt;/td&gt;
&lt;td&gt;1.62413&lt;/td&gt;
&lt;td&gt;lake&lt;/td&gt;
&lt;td&gt;1.75655&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;swift-flowing&lt;/td&gt;
&lt;td&gt;1.62413&lt;/td&gt;
&lt;td&gt;flood-swollen&lt;/td&gt;
&lt;td&gt;1.63798&lt;/td&gt;
&lt;td&gt;sea&lt;/td&gt;
&lt;td&gt;1.87368&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;creek&lt;/td&gt;
&lt;td&gt;1.63744&lt;/td&gt;
&lt;td&gt;river.The&lt;/td&gt;
&lt;td&gt;1.68156&lt;/td&gt;
&lt;td&gt;up-river&lt;/td&gt;
&lt;td&gt;1.92088&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;flood-swollen&lt;/td&gt;
&lt;td&gt;1.63798&lt;/td&gt;
&lt;td&gt;river-bed&lt;/td&gt;
&lt;td&gt;1.68510&lt;/td&gt;
&lt;td&gt;shore&lt;/td&gt;
&lt;td&gt;1.92266&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;river.The&lt;/td&gt;
&lt;td&gt;1.68156&lt;/td&gt;
&lt;td&gt;unfordable&lt;/td&gt;
&lt;td&gt;1.69245&lt;/td&gt;
&lt;td&gt;brook&lt;/td&gt;
&lt;td&gt;2.01973&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;river-bed&lt;/td&gt;
&lt;td&gt;1.68510&lt;/td&gt;
&lt;td&gt;River-&lt;/td&gt;
&lt;td&gt;1.69512&lt;/td&gt;
&lt;td&gt;hill&lt;/td&gt;
&lt;td&gt;2.03419&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;unfordable&lt;/td&gt;
&lt;td&gt;1.69245&lt;/td&gt;
&lt;td&gt;River.The&lt;/td&gt;
&lt;td&gt;1.69539&lt;/td&gt;
&lt;td&gt;pond&lt;/td&gt;
&lt;td&gt;2.04376&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;或者，考虑一下prompt  “war”。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Exhaustive Search&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;FAISS HNSW Index&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;Custom Rust Index&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;strong&gt;Word&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Euclidean Distance&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Word&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Euclidean Distance&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Word&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;Euclidean Distance&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;war&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;war&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;war&lt;/td&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;war&amp;ndash;&lt;/td&gt;
&lt;td&gt;1.38416&lt;/td&gt;
&lt;td&gt;war&amp;ndash;&lt;/td&gt;
&lt;td&gt;1.38416&lt;/td&gt;
&lt;td&gt;war&amp;ndash;&lt;/td&gt;
&lt;td&gt;1.38416&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;war&amp;ndash;a&lt;/td&gt;
&lt;td&gt;1.44906&lt;/td&gt;
&lt;td&gt;war&amp;ndash;a&lt;/td&gt;
&lt;td&gt;1.44906&lt;/td&gt;
&lt;td&gt;wars&lt;/td&gt;
&lt;td&gt;1.45859&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;wars&lt;/td&gt;
&lt;td&gt;1.45859&lt;/td&gt;
&lt;td&gt;wars&lt;/td&gt;
&lt;td&gt;1.45859&lt;/td&gt;
&lt;td&gt;quasi-war&lt;/td&gt;
&lt;td&gt;1.59712&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;war&amp;ndash;and&lt;/td&gt;
&lt;td&gt;1.45907&lt;/td&gt;
&lt;td&gt;war&amp;ndash;and&lt;/td&gt;
&lt;td&gt;1.45907&lt;/td&gt;
&lt;td&gt;war-footing&lt;/td&gt;
&lt;td&gt;1.69175&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;war.It&lt;/td&gt;
&lt;td&gt;1.46991&lt;/td&gt;
&lt;td&gt;war.It&lt;/td&gt;
&lt;td&gt;1.46991&lt;/td&gt;
&lt;td&gt;check-mate&lt;/td&gt;
&lt;td&gt;1.74982&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;war.In&lt;/td&gt;
&lt;td&gt;1.49632&lt;/td&gt;
&lt;td&gt;war.In&lt;/td&gt;
&lt;td&gt;1.49632&lt;/td&gt;
&lt;td&gt;ill-begotten&lt;/td&gt;
&lt;td&gt;1.75498&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;unwinable&lt;/td&gt;
&lt;td&gt;1.51296&lt;/td&gt;
&lt;td&gt;unwinable&lt;/td&gt;
&lt;td&gt;1.51296&lt;/td&gt;
&lt;td&gt;subequent&lt;/td&gt;
&lt;td&gt;1.76617&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;war.And&lt;/td&gt;
&lt;td&gt;1.51830&lt;/td&gt;
&lt;td&gt;war.And&lt;/td&gt;
&lt;td&gt;1.51830&lt;/td&gt;
&lt;td&gt;humanitary&lt;/td&gt;
&lt;td&gt;1.77464&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;hostilities&lt;/td&gt;
&lt;td&gt;1.54783&lt;/td&gt;
&lt;td&gt;Iraw&lt;/td&gt;
&lt;td&gt;1.54906&lt;/td&gt;
&lt;td&gt;execution&lt;/td&gt;
&lt;td&gt;1.77992&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;对于整个 999,994 个单词的语料库，我们还可视化了 HNSW 和自定义 Rust 索引下每个单词到其顶部 K=20 个近似邻居的平均欧几里得距离的分布：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/vector-search-in-200-lines-of-rust/3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;最先进的 HNSW 指数确实提供了比我们的示例索引相对更近的邻居，平均距离和中位距离分别为 1.31576 和 1.20230（与我们的示例索引的 1.47138 和 1.35620 相比）。在随机的 10,000 大小的语料库子集上，HNSW 对前 K=20 的召回率为 58.2%，而我们的示例索引针对不同的配置（如前所述，树的数量较多）产生了不同的召回率（从 11.465% 到 23.115%）提供更高的召回率）：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;num_trees&lt;/th&gt;
&lt;th&gt;max_node_size&lt;/th&gt;
&lt;th&gt;Average runtime&lt;/th&gt;
&lt;th&gt;QPS&lt;/th&gt;
&lt;th&gt;Recall&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;129.48μs&lt;/td&gt;
&lt;td&gt;7723&lt;/td&gt;
&lt;td&gt;0.11465&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;112.02μs&lt;/td&gt;
&lt;td&gt;8297&lt;/td&gt;
&lt;td&gt;0.11175&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;114.48μs&lt;/td&gt;
&lt;td&gt;8735&lt;/td&gt;
&lt;td&gt;0.09265&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;16.77ms&lt;/td&gt;
&lt;td&gt;60&lt;/td&gt;
&lt;td&gt;0.22095&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;1.54ms&lt;/td&gt;
&lt;td&gt;649&lt;/td&gt;
&lt;td&gt;0.20985&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;9&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;370.80μs&lt;/td&gt;
&lt;td&gt;2697&lt;/td&gt;
&lt;td&gt;0.16835&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;35.45ms&lt;/td&gt;
&lt;td&gt;28&lt;/td&gt;
&lt;td&gt;0.29825&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;7.34ms&lt;/td&gt;
&lt;td&gt;136&lt;/td&gt;
&lt;td&gt;0.28520&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;15&lt;/td&gt;
&lt;td&gt;30&lt;/td&gt;
&lt;td&gt;2.19ms&lt;/td&gt;
&lt;td&gt;457&lt;/td&gt;
&lt;td&gt;0.23115&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;为什么fann这么快&#34;&gt;为什么FANN这么快？&lt;/h2&gt;
&lt;p&gt;正如您在上面的数字中看到的，虽然 FANN 算法在质量上无法与最先进的算法竞争，但它至少相当快。为什么会这样？&lt;/p&gt;
&lt;p&gt;老实说，当我们构建这个时，我们得意忘形并开始进行性能优化只是为了好玩。以下是一些最显着的优化：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将文档重复数据删除卸载到索引冷路径。通过索引而不是浮点数组引用向量可以显着加快搜索速度，因为跨树查找唯一候选者需要散列 8 字节索引（而不是 300 维 f32 数据）。&lt;/li&gt;
&lt;li&gt;在将项目添加到全局候选列表之前，急切地散列并查找唯一向量，并通过递归搜索调用之间的可变引用传递数据，以避免跨堆栈帧和堆栈帧内进行复制。&lt;/li&gt;
&lt;li&gt;将 N 作为通用类型参数传递，这允许将 300 维数据作为 300 长度的 f32 数组（而不是可变长度向量类型）进行类型检查，以提高缓存局部性并减少内存占用（向量具有堆上数据的附加重定向级别）。&lt;/li&gt;
&lt;li&gt;我们还怀疑 Rust 编译器正在对内部操作（例如点积）进行向量化，但我们没有检查。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;更多现实世界的考虑&#34;&gt;更多现实世界的考虑&lt;/h2&gt;
&lt;p&gt;此示例跳过了几个对于生产向量搜索至关重要的注意事项：(&lt;strong&gt;注&lt;/strong&gt;：单实例 cpu指令集优化 向量矩阵如axv2，SIMD + OpenMP； 分布式数据存储扩展 RPC + 分布式一致性协议)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;当搜索涉及多棵树时进行并行化。我们可以并行化，而不是按顺序收集候选者，因为每棵树访问不同的内存 - 每棵树可以在单独的线程上运行，其中候选者通过消息沿着通道连续发送到主进程。线程可以在索引时生成，并通过虚拟搜索（使树的部分位于缓存中）进行预热，以减少搜索开销。搜索将不再随树的数量线性缩放。&lt;/li&gt;
&lt;li&gt;大型树可能不适合 RAM，需要有效的方法从磁盘读取 - 某些子图可能需要位于磁盘上，并且算法旨在允许搜索，同时最大限度地减少文件 I/O。&lt;/li&gt;
&lt;li&gt;更进一步，如果树不适合实例的磁盘，我们需要跨实例分布子树，并且如果数据在本地不可用，则递归搜索调用会触发一些 RPC 请求。&lt;/li&gt;
&lt;li&gt;该树涉及许多内存重定向（基于指针的树不适合 L1 缓存）。平衡树可以用数组很好地编写，但我们的树只能用随机超平面接近平衡——我们可以为树使用新的数据结构吗？&lt;/li&gt;
&lt;li&gt;当新数据被动态索引时（可能需要对大树进行重新分片），上述问题的解决方案也应该适用。如果特定的索引顺序导致树高度不平衡，是否应该重新创建树？&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;如果你到达这里，恭喜你！您刚刚看到了大约 200 行 Rust 中的简单向量搜索，以及我们对行星规模应用程序的向量搜索的漫谈。我们希望您喜欢阅读本文，并随时访问&lt;a href=&#34;https://github.com/fennel-ai/fann&#34;&gt;https://github.com/fennel-ai/fann&lt;/a&gt;的源代码。&lt;/p&gt;
&lt;p&gt;(&lt;strong&gt;注&lt;/strong&gt;：实验性质，运行下benchmark.sh 对比faiss hnsw了解下原理, faiss hnsw可以参数调优， LSH 可用于生产环境的库可参考&lt;a href=&#34;https://github.com/FALCONN-LIB/FALCONN&#34;&gt;FALCONN-LIB&lt;/a&gt;实现, 对 K，L,  T 调优，参考&lt;a href=&#34;https://github.com/FALCONN-LIB/FALCONN/wiki/LSH-Primer&#34;&gt;Locality-Sensitive Hashing: a Primer&lt;/a&gt;, 另外一个&lt;a href=&#34;https://github.com/ritchie46/lsh-rs&#34;&gt;lsh-rs&lt;/a&gt; 库也可以参考，&lt;a href=&#34;https://github.com/bwindsor22/thistle&#34;&gt;thistle&lt;/a&gt; 则参考了&lt;a href=&#34;https://github.com/ritchie46/lsh-rs&#34;&gt;lsh-rs&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/jean-pierreBoth/hnswlib-rs&#34;&gt;hnswlib-rs&lt;/a&gt;的实现，不过都不支持动态更新索引）&lt;/p&gt;
&lt;h1 id=&#34;reference&#34;&gt;reference&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Locality-sensitive_hashing&#34;&gt;https://en.wikipedia.org/wiki/Locality-sensitive_hashing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://fennel.ai/blog/vector-search-in-200-lines-of-rust/&#34;&gt;https://fennel.ai/blog/vector-search-in-200-lines-of-rust/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://erikbern.com/2015/09/24/nearest-neighbor-methods-vector-models-part-1&#34;&gt;https://erikbern.com/2015/09/24/nearest-neighbor-methods-vector-models-part-1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html&#34;&gt;https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://erikbern.com/2016/06/02/approximate-nearest-news&#34;&gt;https://erikbern.com/2016/06/02/approximate-nearest-news&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.ritchievink.com/blog/2020/04/07/sparse-neural-networks-and-hash-tables-with-locality-sensitive-hashing/&#34;&gt;https://www.ritchievink.com/blog/2020/04/07/sparse-neural-networks-and-hash-tables-with-locality-sensitive-hashing/&lt;/a&gt; &lt;a href=&#34;https://github.com/ritchie46/lsh-rs&#34;&gt;lsh-rs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2303.16780.pdf&#34;&gt;arxiv paper - Thistle: A Vector Database in Rust&lt;/a&gt; &lt;a href=&#34;https://github.com/bwindsor22/thistle&#34;&gt;thistle&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/FALCONN-LIB/FALCONN/wiki/LSH-Primer&#34;&gt;https://github.com/FALCONN-LIB/FALCONN/wiki/LSH-Primer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/2206.01382.pdf&#34;&gt;Falconn++: A Locality-sensitive Filtering Approach for Approximate Nearest Neighbor Search&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>译：Manas：高性能定制搜索系统</title>
      <link>https://weedge.github.io/post/oneday/manas-a-high-performing-customized-search-system/</link>
      <pubDate>Thu, 14 Sep 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/manas-a-high-performing-customized-search-system/</guid>
      
        <description>&lt;h1 id=&#34;章节一-manas高性能定制搜索系统&#34;&gt;章节一 Manas：高性能定制搜索系统&lt;/h1&gt;
&lt;p&gt;Pinterest 搜索每月处理数十亿次查询，每天返回近 40 亿个 Pin 图。去年，每月移动文本搜索量增长了 40%，视觉搜索量增长了近 60%。最近，通过在主页上推出 &lt;a href=&#34;https://blog.pinterest.com/en/search-and-lens-move-front-and-center&#34;&gt;Search 和 Lens&lt;/a&gt;，使它们在的应用程序中更加突出和集中，因为现在近 85% 的搜索都发生在移动设备上。&lt;/p&gt;
&lt;p&gt;为了继续扩展搜索，系统需要为每个 Pinner 在超过 1000 亿个 Pin 图中找到最相关的结果。此前，搜索系统是建立在 Lucene 之上并用 Java 编写的。但随着业务发展和引入新的发现功能，遗留系统面临着挑战，无法再支持。这就是构建 Manas 的原因，这是一个用 C++ 编写的定制全栈搜索系统，可以在提高容量的同时显着减少延迟。在这篇文章中，将概述 Manas 的架构，并了解 Pinterest 搜索的下一步发展。&lt;/p&gt;
&lt;h2 id=&#34;挑战&#34;&gt;&lt;strong&gt;挑战&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;随着 Pinterest 上的搜索使用量快速增长，基于 &lt;a href=&#34;https://github.com/apache/lucene&#34;&gt;Lucene&lt;/a&gt; 的解决方案日益面临挑战，包括：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;查询量和索引大小增长如此之快，以至于需要减少服务延迟并提高容量。&lt;/li&gt;
&lt;li&gt;除了搜索之外，该系统还为 Pinterest 内的多个用例提供支持，包括 Pinner 搜索、图板搜索、相关 Pin 图、主页推送推荐等。需要灵活地定制搜索过程，这在以前是不可能的。&lt;/li&gt;
&lt;li&gt;希望将该系统应用于复杂而强大的排名模型，但 Lucene 索引格式和评分器界面不适合这些模型。&lt;/li&gt;
&lt;li&gt;还希望个性化搜索结果，这是标准 Lucene 系统无法支持的。&lt;/li&gt;
&lt;li&gt;构建 Manas 来解决这些挑战。Manas被设计为一个具有高性能、高可用性和高可扩展性的通用搜索框架。与旧系统相比，搜索后端延迟减少了一半，容量增加了30%。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;概述&#34;&gt;概述&lt;/h2&gt;
&lt;p&gt;Manas 是一个全栈搜索索引和服务系统。服务系统由几个阶段组成：查询理解、候选检索、轻量级评分、全面评分和混合。&lt;/p&gt;
&lt;h2 id=&#34;索引&#34;&gt;索引&lt;/h2&gt;
&lt;h3 id=&#34;索引格式&#34;&gt;&lt;strong&gt;索引格式&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Manas索引包括倒排索引和正向索引。&lt;/p&gt;
&lt;p&gt;与普通倒排索引相同，Manas倒排索引存储term到帖子列表的映射。每个发布都会记录内部文档 ID 和有效负载。为了优化索引大小和服务延迟，实现了密集倒排列表和分割倒排列表，这是根据所有文档中关键term的分布对倒排列表进行编码的两种方法。倒排索引用于候选生成和轻量级评分。&lt;/p&gt;
&lt;p&gt;另一方面，Manas的正向索引存储了从内部文档ID到实际文档的映射。为了优化数据局部性，前向索引支持列族，类似于HFile。前向指数用于全面评分。&lt;/p&gt;
&lt;h3 id=&#34;manas-doc&#34;&gt;&lt;strong&gt;Manas doc&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;将Manas doc定义为不同应用程序的统一模式，用于描述他们想要为每个文档索引哪些数据。在Manas文档中，可以指定匹配的term进行检索，并且可以添加文档的属性以进行过滤和轻量级评分。例如，系统在按语言属性过滤结果后只能返回英文文档。&lt;/p&gt;
&lt;h3 id=&#34;索引构建器&#34;&gt;&lt;strong&gt;索引构建器&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;索引构建器采用一批 Manas 文档并构建索引。定义了统一的 Manas 文档架构，以便可以为不同的用例共享索引构建器。&lt;/p&gt;
&lt;h3 id=&#34;索引管道&#34;&gt;&lt;strong&gt;索引管道&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/1.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图说明了索引管道。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不同的应用程序为其语料库生成 Manas 文档。&lt;/li&gt;
&lt;li&gt;Manas 文档被划分为多个组。&lt;/li&gt;
&lt;li&gt;索引构建器将分区中的所有 Manas 文档转换为索引段。每个索引段都是完整索引的一小部分。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;服务&#34;&gt;服务&lt;/h2&gt;
&lt;p&gt;下图展示了Manas的搜索周期。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/2.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;当查询进入系统时会发生以下情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;查询理解服务处理原始查询并生成执行计划。&lt;/li&gt;
&lt;li&gt;语料库由服务树提供。Blender 将请求扇出到不同语料库的根，收集这些不同的结果并将它们混合。将这些混合结果存储在缓存中以进行分页。&lt;/li&gt;
&lt;li&gt;Root 是一种分散-聚集服务。它聚合叶子的结果并对它们重新排序。&lt;/li&gt;
&lt;li&gt;Leaf 首先加载由索引管道构建的索引段。它检索候选人并进行轻量级和全面评分。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;叶子服务&#34;&gt;叶子服务&lt;/h3&gt;
&lt;p&gt;Manas Leaf 是可扩展的，允许定制多个不同的应用程序。这是通过在索引中封装特定于应用程序的信息来实现的。可以embedding特定于应用程序的评分逻辑，以便 Manas 在对文档评分时仅执行应用程序执行的任务。&lt;/p&gt;
&lt;p&gt;服务架构设计为多层，层与层之间定义良好的接口，使得每一层都是可扩展的。Leaf节点的架构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/3.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;如上所述，存储层负责加载索引并提供抽象，允许在给定标识符的情况下获取连续的大量二进制数据。这一层允许轻松地改变索引的底层存储。在存储层之上，索引层将二进制数据解码为索引，并提供读取索引的接口。倒排列表层使能够灵活地实现倒排索引。算子层定义了用于实现查询算子的接口，模型运行器定义了用于全面评分的模型接口。最后，API 层指定叶节点评估的查询格式。&lt;/p&gt;
&lt;h2 id=&#34;候选检索和轻量级评分&#34;&gt;候选检索和轻量级评分&lt;/h2&gt;
&lt;h3 id=&#34;wand&#34;&gt;WAND&lt;/h3&gt;
&lt;p&gt;除了支持普通的“AND”、“OR”和“NOT”操作之外，还在 Leaf 中构建了“Weak And”支持（&lt;a href=&#34;https://www.semanticscholar.org/paper/Efficient-query-evaluation-using-a-two-level-Broder-Carmel/89d27fc4c5bf15762d001a39f0a74f84c89d3681&#34;&gt;paper&lt;/a&gt;)。这使能够快速跳过posting list。&lt;/p&gt;
&lt;h3 id=&#34;squery&#34;&gt;Squery&lt;/h3&gt;
&lt;p&gt;使用Squery 以树的形式表示结构化查询。它描述了 Leaf 如何从索引中检索候选者并对其进行轻量级评分。Leaf 理解 Squery 并在索引上执行它。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/4.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图是 Squery 要求 Leaf 检索纯英文文档并匹配term“cute”和“cat”或“kitten”的示例。如果文档的点击率较高，则得分较高。&lt;/p&gt;
&lt;h3 id=&#34;满分&#34;&gt;满分&lt;/h3&gt;
&lt;p&gt;不同的应用程序使用不同的算法来计算最终分数。为了使 Manas 具有通用性，引入了前向索引，它是一个二进制 blob，可以是任何东西。实际上，前向索引是一个序列化的 Thrift 对象。Manas 不会解释前向索引，而是将其注入到 DSL 模型中并执行 DSL 模型来计算分数。DSL 是 Pinterest 使用的一种领域特定语言，用于定制从前向索引中提取特征，并选择机器学习模型来根据提取的特征计算分数。不同的应用程序可以创建不同的 DSL 模型并指定应注入哪个前向索引。&lt;/p&gt;
&lt;h3 id=&#34;ssd&#34;&gt;SSD&lt;/h3&gt;
&lt;p&gt;具有相当大的前向索引以支持复杂的评分算法，总索引大小显着增加。为了支持未来更复杂的评分，将向索引添加更多信号。将所有索引加载到内存中是不可扩展的，因此 Manas 仅加载用于候选检索和轻量级评分的倒排索引，并从 SSD 和本地缓存提供正向索引。&lt;/p&gt;
&lt;h3 id=&#34;索引交换&#34;&gt;索引交换&lt;/h3&gt;
&lt;p&gt;定期执行索引管道来构建索引。一旦新索引准备就绪，就会从 AWS 分配新实例来创建集群。将新索引部署到新创建的集群。然后 Blender 会将流量切换到新集群，旧集群将被弃用。&lt;/p&gt;
&lt;h1 id=&#34;章节二-manas-realtime--使更改能够在眨眼间被搜索到&#34;&gt;章节二 Manas Realtime — 使更改能够在眨眼间被搜索到&lt;/h1&gt;
&lt;p&gt;Manas 是 Pinterest 的内部搜索引擎，是一个通用信息检索平台。正如在&lt;a href=&#34;https://medium.com/pinterest-engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f&#34;&gt;上一篇文章&lt;/a&gt;中讨论的那样，Manas 被设计为具有高性能、可用性和可扩展性的搜索框架。如今，Manas 为大多数 Pinterest 产品提供搜索功能，包括广告、搜索、Homefeed、相关 Pin 图、视觉效果和购物。&lt;/p&gt;
&lt;p&gt;搜索系统的关键指标之一是索引延迟，即更新搜索索引以反映更改所需的时间。随着不断增强系统功能并引入新的用例，即时索引新文档的能力变得更加重要。Manas已经支持增量索引，能够提供数十分钟左右的索引延迟。不幸的是，这无法满足不断增长的广告和关注源的业务需求。决定在 Manas 中构建一个新模块，以进一步将索引延迟减少到几分之一秒。&lt;/p&gt;
&lt;p&gt;在这篇博文中，描述了系统的架构及其主要挑战，并提供了有关所做的权衡的详细信息。&lt;/p&gt;
&lt;h2 id=&#34;挑战-1&#34;&gt;挑战&lt;/h2&gt;
&lt;p&gt;新要求伴随着新挑战。以下是面临的几个主要挑战。&lt;/p&gt;
&lt;h3 id=&#34;索引延迟&#34;&gt;索引延迟&lt;/h3&gt;
&lt;p&gt;小批量方法，又称近实时方法，是&lt;a href=&#34;https://lucene.apache.org/&#34;&gt;Lucene&lt;/a&gt;、&lt;a href=&#34;https://vespa.ai/&#34;&gt;Vespa&lt;/a&gt;等开源项目最流行的选择。通过这种方法，新编写的文档在调用索引提交之前不可搜索。因此，您需要在索引延迟和吞吐量之间进行权衡。不幸的是，无法利用这种方法将索引延迟减少到秒级。&lt;/p&gt;
&lt;h3 id=&#34;索引刷新能力&#34;&gt;索引刷新能力&lt;/h3&gt;
&lt;p&gt;实时服务的缺点之一是缺乏索引刷新敏捷性。对于批处理管道，重新运行索引作业以立即获取所有架构更改非常简单。然而，当涉及到实时服务管道时，高效的索引刷新支持变得复杂。&lt;/p&gt;
&lt;h3 id=&#34;针对不断变化的数据进行扩展&#34;&gt;针对不断变化的数据进行扩展&lt;/h3&gt;
&lt;p&gt;为了避免过度配置，采用自动缩放来根据实际查询负载调整副本。如果索引是不可变的，则创建新副本相对容易：您只需将索引复制到新节点即可。所有的困难都在于处理不断变化的索引：如何确保所有副本最终都有相同的索引？&lt;/p&gt;
&lt;h3 id=&#34;错误恢复&#34;&gt;错误恢复&lt;/h3&gt;
&lt;p&gt;Manas 是一项数据密集型服务，其中每个主机可以提供高达数百 GB 的索引。Manas也是一个有状态的系统。错误的二进制文件可能会引入回滚无法修复的数据问题。需要构建一个支持容错和错误恢复的系统，以便可以从二进制错误和数据损坏中恢复。&lt;/p&gt;
&lt;h3 id=&#34;从静态转向实时&#34;&gt;从静态转向实时&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/5.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;简单看一下传统静态服务和实时服务的区别。如上图所示，实时服务的主要工作是将索引管道从离线转移到在线。&lt;/p&gt;
&lt;p&gt;对于静态服务，索引是通过批处理工作流程离线生成的，然后将它们复制到叶子以进行在线服务。对于批处理工作流程，由于框架开销较高，几乎不可能在几分之一秒内构建可服务的索引。对于实时服务，所有写入都在服务内动态处理，而不是使用离线工作流程。此外，实时索引管道以生成与静态索引管道相同的索引格式的方式处理写入，从而允许重用整个索引读取逻辑。考虑到这一点，让继续了解实时服务的工作原理。&lt;/p&gt;
&lt;h3 id=&#34;索引接口&#34;&gt;索引接口&lt;/h3&gt;
&lt;p&gt;没有直接使用&lt;a href=&#34;https://en.wikipedia.org/wiki/Remote_procedure_call&#34;&gt;RPC&lt;/a&gt;，而是使用&lt;a href=&#34;https://kafka.apache.org/&#34;&gt;&lt;strong&gt;Kafka作为的高写入吞吐量流。&lt;/strong&gt;&lt;/a&gt;叶子服务器不断拉动突变来构建增量索引。事实证明，这个决定在多个方面极大地简化了的系统：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;数据复制和写入失败由 Kafka 负责。&lt;/li&gt;
&lt;li&gt;有了回溯能力，Kafka队列也充当了&lt;a href=&#34;https://en.wikipedia.org/wiki/Write-ahead_logging&#34;&gt;WAL&lt;/a&gt;角色。&lt;/li&gt;
&lt;li&gt;每个分区都有严格的顺序保证，系统可以盲目应用删除，而无需担心正确性。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;架构概述&#34;&gt;架构概述&lt;/h2&gt;
&lt;p&gt;由于服务逻辑可以通过共享索引格式重用，因此将重点关注索引数据流。&lt;/p&gt;
&lt;p&gt;本质上，实时Manas leaf是一个&lt;a href=&#34;https://en.wikipedia.org/wiki/Log-structured_merge-tree&#34;&gt;LSM&lt;/a&gt;引擎，它将随机IO写入转换为顺序IO，并为读放大和写放大应用程序提供高效服务。如下所示，整个索引过程由三个关键步骤组成。来一一讨论。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/6.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;实时分段构建realtime-segment-build&#34;&gt;实时分段构建(Realtime Segment Build)&lt;/h3&gt;
&lt;p&gt;除了现有的静态段之外，还引入了实时段。如上图所示，系统中的实时段有两种类型：活动实时段和密封实时段。（&lt;strong&gt;注&lt;/strong&gt;: 这个类似leveldb/rocksdb LSMtree, 同样是append-only write顺序IO , 不同的是kafka充当了WAL, 内部数据结构变成了正排和倒排索引结构，分段存储）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;活动实时段是唯一的可变组件，用于累积从 Kafka 拉取的突变（添加/删除）。值得指出的是，将文档添加到实时段后，在文档级提交后立即可以搜索它。&lt;/li&gt;
&lt;li&gt;一旦活动实时段达到可配置的阈值，它就会被密封(&lt;strong&gt;sealed&lt;/strong&gt;)，变得不可变，并被放入刷新队列中。同时，创建一个新的活动实时片段以继续累积突变。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;在服务重启的情况下，可以通过重放来自 Kafka 的消息来重建实时片段。&lt;/p&gt;
&lt;h3 id=&#34;索引落盘index-flush&#34;&gt;索引落盘(index flush)&lt;/h3&gt;
&lt;p&gt;索引落盘是将内存中数据从实时段持久保存到紧凑索引文件中的过程。当实时段被密封时，flush落盘会自动触发，也可以使用调试命令手动触发flush落盘。&lt;/p&gt;
&lt;p&gt;索引落盘是一个有益的操作，它可以保证数据持久性，这样就不需要在重启期间从头开始重建内存中的段。此外，flush落盘还可以减少段的内存占用，并通过紧凑的不可变索引提高服务效率。&lt;/p&gt;
&lt;h3 id=&#34;索引压缩index-compaction&#34;&gt;索引压缩(Index Compaction)&lt;/h3&gt;
&lt;p&gt;随着时间的推移，多个生成的小段会损害服务性能。为了克服这个问题，引入了后台压缩线程来将小段合并为更大的段。由于删除操作只是将文档标记为已删除，而不是物理删除它们，因此压缩线程还会保留这些已删除/过期的文档。&lt;/p&gt;
&lt;p&gt;在每个刷新和压缩操作之后，将生成一个由所有静态段组成的新索引清单。用作检查点的 Kafka 偏移量也会添加到每个清单中。根据检查点，服务知道重启后在哪里消费消息。&lt;/p&gt;
&lt;h2 id=&#34;详细设计&#34;&gt;详细设计&lt;/h2&gt;
&lt;p&gt;在本节中，将更详细地介绍几个关键领域。让从最有趣的部分开始，即并发模型。&lt;/p&gt;
&lt;h3 id=&#34;并发模型&#34;&gt;并发模型&lt;/h3&gt;
&lt;p&gt;如上所述，实时段是需要同时处理读取和写入的唯一可变组件。不幸的是，开源项目采用的近实时方法无法满足的业务需求。相反，选择了一种不同的方法，使能够在添加到索引后立即提交文档，而无需等待索引刷新。出于性能考虑，针对适合用途的数据结构采用了&lt;a href=&#34;https://en.wikipedia.org/wiki/Non-blocking_algorithm&#34;&gt;无锁技术。&lt;/a&gt;现在来开箱吧！&lt;/p&gt;
&lt;h4 id=&#34;实时片段realtime-segment&#34;&gt;&lt;strong&gt;实时片段(Realtime Segment)&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;每个实时段由一个倒排索引和一个正向索引组成。倒排索引在逻辑上是term到posting list（用于检索的文档 ID 列表）的映射。同时，前向索引存储用于完整评分和数据获取的任意二进制 blob。只关注实时倒排索引部分，与正向索引相比，实时倒排索引更有趣且更具挑战性。&lt;/p&gt;
&lt;p&gt;在较高的层面上，实时段和静态段之间的主要区别是可变性。对于实时倒排索引，从term到倒排列表的映射需要是并发的。这得到了像 &lt;a href=&#34;https://github.com/facebook/folly&#34;&gt;&lt;strong&gt;folly&lt;/strong&gt;&lt;/a&gt; 的并发hashmap这样的开源的良好支持。更关心的是posting list的内部表示，它可以有效地支持的并发模型。&lt;/p&gt;
&lt;h4 id=&#34;仅附加向量append-only-vector&#34;&gt;&lt;strong&gt;仅附加向量(Append-only Vector)&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;通常single-writer、multiple-readers模型更高效、更容易推理。选择了与&lt;a href=&#34;https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html&#34;&gt;HDFS&lt;/a&gt;类似的数据模型(注:CF)，具有仅附加无锁数据结构。了解reader和writer如何交互如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/7.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Writer将文档 ID 附加到向量中，然后提交大小以使其可供读者访问&lt;/li&gt;
&lt;li&gt;Reader在访问数据之前,获取快照(snapshot)直至提交大小&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/8.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;为了避免随着posting list的增长而产生内存复制开销，在内部将数据作为存储桶列表进行管理。当容量用完时，只需要添加一个新的存储桶，而无需触及旧的存储桶。另外，通常搜索引擎使用跳跃列表来加速跳跃操作。由于这种格式，可以很方便地支持单级跳表，这对于实时倒排索引来说已经足够了，因为它的大小通常很小。&lt;/p&gt;
&lt;h4 id=&#34;文档原子性document-atomicity&#34;&gt;&lt;strong&gt;文档原子性(Document Atomicity)&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;现在，通过仅附加向量，能够实现单个posting list的原子性。但是，文档可以包含term列表，最终可能会返回带有部分更新索引的意外文档。为了解决这个潜在问题，引入了文档级提交来保证文档原子性。在服务管道中，使用附加过滤器来确保仅返回已提交的文档。&lt;/p&gt;
&lt;p&gt;说到文档原子性，文档更新是这里值得一提的另一个场景。对于每个文档更新，特意将其转换为两个操作：添加新文档，然后从索引中删除旧文档。虽然每个操作符都是原子性的，但在一起不能保证原子性。考虑到在很短的时间窗口内返回旧版本或新版本都可以，但尽管如此，还是在服务管道中添加了重复数据删除逻辑，以便在两者都返回时过滤掉旧版本。&lt;/p&gt;
&lt;h4 id=&#34;写入缩放writes-scaling&#34;&gt;&lt;strong&gt;写入缩放(Writes Scaling)&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;自然而然出现的一个问题是，如果你的数据结构只支持单写多读并发模型，那么如果单个线程无法及时处理所有写操作怎么办？仅仅为了扩展写入吞吐量而盲目添加更多分片似乎不是一个好主意。这是一个合理的担忧，在设计中已经考虑到了这一点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/9.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;用于数据结构的单写多读并发模型并不意味着不能使用多线程进行写操作。使用了term分片策略来支持多线程写入。如上图所示，对于给定的包含term列表的文档，每个term将始终映射到固定线程，以便所有为单写和多读定制的数据结构都可以直接重用，没有任何限制。(&lt;strong&gt;注&lt;/strong&gt;：加快索引构建，map/reduce分而治之思考方式(分而治之算法的工作原理是将问题递归地分解为两个或多个相同或相关类型的子问题，直到这些问题变得简单到可以直接解决。然后将子问题的解决方案组合起来以给出原始问题的解决方案)，no block彼此独立可并发执行,可以结合硬件与操作系统异步io操作加速写入)&lt;/p&gt;
&lt;h3 id=&#34;索引刷新index-refresh&#34;&gt;索引刷新(Index Refresh)&lt;/h3&gt;
&lt;p&gt;索引刷新能力是产品的一项关键功能，可以实现快速周转并提高开发速度。一般来说，可以使用两种方法来有效地刷新索引，分别是动态回填和从离线构建的索引恢复。&lt;/p&gt;
&lt;h4 id=&#34;回填索引backfilling-index&#34;&gt;&lt;strong&gt;回填索引(Backfilling Index)&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;能够以合理的吞吐量回填文档。为了避免影响生产新鲜度(freshness)，需要一个单独的流来处理优先级较低的回填流量。因此，两个流中可能存在文档的两个版本，并且旧版本会覆盖新版本。为了克服这个问题，需要在实时索引管道中引入版本控制机制和冲突解决程序来决定哪个更新鲜。&lt;/p&gt;
&lt;h4 id=&#34;从离线构建索引恢复reinstating-from-offline-built-index&#34;&gt;&lt;strong&gt;从离线构建索引恢复(Reinstating from Offline Built Index)&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;有时，以给定速度回填完整数据集会非常耗时。支持的另一种更快的索引刷新方法是离线构建索引，然后通过离线构建的索引和 Kafka 流之间的同步机制从中恢复。()&lt;/p&gt;
&lt;h3 id=&#34;故障转移和自动缩放failover-and-auto-scaling&#34;&gt;故障转移和自动缩放(Failover and Auto-scaling)&lt;/h3&gt;
&lt;p&gt;有时，需要出于各种原因启动新实例，例如故障转移和自动扩展等。对于静态服务，可以很容易地使用从索引存储下载的不可变索引来启动新实例(&lt;strong&gt;注&lt;/strong&gt;：这个类似rocksdb &lt;a href=&#34;https://github.com/facebook/rocksdb/wiki/Creating-and-Ingesting-SST-files#ingesting-sst-files&#34;&gt;bulkloading&lt;/a&gt; SSTable文件)。然而，对于索引不断变化的实时服务来说，它变得很复杂。如何确保新实例最终具有与其他实例相同的索引副本？&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/10.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;决定使用基于领导者的复制，如上图所示。的流程如下所示：(&lt;strong&gt;注&lt;/strong&gt;：这个和分布式存储系统中多副本replica同步操作一样，大多是通过一致性协议来保证，比如&lt;a href=&#34;https://en.wikipedia.org/wiki/Raft_(algorithm)&#34;&gt;raft&lt;/a&gt;/&lt;a href=&#34;https://en.wikipedia.org/wiki/Paxos_(computer_science)&#34;&gt;Paxos&lt;/a&gt; 协议，如果follower落后，从快照中恢复数据，不同的是这里快照是放在支持S3协议云存储服务，使用kafka充当WAL从最新checkpoint开始恢复日志消息，同步完成，提供流量访问；这个看着流程容易，实现起来细节还是挺多的)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;领导者定期dump新快照(snapshots)并将其上传到持久索引存储&lt;/li&gt;
&lt;li&gt;新实例默认从索引存储下载最新快照&lt;/li&gt;
&lt;li&gt;新实例根据快照索引中的检查点恢复消费来自 Kafka 的消息&lt;/li&gt;
&lt;li&gt;新实例赶上后就开始提供流量&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;设计中有一些要点值得指出：&lt;/p&gt;
&lt;h4 id=&#34;领导人选举&#34;&gt;&lt;strong&gt;领导人选举&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;Leader 的唯一职责是定期dump快照并上传索引。这意味着可以承受在短时间内（最多几个小时）没有领导者或有多个领导者的情况。因此，在选择领导者选举算法时具有一定的灵活性。为简单起见，选择使用集群维护作业来静态选择领导者，并定期检查是否有好的领导者。(&lt;strong&gt;注&lt;/strong&gt;：因为这里场景是单写多读模式，只写leader,当leader failover时，业务可以接受一段时间检索不到最新的数据，这个不影响业务使用，但是没有了最新的召回数据)&lt;/p&gt;
&lt;h4 id=&#34;快照上传&#34;&gt;&lt;strong&gt;快照上传&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;通常，新实例只是连接到领导者以下载最新的快照。在这种方法中，从新实例下载快照可能会使领导者过载，从而导致级联故障。相反，选择定期将快照上传到索引存储、交易空间和新鲜度以确保稳定性。此外，上传的快照对于错误恢复很有用，稍后将对此进行介绍。(&lt;strong&gt;注&lt;/strong&gt;： 上传快照，主要是kafka中的数据有错误数据时，用于快速恢复(从历史快照中恢复正确的历史数据，然后从正确数据的checkpoint点开始从kafka中消费日志数据进行恢复，&lt;!-- raw HTML omitted --&gt;跳过损坏的消息，使用修复好的新消息，fix操作&lt;!-- raw HTML omitted --&gt;)，aws s3成本是很低的，常存放大量一段时间的冷日志数据)&lt;/p&gt;
&lt;h3 id=&#34;错误恢复-1&#34;&gt;错误恢复&lt;/h3&gt;
&lt;p&gt;如上所述，错误恢复是实时服务系统的另一个挑战。需要处理一些涉及数据损坏的特定场景。&lt;/p&gt;
&lt;h4 id=&#34;输入数据损坏&#34;&gt;&lt;strong&gt;输入数据损坏&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;使用 Kafka 作为输入写入流；不幸的是，这些消息是不可变的，因为生产者只能将消息附加到其中，但不能更改现有消息的内容。这意味着一旦数据损坏被引入 Kafka 消息中，它就是永久性的。借助上传的快照，能够将索引倒回到没有损坏的位置，跳过损坏的消息，然后使用修复后的新消息。&lt;/p&gt;
&lt;h4 id=&#34;二进制错误导致数据损坏&#34;&gt;&lt;strong&gt;二进制错误导致数据损坏&lt;/strong&gt;&lt;/h4&gt;
&lt;p&gt;尽管有一个成熟的静态集群索引验证管道，可以保证在换入新版本之前新索引和新二进制文件不会出现问题，但仍然可能会出现一些错误潜入生产环境。幸运的是，可以通过回滚二进制文件或索引来解决该问题。对于实时服务来说，回滚二进制文件无法回滚索引中的错误变得更加困难。使用的快照上传机制，能够回滚二进制文件以及回滚索引，然后重播来自 Kafka 的消息以修复索引中的错误。&lt;/p&gt;
&lt;h2 id=&#34;下一步是什么&#34;&gt;下一步是什么&lt;/h2&gt;
&lt;p&gt;随着Manas接入的场景越来越多，需要不断提升系统的效率、扩展性和能力。的路线图中一些有趣的项目如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;共同托管静态和实时集群以简化的服务堆栈&lt;/li&gt;
&lt;li&gt;优化系统以支持大数据集&lt;/li&gt;
&lt;li&gt;构建基于通用embedding的检索来支持高级场景&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;章节三-manas-hnsw-realtime为基于embedding的实时检索提供支持&#34;&gt;章节三 Manas HNSW Realtime：为基于embedding的实时检索提供支持&lt;/h1&gt;
&lt;p&gt;在之前的&lt;a href=&#34;https://medium.com/pinterest-engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f&#34;&gt;博文&lt;/a&gt;中，介绍了的内部搜索引擎 - Manas - 并分享了如何大规模提供基于term的搜索。自推出以来，Manas 已发展成为 Pinterest 的关键候选生成器之一，服务于许多超出其最初目的的用例。&lt;/p&gt;
&lt;p&gt;特别是，基于embedding的检索是 Pinterest 发现和推荐引擎的关键组成部分。Manas 传统上通过倒排索引上的局部敏感哈希 (LSH) 支持近似最近邻 (ANN) 搜索，倒排索引是基于term的搜索引擎的自然扩展。在发布新的最先进技术（例如分层可导航小世界图 (HNSW)&lt;a href=&#34;https://arxiv.org/abs/1603.09320&#34;&gt;论文&lt;/a&gt;，&lt;a href=&#34;https://github.com/nmslib/hnswlib&#34;&gt;开源库&lt;/a&gt;实现了metric space：L2(Euclidean Squared L2),IP(Inner product),Cosine(Cosine similarity)，一般用cosine，归一化处理；其中facebook &lt;a href=&#34;https://github.com/facebookresearch/faiss&#34;&gt;Faiss&lt;/a&gt;加入&lt;a href=&#34;https://github.com/facebookresearch/faiss/wiki/Additive-quantizers&#34;&gt;量化处理(Additive-quantizers)&lt;/a&gt;)后，在 Manas 中构建了一个灵活的基于embedding的检索框架，这使能够轻松采用新的 ANN 技术。使用新框架将 HNSW 启动到批量索引集群（索引延迟从几分钟到几天不等），与 LSH 相比，可以节省大量服务成本并减少延迟。&lt;/p&gt;
&lt;p&gt;计划中的下一个里程碑是将 HNSW 启动到的实时流集群（秒级索引延迟）。实时、大规模地为 HNSW 提供服务并不是一项简单的任务，部分原因是正在开辟新的领域，而无法依赖任何开源实现。&lt;/p&gt;
&lt;p&gt;在这篇博客中，将分享为 HNSW 提供实时服务的历程——解决这个问题的方法、面临的挑战以及为生产系统所做的一些优化。&lt;/p&gt;
&lt;h2 id=&#34;manas-realtime&#34;&gt;Manas Realtime&lt;/h2&gt;
&lt;p&gt;该项目的本质是为 HNSW 构建实时组件并将其集成到&lt;a href=&#34;https://medium.com/pinterest-engineering/manas-realtime-enabling-changes-to-be-searchable-in-a-blink-of-an-eye-36acc3506843&#34;&gt;Manas Realtime&lt;/a&gt;中。为了更好地了解这些组件如何适应更大的情况，让简要了解一下 Manas Realtime 的高级架构。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/11.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Manas Realtime本质上是一个&lt;a href=&#34;https://en.wikipedia.org/wiki/Log-structured_merge-tree&#34;&gt;LSM&lt;/a&gt;引擎，它将随机IO写入转换为顺序IO写入。写入不是公开写入端点，而是从 Kafka 摄取，这使能够简化系统并依赖 Kafka 作为 WAL。写入分为三种类型，以下是它们的处理方式：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;新文档被写入内存中的实时段，最终被密封并刷新到磁盘上的静态段&lt;/li&gt;
&lt;li&gt;使用内存中标记应用删除，并在服务期间过滤掉&lt;/li&gt;
&lt;li&gt;更新是通过删除旧文档并添加新文档来完成的&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;后台压缩过程有时会组合各种静态段，以减少因段过多而产生的服务开销。还依靠压缩过程通过从索引中删除文档来执行实际删除。&lt;/p&gt;
&lt;p&gt;从服务的角度来看，Manas Realtime 与 Manas Static 没有太大区别。对索引进行了抽象，以便存储层对整个检索过程是透明的。因此，随着 HNSW 已经为 Manas Static 启动，大多数服务组件已经存在。工作主要是与Manas Realtime 的LSM 索引组件集成。需要构建和优化两个核心组件，将在下面的部分中详细介绍：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;实时 HNSW 图表&lt;/li&gt;
&lt;li&gt;HNSW 图压缩&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;实时-hnsw-图表realtime-hnsw-graph&#34;&gt;实时 HNSW 图表(Realtime HNSW Graph)&lt;/h3&gt;
&lt;p&gt;实时段是系统中唯一可变的组件，因此该区域的优化对于确保良好的并发读写性能至关重要。&lt;/p&gt;
&lt;p&gt;HNSW 索引本质上是一个多层稀疏图。选择一个邻接列表来表示图，其中键是节点 id，值是邻居 id 列表。从基于锁的版本开始，每个节点都拥有一个锁，在更新邻居列表之前，该锁将由reader和writer持有。它很容易实现和推理。然而，由于锁争用，系统 CPU 使用率较高，别无选择，只能使用&lt;a href=&#34;https://en.wikipedia.org/wiki/Non-blocking_algorithm&#34;&gt;无锁&lt;/a&gt;技术。&lt;/p&gt;
&lt;h3 id=&#34;无锁实现lock-free-implementation&#34;&gt;无锁实现(Lock-free Implementation)&lt;/h3&gt;
&lt;p&gt;让来剖析一下如何以直观的方式处理写入。HNSW的思想源于著名的&lt;a href=&#34;https://en.wikipedia.org/wiki/Skip_list&#34;&gt;跳表&lt;/a&gt;结构。因此，HNSW 的无锁实现也类似于无锁跳表。一般来说，为了向图中添加新节点，每一层都涉及两个步骤，如下图所示。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在层内查找新节点的邻居并将新节点连接到选定的邻居&lt;/li&gt;
&lt;li&gt;更新选定的邻居以连接到新节点。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/12.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;同样，在 HNSW 图中从基础层开始向上层添加新节点，以避免出现新节点被选为上层的进入点但下层实际上没有为其建立连接的情况，从而导致没有结果问题。&lt;/p&gt;
&lt;p&gt;对于删除，避免了将它们应用到图表中的成本和复杂性。相反，使用内存中的删除标记在图外处理它们，依靠过滤器在服务期间过滤掉已删除的节点。&lt;/p&gt;
&lt;p&gt;一些细节优化值得简单提及：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;单写多读&lt;/strong&gt;：为了简单起见，延续了使用单写多读并发模式的传统，从而使代码整洁且易于推理。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;预分配图&lt;/strong&gt;：由于实时图通常较小且大小固定，因此为图预分配内存以避免调整大小带来的复杂性。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;定制邻居选择算法&lt;/strong&gt;：使用标准邻居选择算法，更新邻居列表有三种可能：添加一个新邻居、减少邻居和替换一个邻居。当涉及到无锁实现时，通过回填最近邻居来消除“减少邻居”场景实际上大大简化了逻辑，能够使用原子操作。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;“原子”变量&lt;/strong&gt;：即使使用释放-获取顺序，c++ std::atomic 变量实际上也是昂贵的。相反，使用对齐内存来保证原子性，并使用全局原子变量作为内存屏障，使能够仅一次显式提交一个节点的所有更改。&lt;!-- raw HTML omitted --&gt;一些部分更新仍然有可能泄漏到读取线程可见，从而在短时间内损害全局连接。由于观察没有明显的召回率下降，将其视为性能和质量之间的合理权衡&lt;!-- raw HTML omitted --&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;hnsw-图压缩hnsw-graph-compaction&#34;&gt;HNSW 图压缩(HNSW Graph Compaction)&lt;/h2&gt;
&lt;p&gt;压缩需要解决的主要问题是压缩速度。如前所述，压缩是减少同时服务的段总数的方法。最好的情况是，较长的压缩时间会导致较高的 CPU 使用率；最坏的情况是，系统停止摄取，导致新的更新无法反映和提供。&lt;/p&gt;
&lt;h3 id=&#34;清白合并clean-slate-merger&#34;&gt;清白合并(Clean Slate Merger)&lt;/h3&gt;
&lt;p&gt;对 hnsw 压缩算法的第一次尝试就是所说的 clean slate；本质上，该算法根据所有输入段的未删除embedding构建一个全新的图。这种方法对于的一些用例来说太慢了，所以需要优化算法。&lt;/p&gt;
&lt;h3 id=&#34;添加合并add-on-merger&#34;&gt;添加合并(Add on Merger)&lt;/h3&gt;
&lt;p&gt;下一个策略是尽可能多地重用索引；从所有要压缩的段中选择最大的段，并将索引转换为可以重用的内存结构。然后将其他段的剩余embedding添加到重用图中。&lt;/p&gt;
&lt;p&gt;剩下的问题是如何处理从重用段中删除的embedding。尝试了两种不同的方法：1）持久删除并重新选择邻居，2）将已删除的embedding与附近的活动embedding分组。尽管这两个选项都适合客户，但事实证明第一个选项在某些情况下速度太慢。&lt;/p&gt;
&lt;h3 id=&#34;持久删除persisting-deletions&#34;&gt;持久删除(Persisting Deletions)&lt;/h3&gt;
&lt;p&gt;需要维护图的小世界属性，并且简单地删除已删除的节点及其输入/输出边缘可能会破坏图中的连接性。为了解决这个问题，使用称为邻居重选的过程，其中节点可能连接到已删除节点的邻居以保持连接。&lt;/p&gt;
&lt;p&gt;发现，如果存在大量删除节点，压缩时间实际上会比 clean slate 算法慢，这并不理想。&lt;/p&gt;
&lt;h3 id=&#34;将已删除的节点与其最近的活动节点分组grouping-deleted-nodes-with-their-closest-alive-nodes&#34;&gt;将已删除的节点与其最近的活动节点分组(Grouping Deleted Nodes with their Closest Alive Nodes)&lt;/h3&gt;
&lt;p&gt;持久删除可能比使用全新算法慢的原因有两个。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;正在重用段中回填节点与其邻居之间的距离，从而导致大量昂贵的距离计算。&lt;/li&gt;
&lt;li&gt;邻居重选过程可能非常昂贵，尤其是在删除许多节点的情况下。这是因为如果删除节点的邻居也被删除，则需要更多的重选迭代。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/13.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;第二个优化是将已删除的节点与附近的活动节点分组，从而避免昂贵的重选过程。原始图与以前相同，但现在多个节点映射到相同的embedding。由于图形未更改，因此保持连接性。此外，延迟计算节点与其邻居之间的距离，而不是主动回填它们，从而避免了不必要的距离计算。还需要在算法中添加重复数据删除步骤，因为多个节点可以对应相同的embedding。&lt;/p&gt;
&lt;h2 id=&#34;在线召回监控online-recall-monitoring&#34;&gt;在线召回监控(Online Recall Monitoring)&lt;/h2&gt;
&lt;p&gt;到目前为止，一直专注于如何构建和优化系统中的组件。但生产系统还有另一个非常重要的方面——质量验证。对于 HNSW，召回率是用来验证索引质量的指标。它是通过将近似最近邻 (ANN) 搜索的结果与精确最近邻 (KNN) 搜索返回的理想结果进行比较来计算的。&lt;/p&gt;
&lt;p&gt;监控召回也特别重要，因为某些优化可能涉及为了更好的系统性能而进行的质量权衡。需要跟踪这些质量下降情况，以确保仍然为客户提供良好的结果。&lt;/p&gt;
&lt;p&gt;通过一组不可变的embedding，计算给定查询的召回率相对容易。可以使用离线批处理作业预先计算 KNN，并通过生成索引并向其发出查询来计算 ANN。由于embedding集是恒定的，KNN 结果永远不会改变，可以调整索引构建参数来优化召回率。&lt;/p&gt;
&lt;p&gt;然而，在实时场景中，embedding不断被添加和删除，使得预先计算的 KNN 集无法使用。为了解决这个问题，开发了一个在线召回工具；在服务集群中添加了计算 ANN 和 KNN 结果的功能，这使能够计算给定时间点的召回率。&lt;/p&gt;
&lt;h2 id=&#34;下一步是什么-1&#34;&gt;下一步是什么&lt;/h2&gt;
&lt;p&gt;对于来说，在批量索引集群上启动 HNSW 并通过为 HNSW 提供实时服务来突破的能力界限是一次激动人心的旅程。但 HNSW 只是基于embedding的检索系统愿景的第一步。&lt;/p&gt;
&lt;h3 id=&#34;效率和实验efficiency-and-experimentation&#34;&gt;效率和实验(Efficiency and Experimentation)&lt;/h3&gt;
&lt;p&gt;构建了一个系统，可以为基于embedding的检索进行生产化，从而使机器学习工程师能够尝试新的embedding或新算法，而无需从头开始构建新的生产系统。将继续迭代该系统，改进服务性能、渠道效率和促进轻松实验等方面。&lt;/p&gt;
&lt;h3 id=&#34;流式过滤streaming-filtering&#34;&gt;流式过滤(Streaming Filtering)&lt;/h3&gt;
&lt;p&gt;当前的过滤方法是从 HNSW 图中预取 K 个 ANN，然后应用过滤器来获得最终的候选集。这不是非常有效的漏斗，并且很难弄清楚 K 的值将给带来需要的最终候选者的数量。计划以流式方式实现 HNSW 算法，其中可以在获取期间应用过滤器，并且流式获取仅在检索到所需数量的候选者时才终止。&lt;/p&gt;
&lt;p&gt;敬请关注！&lt;/p&gt;
&lt;h1 id=&#34;章节四-manas-hnsw-流式过滤器&#34;&gt;章节四 Manas HNSW 流式过滤器&lt;/h1&gt;
&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;基于embedding的检索是 Pinterest 推荐引擎的核心部分。支持无数的用例，从基于内容相似性的检索到学习检索。它由内部搜索引擎&lt;a href=&#34;https://medium.com/pinterest-engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f&#34;&gt;Manas&lt;/a&gt;提供支持，该引擎提供近似最近邻 (ANN) 搜索服务，主要使用&lt;a href=&#34;https://arxiv.org/abs/1603.09320&#34;&gt;分层可导航小世界图 (HNSW)&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;传统的基于token的搜索根据具有 AND 和 OR 等逻辑连接，匹配term在对应term树结构中来检索文档，而 ANN 搜索则基于embedding相似性进行检索。通常希望进行将两者结合起来的混合搜索查询。例如，“找到与这双鞋相似、价格低于 100 美元、评级为 4 星或以上的产品，然后运送到英国。” 这是一个常见问题，并非完全没有解决，但每种解决方案都有各自的注意事项和权衡。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：这个类似查询paser流程的优化，引入filter, 相当于算子，尽量利用索引。&lt;/p&gt;
&lt;h2 id=&#34;现有解决方案&#34;&gt;现有解决方案&lt;/h2&gt;
&lt;h3 id=&#34;后置过滤&#34;&gt;后置过滤&lt;/h3&gt;
&lt;p&gt;之前的方法是后过滤，本质上是首先执行 ANN 搜索，然后执行仅限于结果集基于token的搜索。后过滤会受到漏斗效率的影响，使用超取来解决这个问题。然而，这是不可扩展的，因为客户端需要不断调整其超取，并且每个请求都可以具有不同的过滤率。&lt;/p&gt;
&lt;h3 id=&#34;预过滤&#34;&gt;预过滤&lt;/h3&gt;
&lt;p&gt;另一种方法是预过滤。首先，在索引期间或首先评估token搜索查询来找出与基于token过滤器匹配的文档集。然后执行 ANN 搜索，同时过滤掉该集合中不存在的文档。然而，索引时间方法很难推广到任意树过滤器；预评估token搜索查询对于一组简单的过滤器或一小部分文档可以很好地工作，但有不属于任一类别的用例。即使没有人工神经网络的传统搜索，导致提前终止，通常也只能搜索大型语料库的一小部分。&lt;/p&gt;
&lt;h3 id=&#34;解决方案&#34;&gt;解决方案&lt;/h3&gt;
&lt;p&gt;每种方法都有其优点，根据具体情况，它们甚至可能是解决问题的最理想方法。做为 Pinterest 的无数用例提供服务的通用平台，每个用例都有不同的语料库大小、查询复杂性和过滤条件。因此，选择了一种在 HNSW 图遍历过程中以流方式应用过滤器的通用方法。不对用例做出任何假设，同时仍然提供一种在此框架上构建并根据需要应用优化的方法（例如，可以将预评估作为构建过滤器添加预处理步骤）。&lt;/p&gt;
&lt;h2 id=&#34;概述-1&#34;&gt;概述&lt;/h2&gt;
&lt;p&gt;之前：查询被表示为一棵树，在叶子处执行 HNSW 预取，将混合查询减少为传统的搜索查询。 之后：HNSW 从叶子中提取到迭代器中，该迭代器可以流式传输近似按距离排序的结果。 树的其余部分用作这些结果的过滤器。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/14.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图总结了系统在流变化之前和之后如何处理 ANN 查询。有几个值得注意的点：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;HNSW从查询解析阶段的批量预取变为查询执行阶段的流式取。&lt;/li&gt;
&lt;li&gt;查询执行从按 doc_id 顺序检索文档更改为按近似距离顺序检索文档。这是一个需要解决的问题，因为作为搜索引擎，索引格式针对 doc_id 顺序进行了优化。&lt;/li&gt;
&lt;li&gt;查询结构保持不变，提供向后兼容性和无缝迁移。&lt;/li&gt;
&lt;li&gt;轻量级评分已与迭代器树中的执行解耦。这对于 HNSW 流并不重要，但它符合将评分从基于树的线性组合方法中推广出来。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;还有一些影响设计的原则，指出这些原则可能会有所帮助：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;模块化&lt;/strong&gt;：ANN 检索、过滤和评分都应该相互解耦。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;最小的更改&lt;/strong&gt;：通过尽可能地重用现有组件来快速构建和启动，并在以后根据需要进行优化。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;向后兼容性&lt;/strong&gt;：客户应该能够在对其请求进行最小程度的更改的情况下加入。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;前向兼容性&lt;/strong&gt;：接口应该是通用的，并且每个组件（例如过滤器索引格式）应该易于升级。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;希望本节能够对系统组件以及为何以这种方式构建事物提供良好的高级概述。为了更深入地了解一切如何工作，需要打开两个黑匣子：1）流算法，以及 2）过滤器如何工作。&lt;/p&gt;
&lt;h2 id=&#34;流式算法&#34;&gt;流式算法&lt;/h2&gt;
&lt;p&gt;流式算法实际上在高层次上非常简单：获取一些候选者，应用过滤器，评分，将候选者添加到结果堆中，然后重复。下图从高层次上展示了这一点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/manas-a-high-performing-customized-search-system/15.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;获取候选 -&amp;gt; 应用过滤器 -&amp;gt; 评分 -&amp;gt; 添加到结果堆 重复此操作，直到达到停止条件。&lt;/p&gt;
&lt;p&gt;以下是在实施过程中考虑的一些事项：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;最初，设计的流处理过程是一次检索一个候选者，但很快意识到往返获取/过滤/评分效率不高，因此转而使用小批量。然后需要决定使用什么小批量大小。HNSW 实际上存储了每个节点的邻居列表，因此使用邻居列表作为小批量。&lt;/li&gt;
&lt;li&gt;为了继续流，需要存储内部 HNSW 算法的一些状态。由于使用邻居列表作为小批量，因此只存储已经处理的候选者（访问列表）和仍需要处理的候选者（候选集）。&lt;/li&gt;
&lt;li&gt;最后，必须弄清楚何时停止流式搜索。这需要单独的一节，将在接下来讨论。&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;停止条件&#34;&gt;停止条件&lt;/h3&gt;
&lt;h4 id=&#34;hnsw-停止条件hnsw-stopping-condition&#34;&gt;HNSW 停止条件(HNSW Stopping Condition)&lt;/h4&gt;
&lt;p&gt;退后一步，如果看一下最初的 HNSW 论文，当检索到足够的候选者时，算法不会终止；相反，当积累的候选者都比候选集中最接近的候选者更接近时，它就会终止。这背后的主要直觉是确保算法以高概率检索最佳（最接近）的候选者。在流式搜索中应用了相同的概念，主要区别在于仅对过滤后的候选者进行操作。&lt;/p&gt;
&lt;h4 id=&#34;时间预算time-budget&#34;&gt;时间预算(Time Budget)&lt;/h4&gt;
&lt;p&gt;在高过滤率场景中，最终可能会遍历整个图，但仍然找不到足够的候选者，从而导致极高的延迟。由于大多数客户都有延迟要求，因此使用时间预算来限制流式搜索所花费的时间。一旦达到预算，就会退回已经积累的候选人。&lt;/p&gt;
&lt;h3 id=&#34;过滤器filters&#34;&gt;过滤器(Filters)&lt;/h3&gt;
&lt;p&gt;设计过滤的方式很大程度上受到上面列出的一些原则的影响：模块化和前向兼容性。实现过滤最简单的方法就是直接在HNSW代码中添加代码。事实上，开源 HNSW 代码中的删除标记已经这样做了。然而，这破坏了模块化性，并且对于过滤器代码的可维护性和前向兼容性来说并不理想。这对应用场景来说尤其重要，因为为许多具有不同过滤器要求的客户提供服务。&lt;/p&gt;
&lt;p&gt;设计接口时不采用任何底层过滤器结构或存储格式。实现了对主要用例的支持，其中客户端可以在请求中指定任意过滤树，用合取和析取连接词表示。&lt;/p&gt;
&lt;p&gt;本着最小改变的精神，重新使用倒排索引作为过滤器存储。因此，本质上有一个由叶子处的postinglists支持的过滤树，其结构与在基于标记的搜索中使用的迭代器树非常相似。这方便重用，但效率低下，因为倒排索引针对 doc_id 有序迭代进行了优化，但 HNSW 流需要非有序逐点查找。通过使用位图和数组支持的倒排列表而不是跳表支持的倒排列表来解决这个问题，以内存效率换取计算效率。这确实带来了明显的可扩展性挑战：使用大量过滤器，根本无法承受内存成本，但这并不是短期内需要解决的主要问题。计划未来的工作是升级过滤器存储。&lt;/p&gt;
&lt;h2 id=&#34;优化&#34;&gt;优化&lt;/h2&gt;
&lt;h3 id=&#34;如果已经有足够的候选者则放弃远处的候选者&#34;&gt;如果已经有足够的候选者，则放弃远处的候选者&lt;/h3&gt;
&lt;p&gt;在一些客户端用例中，过滤器树非常复杂，导致过滤器阶段占用最多的延迟。一种优化是当结果堆已满时跳过距离比结果堆中的候选者更差的候选者，以避免过滤无论如何都不会选择的候选者。&lt;/p&gt;
&lt;h3 id=&#34;批处理初始化&#34;&gt;批处理初始化&lt;/h3&gt;
&lt;p&gt;不是从头开始流式传输，而是首先检索等于客户端想要的候选者数量的批量大小，因为最初需要至少检索那么多。&lt;/p&gt;
&lt;h3 id=&#34;重新排序过滤器树节点&#34;&gt;重新排序过滤器树节点&lt;/h3&gt;
&lt;p&gt;由于流式处理进行非排序的逐点查找，因此过滤器树节点的排序变得很重要，因为首先评估最严格的过滤器会更有效。&lt;/p&gt;
&lt;h2 id=&#34;未来的工作&#34;&gt;未来的工作&lt;/h2&gt;
&lt;h3 id=&#34;带子图的流式传输streaming-with-subgraphs&#34;&gt;带子图的流式传输(Streaming with Subgraphs)&lt;/h3&gt;
&lt;p&gt;上面需要注意的关键是，当前的流方法实际上并没有减少检索所需的候选数量，它只是自动为每个请求计算出适当的超取。每个过滤的候选者仍然是浪费的距离计算。&lt;/p&gt;
&lt;p&gt;目前正在尝试通过更大的过滤器（例如美国或非美国）将空间划分为单独的子图。这对于使用一些大型过滤器的用例来说效果很好。更具可扩展性的扩展可能是使用过滤器来标记图形，并允许遍历标签的析取或合取。&lt;/p&gt;
&lt;h3 id=&#34;高效过滤器存储efficient-filter-store&#34;&gt;高效过滤器存储(Efficient Filter Store)&lt;/h3&gt;
&lt;p&gt;使用倒排索引作为过滤器存储在某些场景下效果很好，但它确实针对传统搜索进行了优化，而不是针对图遍历的过滤进行了优化。可以从头开始设计一个针对基于图的过滤进行优化的过滤器存储，并将其与其他基于图的检索系统（如&lt;a href=&#34;https://medium.com/pinterest-engineering/an-update-on-pixie-pinterests-recommendation-system-6f273f737e1b&#34;&gt;Pixie&lt;/a&gt;)共享。&lt;/p&gt;
&lt;h3 id=&#34;量化quantization&#34;&gt;量化(Quantization)&lt;/h3&gt;
&lt;p&gt;极高的过滤率场景可以通过暴力破解来解决，但仍然存在一系列具有非常高的过滤率但使用暴力破解成本高昂的情况。这些情况的瓶颈是大量浪费的距离计算。通过量化可以大大降低这一成本。可以转向不同的算法，例如 PQ IVF，或者HNSW 引入 PQ（注：这部分参考faiss，需要提供训练接口）&lt;/p&gt;
&lt;h2 id=&#34;结论&#34;&gt;结论&lt;/h2&gt;
&lt;p&gt;实现了流式过滤，它抽象了如何执行过滤的实现细节，并减轻了客户端过度获取调整的负担。从系统的角度来看，有一个通用的过滤器解决方案，它足够灵活，可以支持所有的用例，并且可以支持未来的优化，例如预过滤和过滤器存储升级。通过消除不精确的超取调整，已经看到了巨大的成本节省和质量改进，并且了解到了未来优化的许多机会。&lt;/p&gt;
&lt;p&gt;敬请关注！&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;题外话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;不能脱离应用场景去理解算法所要解决的实际问题；&lt;/p&gt;
&lt;p&gt;没有上下文引发的问题，何来解决方案；只谈结果，拿果子，忽略了上下文case, YY~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1 id=&#34;reference&#34;&gt;reference&lt;/h1&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Non-blocking_algorithm&#34;&gt;https://en.wikipedia.org/wiki/Non-blocking_algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://fulmanski.pl/tutorials/computer-science/nosql/column-family-bigtable-stores/&#34;&gt;https://fulmanski.pl/tutorials/computer-science/nosql/column-family-bigtable-stores/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f&#34;&gt;https://medium.com/pinterest-engineering/manas-a-high-performing-customized-search-system-cf189f6ca40f&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/manas-realtime-enabling-changes-to-be-searchable-in-a-blink-of-an-eye-36acc3506843&#34;&gt;https://medium.com/pinterest-engineering/manas-realtime-enabling-changes-to-be-searchable-in-a-blink-of-an-eye-36acc3506843&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/manas-hnsw-realtime-powering-realtime-embedding-based-retrieval-dc71dfd6afdd&#34;&gt;https://medium.com/pinterest-engineering/manas-hnsw-realtime-powering-realtime-embedding-based-retrieval-dc71dfd6afdd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/pinterest-engineering/manas-hnsw-streaming-filters-351adf9ac1c4&#34;&gt;https://medium.com/pinterest-engineering/manas-hnsw-streaming-filters-351adf9ac1c4&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/rXXm6c8LrTqqP4iWf9mtxA&#34;&gt;为什么微信推荐这么快？&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/1a2bl983bGKM713xI_3v_A&#34;&gt;小红书高时效推荐系统背后的技术升级&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/1ed9BDZKzjQIgDScyxpbHw&#34;&gt;快手搜索在向量检索方向的探索和实践&lt;/a&gt; &lt;a href=&#34;https://yongyuan.name/blog/vector-ann-search.html&#34;&gt;向量索引&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://damo.alibaba.com/events/112?lang=zh&#34;&gt;达摩院自研向量检索引擎 Proxima&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/baidu/puck/blob/main/docs/README.md&#34;&gt;baidu-puck&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.research.google/2020/07/announcing-scann-efficient-vector.html&#34;&gt;Announcing ScaNN: Efficient Vector Similarity Search&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.pinecone.io/learn/series/faiss/&#34;&gt;Faiss: The Missing Manual&lt;/a&gt; &lt;a href=&#34;https://www.pinecone.io/learn/&#34;&gt;https://www.pinecone.io/learn/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Vector Search and Databases at Scale&lt;/strong&gt;. Highload++ Conference, Serbia. &lt;a href=&#34;https://highload.rs/2023/abstracts/9770&#34;&gt;Event&lt;/a&gt;. &lt;a href=&#34;https://drive.google.com/file/d/11M51Jw9UdEmzHDTGZmn4n3bxgTcQt3sw/view?usp=sharing&#34;&gt;Slides&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=UMrhB3icP9w&amp;amp;t=65s&#34;&gt;YouTube&lt;/a&gt;.   &lt;a href=&#34;https://ashvardanian.com/talks/&#34;&gt;ash.vardanian&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;附相关向量数据库hnsw使用一般都会支持&#34;&gt;附：相关向量数据库HNSW使用(一般都会支持)&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/vearch/vearch/wiki/Hnsw%E5%AE%9E%E6%97%B6%E7%B4%A2%E5%BC%95%E8%AF%A6%E7%BB%86%E8%AE%BE%E8%AE%A1&#34;&gt;vearch-Hnsw Real time Index Detailed Design&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://weaviate.io/developers/weaviate/concepts/vector-index&#34;&gt;weaviate-Vector Indexing&lt;/a&gt;。文档不错，知其然知其所以然~
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://weaviate.io/blog/why-is-vector-search-so-fast&#34;&gt;Why is Vector Search so fast?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://weaviate.io/blog/ann-algorithms-vamana-vs-hnsw&#34;&gt;Vamana vs. HNSW - Exploring ANN algorithms Part 1&lt;/a&gt; (In-memory Index 和 DiskANN)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://weaviate.io/blog/ann-algorithms-hnsw-pq&#34;&gt;HNSW+PQ - Exploring ANN algorithms Part 2.1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://weaviate.io/blog/ann-algorithms-tiles-enocoder&#34;&gt;The Tile Encoder - Exploring ANN algorithms Part 2.2&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://milvus.io/docs/index.md&#34;&gt;milvus-Vector Index&lt;/a&gt; (In-memory Index 和 DiskANN)  包括新ANN算法支持跟进活跃，比如ScANN ；好的开源生态~&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://qdrant.tech/documentation/concepts/indexing/#vector-index&#34;&gt;qdrant-vector index&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.elastic.co/guide/en/elasticsearch/reference/8.0/knn-search.html&#34;&gt;ES8.0/knn-search&lt;/a&gt; &lt;a href=&#34;https://opensearch.org/docs/latest/search-plugins/knn/index/&#34;&gt;OpenSearch-plugin-knn&lt;/a&gt; &lt;a href=&#34;https://github.com/opensearch-project/k-NN&#34;&gt;https://github.com/opensearch-project/k-NN&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redis.io/docs/interact/search-and-query/search/vectors/&#34;&gt;Redis Stack7.2/vss&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.alibabacloud.com/help/zh/tair/developer-reference/vector&#34;&gt;alibabacloud-tair-vector&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>译：如何避免事务期间读取不一致</title>
      <link>https://weedge.github.io/post/oneday/distributed-system-question-how-to-avoid-read-inconsistency-during-a-transaction/</link>
      <pubDate>Sat, 26 Aug 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/distributed-system-question-how-to-avoid-read-inconsistency-during-a-transaction/</guid>
      
        <description>&lt;p&gt;想象一下，当您尝试将 100 美元从账户 A 转账到账户 B，并且两个账户都在同一家银行时。启动传输后，您刷新屏幕。然而，当您刷新屏幕时，您的总余额就会下降——那 100 美元似乎凭空消失了。您看到帐户 A 少了 100 美元。然而，B账户并没有多出100美元。然后，您刷新屏幕几次，可以看到帐户 B 获得了 100 美元。&lt;/p&gt;
&lt;p&gt;您在事务期间遇到的这个问题称为读取偏差。当您在不幸运的时间（写入交易期间和之后）读取交易时，就会发生异常。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://edward-huang.com/images/distributed-system-question-how-to-avoid-read-inconsistency-during-a-transaction/Distributed%20System%20Question_%20How%20to%20Avoid%20Read%20Inconsistency%20during%20a%20Transaction-%20bank%20transfer.png&#34; alt=&#34;银行转账时序图&#34;&gt;&lt;/p&gt;
&lt;p&gt;这可能会带来不好的用户体验，但如果转账交易成功后刷新页面，这不会造成任何问题。&lt;/p&gt;
&lt;p&gt;然而，在进行数据库备份或分析查询时，读取偏差会成为一个问题。&lt;/p&gt;
&lt;p&gt;在数据库备份中，我们需要制作数据库的副本。备份过程中可能会有写请求进来，如果出现读倾斜不一致的情况，可能会导致备份结果不一致。部分数据为旧版本，部分数据为新版本。通过这样的操作，这种不一致的问题可能会永久存在。&lt;/p&gt;
&lt;p&gt;我们需要在分析查询中扫描大型数据库并定期检查数据损坏。读取偏差可能会导致搜索和检查不一致 - 通常可能会产生不一致的结果并引发有关数据损坏的错误警报。&lt;/p&gt;
&lt;h2 id=&#34;解决读取偏差&#34;&gt;解决读取偏差&lt;/h2&gt;
&lt;p&gt;读取倾斜的问题是读事务在旧数据库版本中读取一次，在新数据库版本中读取另一次。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://edward-huang.com/images/distributed-system-question-how-to-avoid-read-inconsistency-during-a-transaction/Distributed%20System%20Question_%20How%20to%20Avoid%20Read%20Inconsistency%20during%20a%20Transaction-reading%20skew.png&#34; alt=&#34;读取倾斜的图像&#34;&gt;&lt;/p&gt;
&lt;p&gt;这里重要的一点是读取事务需要一致 - 它不需要是最新版本。从事务开始到结束需要保持一致，所以我们需要保持数据版本相同。&lt;/p&gt;
&lt;p&gt;例如，如果 Bob 正在以数据版本 1 运行读事务，则在整个事务中，Bob 应该只能读取数据库数据版本 1。如果在事务处理过程中，发生新的写事务，这将导致更新数据库中的数据。Bob 将不会在他的交易中看到该新版本。&lt;/p&gt;
&lt;p&gt;因此，我们可以使事务从数据库的一致快照中读取——事务将从事务开始时其他事务在数据库中提交的所有数据中看到。&lt;/p&gt;
&lt;p&gt;此功能称为快照隔离，许多关系数据库都提供此功能，例如 PostgreSQL 和 MySQL。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://edward-huang.com/images/distributed-system-question-how-to-avoid-read-inconsistency-during-a-transaction/Distributed%20System%20Question_%20How%20to%20Avoid%20Read%20Inconsistency%20during%20a%20Transaction-snapshot%20isolation%20sequence%20diagram.png&#34; alt=&#34;快照隔离序列图的图像&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;实施快照隔离&#34;&gt;实施快照隔离&lt;/h2&gt;
&lt;p&gt;我们需要在数据库中保留各种快照版本来实现快照隔离。每次事务开始时，数据库都会将最新提交的快照版本赋予该事务。然后，数据库将跟踪每个事务及其相应的快照版本，以保持读取的一致性。&lt;/p&gt;
&lt;p&gt;每个事务都有一个&lt;code&gt;transactionId&lt;/code&gt;，并且&lt;code&gt;transactionId&lt;/code&gt;是从数据库中检索的。因此，&lt;code&gt;transactionId&lt;/code&gt;总是在增加。数据库跟踪每个&lt;code&gt;transactionId&lt;/code&gt;写入数据库的使用&lt;code&gt;createdAt&lt;/code&gt;和&lt;code&gt;deletedAt&lt;/code&gt;值。&lt;code&gt;transactionId&lt;/code&gt;提交事务后，数据库使用事务中的 对该操作创建了一个标记。数据库进一步制作新交易的快照，并用最新的 transactionId 标记该快照。当有新的事务从数据库读取时，数据库会检索该事务之前最新提交的事务，有以下几个规则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;即使提交了后续事务，也不会显示当前尚未提交到数据库的任何 transactionId。&lt;/li&gt;
&lt;li&gt;任何中止的交易也不会显示。&lt;/li&gt;
&lt;li&gt;数据库不会显示任何晚于&lt;code&gt;transactionId&lt;/code&gt;（大于）当前的事务&lt;code&gt;transactionId&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;数据库将向读取数据库的其他传入事务显示任何其他事务。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;让我们看看 Bob 的场景中会发生什么：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://edward-huang.com/images/distributed-system-question-how-to-avoid-read-inconsistency-during-a-transaction/Distributed%20System%20Question_%20How%20to%20Avoid%20Read%20Inconsistency%20during%20a%20Transaction-snapshot%20isolation%20on%20Bob%20banking%20scenario%20with%20the%20algorithm%20implementation.png&#34; alt=&#34;Bob 银行业务场景的快照隔离图像以及算法实现&#34;&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;当 Bob 发起转账交易时，它会启动一个后台进程，将 100 美元从账户 A 转账到账户 B。该交易将首先调用数据库或辅助服务来获取增量，然后发起交易 - 假设交易是&lt;code&gt;transactionId&lt;/code&gt;1234 。&lt;/li&gt;
&lt;li&gt;后续的读取事务将需要通过获取增量&lt;code&gt;transactionId&lt;/code&gt;并向数据库调用读取请求来执行相同的操作 - 假设是&lt;code&gt;transactionId&lt;/code&gt;1345。&lt;/li&gt;
&lt;li&gt;当传输尚未完成时，数据库不会向 Bob 显示&lt;code&gt;transactionId&lt;/code&gt;1234（规则 1）应用的数据。&lt;/li&gt;
&lt;li&gt;如果在 1345 之后启动另一个写入事务&lt;code&gt;transactionId&lt;/code&gt;，因为该事务具有更大的&lt;code&gt;transactionId&lt;/code&gt;，数据库将不会向&lt;code&gt;transactionId&lt;/code&gt;1345 显示该事务（规则号 3）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在删除过程中，数据库不会立即删除该字段中的值，而是会在该字段上标记一个&lt;a href=&#34;https://en.wikipedia.org/wiki/Tombstone_(data_store)#:~:text=A%20tombstone%20is%20a%20deleted,is%20considered%20to%20be%20successful.&#34;&gt;墓碑&lt;/a&gt; 逻辑删除。不立即删除该值的原因之一是那些早期的交易可能仍然使用该值。因此，一旦所有事务都使用提交给其事务的值，我们就可以利用垃圾收集来异步检查和删除该值。&lt;/p&gt;
&lt;h2 id=&#34;对分布式环境进行快照隔离&#34;&gt;对分布式环境进行快照隔离&lt;/h2&gt;
&lt;p&gt;到目前为止，我们已经探索了如何解决单节点环境中的读取倾斜——我们假设数据库不分布在多个集群上。&lt;/p&gt;
&lt;p&gt;如何在分布式环境中扩展快照隔离？&lt;/p&gt;
&lt;p&gt;&lt;code&gt;transactionId&lt;/code&gt;在分布式环境中很难得到一个全局的、不断增长的。出于一个原因，可能驻留在不同数据库中的每台计算机可能都有其 UUID 计数器，我们需要进行一些协调以确保因果关系。如果事务B从事务A读取值，我们要确保事务B的值大于&lt;code&gt;transactionId&lt;/code&gt;事务A。我们如何处理复制数据库中的一致快照？&lt;/p&gt;
&lt;p&gt;我们可以使用时钟或一天中的时间作为&lt;code&gt;transactionId&lt;/code&gt;写入数据库吗？当天时钟不可靠，因为 NTP 同步基于不可靠的网络。因此，有些机器可能会出现时钟偏差，在时间上任意向后移动。一个节点的时间也可能与另一节点的时间不同。然而，如果我们能让时钟足够准确，它就可以作为&lt;code&gt;transactionId&lt;/code&gt;——时钟的时间晚意味着事件产生的晚。我们如何确保时钟对于 transactionId 来说足够准确？&lt;/p&gt;
&lt;p&gt;当检索每台机器中的时间值时，我们希望它返回一个置信区间，&lt;code&gt;[Tbegin, Tlast]&lt;/code&gt;而不是获取单个值。置信区间表示时钟的标准偏差为正负范围&lt;code&gt;Begin&lt;/code&gt;和&lt;code&gt;Tlast&lt;/code&gt;。如果有两笔交易，&lt;code&gt;transactionX&lt;/code&gt;，&lt;code&gt;transactionY&lt;/code&gt;进来，&lt;code&gt;[TbeginX, TlastX]&lt;/code&gt;，&lt;code&gt;[TbeginY, TlastY]&lt;/code&gt;， 和&lt;code&gt;TlastX &amp;lt; TbeginY&lt;/code&gt;。我们可以确保&lt;code&gt;transactionX&lt;/code&gt;早于&lt;code&gt;tranasctionY&lt;/code&gt;。但是，如果值重叠，我们就无法确定顺序。&lt;a href=&#34;https://cloud.google.com/spanner/docs/true-time-external-consistency&#34;&gt;Google Spanner&lt;/a&gt;使用的是这种方法实现其快照隔离。Spanner 会故意等到超过前一个事务的置信区间而不重叠时才提交当前事务。因此，他们需要保持机器上每个时钟的置信时间间隔尽可能小，以避免延迟。Google 在每个数据中心部署原子钟或 GPS 服务器，以实现时钟同步。&lt;/p&gt;
&lt;p&gt;为了确保每个数据库副本上的快照都是最新的，我们可以使用&lt;a href=&#34;https://en.wikipedia.org/wiki/Quorum_(distributed_computing)#:~:text=A%20quorum%20is%20the%20minimum,operation%20in%20a%20distributed%20system.&#34;&gt;Quorum&lt;/a&gt;仲裁策略从其所有数据库集群中获取所有最新的事务快照。我们可以使用的另一个策略是确保事务始终路由到同一数据库实例以获得一致的快照结果。&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;p&gt;当由于后台发生另一个写入事务而无法从读取数据库数据中看到一致的结果时，就会发生读取偏差。一致性快照是单节点数据库读取倾斜的解决方案。&lt;/p&gt;
&lt;p&gt;一致性快照是一种隔离级别，可保证每个事务都从数据库的一致性快照中读取数据，通常是当前启动的事务之前的最新快照。&lt;/p&gt;
&lt;p&gt;实现快照隔离需要一个单调递增的计数器transactionId来确定返回哪个版本给事务调用。然而，在处理分布式环境时，这可能很困难，因为需要协调才能产生因果关系。解决此问题的一种解决方案是使用时钟返回置信区间来创建不断增加的&lt;code&gt;transactionId&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;最后，为了确保每个事务获得一致的快照，我们可以使用仲裁策略始终返回大多数节点返回的当前事务的最新快照，或者在事务调用和数据库实例上具有会话关联性。&lt;/p&gt;
&lt;p&gt;如何确保分布式系统中的读取一致性？将如何解决创建全局的问题&lt;code&gt;transactionId&lt;/code&gt;？&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://edward-huang.com/distributed-system/2022/04/03/distributed-system-question-how-to-avoid-read-inconsistency-during-a-transaction/&#34;&gt;https://edward-huang.com/distributed-system/2022/04/03/distributed-system-question-how-to-avoid-read-inconsistency-during-a-transaction/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>译：Uber是如何解决数据一致性问题的？</title>
      <link>https://weedge.github.io/post/oneday/how-did-uber-solve-data-consistency-problem/</link>
      <pubDate>Wed, 16 Aug 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/how-did-uber-solve-data-consistency-problem/</guid>
      
        <description>&lt;h1 id=&#34;介绍&#34;&gt;介绍&lt;/h1&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/how-did-uber-solv-data-consistency-problem/1.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Uber 的请求流程相当复杂，从上图可以看出，他们使用 Spanner 来存储大量数据。Spanner 是一种完全托管的关键任务关系数据库服务，可提供全球范围内的事务一致性、自动同步复制以实现高可用性。&lt;/p&gt;
&lt;p&gt;但在此之前，最初的架构有本地数据库。更具体地说，他们使用 Cassandra 来存储实时数据。另外，在 Cassandra 之上，他们还使用了 Ringpop。有关更多详细信息，您可以查看&lt;a href=&#34;https://www.uber.com/blog/ringpop-open-source-nodejs-library/&#34;&gt;此博客文章&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;但当扩展到数百万个并发请求时，Cassandra 很难保证低延迟写入。另一个问题是工程团队开始注意到需要多行和多表写入的复杂存储交互（我不知道这意味着什么）。但无论如何，本地 Cassandra DB 开始变得非常具有挑战性。&lt;/p&gt;
&lt;p&gt;对于 Uber 来说，数据不一致可能会导致两名司机接送同一位顾客。&lt;/p&gt;
&lt;p&gt;解决方案是构建一个应用层框架，引入中间层(间), 使用&lt;strong&gt;Saga 模式&lt;/strong&gt;来编排数据库操作。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Saga设计模式&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/how-did-uber-solv-data-consistency-problem/2.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Saga设计模式是一种在分布式事务场景中管理跨微服务的数据一致性的方法。saga是更新每个服务并发布消息或事件以触发下一个事务步骤的事务序列。如果某个步骤失败，saga 会执行补偿事务来抵消前面的事务。&lt;/p&gt;
&lt;p&gt;简而言之，如果事务期间出现问题（&lt;em&gt;事务&lt;/em&gt;是单个逻辑或工作单元，有时由多个操作组成），则应恢复之前的更改。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;什么是事务？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;事务是单个逻辑或工作单元，有时由多个操作组成。在事务中，&lt;em&gt;事件&lt;/em&gt;是实体发生的状态更改，&lt;em&gt;命令&lt;/em&gt;封装了执行操作或触发后续事件所需的所有信息。&lt;/p&gt;
&lt;p&gt;事务必须是&lt;em&gt;原子的、一致的、隔离的和持久的（ACID）&lt;/em&gt;。单个服务内的事务是ACID的，但是跨服务的数据一致性需要跨服务的事务管理策略。&lt;/p&gt;
&lt;p&gt;在多服务架构中：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;原子性&lt;/em&gt; 是一组不可分割且不可简化的操作，要么全部发生，要么不发生。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;一致性&lt;/em&gt; 是指事务仅将数据从一种有效状态带到另一种有效状态。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;隔离性&lt;/em&gt; 保证并发事务产生与顺序执行的事务产生的数据状态相同的数据状态。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;持久性&lt;/em&gt; 确保即使在系统故障或断电的情况下，已提交的事务仍保持提交状态。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;解决方案&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Saga 模式使用本地事务&lt;/em&gt;序列提供事务管理。本地事务是 saga 参与者执行的原子工作。每个本地事务都会更新数据库并发布消息或事件以触发Sagas中的下一个本地事务。如果本地事务失败，saga 会执行一系列&lt;em&gt;补偿事务&lt;/em&gt;，以撤消先前本地事务所做的更改。&lt;/p&gt;
&lt;p&gt;有两种常见的 saga 实现方法：choreography 和 orchestration。每种方法都有自己的一套挑战和技术来协调工作流程。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;choreography&lt;/strong&gt;是一种协调sagas的方法，参与者可以在没有集中控制点的情况下交换事件。通过编排，每个本地事务都会发布触发其他服务中的本地事务的域事件。rocketMQ中的消息事务采用的这种编排模式，满足RC隔离(&lt;em&gt;Read Committed&lt;/em&gt;)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/how-did-uber-solv-data-consistency-problem/3.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;orchestration&lt;/strong&gt;是一种协调sagas的方法，其中集中控制器告诉saga参与者要执行哪些本地事务。saga 协调器处理所有事务并告诉参与者根据事件执行哪个操作。编排器执行 saga 请求，存储和解释每个任务的状态，并通过补偿事务处理故障恢复，本质是2PC。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/how-did-uber-solv-data-consistency-problem/4.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;观看视频&lt;a href=&#34;https://www.youtube.com/watch?v=DY2AR8Wzg3Y&#34;&gt;How does Uber scale to millions of concurrent requests?&lt;/a&gt;了解有关 Uber 迁移及其挑战的更多信息。如果您想了解有关 Saga 模式的更多详细信息参考&lt;a href=&#34;https://learn.microsoft.com/en-us/azure/architecture/reference-architectures/saga/saga&#34;&gt;此链接&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;spanner：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/how-did-uber-solv-data-consistency-problem/5.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;主要是为了保证数据一致性， 不出现司机乘客对同一个事务操作异常，从原来的nosql 转向 newsql， 引入了google cloud spanner (new SQL) 提供全球范围内的事务一致性、自动同步复制以实现高可用性。结合uber这个场景，然后看下spanner的论文去寻求解决方案，了解下细节结合场景进行设计。视频中提到了大规模数据迁移的挑战，特别是全球跨数据中心的迁移同步，有相应的网络优化技术（这些技术解决方案刚出来的时候国内有跟进，当然技术文章介绍肯定少不了）&lt;/p&gt;
&lt;p&gt;题外话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;需求场景驱动技术方案去落地，技术方案不一定最优解， 能满足当前需求场景，过度设计优化产生无意义的消耗，不过可以留下接口可以去扩展，满足不同场景的进一步优化，软件中没有通用的解决方案银弹。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&#34;reference&#34;&gt;reference&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@dmosyan/how-did-uber-solve-data-consistency-problem-dcdd39bd3ed6&#34;&gt;https://medium.com/@dmosyan/how-did-uber-solve-data-consistency-problem-dcdd39bd3ed6&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uber.com/blog/ringpop-open-source-nodejs-library/&#34;&gt;https://www.uber.com/blog/ringpop-open-source-nodejs-library/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uber.com/blog/fulfillment-platform-rearchitecture/&#34;&gt;https://www.uber.com/blog/fulfillment-platform-rearchitecture/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.uber.com/blog/building-ubers-fulfillment-platform/&#34;&gt;https://www.uber.com/blog/building-ubers-fulfillment-platform/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=DY2AR8Wzg3Y&#34;&gt;https://www.youtube.com/watch?v=DY2AR8Wzg3Y&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://research.google/pubs/pub39966/&#34;&gt;https://research.google/pubs/pub39966/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>kv-codis迁移</title>
      <link>https://weedge.github.io/post/codis-slot/</link>
      <pubDate>Sun, 30 Jul 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/codis-slot/</guid>
      
        <description>&lt;iframe frameborder=&#34;no&#34; border=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; width=330 height=86 src=&#34;//music.163.com/outchain/player?type=2&amp;id=1890574156&amp;auto=1&amp;height=66&#34;&gt;&lt;/iframe&gt;



&lt;p&gt;最近在搞一个kv系统，想接入codis来管理slot，实现数据的迁移，进行scaling水平扩展，从网上找了点资料，然后随笔记录梳理一下，以便相应的代码可以联调接入时优化下~&lt;/p&gt;
&lt;h3 id=&#34;codis-slot迁移&#34;&gt;codis slot迁移&lt;/h3&gt;
&lt;h4 id=&#34;同步&#34;&gt;同步：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;主动调用&lt;code&gt;SLOTSMGRTTAGSLOT&lt;/code&gt; 进行同步迁移,  对val dump成rdb 格式进行单个key的同步，直到db,slot同步完成&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/codis1&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;key所属的slot正在迁移，则被动调用&lt;code&gt;SLOTSMGRTTAGONE&lt;/code&gt;命令将这个key迁移完成再返回给客户端，即必须要迁移这个key完成才返回给客户端。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;异步&#34;&gt;异步：&lt;/h4&gt;
&lt;p&gt;（针对redis 处理命令的主线程的优化，因为是单线程，命令通eventloop分发在单线程中依次执行，为了缓解该问题，进行了优化 ）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;主动调用&lt;code&gt;SLOTSMGRTTAGSLOT-ASYNC&lt;/code&gt;命令，整体流程和同步差不多，主要是将耗时命令进行拆解成耗时小的命令进行批量处理。&lt;/p&gt;
&lt;p&gt;1）源Redis对key进行序列化异步发送给目标Redis；&lt;/p&gt;
&lt;p&gt;2）目标Redis通过Restore还原后回复给源Redis；&lt;/p&gt;
&lt;p&gt;3）源Redis收到目标Redis确认后标记这个key迁移完成，迁移下一个key；&lt;/p&gt;
&lt;p&gt;对于大key，如一个长度为1W的list，Codis会将key分拆成多个命令chunck，因为通过不断的rpush最终的结果一样；&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/codis2&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Codis会在每一个拆分后的指令中加上一个临时TTL；等全部拆分的指令执行成功才会删除本地的key；因此即使中途迁移失败，已迁移成功的key也会超时自动删除，最终效果就好比迁移没有发生一样。 但是这里不是原子的，如果执行设置真正的过期时间expire key ttl 执行超时了，这个时候目标节点已经设置成功了，但是源节点没有收到ack，本地没有删除，返回迁移失败(其实已经成功了)，则需要重新触发迁移。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/codis3&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;迁移通过分批pipeline进行了优化&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/codis4&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;key所属的slot正在迁移，则被动调用&lt;code&gt;SLOTSMGRT-EXEC-WRAPPER&lt;/code&gt;命令，将key请求操作发给迁移的slot节点，返回错误码(-1 参数错误，0 不存在，1.命令是写操作并且正在迁移，2.命令是读操作并且执行)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;如果正在迁移并且当前命令是写命令则返回错误码1，由Prxoy进行重试。&lt;/li&gt;
&lt;li&gt;如果是读命令则执行返回错误码2和执行结果，由proxy 返回。&lt;/li&gt;
&lt;li&gt;如果key已经迁移走，则返回错误码0，Proxy需要更新路由表。&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;同步和异步有两个区别&#34;&gt;同步和异步有两个区别：&lt;/h4&gt;
&lt;p&gt;一是处理请求的不同，如果当前要操作的key所属Slot正在迁移，同步处理会发送命令等待后端迁移完成才往下操作，异步则是将当前请求封装成一次SLOTSMGRT-EXEC-WRAPPER调用，并且将操作命令及参数都发送过去，后者会判断这个key是否在迁移或阻塞，如果是并且当前为写命令则直接返回失败，由Proxy重试。&lt;/p&gt;
&lt;p&gt;二是迁移逻辑不同，同步会调用SLOTSMGRTTAGSLOT迁移，异步则是调用SLOTSMGRTTAGSLOT-ASYNC，前者每次随机迁移一个key，异步的过程则复杂得多，对于小key需要确认才算迁移完成，对于大key还会分拆成多条命令，以保证不阻塞主流程，并且在拆分后的命令都加上TTL，以保证如果中途失败目标Redis的key会及时清掉而不会产生脏数据。&lt;/p&gt;
&lt;p&gt;同步,异步迁移通过dashboard配置文件设置 migration_method。&lt;/p&gt;
&lt;p&gt;Gist: &lt;a href=&#34;https://gist.github.com/weedge/8d1d37963a2dfd7ecd47fefc7d8016b1&#34;&gt;https://gist.github.com/weedge/8d1d37963a2dfd7ecd47fefc7d8016b1&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;其他kv引擎接入&#34;&gt;其他kv引擎接入：&lt;/h4&gt;
&lt;p&gt;理论上只要实现了codis的迁移命令就可以对数据实例slot进行管理操作了，还可以进行不同类型实例的数据迁移，不同类型kv存储引擎实例来实现不同的功能slot上， 比如 热数据 可以请求到 内存kv中， 冷数据可以请求到磁盘kv中，有种乾坤大挪移的感觉~，主要是利用codis管理key-&amp;gt; slot 与 node之间的会话关系，其实现在云原生网关中常说的控制面(control)和数据面(data)，这里分别对应dashboard(发送迁移命令)和 proxy (tcp长连,根据session db , key-&amp;gt;slot与node映射的路由规则转发命令)。&lt;/p&gt;
&lt;p&gt;如果管理迁移slot的kv节点处理命令不是单线程的，比如&lt;a href=&#34;https://github.com/dragonflydb/dragonfly&#34;&gt;dragonfly&lt;/a&gt; 等处理命令是多线程的sharding 内存(多线程IO模型 &lt;a href=&#34;https://github.com/romange/helio&#34;&gt;helio&lt;/a&gt; 支持io_uring)，以及 &lt;a href=&#34;https://github.com/weedge/wedis&#34;&gt;wedis&lt;/a&gt;  处理命令是多协程（一个连接会话对应一个协程，本质调度执行是内核线程, 网络IO模型根据场景使用netpoll可以优化下,以及批量迁移batch put 尽量减少io），则操作只需要优化实现 同步命令 &lt;code&gt;SLOTSMGRTTAGSLOT&lt;/code&gt; 和被动触发的 &lt;code&gt;SLOTSMGRTTAGONE&lt;/code&gt; 可以满足需求，当然如果想对接异步操作命令也是可以的。&lt;/p&gt;
&lt;p&gt;tips:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对于slot相关操作如果已插件的方式对接到kv引擎中实现，是比较符合工程实现的，一种是动态链接(c/c++)，通过MODULE LOAD 命令，或者loadmodule 配置项，可以参考&lt;a href=&#34;https://github.com/weedge/RedisXSlot&#34;&gt;RedisXSlot&lt;/a&gt; module，实现异步非阻塞执行  &lt;code&gt;SLOTSMGRTTAGSLOT&lt;/code&gt; 和被动触发的 &lt;code&gt;SLOTSMGRTTAGONE&lt;/code&gt; 等同步命令; 一种是编译时静态链接(plugin比较鸡肋，两种方式：1. golang 依赖注入运行的时候配置区分，2. golang本身是静态编译, 通过go build tag的方式分开编译不同的feature，像rust cargo build with feature crate)&lt;/li&gt;
&lt;li&gt;如果使用redis cluster 是去中心化的scaling 方案，slot的迁移会话管理方式嵌入到node节点中，通过gossip协议进行协同，运维相对简单，但是少了些灵活，当然也可以做一层控制面来管理会话元数据，当集群节点比较多的时候。(这个实现下cluster中的slot相关命令可以在思考记录一些~)&lt;/li&gt;
&lt;li&gt;codis现在没有维护了，但是fork出来进行二次开发，和内部监控系统打通，也可以借鉴下reborndb,但是没有但是了。。。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;题外话：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;基础组件(中间件)如同搭积木(前后端本质上一样，后端需要考虑分布式情况)，稳固牢靠，易扩展，这就考验需求中事件本质的抽象，这个本质的抽象感觉也有点像套路；如果把开源组件进行拼装，给出需求抽象出的安装步骤，画出架构图，交给大模型， 能否给出相关详细设计文档，甚至直接代码模块化，具体细节根据业务需求来写，有套路的东东，应该可以AI化；如果反过来呢，根据业务需求，画出架构图，甚至给出ppt模版，给出模块化的代码，细节也是根据业务来填充；现在有预训练好的开源大模型黑盒，这些数据可以私有安全部署(利用开源，然后商业化闭源，想想都有意思哈~) :d ，但是前提是：提出问题者需要某个垂直领域认知提升上的经验教训(局内人从坑里爬出来过或者旁观者认真思考过前人躺过的坑)，能把控全局~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;声明：一些资料图片来自互联网，农夫山泉&lt;/p&gt;
&lt;h3 id=&#34;参考&#34;&gt;参考：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/CodisLabs/codis&#34;&gt;https://github.com/CodisLabs/codis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redis.io/docs/management/scaling/&#34;&gt;redis-cluster&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.dragonflydb.io/docs/managing-dragonfly/high-availability&#34;&gt;dragonfly/high-availability&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.google.com/document/d/1hJXa0LjMaGYHgL3PeQQu3QMrstxof241OVxbdDKvSbY/edit?usp=sharing&#34;&gt;RebornDB: the Next Generation Distributed Key-Value Store&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>OpenAI体验</title>
      <link>https://weedge.github.io/post/doraemon/openai/</link>
      <pubDate>Sun, 26 Feb 2023 20:16:30 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/doraemon/openai/</guid>
      
        <description>&lt;iframe frameborder=&#34;no&#34; border=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; width=330 height=86 src=&#34;//music.163.com/outchain/player?type=2&amp;id=1428273917&amp;auto=1&amp;height=66&#34;&gt;&lt;/iframe&gt;



&lt;p&gt;OpenAI chatGPT 很火，体验了一把，哇哦之后，心想这个会成为内容创造的辅助工具，目前大部分是通过搜索寻找来解答难题，以后可能收敛到具体应用场景中了，不过底层可能还是掌握大数据公司来提供模型资源。&lt;/p&gt;
&lt;p&gt;按使用方大致分为如下场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;企业ToB常应用在Saas办公软件，低代码，客服，生物医疗，教育当中，比如微软办公软件，notion等相关笔记软件, 飞书，钉钉，企业微信等办公聊天，文档，视屏会议等软件，以及银行智能客服，生物蛋白质生成和基因测序领域等等；付费模式，开放的模型Pass平台提供模型训练，以及微调，交互api等；按使用资源和更好的体验质量速度来收费，比如国内BAT；上层SaaS服务通过租户使用更多实用便利功能组合(三方资源和内部资源整合)来付费。&lt;/li&gt;
&lt;li&gt;ToC主要是UGC的场景，随着多模交互场景下的大模型出现，AIGC方面的应用应该会更多，普通玩家更多，想象空间应该也更大，这块比ToB要大的多，而且较为通用，有UGC大数据公司才可能出大模型吧，并且开放给上游应用玩家使用，按功能体验质量来付费；比如国内抖音，微信这些app应用，以及和企业合作的实验室。可能还会有其他好玩的智能硬件出现。&lt;/li&gt;
&lt;li&gt;可能还有数据库方向，结合用户经常输入查询，结合数据库产品特性进行智能补偿纠错优化推荐等，类似tabnine, &lt;a href=&#34;https://docs.github.com/en/copilot&#34;&gt;Copilot&lt;/a&gt; 这类型工具，反正上层交互类的场景应该都可以渗透到。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总的概括玩家分为3种：底层大模型 -&amp;gt; 定制场景下的数据模型微调 -&amp;gt; 上层应用百花齐放；&lt;/p&gt;
&lt;p&gt;想象空间有限，未来是怎样，以上说的可能有误:)，anyway，Just Do IT~&lt;/p&gt;
&lt;p&gt;PS: 梯子不要选择香港，可以使用美国的节点；openai如何注册可以google一下，教程很多，注册的邮箱用的gmail，使用 &lt;a href=&#34;https://sms-activate.org/&#34;&gt;https://sms-activate.org/&lt;/a&gt; 代理接受短信验证码，可以选择🇮🇳印度。&lt;/p&gt;
&lt;p&gt;chatGPT体验挺有意思的，如果问一些理性逻辑相关的case, 比如自然语言处理怎么学习相关的语义，可以给出相同的参考标准答案，逻辑套路满满，而且还可以纠正错别字意图，(关于如何学习的模版套路，可以用来建个思维导图，然后自己填充学习内容笔记，或者ppt之类的等等)；如果问一些感性的case, 比如一段歌词，一首诗歌，会给出相应的场景，文字还挺优美的，一个字绝，懂你的。感觉AI很适合逻辑套路，但是人类的情感是很难琢磨的哈，人心难测嘛；当然提问也是比较重要的，也有些bad case，比如：&amp;ldquo;什么是快乐星球&amp;rdquo;，需要多沟通，让它理解上下文（只能意会不能言传-人类专属功能，它倒像个三体人），继续追问，会出现一本正经的错误回答，明明是胡歌，舒淇，张艺兴等小朋友~ （模型自我迭代学习，下次访问回答时已经就正确了，知错能改，善莫大焉）&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/doraemon/openai-case.png&#34; alt=&#34;openai-case&#34;&gt;&lt;/p&gt;
&lt;p&gt;openai使用GPT模型(公开使用的是GPT-3以上), 底层具体对应的大模型已经训练好了，提供openAPI给应用开发者来进行微调模型使用。&lt;/p&gt;
&lt;p&gt;作为一个开发者，当然想在通过开放的api来使用openai模型啦；如果是研究人员，虽然木有大数据和服务器计算资源来玩，也可以使用openai开放的GPT-3以及以上的模型来微调。&lt;/p&gt;
&lt;p&gt;以下是chatGPT 对使用的回答(这个就相当于是智能客服场景)，提供的开放的(text/image/audio/video)多模交互api使用如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;GPT-3, GPT-3.5 &amp;hellip; 模型，用于模型参数微调；文本补全，编辑；以及搜索(相关性排序)，聚类(相似性分组)，推荐(推荐相关文本)，异常检测(识别相关性很小的异常值)，多样性测试(分析相似性分布)，分类(最相似的标签分类)等embedding，通过向量列表表示，计算文本相关性(向量距离)；主要用于文本类交互，以及基于上下文聊天场景；&lt;/li&gt;
&lt;li&gt;Codex api 通过描述文本提示&lt;strong&gt;Prompt&lt;/strong&gt;生成对应代码；这个挺适合开发人员的，对于新语言的新手，结合ide，记事本通过Prompt提示词语来生成相关代码还是挺爽的，至少不用去google 来回找确认是否是需要方案代码，搜索则可以用于兜底方案；&lt;/li&gt;
&lt;li&gt;DALL-E /2 api 通过描述文本提示&lt;strong&gt;Prompt&lt;/strong&gt;生成图片或者编辑原始图片 ；插画，设计师 辅助类工具，大概构思草图；&lt;/li&gt;
&lt;li&gt;音频转换为文本, 使用开源大型 v2 &lt;a href=&#34;https://openai.com/blog/whisper/&#34;&gt;Whisper 模型&lt;/a&gt;。 这个用在硬件设备上挺好的，硬件操作系统如果有开放口子可以开发的话，直接就可以对接上赋能了。将音频转录成音频所使用的任何语言；将音频翻译并转录成英文；&lt;/li&gt;
&lt;li&gt;视频类的api暂时还没有；&lt;/li&gt;
&lt;li&gt;需要生成 &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;api-keys&lt;/a&gt; 用于api接口调用时使用；&lt;/li&gt;
&lt;li&gt;提供了不同开发语言的 &lt;a href=&#34;https://platform.openai.com/docs/libraries/community-libraries&#34;&gt;client库&lt;/a&gt; ，默认包括：python,nodejs, 还有其他语言三方包，比如golang: &lt;a href=&#34;https://github.com/sashabaranov/go-gpt3&#34;&gt;sashabaranov/go-gpt3&lt;/a&gt; ; 以及api 错误说明；&lt;/li&gt;
&lt;li&gt;可以在 &lt;a href=&#34;https://platform.openai.com/playground&#34;&gt;playground&lt;/a&gt; 中编辑描述文本提示&lt;strong&gt;Prompt&lt;/strong&gt;对模型接口调试测试，还可以用语音生成描述文本(speech to text)，适合端到端的语音智能设备；&lt;/li&gt;
&lt;li&gt;而且在 &lt;a href=&#34;https://platform.openai.com/examples&#34;&gt;openai examples&lt;/a&gt; 中提供各种应用场景样例和Q&amp;amp;A；&lt;/li&gt;
&lt;li&gt;文档中还介绍了最佳实践：&lt;a href=&#34;https://platform.openai.com/docs/guides/safety-best-practices&#34;&gt;&lt;strong&gt;&lt;!-- raw HTML omitted --&gt;安全最佳实践&lt;!-- raw HTML omitted --&gt;&lt;/strong&gt;&lt;/a&gt; 和 &lt;a href=&#34;https://platform.openai.com/docs/guides/production-best-practices&#34;&gt;&lt;strong&gt;&lt;!-- raw HTML omitted --&gt;生产最佳实践&lt;!-- raw HTML omitted --&gt;&lt;/strong&gt;&lt;/a&gt; ；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/doraemon/openai.png&#34; alt=&#34;openai&#34;&gt;&lt;/p&gt;
&lt;p&gt;像国内BAT在这块也早已开始布局了，大概15,16年左右就已经开始搭建智能平台底座，只不过被国外chatGPT “大力出奇迹” 给引爆了；大模型的训练需要大量的数据和参数调整，而且需要消耗大量服务器计算资源，特别是GPU 。像百度的 &lt;a href=&#34;https://wenxin.baidu.com/&#34;&gt;文心大模型&lt;/a&gt; （塑造了一个二次元create大会） ; 中国素有基建狂魔之称，希望能在中国版的&amp;quot;大力神丸&amp;quot;上出奇迹。&lt;/p&gt;
&lt;p&gt;Tips: 国内微信也已经有对应类似开放api，https://welm.weixin.qq.com/docs/api/  微信应该最适合的应用场景，对应背景论文：&lt;a href=&#34;https://arxiv.org/pdf/2209.10372.pdf&#34;&gt;WeLM: A Well-Read Pre-trained Language Model for Chinese&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;附学习demo:&lt;/p&gt;
&lt;p&gt;openai提供了开放接口，借这个AI东风，推进下工程方面的熟练。大部分是dev/app ops工作，业务由应用场景和idea来决定。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;本地命令行交互&lt;/p&gt;
&lt;p&gt;目的：&lt;!-- raw HTML omitted --&gt;快速熟悉openai的调用接口进行参数设置， 或者对模型进行微调训练。&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;源码地址：&lt;a href=&#34;https://github.com/weedge/craftsman/tree/main/doraemon/openai&#34;&gt;https://github.com/weedge/craftsman/tree/main/doraemon/openai&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;git clone  https://github.com/weedge/craftsman &amp;amp;&amp;amp; cd craftsman/doraemon/openai
# cmd chat Q&amp;amp;A
export OPENAI_API_SK=
make run
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;
&lt;p&gt;web交互(使用AWS &lt;a href=&#34;https://serverlessland.com/&#34;&gt;&lt;strong&gt;Serverless&lt;/strong&gt;&lt;/a&gt;  架构搭建)☁️智能底座+上层轻/微应用，适合快速迭代的业务，just code serverless biz logic handler func run on the could  &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/lambda-runtimes.html&#34;&gt;lambda runtime&lt;/a&gt;, like shell/c++/rust use &lt;a href=&#34;https://docs.aws.amazon.com/lambda/latest/dg/runtimes-walkthrough.html&#34;&gt;custom runtime&lt;/a&gt; 特别是rust lambda runtime 是开源的，值得关注，对于使用运行时语言来进行无服务化平台化改造，比如数据模型训练是的pipeline，数据库cloud平台，而且在aws内部大量使用，Rust 已迅速成为大规模构建基础设施的关键语言，&lt;a href=&#34;https://firecracker-microvm.github.io/&#34;&gt;Firecracker&lt;/a&gt; 是一种开源虚拟化技术，为&lt;a href=&#34;https://aws.amazon.com/lambda/&#34;&gt;AWS Lambda&lt;/a&gt;和其他无服务器产品提供支持。 aws抽象出来的服务，复杂都留在后面，简单交互留给用户，按业务场景自由组装infrastructure。智能底座需要这样的抽象工程给上层应用赋能。&lt;/p&gt;
&lt;p&gt;目的： &lt;!-- raw HTML omitted --&gt;熟悉aws serverless 事件驱动整体架构，以及整体lambda runtime运行原理； 在数据库cloud 或者内部/外部pass平台场景中，提供给客户使用serverless来实现具体业务逻辑。aws在这块做的深入，通过学习以便这些思想用于实际工作场景中。&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;源码地址：&lt;a href=&#34;https://github.com/weedge/craftsman/tree/main/cloud/aws/cdk/serverless-openai-chatbot&#34;&gt;https://github.com/weedge/craftsman/tree/main/cloud/aws/cdk/serverless-openai-chatbot&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;使用aws无服务lambda系统设施架构如下：(push模块异步对接openai 推送结果，这里分不同开放语言，是为了熟悉lambda对不同语言runtime，具体语言根据公司组织应用场景而定，不过 golang挺适合push服务的，分channel治之)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/doraemon/aws-serverless-openai-chatbot.drawio.png&#34; alt=&#34;architecture&#34;&gt;&lt;/p&gt;
&lt;p&gt;按照demo readme 配置好文件，后端服务可以一键部署这个demo应用，第一次部署过程可能比较长，主要是用docker容器来CI lambda不同语言所依赖的库，用于部署至aws lambda容器环境中；前段静态资源则需要手动配置, 看 &lt;a href=&#34;https://docs.aws.amazon.com/AmazonS3/latest/userguide/HostingWebsiteOnS3Setup.html&#34;&gt;Tutorial: Configuring a static website on Amazon S3&lt;/a&gt; 这个教程就可以，配置好后可提供对象存储S3域名使用，如果需要配置公司组织域名，使用CDN加速，则自行查看相关文档解决~&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;k8s部署方式&lt;/p&gt;
&lt;p&gt;目的：&lt;!-- raw HTML omitted --&gt;熟悉k8s资源工程化部署，了解整体生态， 熟练相关工具及原理。&lt;!-- raw HTML omitted --&gt;&lt;/p&gt;
&lt;p&gt;源码地址：&lt;a href=&#34;https://github.com/weedge/craftsman/tree/main/doraemon/ai-creator&#34;&gt;https://github.com/weedge/craftsman/tree/main/doraemon/ai-creator&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tips: 技术上 不要把openAI 放大了，对于工程化方面来说只是多了一项方便调试的智能化接口，加上了更多的赋能，应用上玩出花，也只是在原有的产品功能上定制化数据场景模型的微调，至于算法模型，大部分都开源，关键是大数据场景下的训练资源调度调优，垂直领域场景下用于参数微调训练的数据吧；对边缘模型在边缘端自适应学习调优推理，占用少的资源就能快速响应的模型，可能离机器人智能不远了。&lt;/p&gt;
&lt;p&gt;附2 好玩的网站：(国外玩出花了)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.notion.so/product/ai&#34;&gt;https://www.notion.so/product/ai&lt;/a&gt; 笔记思路智能套路&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.midjourney.com/&#34;&gt;https://www.midjourney.com/&lt;/a&gt; 需要注册Discord 在channel下通过聊天命令交互 生成图片 &lt;a href=&#34;https://docs.midjourney.com/docs/quick-start&#34;&gt;https://docs.midjourney.com/docs/quick-start&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://piggy.to/&#34;&gt;https://piggy.to/&lt;/a&gt; ui设计师&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://soundraw.io/&#34;&gt;https://soundraw.io/&lt;/a&gt;  寻找音乐灵感&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://typeset.io/&#34;&gt;https://typeset.io/&lt;/a&gt;&lt;/strong&gt; 读论文神器，非常值得推荐，so nice~&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://you.com/&#34;&gt;https://you.com/&lt;/a&gt;&lt;/strong&gt; 新一代人工智能搜索引擎(遵从用户隐私数据，结合AI技术,chat,code,study等)，加入了社交属性，搜索质量很高；(国内搜索引擎应该有跟进一波的吧~) ；一些反馈功能还在迭代完善 &lt;a href=&#34;https://yousearch.canny.io/&#34;&gt;https://yousearch.canny.io/&lt;/a&gt;；&lt;a href=&#34;https://www.socher.org/&#34;&gt;Richard Socher&lt;/a&gt; - &lt;a href=&#34;https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6&#34;&gt;&lt;strong&gt;Natural Language Processing with Deep Learning&lt;/strong&gt;&lt;/a&gt;( &lt;a href=&#34;https://web.stanford.edu/class/cs224n/&#34;&gt;当前课程&lt;/a&gt;挺贵的,可以看下&lt;a href=&#34;https://www.youtube.com/playlist?list=PLoROMvodv4rOSH4v6133s9LFPRHjEmbmJ&#34;&gt;以前免费视频&lt;/a&gt;, 感觉听不懂先用notion记录下，再去找资料了解下，orz, ps: CMU数据库课程 &lt;a href=&#34;https://15721.courses.cs.cmu.edu/spring2023/&#34;&gt;Advanced Database Systems&lt;/a&gt; 类似学习，今年的学习OKR有了~)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;携手AI前行，效率优先，压缩时间成本~&lt;/p&gt;
&lt;p&gt;附3 openai 官方提供的应用类产品，&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://chat.openai.com/&#34;&gt;chatGPT&lt;/a&gt;: 这个大家都知道一款火爆应用产品，发现社交永远是人类永恒需求哈；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://labs.openai.com/&#34;&gt;DALL·E 2&lt;/a&gt;：使用文本生成图片；有相关的提示文本推荐，体验更好；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.yabble.com/&#34;&gt;yabble&lt;/a&gt;：数据洞察(insights)，进行归纳终结，并且帮助规划日程，提出建议；小助手类型工具，网上有用来分析炒股的~；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://openai.com/research/jukebox&#34;&gt;jukebox&lt;/a&gt;：使用文本生成音乐；涉及到音乐版权，数据资源可能不好弄~；&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://waymark.com/&#34;&gt;waymark&lt;/a&gt;：使用文本生成视频；主要用于制作电视广告和数字视频广告；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;以上应用产品底层大模型大多是基于GPT相关最新模型，官网提供的GPT-3: &lt;a href=&#34;https://openai.com/blog/gpt-3-apps&#34;&gt;https://openai.com/blog/gpt-3-apps&lt;/a&gt;介绍。&lt;/p&gt;
&lt;p&gt;附一张midjourney 生成的图片，采用的prompt 描述如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;/imagine prompt a cute long distance couple with souls connection, asian, chinese, fantasy style 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/doraemon/midjourney-aigc-chinese-couple.png&#34; alt=&#34;midjourney&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;reference&#34;&gt;reference&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/product&#34;&gt;https://openai.com/product&lt;/a&gt; (可以先了解清楚openai自己的应用根源产品，后续有时间整理下，感兴趣的话，然后去发散吧)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://openai.com/blog&#34;&gt;https://openai.com/blog&lt;/a&gt; (技术宅，可以订阅一波)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://platform.openai.com/docs/introduction/overview&#34;&gt;https://platform.openai.com/docs/introduction/overview&lt;/a&gt; (适合开发，模型微调)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://platform.openai.com/examples/&#34;&gt;https://platform.openai.com/examples/&lt;/a&gt; (找灵感)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://gpt3demo.com/&#34;&gt;https://gpt3demo.com/&lt;/a&gt;  &lt;a href=&#34;https://gpt4demo.com/&#34;&gt;https://gpt4demo.com/&lt;/a&gt; （潘多拉盒子）&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/mli/paper-reading#%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86---transformer&#34;&gt;https://github.com/mli/paper-reading#自然语言处理-transformer&lt;/a&gt; (背后模型原理导读)&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: 优化 91-100 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-12-optimizations/</link>
      <pubDate>Thu, 23 Feb 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-12-optimizations/</guid>
      
        <description>&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;在大多数情况下，编写可读、清晰的代码比编写经过优化但更复杂、更难理解的代码要好，不要过早的优化。建议遵循软件工程师 Wes Dyer 的这句名言：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Make it correct, make it clear, make it concise, make it fast, in that order.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;并不意味着禁止为速度和效率优化应用程序, 了解并掌握这些优化点，以备不时之需；文中给出了常见的优化技术；有些特定于 Go 内存模型，内存分配，GPM调度模型；有些是关于了解硬件有助于写出好的代码(适用于不同语言)，其中会有硬件方面的术语，可以结合wiki进行学习；&lt;/p&gt;
&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;h3 id=&#34;91不了解-cpu-缓存&#34;&gt;91.不了解 CPU 缓存&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;Mechanical sympathy(机械同情)&lt;/em&gt;  来自三届 F1 世界冠军 Jackie Stewart 创造的一个术语&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;You don’t have to be an engineer to be a racing driver, but you do have to have mechanical sympathy.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;简而言之，当了解系统的设计用途时，无论是 F1 赛车、飞机还是计算机，都可以与设计保持一致以获得最佳性能。对 CPU 缓存工作方式的机械同情可以帮助优化 Go 应用程序。&lt;/p&gt;
&lt;h4 id=&#34;cpu架构-cpu-architecture&#34;&gt;CPU架构 CPU architecture&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F01_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F01_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图为简单的Intel Core i5-7300u cpu架构图；&lt;a href=&#34;https://en.wikichip.org/wiki/intel/core_i5/i5-7300u&#34;&gt;https://en.wikichip.org/wiki/intel/core_i5/i5-7300u&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;每个物理核心（Core0和Core1）被分成两个逻辑核心Hyper-Threading（T0和T1）。&lt;/p&gt;
&lt;p&gt;L1 缓存分为两个子缓存：用于数据的 L1D 和用于指令的 L1I（每个 32 KB）。当 CPU 执行应用程序时，缓存不仅仅与数据相关，它还可以缓存一些指令，L2, L3其原理相同：加快整体执行速度。&lt;/p&gt;
&lt;p&gt;内存位置离逻辑核心越近，访问速度越快（参见&lt;a href=&#34;http://mng.bz/o29v&#34;&gt;http://mng.bz/o29v&lt;/a&gt;）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;L1：约1ns&lt;/li&gt;
&lt;li&gt;L2：比L1慢约4倍&lt;/li&gt;
&lt;li&gt;L3：比L1慢10倍左右&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;CPU 缓存的物理位置也可以解释这些差异。L1 和 L2 是称为&lt;em&gt;on-die(片上)&lt;/em&gt;，这意味着它们与处理器的其余部分属于同一块硅片。相反，L3 是&lt;em&gt;off-die(片外)。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;对于主存储器（RAM），平均访问速度比 L1 慢 50 到 100 倍。可以访问存储在 L1 上的多达 100 个变量，只需访问一次主内存的价格。因此，作为 Go 开发人员，改进的一种途径是确保应用程序使用 CPU 缓存。进一不了解可以查看以下视频：&lt;/p&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/vgPFzblBh7w&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;h4 id=&#34;缓存行-cache-line&#34;&gt;缓存行 Cache Line&lt;/h4&gt;
&lt;p&gt;缓存行的概念对于理解至关重要。但在介绍它们是什么之前，了解为什么需要它们。&lt;/p&gt;
&lt;p&gt;当访问特定的内存位置时(例如 通过读取变量)，在不久的将来可能会发生以下情况之一：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;将再次引用相同的位置；时间局部性。&lt;/li&gt;
&lt;li&gt;附近的内存位置将被引用；空间局部性。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;两者都是局部性原则 &lt;em&gt;locality of reference&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;时间局部性是需要 CPU 缓存的部分原因：加速对相同变量的重复访问。由于空间局部性，CPU 会复制缓存行将包括单个变量的缓存行从主存复制到高速缓存，并加载到寄存器中执行。&lt;/p&gt;
&lt;p&gt;高速缓存行是固定大小的连续内存段，通常为 64 字节（8 个&lt;code&gt;int64&lt;/code&gt;变量）。每当 CPU 决定缓存 RAM 中的内存块时，它会将内存块复制到缓存行。因为内存是有层次结构的，所以当CPU要访问一个特定的内存位置时，它首先检查L1，然后是L2，然后是L3，最后，如果位置不在那些缓存中，则在主内存中。&lt;/p&gt;
&lt;p&gt;举一个简单的例子， 遍历容量为16的slice切片s []int64;  这个内存地址还没在缓存中；程序开始遍历，cpu决定缓存这个s[0]这个变量，会复制整个内存块复制到缓存行，缓存行中包含了8个int64，0到7的数据将会在cpu cache中命中；访问s[8]时同理；迭代16个int64元素导致2次强制缓存未命中(&lt;em&gt;compulsory miss&lt;/em&gt;)和 14 次缓存命中。&lt;/p&gt;
&lt;p&gt;CPU缓存策略有个大致的了解：有时缓存是包容性的（例如，L2 数据也存在于 L3 中），有时缓存是排他性的（例如，L3 称为受害者缓存，因为它只包含从 L2 逐出的数据）；这些策略被 CPU 供应商隐藏起来；大致了解下即可。&lt;/p&gt;
&lt;p&gt;如果感兴趣，可以通过 &lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/CPU_cache&#34;&gt;https://en.wikipedia.org/wiki/CPU_cache&lt;/a&gt;&lt;/strong&gt; 进一步了解，比较硬核。&lt;/p&gt;
&lt;h4 id=&#34;结构切片与切片结构-slice-of-structs-vs-struct-of-slices&#34;&gt;结构切片与切片结构 Slice of structs vs. struct of slices&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Foo&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int64&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int64&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Bar&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int64&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int64&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;对[]Foo 和 Bar.a 容量长度为16的切片遍历，遍历数据结构切片 比 遍历切片结构 慢， 因为cache line的空间局部性原理，加载切片结构更紧凑，需要更少的缓存行来迭代，如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F04_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F04_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;可预测性-predictability&#34;&gt;可预测性 Predictability&lt;/h4&gt;
&lt;p&gt;要理解这一点，必须了解跨步striding的概念。跨步与 CPU 如何处理数据有关。共有三种不同类型的步幅(stride)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;单位步幅Unit stride&lt;/em&gt;：全部想要访问的值是连续分配的：例如，切片[]int64元素。这个步幅对于 CPU 来说是可预测的并且是最有效的，因为它需要最少数量的缓存行来遍历元素。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;恒定步幅Constant stride&lt;/em&gt;：对于 CPU 来说仍然是可预测的：例如，一个切片每两个元素迭代一次。此步幅需要更多缓存行来遍历数据，因此它的效率低于单位步幅。&lt;/li&gt;
&lt;li&gt;&lt;em&gt;非单位步幅Non-unit stride&lt;/em&gt; ：CPU 无法预测的跨步：例如，链表或指针切片。因为 CPU 不知道数据是否连续分配，所以它不会获取任何缓存行。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F06_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F06_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;由于不同的步幅和相似的空间局部性，迭代链表比值的切片要慢得多。由于更好的空间局部性，通常应该支持单位步幅而不是恒定步幅。但是当CPU 都无法预测非单位步长，无论数据如何分配，都会有性能上的影响。&lt;/p&gt;
&lt;p&gt;到目前为止，已经讨论了 CPU 缓存速度很快但比主内存小得多。因此，CPU 需要一种策略来将内存块提取到缓存行。此策略称为&lt;em&gt;缓存放置策略&lt;/em&gt;，并且会显着影响性能。&lt;/p&gt;
&lt;h4 id=&#34;缓存放置策略-cache-placement-policy&#34;&gt;缓存放置策略 Cache placement policy&lt;/h4&gt;
&lt;p&gt;当 CPU 决定复制一个内存块并将其放入缓存时，它必须遵循特定的策略。假设一个 32 KB 的 L1D 缓存和一个 64 字节的缓存行，如果一个块被随机放入 L1D，CPU 在最坏的情况下将不得不迭代 512 个缓存行来读取一个变量。这种缓存是称为&lt;em&gt;完全结合(fully associative)&lt;/em&gt;。&lt;/p&gt;
&lt;p&gt;为了提高从 CPU 缓存访问地址的速度，设计人员制定了有关缓存放置的不同策略。跳过历史，讨论当今使用最广泛的策略：集合关联缓存策略(&lt;em&gt;set-associative cache)&lt;/em&gt; ，它依赖缓存分区。&lt;/p&gt;
&lt;p&gt;具体参考以下资料进一步了解：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_placement_policies&#34;&gt;https://en.wikipedia.org/wiki/Cache_placement_policies&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://lwn.net/Articles/250967/&#34;&gt;https://lwn.net/Articles/250967/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://coolshell.cn/articles/20793.html&#34;&gt;https://coolshell.cn/articles/20793.html&lt;/a&gt; (结合文章中&lt;a href=&#34;https://github.com/haoel/cpu-cache&#34;&gt;c++代码&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;为了便于理解，举一个简单的例子，有一个矩阵 二维数组arr [4][32]int64  4行32列存放int64，从中取出前8列res [4][8]int64；假设L1D缓存大小512B,  缓存行cache line 64B， 有8个cache line；&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F07_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F07_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;图中所示该矩阵如何存储在内存中。这里使用二进制表示来表示内存块地址,为简单起见，使用 13 位表示一个地址；灰色块代表迭代的前 8 个int64元素，其余块在迭代期间被跳过。每个主存内存块包含 64 个字节，因此块内包含 8 个int64元素。第一个内存块从 0x0000000000000 开始，第二个从 0001000000000（二进制为 512）开始，依此类推。 以及可以容纳 8 行的缓存cache。&lt;/p&gt;
&lt;p&gt;使用集合关联缓存策略(&lt;em&gt;set-associative cache)&lt;/em&gt;，缓存被划分为集合。假设缓存是N-way集合关联的(N=2)，这意味着每个集合包含两行。一个内存块只能属于一个集合，其放置位置由其内存地址决定。要理解这一点，必须将内存块地址分解为三个部分：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;块&lt;em&gt;偏移量&lt;/em&gt;是基于块大小。这里的块大小是 512 字节，512 等于 2^9。因此，地址的前 9 位代表块偏移量（bo）。&lt;/li&gt;
&lt;li&gt;集合&lt;em&gt;索引&lt;/em&gt;表示地址所属的集合。因为缓存是两路集合关联的并且包含 8 行，所以有 8 / 2 = 4 个集合。此外，4 等于 2^2，因此接下来的两位代表集合索引 (si)。&lt;/li&gt;
&lt;li&gt;地址的其余部分由标记位 (tb) 组成。为简单起见使用 13 位表示一个地址。计算 tb 位数 = 13 – bo – si。这意味着剩下的两位代表标记位。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;假设该函数启动并尝试读取&lt;code&gt;s[0][0]&lt;/code&gt;属于地址 0000000000000 的地址。由于该地址尚未出现在缓存中，因此 CPU 计算其集合索引并将其复制到相应的缓存集合。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F08_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F08_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;如前所述，9 位表示块偏移量：它是每个内存块地址的最小公共前缀。然后，2位表示集合索引。地址为 0000000000000 时，si 等于 00。因此，该内存块被复制到Set 0。&lt;/p&gt;
&lt;p&gt;当函数从 读取&lt;code&gt;s[0][1]&lt;/code&gt;到时&lt;code&gt;s[0][7]&lt;/code&gt;，数据已经在缓存中。CPU 是怎么知道的？CPU 计算内存块的起始地址，计算集合索引和标记位，然后检查Set 0 中是否存在 00。&lt;/p&gt;
&lt;p&gt;接下来函数读取&lt;code&gt;s[1][0]&lt;/code&gt;，这个地址还没有被缓存。因此复制内存块 0100000000000 时发生相同的操作&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F09_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F09_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;该内存的集合索引等于 00，因此它也属于Set 0。缓存行被复制到Set 0 中的下一个可用行。然后，再次从 读取到导致缓存&lt;code&gt;s[1][1]&lt;/code&gt;命中&lt;code&gt;s[1][7]&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;现在事情变得有趣了。该函数读取&lt;code&gt;s[2][0]&lt;/code&gt;，并且该地址不存在于缓存中。执行相同的操作&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F10_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F10_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;集合索引再次等于 00。但是， Set0 已满，CPU 会替换现有缓存行之一以复制内存块 1000000000000。&lt;/p&gt;
&lt;p&gt;缓存替换策略(&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_replacement_policies&#34;&gt;Cache replacement policies&lt;/a&gt;)取决于 CPU，但它通常是伪 LRU 策略（真正的 LRU [最近最少使用] 会太复杂而无法处理）。在这种情况下，假设它替换了第一个缓存行：0000000000000。当迭代第 3 行时会重复这种情况：内存地址 1100000000000 也有一个等于 00 的集合索引，导致替换现有的缓存行。&lt;/p&gt;
&lt;p&gt;现在，假设基准测试执行函数，其中一个切片指向从地址 0000000000000 开始的相同矩阵。每次基准测试，当函数读取时，&lt;code&gt;s[0][0]&lt;/code&gt;地址不在缓存中；该块已被替换。&lt;/p&gt;
&lt;p&gt;基准测试将导致更多的缓存未命中，而不是从一个执行到另一个执行使用 CPU 缓存。这种类型的缓存未命中称为*冲突未命中conflict miss；*如果未对缓存进行分区，则不会发生未命中。迭代的所有变量都属于一个集合索引为00的内存块。因此，只使用一个缓存集合，而不是分布在整个缓存中。&lt;/p&gt;
&lt;p&gt;之前讨论了步幅&lt;em&gt;stride&lt;/em&gt;的概念， CPU 如何遍历数据。在这个例子中，这个步幅是称为*临界步幅critical stride；*它导致访问具有相同集合索引的内存地址，存储到相同的缓存集合中。&lt;/p&gt;
&lt;p&gt;Intel 大多数处理器的存放数据的L1D都是32KB，8-Way 组相联，Cache Line 是64 Bytes。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;32KB可以分成，32KB / 64 = 512 条 Cache Line。&lt;/li&gt;
&lt;li&gt;因为有8 Way，于是会每一Way 有 512 / 8 = 64 条 Cache Line。&lt;/li&gt;
&lt;li&gt;于是每一路就有 64 x 64 = 4096 Byts 的内存。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;回到前面&lt;a href=&#34;https://weedge.github.io/post/go-tips/go-tips-11-testing/#89%E7%BC%96%E5%86%99%E4%B8%8D%E5%87%86%E7%A1%AE%E7%9A%84%E5%9F%BA%E5%87%86&#34;&gt;#89&lt;/a&gt; 真实示例中，使用两个函数&lt;code&gt;calculateSum512&lt;/code&gt;和&lt;code&gt;calculateSum513&lt;/code&gt;。基准测试在 32 KB 8-way set-associative L1D cache上执行，总共 64 组。因为缓存行是 64 字节，所以每一路步长等于 64 × 64 字节 = 4 KB；代表512 个&lt;code&gt;int64&lt;/code&gt;类型元素。因此，达到了 512 列矩阵的&lt;em&gt;临界步幅critical stride&lt;/em&gt;，缓存分布很差(&lt;em&gt;冲突未命中conflict miss&lt;/em&gt;)。同时，如果矩阵包含 513 列，则不会导致&lt;em&gt;临界步幅&lt;/em&gt;。这就是为什么观察到两个基准之间存在如此巨大差异的原因。这个同样适用于在intel CPU架构上运行的其他语言。&lt;/p&gt;
&lt;p&gt;总之，必须意识到现代缓存是分区的。根据步幅，在某些情况下只使用一组，这可能会损害应用程序性能并导致冲突未命中。这种步幅称为临界步幅。对于性能密集型应用程序，应该避免关键步骤来充分利用 CPU 缓存。&lt;/p&gt;
&lt;p&gt;tips: 应该注意基准测试的结果在不同底层CPU架构而有所不同。注意开发测试 和 生产环境下的CPU架构一致，如果有对计算密集型的调优，最好在生产环境待部署的机器上都进行基准测试一下。&lt;/p&gt;
&lt;h3 id=&#34;92编写导致伪共享false-sharing的并发代码&#34;&gt;92.编写导致伪共享(false sharing)的并发代码&lt;/h3&gt;
&lt;p&gt;由于多核处理器cpu之间独立的L1/L2 cache，会出现cache line不一致的问题，为了解决这个问题，有相关协议模型，常用MESI协议，MESI 通过 这个网站模拟更直观的了解 &lt;a href=&#34;https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm&#34;&gt;https://www.scss.tcd.ie/Jeremy.Jones/VivioJS/caches/MESIHelp.htm&lt;/a&gt;；为了保证一个core上修改的cache line数据同步到其他core的cache line上，则需要MESI协议来保证，如果同一个cache line上有个两个变量sum1 和 sum2 之间虽然没有相互依赖逻辑，但是当修改sum1 或者sum2 时，需要同步同一块cache line的内容，导致 即使没有相互关系的变量在同一cache line中， 需要彼此共享同步，从而出现所说的&lt;em&gt;伪共享 flase sharing&lt;/em&gt;。伪共享因为cache line的同步会带来一些cpu 时钟周期的性能损失。&lt;/p&gt;
&lt;p&gt;了解伪共享的情况，知道如何破解了，直接让sum1和sum2 放置在不同的cache line就可以；比如一个结构体中sum1和sum2 的存放结构：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Result2&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;sumA&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int64&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;    &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;56&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// a cache line 64B 
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;sumB&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int64&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// sumB in other cache line
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;还有一种解决方案是重新设计算法的结构。例如，不是让两个 goroutines 共享相同的结构，通过channel传递它们的本地结果。结果基准与填充大致相同。&lt;/p&gt;
&lt;p&gt;并发编程中，操作cpu L1/L2 cache 时，因为多核同步cache的最小单元是cache line，所以当缓存行在两个内核之间共享时，至少一个 goroutine 是 writer 时，就会发生伪共享。如果需要优化依赖于并发的应用程序，应该检查是否存在伪共享的代码，众所周知这种模式会降低应用程序性能。可以通过填充或通信来防止虚假共享。&lt;/p&gt;
&lt;h3 id=&#34;93不考虑指令级并行性-instruction-level-parallelism&#34;&gt;93.不考虑指令级并行性 instruction-level parallelism&lt;/h3&gt;
&lt;p&gt;这个很大一部分取决于编程语言的编译器软件，编译优化之后代码指令是否可以充分利用指令级并行&lt;em&gt;instruction-level parallelism&lt;/em&gt;（ILP）；以及在硬件cpu上进行指令级并行(ILP)；&lt;/p&gt;
&lt;p&gt;tips: 两者结合效果更佳，对于上层应用使用语言的开发者，了解其背后的原理即可，在应用程序上的性能优化可能效果不大，因为随着编译器升级可能会兼顾了应用程序上对ILP考虑优化。不过了解原理可以有助于上层宏观层面的思考并行，用于借鉴嘛~，微观到宏观(3体里经常浮现的词汇，降维打击)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Compiler&#34;&gt;编译器&lt;/a&gt;和&lt;a href=&#34;https://en.wikipedia.org/wiki/Central_processing_unit&#34;&gt;CPU&lt;/a&gt;设计人员的目标是尽可能多地识别和利用 ILP。普通程序通常是在顺序执行模型下编写的，其中指令一条接一条地执行，并按照程序员指定的顺序执行。ILP 允许编译器和处理器重叠执行多条指令，甚至可以改变指令执行的顺序。cpu利用ILP执行指令时，当表现出&lt;a href=&#34;https://en.wikipedia.org/wiki/Data_dependence&#34;&gt;数据依赖性&lt;/a&gt;的指令在流水线的不同阶段修改数据时，就会发生&lt;a href=&#34;https://en.wikipedia.org/wiki/Hazard_(computer_architecture)&#34;&gt;数据冒险危害&lt;/a&gt;。忽略潜在的数据危害会导致&lt;a href=&#34;https://en.wikipedia.org/wiki/Race_condition&#34;&gt;竞争条件&lt;/a&gt;（也称为竞争危害），进而触发控制风险；为了避免控制风险发生，可以通过&lt;a href=&#34;https://en.wikipedia.org/wiki/Branch_predictor&#34;&gt;预测分支&lt;/a&gt;来解决。&lt;/p&gt;
&lt;p&gt;了解利用ILP的微架构技术见wiki: &lt;a href=&#34;https://en.wikipedia.org/wiki/Instruction-level_parallelism&#34;&gt;https://en.wikipedia.org/wiki/Instruction-level_parallelism&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在Go中，可以通过 &lt;a href=&#34;https://research.swtch.com/mm&#34;&gt;https://research.swtch.com/mm&lt;/a&gt; 来了解在这方面的思考&lt;/p&gt;
&lt;h3 id=&#34;94不知道数据对齐&#34;&gt;94.不知道数据对齐&lt;/h3&gt;
&lt;p&gt;数据对齐是一种安排数据分配方式以加速 CPU 访问内存的方法。不了解这个概念会导致额外的内存消耗甚至性能下降。&lt;/p&gt;
&lt;p&gt;tips: 这个属于老生常谈的问题了，尤其在c语言开发的程序中，数据对齐，直接通过地址+偏移大小来指向对应内存数据，进行读写操作；golang很多思想来自c，自然也会有，只不过更加友好，unsafe形式来操作指针。&lt;/p&gt;
&lt;p&gt;在 64 位cpu架构上,处理最小单位是8字节的地址，如果没有数据对齐，变量j分配可以分布在两个地址上。如果 CPU 想要读取j，则需要两次而不是一次内存访问。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F22_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F22_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;为防止这种情况，变量的内存地址应该是其自身大小的倍数。这就是数据对齐的概念。在 Go 中，对齐保证如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;byte&lt;/code&gt;, &lt;code&gt;uint8&lt;/code&gt;, &lt;code&gt;int8&lt;/code&gt;: 1 字节&lt;/li&gt;
&lt;li&gt;&lt;code&gt;uint16&lt;/code&gt;, &lt;code&gt;int16&lt;/code&gt;: 2 字节&lt;/li&gt;
&lt;li&gt;&lt;code&gt;uint32&lt;/code&gt;, &lt;code&gt;int32&lt;/code&gt;, &lt;code&gt;float32&lt;/code&gt;: 4 字节&lt;/li&gt;
&lt;li&gt;&lt;code&gt;uint64&lt;/code&gt;, &lt;code&gt;int64&lt;/code&gt;, &lt;code&gt;float64&lt;/code&gt;, &lt;code&gt;complex64&lt;/code&gt;: 8 字节&lt;/li&gt;
&lt;li&gt;&lt;code&gt;complex128&lt;/code&gt;: 16 字节&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有这些类型都保证对齐：它们的地址是它们大小的倍数。例如，任何&lt;code&gt;int32&lt;/code&gt;变量的地址都是 4 的倍数。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F23_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F23_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;这样上面的情况，按在字节对齐，出现两种情况：&lt;/p&gt;
&lt;p&gt;第一种情况，在i之前分配了一个32位变量。因此i和j被连续分配。&lt;/p&gt;
&lt;p&gt;第二种情况，在i之前没有分配32位变量；i被分配在一个词的开头。为了数据对齐（地址是 64 的倍数），i不能与下一个 64 的倍数j一起分配。灰色框表示 32 位填充。&lt;/p&gt;
&lt;p&gt;所以了解了字节对齐之后，在设计数据结构的时候，需要清楚，数据结构通过编译器优化编译之后方便cpu访问 的数据对齐结构，所占内存大小；防止出现本来不需要这么多内存空间的设计。尤其在设计非常依赖缓存存储的项目中。申请内存空间越多越频繁，对于Go来说，将带来更多的GC, 影响整体应用性能。&lt;/p&gt;
&lt;p&gt;还有一个好处是，考虑了字节对齐后的合理结构体(所占内存空间的结构体大小最小情况，&lt;strong&gt;结构体中的字段按大小降序对它们进行排序对齐&lt;/strong&gt;)；利用cache 局部性原理，可以在cpu cache line中存放更多的对象，这样在遍历对象时，需要更少的缓存行总数，性能更好。&lt;/p&gt;
&lt;p&gt;PS: 在硬件存储设备上，也存在同样的读写IO对齐，在编写硬件存储系统，使用直接io(linux fs.open O_DIRECT 模式)的情况，硬件存储IO性能尤其注意的地方，比如磁盘最小单元扇区 512B 对齐，SSD最小单元page 4K 对齐。如果不利用好对齐，会增加额外的读写放大，比如读写一个存储单元大小数据，数据没有对齐，需要访问多个存储单元数据，存在读写放大，增加IO次数，影响性能。一次磁盘读 io 2ms 级别，ssd则在几十us；相对于cpu cache的读写 几ns级别，磁盘io通常是系统主要优化的点。不过这方面操作系统和硬件打交道都已经考虑了，除非不使用操作系统的系统调用函数操作硬件。&lt;/p&gt;
&lt;p&gt;附：Latency Numbers Every Programmer Should Know： &lt;a href=&#34;https://colin-scott.github.io/personal_website/research/interactive_latency.html&#34;&gt;https://colin-scott.github.io/personal_website/research/interactive_latency.html&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;95不了解栈与堆&#34;&gt;95.不了解栈与堆&lt;/h3&gt;
&lt;p&gt;在 Go 中，变量可以分配在栈上或堆上。这两种类型的内存根本不同，影响数据密集型应用程序。需要了解栈和堆这些概念，以及编译器决定变量分配位置所遵循的规则。&lt;/p&gt;
&lt;h4 id=&#34;栈与堆&#34;&gt;栈与堆&lt;/h4&gt;
&lt;p&gt;首先，讨论一下栈和堆的区别。栈是它是一种后进先出 (LIFO) 数据结构，用于存储特定 goroutine 的所有局部变量。当一个 goroutine 启动时，它会获得 2 KB 的连续内存作为它的栈空间（这个大小随着时间的推移而变化并且可能会再次改变）。但是，此大小在运行时不是固定的，可以根据需要增大和缩小（但它始终在内存中保持连续，从而保留数据局部性）。&lt;/p&gt;
&lt;p&gt;tips: Go 在1.3之前栈扩容采用的是分段栈（Segemented Stack），在栈空间不够的时候新申请一个栈空间用于被调用函数的执行， 执行后销毁新申请的栈空间并回到老的栈空间继续执行，当函数出现频繁调用（递归）时可能会引发hot split。为了避免hot split, 1.3之后采用的是连续栈（Contiguous Stack），栈空间不足的时候申请一个2倍于当前大小的新栈，并把所有数据拷贝到新栈， 接下来的所有调用执行都发生在新栈上。&lt;/p&gt;
&lt;p&gt;当 Go 进入一个函数时，会创建一个栈帧，代表内存中只有当前函数才能访问的一个区间。&lt;/p&gt;
&lt;p&gt;通过一个简单示例来介绍stack的指令执行过程&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F27_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F27_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;为了简化，图中stack没有使用汇编指令来表明，执行了&lt;code&gt;main&lt;/code&gt;，所以为这个函数创建了一个栈帧，&lt;code&gt;a&lt;/code&gt;和&lt;code&gt;b&lt;/code&gt;都分配在栈上，valid为有效地址，invalid为无效地址。栈从高地址往地址空间增长，其中基准指针寄存器BP 来维护栈基地址 ，栈指针寄存器SP 指向栈顶地址； 至于汇编相关的细节见官方文档查阅解释：&lt;strong&gt;&lt;a href=&#34;https://go.dev/doc/asm&#34;&gt;https://go.dev/doc/asm&lt;/a&gt;&lt;/strong&gt;。查看命令如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-fallback&#34; data-lang=&#34;fallback&#34;&gt;GOOS=linux GOARCH=amd64 go tool compile -S -L -N -l -m 12-optimizations/95-stack-heap/main.go | less
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F28_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F28_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;调用&lt;code&gt;sumValue&lt;/code&gt;创建一个新的栈帧。x,y为值传递分别赋值，x+y后(简单起见，操作指令未给出)，z赋值; 先前的栈帧&lt;code&gt;(main)&lt;/code&gt;包含仍被视为有效的地址，但无法访问a和b对其操作，如果是指针传递则可以获取地址对其操作。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F29_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F29_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;执行完出函数，出栈，sumValue栈帧被擦除，替换为原来的main栈帧，x已经被擦除，y和z仍在内存中分配，但是无法访问。&lt;/p&gt;
&lt;p&gt;注意 栈&lt;code&gt;sumValue&lt;/code&gt;帧并未从内存中完全删除。当函数返回时，Go 不会花时间释放变量来回收可用空间。但是这些以前的变量不能再被访问，当来自父函数的新变量被分配到栈时，它们取代了之前的分配。从某种意义上说，栈是自清洁的；它不需要额外的机制，例如 GC。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F30_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F30_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;把调用函数改成指针返回时，z 如果 继续分配在栈上的话，函数返回后，z不在有效，main栈帧继续增长，会擦除掉z, 这样c指向的地址空间已经不存在了，变成了错位的悬挂指针，如果使用c进行操作会出现异常(C语言中，会出现Segmentation fault)，所以在Go中，为了代码安全，在编译的时候，将z 原本在栈上分配的空间，逃逸分配到了堆上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F31_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F31_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;堆内存空间是所有goroutine的共享池，由Go的内存分配器来管理，具体见&lt;a href=&#34;https://medium.com/@ankur_anand/a-visual-guide-to-golang-memory-allocator-from-ground-up-e132258453ed&#34;&gt;Go Memory Allocator&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;三个协程&lt;code&gt;G1&lt;/code&gt;,&lt;code&gt;G2&lt;/code&gt;和&lt;code&gt;G3&lt;/code&gt;都有自己的栈，共享同一个堆进行内存分配管理。&lt;/p&gt;
&lt;p&gt;tips: 在Go中，为了加速内存分配，Golang自己维护了类似https://github.com/google/tcmalloc 的内存分配器来管理，每个运行时P都有一个本地mcache，用于执行状态的协程G分配内存空间，对应多线程中内存tcmalloc的分配机制，线程本地mcache。&lt;/p&gt;
&lt;p&gt;栈是自清洁的，并由单个 goroutine 访问。相反，堆上分配的对象需要通过GC标注扫描进行清理。堆分配越多对象，对 GC 施加的压力就越大。当 GC 运行时，会使用大约 25% 的可用 CPU 容量，并且可能会产生毫秒级的“停止世界”延迟（应用程序暂停的阶段）。具体见官方文档： &lt;a href=&#34;https://tip.golang.org/doc/gc-guide&#34;&gt;gc-guide&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在基准压测的结果中，使用的testing.B.ReportAllocs函数, 或者使用参数-benchmem ，显示了堆分配情况（栈分配不计算在内）：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;B/op:&lt;/code&gt;每个操作分配多少字节&lt;/li&gt;
&lt;li&gt;&lt;code&gt;allocs/op:&lt;/code&gt;每个操作有多少分配&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;tips:&lt;/p&gt;
&lt;p&gt;由于Go中的用户栈空间是自动扩缩容的，需要注意每个协程goroutine栈扩容对内存空间的影响，特别是在长连接的场景，单机连接数在100w级别的时候，尽量保持每个goroutine 处理函数的逻辑在2kb内(功能职责分离)，防止栈扩容，导致内存指数级暴涨。&lt;/p&gt;
&lt;p&gt;栈扩容了，长时间没有运行，为了提高内存利用率，在GC触发的时候，计算当前栈使用的空间，小于栈空间的1/4，会触发栈缩容操作到原来的1/2，最小到2kb，不会再缩容；但在缩容过程中会存在栈拷贝和写屏障(write barrier)，对于一些准实时应用可能会存在一些影响。 好在go提供了可设置的参数，可以通过设置环境变量 GODEBUG=gcshrinkstackoff=1 来关闭栈缩容。关闭栈缩容后， 需要承担栈持续增长的风险，在关闭前需要慎重考虑。&lt;/p&gt;
&lt;h4 id=&#34;逃逸分析-重要&#34;&gt;逃逸分析 (重要)&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/cmd/compile/internal/escape/escape.go&#34;&gt;逃逸分析(escape analysis)&lt;/a&gt; 在程序编译阶段根据程序代码中的数据变量，对代码中哪些变量需要在栈上分配，哪些变量需要在堆上分配进行静态分析的方法；Go 语言的逃逸分析遵循以下两个不变性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;指向栈对象的指针不能存储在堆中（pointers to stack objects cannot be stored in the heap）；&lt;/li&gt;
&lt;li&gt;指向栈对象的指针不能超过该栈对象的存活期（pointers to a stack object cannot outlive that object）。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;tips: 发生逃逸时，底层会使用runtime.newobject调用&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/runtime/malloc.go#L878&#34;&gt;&lt;strong&gt;mallocgc&lt;/strong&gt;&lt;/a&gt;通过内存分配器来管理分配；&lt;/p&gt;
&lt;p&gt;无法在栈上完成分配时，它会在堆上完成, 比如：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果局部变量太大而不适合栈。&lt;/li&gt;
&lt;li&gt;如果局部变量的大小未知。例如，&lt;code&gt;s := make([]int, 10)&lt;/code&gt;可能不会逃逸到堆中，但&lt;code&gt;s := make([]int, n)&lt;/code&gt;会，因为它的大小是基于变量的。&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// go run -gcflags=&amp;#39;-m=1 -l -L -S -N&amp;#39;
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;test1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8193&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// &amp;gt;64kb a and a.Data escape to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nf&#34;&gt;printSliceLocalAndDataPointAddr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;aa&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8192&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// &amp;lt;=64kb aa and aa.Data don&amp;#39;t escape to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nf&#34;&gt;printSliceLocalAndDataPointAddr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;aa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;aaa&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;8192&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// &amp;lt;=64kb aaa and aaa.Data don&amp;#39;t escape to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nf&#34;&gt;printSliceLocalAndDataPointAddr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;aaa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;aaa&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;aaa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// happen runtime.growslice; aaa don&amp;#39;t escape to heap，but aaa.Data move to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nf&#34;&gt;printSliceLocalAndDataPointAddr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;aaa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;// so if make a slice, &amp;lt;=64kb please init cap, eg: make([]int, 0, 8192) allocate in stack
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;bb&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;  &lt;span class=&#34;c1&#34;&gt;// don&amp;#39;t move to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;bbb&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1024&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// move to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;([]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// escapes to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;aa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;aaa&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bb&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bbb&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;printSliceLocalAndDataPointAddr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nb&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;addr of local slice = &amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;pd&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;reflect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;SliceHeader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
	&lt;span class=&#34;nb&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;slice data =&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;pd&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;指向栈对象的指针不能在栈对象回收后存活；interface操作以及返回函数中局部变量的指针， 比如：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// go tool compile -m=1 -l -L -S -N   use -m=2 , -m3, -m4 see more
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;hi&amp;#34;&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%s&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// a escapes to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;sum&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;y&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;y&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;z&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// moved to heap: z
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;noescape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Pointer&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// p does not escape
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;uintptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;^&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;leakNoEscape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// leaking param: p to result ~r0 level=0
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;escape&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// x escapes to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果指向栈对象的指针存在于栈中；这不会分配到堆上，比如&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F32_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F32_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;x, y 的值(对象地址)，以及指向对象 a 和 b. 都在栈上，所以不会分配在堆上。&lt;/p&gt;
&lt;p&gt;以下是变量可以逃逸到堆的其他情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全局变量，因为多个 goroutines 可以访问它们。&lt;/li&gt;
&lt;li&gt;发送到channel的指针：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Foo&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;ch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;chan&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Foo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;foo&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Foo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// escapes to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;foo&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;由发送到通道的值引用的变量：&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Foo&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;ch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;chan&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Foo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;x&amp;#34;&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// moved to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bar&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Foo&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;ch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bar&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上逃逸分析的测试随着编译器的升级，可能在未来的 Go 版本中发生变化。为了确认假设，可以使用 &lt;code&gt;go build -gcflags &amp;quot;-m=2&amp;quot;&lt;/code&gt; -m=3,-m4 来进行详细分析。&lt;/p&gt;
&lt;p&gt;了解堆和栈之间的根本区别对于优化 Go 应用程序至关重要。堆分配对于 Go 运行时处理来说更为复杂，并且需要具有 GC 的外部系统来释放数据。在某些数据密集型应用程序中，堆管理可占总 CPU 时间消耗的 20% 或 30%。另一方面，栈是自清洁的，并且对单个 goroutine 而言是本地的，从而使分配速度更快。因此，优化内存分配可以获得很大的投资回报。&lt;/p&gt;
&lt;p&gt;理解逃逸分析的规则对于编写更高效的代码也很重要。一般来说，向下共享留在栈上，而向上共享逃逸到堆中。这应该可以防止常见错误，例如想要返回指针的过早优化，例如“避免复制”。首先关注可读性和语义，然后在需要时优化分配。&lt;/p&gt;
&lt;p&gt;tips: 想更深入了解逃逸分析，可以一起学习这篇论文：&lt;a href=&#34;http://www.wingtecher.com/themes/WingTecherResearch/assets/papers/ICSE20.pdf&#34;&gt;Escape from Escape Analysis of Golang&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;96不知道如何减少分配&#34;&gt;96.不知道如何减少分配&lt;/h3&gt;
&lt;p&gt;减少分配是加速 Go 应用程序的常见优化技术。已经涵盖了一些减少堆分配数量的方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;未优化的字符串连接（错误 &lt;a href=&#34;https://weedge.github.io/post/notions/go-tips/go-tips-05-strings/#39%E4%BC%98%E5%8C%96%E4%B8%8D%E8%B6%B3%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BF%9E%E6%8E%A5&#34;&gt;#39&lt;/a&gt;）：使用&lt;code&gt;strings.Builder&lt;/code&gt;替代&lt;code&gt;+&lt;/code&gt;运算符来连接字符串。&lt;/li&gt;
&lt;li&gt;无用的字符串转换（错误 &lt;a href=&#34;https://weedge.github.io/post/notions/go-tips/go-tips-05-strings/#40%E6%97%A0%E7%94%A8%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E8%BD%AC%E6%8D%A2&#34;&gt;#40&lt;/a&gt;）：尽可能避免转换&lt;code&gt;[]byte&lt;/code&gt;成字符串。&lt;/li&gt;
&lt;li&gt;切片和映射初始化效率低下（错误 &lt;a href=&#34;https://weedge.github.io/post/notions/go-tips/go-tips-03-data-types/#21%E5%88%87%E7%89%87%E5%88%9D%E5%A7%8B%E5%8C%96%E6%95%88%E7%8E%87%E4%BD%8E%E4%B8%8B&#34;&gt;#21&lt;/a&gt; 和 &lt;a href=&#34;https://weedge.github.io/post/notions/go-tips/go-tips-03-data-types/#27%E4%BD%8E%E6%95%88%E7%9A%84map%E5%88%9D%E5%A7%8B%E5%8C%96&#34;&gt;#27&lt;/a&gt;）：如果长度已知，则预分配切片和映射。&lt;/li&gt;
&lt;li&gt;更好的数据结构对齐以减少结构大小（错误 &lt;a href=&#34;https://weedge.github.io/post/notions/go-tips/go-tips-12-optimizations/#94%E4%B8%8D%E7%9F%A5%E9%81%93%E6%95%B0%E6%8D%AE%E5%AF%B9%E9%BD%90&#34;&gt;#94&lt;/a&gt;）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;另外还有三种减少内存分配的常见方式：&lt;/p&gt;
&lt;h4 id=&#34;api-设计&#34;&gt;API 设计&lt;/h4&gt;
&lt;p&gt;只要涉及到I/O读写，会大量使用到在io库https://pkg.go.dev/io中，定义的读Reader / 写Writer接口, 对应的API方法，设计时为什么使用[]byte 作为传入参数，返回读取了多少， 而不使用读取多少来返回对应[]byte呢？&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Reader&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;interface&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nf&#34;&gt;Read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Reader&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;interface&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nf&#34;&gt;Read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果使用切片[]byte返回的方式，Read函数内部会读取函数局部变量的切片赋值给返回的切片， 类似如下操作：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;HiString&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;HiString&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;Read&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;n&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;4&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;6&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;7&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;p&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[:&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;n&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;//[]byte{...} escapes to heap
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这样函数局部变量会逃逸到堆上分配，这样带了额外的gc影响，而且io库的接口经常会被不同对象实例化使用到。所以Go 的设计者使用向下共享的方法来防止自动将切片转义到堆中；由调用者提供读写的切片[]byte，至于是否分配在堆上还是栈上，这取决于调用者来处理它，而不是直接返回，导致逃逸发生的可能。&lt;/p&gt;
&lt;p&gt;有时，即使是 API 的微小变化也会对分配产生积极影响。在设计 API 时，了解逃逸分析规则，并在需要时使用它&lt;code&gt;-gcflags&lt;/code&gt;来理解编译器的决策。&lt;/p&gt;
&lt;h4 id=&#34;依赖编译器优化&#34;&gt;依赖编译器优化&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// go tool compile -m=1 -l -L -S -N see if use runtime.slicebytetostring
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;bytes&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;key&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// m[string(key)] would be more efficient than k := string(key); m[k] (SA6001)go-staticcheck
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;key&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nb&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如上代码，通过linter相关静态编译检查工具可以提示出 直接使用m[string(key)]的方式比k := string(key); m[k] 效率更高一些，因为编译器对m[string(key)] 进行了优化，不会调用runtime.slicebytetostring 进行复制转化，执行效率更快，也不会带了额外内存分配。&lt;/p&gt;
&lt;h4 id=&#34;池化syncpool&#34;&gt;池化sync.Pool&lt;/h4&gt;
&lt;p&gt;当处理的对象，分配在堆上，且频繁被创建使用，这样会触发频繁gc，对这些临时对象标记扫描，会带来额外性能影响，所以在Go引入了sync.Pool，复用临时对象，减少频繁创建，并且在池中的临时对象一段时间不在使用时，会从对象池中移出，并被gc回收，合理的触发机制由gc来管理，进而减少频繁gc。而且sync.Pool 本身就是线程安全的，多个 goroutine 可以并发地调用Get方法存取对象；sync.Pool 不可在使用之后再复制使用，引入了noCopy机制，可以通过go vet来检查。&lt;/p&gt;
&lt;p&gt;sync.Pool有两个公开方法Get， Put 以及初始化Pool是的New 函数成员。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F34_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F34_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Get 方法分为两种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;pool为空，通过自定义的New方法创建一个新对象，注意这个对象是同一类型；然后返回刚创建的对象，除了返回值是正常实例化的对象，Get 方法的返回值还可能会是一个 nil（Pool.New 字段没有设置，又没有空闲元素可以返回），所以在使用的时候，需要判断。当没有设置 New 字段，没有更多的空闲元素可返回时，Get 方法将返回 nil，表明当前没有可用的元素。&lt;/li&gt;
&lt;li&gt;pool不为空， 直接从池子中选一个复用对象返回&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Put： 将对象重置为初始对象，放入池子中(poolLocalInternal结构)，如果放入对象为nil，则会忽略掉。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// Local per-P Pool appendix.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;poolLocalInternal&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;private&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;any&lt;/span&gt;       &lt;span class=&#34;c1&#34;&gt;// Can be used only by the respective P.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;shared&lt;/span&gt;  &lt;span class=&#34;nx&#34;&gt;poolChain&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// Local P can pushHead/popHead; any P can popTail.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;private: 仅被本地P使用，互斥 Put/Get&lt;/p&gt;
&lt;p&gt;shared: poolChain(lock-free queue)： 一个本地的 P 作为生产者（Producer）pushHead/popHead (Put/Get)，多个 P 作为消费者（Consumer）popTail (Get)&lt;/p&gt;
&lt;p&gt;具体见源码分析：&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/sync/pool.go&#34;&gt;go1.20/src/sync/pool.go&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;在频繁读写IO场景下，sync.Pool  常用作 buffer pool（缓冲池）来提升读写性能。类似这种封装：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bufferPool&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;sync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Pool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;New&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;any&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Buffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;},&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;// GetBuffer returns a buffer from the pool.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;GetBuffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;buf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Buffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bufferPool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;().(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Buffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;// PutBuffer returns a buffer to the pool.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// The buffer is reset before it is put back into circulation.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;PutBuffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;buf&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Buffer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;buf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Reset&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;bufferPool&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Put&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;buf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;sync.Pool不适合长时间不会释放的资源 比如长连接；因为sync.Pool池化的对象可能会被垃圾回收掉，对于数据库长连接等场景是不合适。&lt;/p&gt;
&lt;p&gt;如果经常分配很多同类型的对象，可以考虑使用sync.Pool. 它是一组临时对象，可以防止重复重新分配同一种数据；并且sync.Pool可以安全地同时被多个 goroutines 使用。&lt;/p&gt;
&lt;h3 id=&#34;97不依赖内联&#34;&gt;97.不依赖内联&lt;/h3&gt;
&lt;p&gt;内联是将较小的函数组合到它们各自的调用者中的行为。在计算的早期，这种优化通常是手动执行的。如今，内联是在编译过程中自动执行的一类基本优化之一。&lt;/p&gt;
&lt;p&gt;内联很重要有两个原因。首先是它消除了函数调用本身的开销。第二个是它允许编译器更有效地应用其他优化策略,比如栈中内联(Go 1.9 引入 Mid-stack inlining)；&lt;/p&gt;
&lt;p&gt;了解更多Mid-stack inlining相关内容： &lt;a href=&#34;https://go.googlesource.com/proposal/+/master/design/19348-midstack-inlining.md&#34;&gt;提案&lt;/a&gt;  , HN 上的讨论以及PPT: &lt;a href=&#34;https://news.ycombinator.com/item?id=13803447&#34;&gt;Mid-stack inlining in the Go compiler&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这种优化技术是关于区分快路径和慢路径。如果可以内联快速路径但不能内联慢速路径，可以将慢速路径提取到专用函数中。如果没有超出内联预算，函数就是内联的候选者。&lt;/p&gt;
&lt;p&gt;了解内联如何工作以及如何访问编译器的决定，可以成为使用快速路径内联技术进行优化的途径。如果执行快速路径，则在专用函数中提取慢速路径可防止函数调用。例如：sync库中使用Mutex.Lock Mutex.UnLock；&lt;a href=&#34;http://Once.Do&#34;&gt;Once.Do&lt;/a&gt; 用到了快速路径内联技术进行优化。&lt;/p&gt;
&lt;p&gt;tips: 具体优化收益，都需要进行基准压测为准&lt;/p&gt;
&lt;h3 id=&#34;98不使用-go-诊断工具-重要&#34;&gt;98.不使用 Go 诊断工具 （重要）&lt;/h3&gt;
&lt;p&gt;Go 提供了一些优秀的诊断工具来帮助深入了解应用程序的执行情况，重点介绍最重要的部分：剖析Profiling 和 执行跟踪器 Execution Tracer。具体查看官方文档： &lt;strong&gt;&lt;a href=&#34;https://go.dev/doc/diagnostics&#34;&gt;https://go.dev/doc/diagnostics&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Profiling 对运行中的代码采用基于定时器的采样。其缺点是，采样只能提供一个关于目标的粗略的图像，并且可能会遗漏事件。 比如cpu数据的采集，由于每次采集都会触发一次SIGPROF 信号中断，收集当时的调用堆栈；会对被采集的系统带来额外的负载影响，在采集cpu数据频率一般控制毫秒级别，所以存在采集精度的影响；对于微妙级别的采样，现在还不支持，有个改进的 &lt;a href=&#34;https://go.googlesource.com/proposal/+/refs/changes/08/219508/2/design/36821-perf-counter-pprof.md&#34;&gt;提案&lt;/a&gt; ，还未合并。&lt;/p&gt;
&lt;p&gt;Execution Tracer用来捕获各种运行时事件。调度、系统调用、垃圾收集、堆大小和其他事件由运行时收集，并可通过 go 工具跟踪进行可视化。执行跟踪器是一种检测延迟和利用率问题的工具，可以用来检查 CPU 的使用情况，以及在网络或系统调用时goroutine 抢占的原因。&lt;/p&gt;
&lt;h4 id=&#34;分析-profiling&#34;&gt;分析 Profiling&lt;/h4&gt;
&lt;p&gt;分析提供了对应用程序执行的洞察力。能够解决性能问题、检测争用、定位内存泄漏等。通过如下几个采集类型收集，并通过go tool pprof 分析：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cpu: 确定应用程序将时间花在哪里&lt;/li&gt;
&lt;li&gt;threadcreate: 创建的线程数, 这个采集点，2013年 &lt;a href=&#34;https://github.com/golang/go/issues/17280&#34;&gt;https://github.com/golang/go/issues/17280&lt;/a&gt; 这个issue 已经不可用了，新的还未merged。&lt;/li&gt;
&lt;li&gt;goroutine：报告正在进行的 goroutines 的堆栈跟踪&lt;/li&gt;
&lt;li&gt;heap：报道堆内存分配以监视当前内存使用情况并检查可能的内存泄漏&lt;/li&gt;
&lt;li&gt;mutex：报告锁查看代码中使用的互斥体的行为以及应用程序是否在锁定调用上花费了太多时间的争用&lt;/li&gt;
&lt;li&gt;block：显示 goroutines 阻塞等待同步原语的位置&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Go中提供3种方式使用pprof来采样数据，通过go tool pprof 工具来分析，具体见文档说明： &lt;a href=&#34;https://github.com/google/pprof/blob/main/doc/README.md&#34;&gt;https://github.com/google/pprof/blob/main/doc/README.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用运行时pprof包 接口API来采样数据&lt;/strong&gt;： &lt;a href=&#34;https://pkg.go.dev/runtime/pprof&#34;&gt;https://pkg.go.dev/runtime/pprof&lt;/a&gt; ；接口 api分析采样数据类型如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;goroutine    - stack traces of all current goroutines
heap         - a sampling of memory allocations of live objects
allocs       - a sampling of all past memory allocations
threadcreate - stack traces that led to the creation of new OS threads
block        - stack traces that led to blocking on synchronization primitives
mutex        - stack traces of holders of contended mutexes
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;具体见源码：&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/runtime/pprof/pprof.go&#34;&gt;go1.20/src/runtime/pprof/pprof.go&lt;/a&gt;，可以使用Profile结构来进行二次开发,新增采样类型。运行时分析适用于没有 HTTP 接口的应用程序，通常用于库。必须在主函数中放置一个启动和停止函数句柄。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用网络net/http pprof包 http接口来采样数据&lt;/strong&gt;： &lt;a href=&#34;http://pkg.go.dev/net/http/pprof&#34;&gt;https: //pkg.go.dev/net/http/pprof&lt;/a&gt;； http api接口采样数据类型如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;import _ &lt;span class=&#34;s2&#34;&gt;&amp;#34;net/http/pprof&amp;#34;&lt;/span&gt;
go func&lt;span class=&#34;o&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
	log.Println&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;http.ListenAndServe&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;localhost:6060&amp;#34;&lt;/span&gt;, nil&lt;span class=&#34;o&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;}()&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# use 6060 port&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# cpu seconds=30s , debug=1&lt;/span&gt;
http://localhost:6060/debug/pprof/profile?seconds&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;30&lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
http://localhost:6060/debug/pprof/heap
http://localhost:6060/debug/pprof/block
http://localhost:6060/debug/pprof/mutex
http://localhost:6060/debug/pprof/goroutine?debug&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
http://localhost:6060/debug/pprof/allocs?debug&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
http://localhost:6060/debug/pprof/threadcreate?debug&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;

http://localhost:6060/debug/pprof/cmdline?debug&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;# view all pprof&lt;/span&gt;
http://localhost:6060/debug/pprof
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;网络分析更适合依赖 HTTP 的 API 应用程序。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用基准压测来采样数据：&lt;/strong&gt; &lt;a href=&#34;https://pkg.go.dev/cmd/go#hdr-Testing_flags&#34;&gt;https://pkg.go.dev/cmd/go#hdr-Testing_flags&lt;/a&gt; ，没有goroutine的采样，可以借助 trace工具来分析goroutine的细粒度调度情况，使用 -trace trace.out 。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# sampling&lt;/span&gt;
go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; -v -bench&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;Benchmark_parallelMergesortV1$  -count&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; -benchtime&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1s -benchmem -cpuprofile cpu.out -memprofile mem.out -mutexprofile mutex.out -blockprofile block.out ./08-concurrency-foundations/56-faster/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;最终采集的样本数据, 这些数据由pb格式编码(pb格式数据经常用于大数据场景，数据占用空间低)， pprof 读取 profile.proto 格式的分析样本集合并生成报告以可视化和帮助分析数据。它可以生成文本和图形报告（通过使用点可视化包）。通过命令 go tool pprof 来分析：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# text cmd pprof or use web cmd in pprof view need graphviz&lt;/span&gt;
go tool pprof cpu.out
go tool pprof mem.out
go tool pprof mutex.out
go tool pprof block.out

&lt;span class=&#34;c1&#34;&gt;# http webui pprof view see flamegraph&lt;/span&gt;
go tool pprof -http&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;:8080&amp;#34;&lt;/span&gt; cpu.out

&lt;span class=&#34;c1&#34;&gt;# if use net/http/pprof; use http api fetch sample data **.pb.gz file to pprof&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# fetch cpu profiling&lt;/span&gt;
 go tool pprof http://localhost:6060/debug/pprof/profile?seconds&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;30&lt;span class=&#34;p&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;debug&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;

 go tool pprof http://localhost:6060/debug/pprof/heap
 go tool pprof http://localhost:6060/debug/pprof/block
 go tool pprof http://localhost:6060/debug/pprof/mutex
 go tool pprof http://localhost:6060/debug/pprof/goroutine?debug&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
 go tool pprof http://localhost:6060/debug/pprof/allocs?debug&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
 go tool pprof http://localhost:6060/debug/pprof/threadcreate?debug&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;cpu分析&#34;&gt;CPU分析&lt;/h4&gt;
&lt;p&gt;CPU 分析器依赖于操作系统和信号。当它被激活时，应用程序默认要求操作系统每 10 毫秒中断一次，通过一个&lt;code&gt;SIGPROF&lt;/code&gt;信号。当应用程序收到一个 时&lt;code&gt;SIGPROF&lt;/code&gt;，它会暂停当前活动并将执行转移到探查器。探查器收集诸如当前 goroutine 活动之类的数据，并汇总可以检索的执行统计信息。然后它停止，并继续执行直到下一个&lt;code&gt;SIGPROF&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;可以访问 /debug/pprof/profile 端点来激活 CPU 分析。默认情况下，访问此端点会执行 30 秒的 CPU 分析。在 30 秒内，应用程序每 10 毫秒中断一次。请注意，可以更改这两个默认值：可以使用参数&lt;code&gt;seconds&lt;/code&gt;将分析应该持续多长时间传递给端点（例如，/debug/pprof/profile?seconds=15），可以更改中断率（甚至小于 10 毫秒）。但在大多数情况下，10 毫秒应该足够了，在减小这个值（意味着增加速率）时，应该注意不要损害性能。30 秒后，下载 CPU 分析器的结果。&lt;/p&gt;
&lt;p&gt;可以为不同的函数附加标签。例如，想象一个从不同客户端调用的通用函数。要跟踪两个客户花费的时间，可以使用&lt;code&gt;pprof.Labels&lt;/code&gt;.Go 1.9 开始引入 &lt;strong&gt;&lt;a href=&#34;https://github.com/golang/proposal/blob/master/design/17280-profile-labels.md&#34;&gt;profiler labels&lt;/a&gt;，&lt;/strong&gt; 对于特殊调优性能，比如某个算法模型，或者线上特殊场景触发的性能问题，在这些特殊逻辑段，单独打上一个tag label 进行profiling的收集，通过pprof 工具分析，可以通过tag相关命令来过滤出样本数据分析。使用 &lt;strong&gt;&lt;a href=&#34;http://godoc.org/github.com/rakyll/goutil/pprofutil&#34;&gt;pprofutil&lt;/a&gt;&lt;/strong&gt; 包自动将 HTTP 路径标签添加到处理程序。&lt;/p&gt;
&lt;h4 id=&#34;heap堆分析&#34;&gt;Heap堆分析&lt;/h4&gt;
&lt;p&gt;堆分析可以获得有关当前堆使用情况的统计信息。与 CPU 分析一样，堆分析也是基于样本的。可以更改此速率，但不应该过于细化，因为降低速率越多，堆分析收集数据所需的工作就越多。默认情况下，样本在每 512 KB 堆分配的一次分配中进行分析。&lt;/p&gt;
&lt;p&gt;堆分析还可以查看不同的样本类型：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;alloc_objects&lt;/code&gt;全部的分配的对象数&lt;/li&gt;
&lt;li&gt;&lt;code&gt;alloc_space&lt;/code&gt;全部的分配的内存量&lt;/li&gt;
&lt;li&gt;&lt;code&gt;inuse_objects&lt;/code&gt;数字已分配但尚未释放的对象&lt;/li&gt;
&lt;li&gt;&lt;code&gt;inuse_space&lt;/code&gt;数量已分配但尚未释放的内存&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;堆分析的另一个非常有用的功能是跟踪内存泄漏。使用基于 GC 的语言，通常的过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;触发 GC。&lt;/li&gt;
&lt;li&gt;下载堆分析数据。&lt;/li&gt;
&lt;li&gt;等待几秒钟/分钟。&lt;/li&gt;
&lt;li&gt;触发另一个 GC。&lt;/li&gt;
&lt;li&gt;下载另一个堆分析数据。&lt;/li&gt;
&lt;li&gt;比较这两个采集的分析文件。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在下载数据之前强制执行 GC 是一种防止错误假设的方法。例如，如果在没有先运行 GC 的情况下看到保留对象的峰值，无法确定这是泄漏还是下一次 GC 将收集的对象。&lt;/p&gt;
&lt;p&gt;使用&lt;code&gt;pprof&lt;/code&gt;，可以下载堆分析文件并同时强制执行 GC。Go中的过程如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;转到 /debug/pprof/heap?gc=1（触发 GC 并下载采集的样本文件）。&lt;/li&gt;
&lt;li&gt;等待几秒钟/分钟。&lt;/li&gt;
&lt;li&gt;再次转到 /debug/pprof/heap?gc=1。&lt;/li&gt;
&lt;li&gt;用于&lt;code&gt;go tool pprof -http=:8080 -diff_base &amp;lt;file2&amp;gt; &amp;lt;file1&amp;gt;&lt;/code&gt;比较两个采集文件：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;注意&lt;/strong&gt; 与堆相关的另一种分析类型是&lt;code&gt;allocs&lt;/code&gt;，它报告分配。堆分析显示堆内存的当前状态。要了解自应用程序启动以来过去的内存分配情况，可以使用分配分析。如前所述，由于栈分配很便宜，因此它们不属于此分析的一部分，该分析仅关注堆。&lt;/p&gt;
&lt;p&gt;tips: 关于性能分析，方法论，关注的指标，可以在 &lt;a href=&#34;https://www.brendangregg.com/systems-performance-2nd-edition-book.html&#34;&gt;&lt;strong&gt;性能之巅&lt;/strong&gt;&lt;/a&gt; 这本书中找到相关介绍，本质上都是在系统层面监控，分析，定位。&lt;/p&gt;
&lt;h4 id=&#34;goroutines分析&#34;&gt;Goroutines分析&lt;/h4&gt;
&lt;p&gt;该&lt;code&gt;goroutine&lt;/code&gt;配置文件报告应用程序中所有当前 goroutine 的堆栈跟踪。可以使用 debug/pprof/goroutine/?debug=0 下载一个文件并go tool pprof再次采集分析， 可以分析是否golang在持续上涨，进而判断是否泄露。可以查看 goroutine 分析器数据以了解系统的哪一部分是可疑的。&lt;/p&gt;
&lt;h4 id=&#34;block分析&#34;&gt;Block分析&lt;/h4&gt;
&lt;p&gt;block 分析正在进行的 goroutines 阻塞等待同步原语的位置，包括&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在无缓冲通道上发送或接收&lt;/li&gt;
&lt;li&gt;发送到一个完整的频道&lt;/li&gt;
&lt;li&gt;从空频道接收&lt;/li&gt;
&lt;li&gt;互斥锁争用&lt;/li&gt;
&lt;li&gt;网络或文件系统等待&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Block分析还记录了 goroutine 等待的时间，可以通过 debug/pprof/block 访问。如果怀疑性能因阻止调用而受到损害，此采样分析文件可能会非常有用。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;block&lt;/code&gt;默认情况下不启用采样分析文件：必须调用才能&lt;code&gt;runtime.SetBlockProfileRate&lt;/code&gt;启用它。此函数控制报告的 goroutine 阻塞事件的比例。一旦启用，分析器将继续在后台收集数据，即使不调用 debug/pprof/block 。如果想设置一个高速率，那么要小心，以免损害性能。&lt;/p&gt;
&lt;h4 id=&#34;完整的-goroutine-栈dump&#34;&gt;完整的 goroutine 栈dump&lt;/h4&gt;
&lt;p&gt;如果遇到死锁或怀疑 goroutines 处于阻塞状态，则完整的 goroutine 栈dump (debug/pprof/goroutine/?debug=2) 会创建所有当前 goroutine 堆栈跟踪的dump数据。这有助于作为分析首次步骤&lt;/p&gt;
&lt;h4 id=&#34;mutex分析&#34;&gt;Mutex分析&lt;/h4&gt;
&lt;p&gt;如果怀疑应用程序花费大量时间等待锁定互斥量，从而损害执行，可以使用mutex分析。&lt;/p&gt;
&lt;p&gt;在生产环境建议启用&lt;code&gt;pprof&lt;/code&gt;，在发现性能问题，延时，负载，内存空间上涨等问题，可以采集对应现场信息进行分析，对于cpu的采集会导致性能下降，但仅在启用它们期间才会发生。&lt;/p&gt;
&lt;p&gt;tips: 通过 &lt;strong&gt;&lt;a href=&#34;https://go.dev/blog/pprof&#34;&gt;https://go.dev/blog/pprof&lt;/a&gt;&lt;/strong&gt; 学习pprof 入门很合适，demo: &lt;a href=&#34;https://github.com/rsc/benchgraffiti&#34;&gt;https://github.com/rsc/benchgraffiti&lt;/a&gt;&lt;/p&gt;
&lt;h4 id=&#34;执行跟踪器-execution-tracer&#34;&gt;执行跟踪器 Execution Tracer&lt;/h4&gt;
&lt;p&gt;trace和pprof一样，也有三种方式：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用运行时trace包 接口API来采样数据&lt;/strong&gt;：https://pkg.go.dev/runtime/trace 接口api来收集开始到结束区间的trace信息，和 runtime/pprof 包一样将采集的trace信息写入文件，或者二次开发写入网络io, push到三方平台去分析，常用语微服务的可视化分析监控。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;使用网络net/http pprof包 http接口来采样数据&lt;/strong&gt;： &lt;a href=&#34;http://pkg.go.dev/net/http/pprof&#34;&gt;https: //pkg.go.dev/net/http/pprof&lt;/a&gt;； 和pprof http接口一样，采集trace的下载接口，如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;http://localhost:6060/debug/pprof/trace?seconds&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;使用基准压测来采样数据：&lt;/strong&gt; &lt;a href=&#34;https://pkg.go.dev/cmd/go#hdr-Testing_flags&#34;&gt;https://pkg.go.dev/cmd/go#hdr-Testing_flags&lt;/a&gt;  使用 -trace trace.out&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# sampling&lt;/span&gt;
go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; -v -bench&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;Benchmark_parallelMergesortV1$ -count&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; -benchtime&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;1s ./08-concurrency-foundations/56-faster/ -trace&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;trace.out
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;将采集到的trace数据通过 go tool trace 对采集数据文件 trace.out 进行可视化分析。在可视化页面就可以看到对应分析的信息，有对应说明，其分析的信息如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;运行 goroutines 的事件时间表：查看整体时间段的trace信息，线程数，协程数，堆，GC时间等等； goroutine 分析，查看每个goroutine的执行时间，包括网络等待，同步block, 系统调用，调度等待，GC清扫，GC暂停(SWT)&lt;/li&gt;
&lt;li&gt;查看调用链路即每个函数耗时delay，包括net 网络io, block 阻塞io, syscall 系统调用，sched 协程调度情况，这些profile 可以导出，进行单独分析&lt;/li&gt;
&lt;li&gt;使用&lt;a href=&#34;https://pkg.go.dev/runtime/trace&#34;&gt;https://pkg.go.dev/runtime/trace&lt;/a&gt; 包开发，具体在模块区域Region，摸个任务task下的监控信息，开放出来，根据用户场景自定以开发。显示的每个直方图桶都包含一个样本跟踪记录事件序列，例如 goroutine 创建、日志事件和子区域开始/结束时间。&lt;/li&gt;
&lt;li&gt;垃圾收集指标, Minimum mutator utilization。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;而且可以通过&lt;code&gt;go tool trace -pprof=TYPE trace.out &amp;gt; TYPE.pprof&lt;/code&gt; 将不同采集类型的数据从trace数据中导出，进而可以通过go tool pprof进行单独分析，导出数据类型如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# net: network blocking profile&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# sync: synchronization blocking profile&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# syscall: syscall blocking profile&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;# sched: scheduler latency profile&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;profiling和tracer结合使用： 比如 使用profiling分析工具来分析内存或 CPU 使用率过高的原因；然后通过tracer 工具来分析每个goroutine的调度情况，以及时间段的执行情况，是否发生GC, 是否有系统调用等等。trace粒度更细，但是分析更耗时。&lt;/p&gt;
&lt;p&gt;tips:  具体进一步实践，可以一起学习，掌握原理，熟练工具：&lt;/p&gt;
&lt;p&gt;Felix Geisendörfer  &lt;strong&gt;&lt;a href=&#34;https://github.com/DataDog/go-profiler-notes/blob/main/guide/README.md&#34;&gt;The Busy Developer’s Guide to Go Profiling, Tracing and Observability&lt;/a&gt;&lt;/strong&gt; 中的profiling, tracing, ob相关实验notes；&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://swtch.com/~rsc/&#34;&gt;Russ Cox&lt;/a&gt; 关于 &lt;a href=&#34;https://research.swtch.com/telemetry&#34;&gt;&lt;strong&gt;telemetry&lt;/strong&gt;&lt;/a&gt; 引入 go toolchain(工具链)相关的设计思考; 讨论非常活跃，与时俱进呀~ 很期待这个功能。可以打通golang开发的应用程序 和 OTEL 相关监控系统的数据格式交互，进行同一标准管理。&lt;/p&gt;
&lt;h3 id=&#34;99不了解-gc-的工作原理&#34;&gt;99.不了解 GC 的工作原理&lt;/h3&gt;
&lt;p&gt;垃圾收集器（GC）是Go 语言的重要组成部分，跟踪和释放不再需要的堆分配。了解 GC 的工作原理有助于优化应用程序。&lt;/p&gt;
&lt;h4 id=&#34;概念简介&#34;&gt;概念简介&lt;/h4&gt;
&lt;p&gt;跟踪垃圾回收，其通过循着指针来标识正在使用的、所谓的活动对象，通过活动对象构建的对象图，&lt;/p&gt;
&lt;p&gt;GC是基于标记清除算法，主要是mark-sweep 2个阶段，将mark操作进行进一分解，其过程如下：&lt;/p&gt;
&lt;p&gt;Mark setup (func Stack scan) → Make (concurrent make and assist make, make  termination) → concurrent Sweep ； 其中 开始Mark setup的时候会有非常短暂的STW(平均每 10 到 30 微秒),  标记终止(make  termination) 也会有STW, 进行收尾工作时间稍长，可以简单认为，STW发生在mark的开始和结束(开始时找到扫描开始的初始位置，开启写屏障；结束时关闭写屏障，进行收尾)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Mark 标记阶段：遍历堆的所有对象，采用 &lt;a href=&#34;https://github.com/rubinius/rubinius-website-archive/blob/cf54187d421275eec7d2db0abd5d4c059755b577/_posts/2013-06-22-concurrent-garbage-collection.markdown&#34;&gt;&lt;strong&gt;三色标记算法&lt;/strong&gt;&lt;/a&gt; (Go 1.5引入)，标记是否还在使用。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;mark setup:  即mark开始前的准备工作，找到goroutine中函数栈帧中的扫描位置， 打开写屏障(write barrier，前面已经介绍过)，允许在垃圾回收期间在堆上保持数据完整性，因为回收器和应用程序的 goroutine 将同时运行。要打开写保护，必须停止运行的每个应用程序 goroutine，产生STW,通常非常快，平均每 10 到 30 微秒；但是有特殊情况，紧密循环比如一个死循环或者循环时间长，没有调用函数触发，进而可能导致垃圾回收无法开始；&lt;/li&gt;
&lt;li&gt;concurrent mark: 在开启写保护器后，开始并发标记阶段。首先，回收器为其自身保留了 25% 可用 CPU 容量 。使用 Goroutine 执行回收工作，并需要应用程序 Goroutine 使用的相同的 P 和 M。开始标记堆内存中仍在使用的值。该工作首先通过检查所有现有 Goroutine 的栈帧以找到指向堆内存的根指针。然后从这些根指针遍历对象图 进行标记。&lt;/li&gt;
&lt;li&gt;assist mark: 如果收集器确定它需要减缓分配，它将会招募应用程序的 Goroutine 协助 Marking 工作，这称为 Mark Assist。任何应用程序 Goroutine 在 Mark Assist 中的时间量与它对堆内存的数据添加量成比例，可以更快地完成收集；如果任意一次收集最终需要大量的 Mark Assist，收集器可以更早开始下一次垃圾收集，以减少下一次收集所需的 Mark Assist 数量(需要辅助mark的任务多，需要提早开始)。&lt;/li&gt;
&lt;li&gt;make  termination： 一旦标记工作完成，开始标记终止。这个阶段将关闭写屏障，执行各种清理任务以及计算下一个回收目标的时刻。在标记阶段处于紧密循环的协程也可能导致标记终止 STW 延迟延长。回收完成后，应用程序协程可以再次使用每个P，应用程序Goroutine可以充分使用cup资源。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Sweep 清除阶段&lt;/strong&gt;：从根开始遍历对象图并释放不再被引用的对象块，清除操作是并发的；释放的过程是异步的，不是真正的清除；当应用程序goroutine尝试在堆内存中分配新内存时，会触发该操作，清理导致的延迟和吞吐量降低被分散到每次内存分配时。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ps: 整体思想可以借鉴&lt;/p&gt;
&lt;p&gt;整体GC算法如下：from：&lt;a href=&#34;https://go.dev/talks/2015/go-gc.pdf&#34;&gt;https://go.dev/talks/2015/go-gc.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/2015-go-gc.png?raw=true&#34; alt=&#34;https://raw.githubusercontent.com/weedge/mypic/master/2015-go-gc.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;Go GC 还包括一种在消耗高峰后释放内存的方法。假设应用程序基于两个阶段：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;导致频繁分配大的堆空间的初始化阶段&lt;/li&gt;
&lt;li&gt;具有适度分配小的堆空间的运行时阶段&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Go 将如何解决大的heap空间回收后，还会继续使用呢？这是作为 GC 中的周期清理 &lt;em&gt;periodic scavenger&lt;/em&gt;  所考虑的问题(具体可以看&lt;a href=&#34;https://cs.opensource.google/go/go/+/refs/tags/go1.20:src/runtime/mgcscavenge.go&#34;&gt;go1.20:src/runtime/mgcscavenge.go&lt;/a&gt; 代码了解)。一段时间后，GC 检测到不再需要这么大的堆空间，因此它会释放一些内存并将其返回给 OS。&lt;/p&gt;
&lt;p&gt;tips:&lt;/p&gt;
&lt;p&gt;如果GC &lt;em&gt;periodic scavenger&lt;/em&gt; 不够快呢，可以使用手动强制将内存返回给操作系统&lt;code&gt;debug.FreeOSMemory()&lt;/code&gt;；但是这样有些问题，需要慎重使用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一次将内存都归还给系统，这个操作太重了。会有延迟抖动，因为涉及到 lock&lt;/li&gt;
&lt;li&gt;需要用户自己调这个函数，对代码是有侵入性&lt;/li&gt;
&lt;li&gt;再次重用内存的时候会有较多开销，因为有 page fault&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过pprof/heap采集到的数据，在监控查看 RSS(进程/线程使用的物理内存) 的值 比 正常计算的Go应用进程使用的内存空间要大，主要原因是 Go GC之后内存空间没有马上返回给OS, 而是等到GC &lt;em&gt;periodic scavenger&lt;/em&gt; 触发之后才会释放内存空间到OS中, GC之后未归还的内存空间大小为：HeapIdle(空闲内存大小) - HeapReleased(已释放归还给OS内存大小)；&lt;/p&gt;
&lt;p&gt;重要的问题是，GC 何时运行？Go 中提供两种方式设置 GOGC 环境变量 or debug.SetGCPercent 以及  debug.SetMaxHeap :&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;GOGC (debug.SetGCPercent )&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;与 Java 等其他语言相比，Go 配置仍然相当简单。它依赖于单一环境变量：&lt;code&gt;GOGC&lt;/code&gt;. 该变量定义了自上次 GC 后触发另一次 GC 之前堆增长的百分比；默认值为 100%。&lt;/p&gt;
&lt;p&gt;看一个具体的例子，假设 GC 刚刚被触发，当前堆大小为 128 MB。默认&lt;code&gt;GOGC=100&lt;/code&gt;，则在堆大小达到 256 MB 时触发下一次 GC。每当堆大小翻倍时，默认情况下都会执行一次 GC。此外，如果在过去 2 分钟内未执行 GC，Go 将强制执行一次。&lt;/p&gt;
&lt;p&gt;在生产环境中使用&lt;code&gt;GOGC&lt;/code&gt;使用时需要注意，分析进行微调(取决于具体场景，机器性能)：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;减少阈值，会减低 堆空间 增长，但是增加了 GC 的压力。&lt;/li&gt;
&lt;li&gt;增加阈值，会增加 堆空间 增长，但是减少了 GC 的压力。(适用于free 内存空间大的场景，因为清扫是异步触发的~)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;tips: 通过设置&lt;code&gt;GOGC=off&lt;/code&gt;或者&lt;code&gt;debug.SetGCPercent(-1)&lt;/code&gt;关闭&lt;code&gt;GC&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;debug.SetMaxHeap&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;对内存不足（OOM）的情况非常敏感的场景，直接自定一个使用堆大小的上限，可以结合&lt;code&gt;debug.SetGCPercent(-1)&lt;/code&gt;手动关闭&lt;code&gt;GC&lt;/code&gt; 使用，到达最大限制，则触发GC,  对于内存使用比较有规律的场景适合使用，如果频繁很快到达最大限制，则会频繁GC，得不偿失了。&lt;/p&gt;
&lt;h4 id=&#34;gc-跟踪&#34;&gt;GC 跟踪&lt;/h4&gt;
&lt;p&gt;可以通过设置打印 GC 跟踪&lt;code&gt;GODEBUG&lt;/code&gt;环境变量，例如在运行基准测试时：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;nv&#34;&gt;GODEBUG&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nv&#34;&gt;gctrace&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;m&#34;&gt;1&lt;/span&gt; go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; -bench&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;. -v
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;tips: 命令中的环境变量GODEBUG值 参考官方文档：&lt;a href=&#34;https://pkg.go.dev/runtime#hdr-Environment_Variables&#34;&gt;Environment_Variables&lt;/a&gt; 设置，以及查看输出格式具体内容说明。每次 GC 运行时启用一个跟踪&lt;code&gt;gctrace&lt;/code&gt;都会写入&lt;code&gt;stderr&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;必须了解 GC 的行为方式才能对其进行优化。可以使用&lt;code&gt;GOGC&lt;/code&gt;来配置下一个 GC 周期何时被触发。在大多数情况下，保持它就&lt;code&gt;100&lt;/code&gt;足够了。但是，如果应用程序可能面临导致频繁 GC 和延迟影响的请求峰值，可以增加该值。最后，在异常请求高峰的情况下，可以考虑使用将虚拟堆大小保持在最小值的技巧。&lt;/p&gt;
&lt;p&gt;tips: 上面只是简单概括的介绍了下，随着时间推移可能不准确，Go中GC是一个复杂的过程，具体细节，可以通过如下文档一起实践学习：&lt;/p&gt;
&lt;p&gt;了解GC细节入门:  &lt;strong&gt;&lt;a href=&#34;https://tip.golang.org/doc/gc-guide?continueFlag=bf311ba190bf0d160b5d3461e092f0f4&#34;&gt;A Guide to the Go Garbage Collector&lt;/a&gt;&lt;/strong&gt;  &lt;strong&gt;&lt;a href=&#34;https://go.dev/blog/ismmkeynote&#34;&gt;Getting to Go: The Journey of Go&amp;rsquo;s Garbage Collector&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;了解通过GC Trace定位问题: &lt;a href=&#34;https://www.ardanlabs.com/blog/2018/12/garbage-collection-in-go-part1-semantics.html&#34;&gt;&lt;strong&gt;Garbage Collection In Go : Part I - Semantics&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;100不了解在-docker-和-kubernetes-中运行-go-的影响&#34;&gt;100.不了解在 Docker 和 Kubernetes 中运行 Go 的影响&lt;/h3&gt;
&lt;p&gt;根据 2021 年 Go 开发人员调查 ( &lt;a href=&#34;https://go.dev/blog/survey2021-results&#34;&gt;https://go.dev/blog/survey2021-results&lt;/a&gt; )，使用 Go 编写服务是最常见的用途。同时，Kubernetes 是部署这些服务的最广泛使用的平台。了解在 Docker 和 Kubernetes 中运行 Go 的含义非常重要，以防止出现 CPU 节流等常见情况。&lt;/p&gt;
&lt;p&gt;GOMAXPROCS变量定义了负责同时执行用户级代码的操作系统线程的限制。默认情况下，它设置为 OS-apparent 逻辑 CPU 核心数。这在 Docker 和 Kubernetes 的上下文中意味着什么？&lt;/p&gt;
&lt;p&gt;假设 Kubernetes 集群由八个核心节点组成。当一个容器部署在 Kubernetes 中时，可以定义一个 CPU 限制，以确保一个应用程序不会耗尽宿主机的所有资源。例如，以下配置将 CPU 的使用限制为 4,000 millicpu（或 millicores），因此四个 CPU 内核&lt;/p&gt;
&lt;p&gt;可以假设在部署应用程序时，GOMAXPROCS将基于这些限制，因此值为4. 但事实并非如此；它被设置为主机上的逻辑核心数：8。那么，有什么影响呢？&lt;/p&gt;
&lt;p&gt;Kubernetes 使用完全公平调度器 (CFS) 作为进程调度程序。CFS 还用于对 Pod 资源实施 CPU 限制。在管理 Kubernetes 集群时，管理员可以配置这两个参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;cpu.cfs_period_us（全局设置）&lt;/li&gt;
&lt;li&gt;cpu.cfs_quota_us（每个 Pod设置）&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;前者定义了一个时期，后者定义了一个配额。默认情况下，周期设置为 100 毫秒。同时，默认配额值是应用程序在 100 毫秒内可以消耗多少 CPU 时间。限制设置为四个核心，这意味着 400 ms (4 × 100 ms)。因此，CFS 将确保应用程序不会在 100 毫秒内消耗超过 400 毫秒的 CPU 时间。&lt;/p&gt;
&lt;p&gt;想象一个场景，多个 goroutine 当前正在四个不同的线程上执行。每个线程被安排在不同的核心（1、3、4 和 8）上；&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F49_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F49_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;在第一个 100 ms 期间，有四个线程处于忙碌状态，因此消耗了 400 ms 中的 400：100% 的配额。在第二个时期，消耗了 400 毫秒中的 360 毫秒，依此类推。一切都很好，因为应用程序消耗的资源少于配额。&lt;/p&gt;
&lt;p&gt;但是，记住GOMAXPROCS设置为8。因此，在最坏的情况下，可以有八个线程，每个线程都安排在不同的核心上。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F50_Harsanyi.png&#34; alt=&#34;https://learning.oreilly.com/api/v2/epubs/urn:orm:book:9781617299599/files/Images/CH12_F50_Harsanyi.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;对于每 100 毫秒，配额设置为 400 毫秒。如果八个线程忙于执行 goroutine，50 毫秒后，达到 400 毫秒的配额（8 × 50 毫秒 = 400 毫秒）。会有什么后果？CFS 将限制 CPU 资源。因此，在另一个周期开始之前不会分配更多的 CPU 资源。换句话说，应用程序将暂停 50 毫秒。&lt;/p&gt;
&lt;p&gt;例如，平均延迟为 50 毫秒的服务最多可能需要 150 毫秒才能完成。这可能是延迟的 300% 惩罚。&lt;/p&gt;
&lt;p&gt;首先，请关注 Go &lt;a href=&#34;https://github.com/golang/go/issues/33803&#34;&gt;issue 33803&lt;/a&gt;。也许在 Go 的未来版本中，GOMAXPROCS将支持 CFS。&lt;/p&gt;
&lt;p&gt;今天的解决方案是依赖于由优步调用automaxprocs（&lt;a href=&#34;http://github.com/uber-go/automaxprocs&#34;&gt;github.com/uber-go/automaxprocs&lt;/a&gt;）。可以通过&lt;a href=&#34;http://xn--go-hf3c1a925dgwxre7e7sa.uber.org/automaxprocs%E5%9C%A8&#34;&gt;go.uber.org/automaxprocs&lt;/a&gt; 在main.go 中添加一个空白导入来使用这个库；它会自动设置GOMAXPROCS以匹配 Linux 容器 CPU 配额。在前面的示例中，GOMAXPROCS将设置为4而不是8，因此将无法达到 CPU 被节流的状态。&lt;/p&gt;
&lt;p&gt;目前Go 不支持 CFS。GOMAXPROCS基于主机而不是定义的 CPU 限制。因此，可能会达到 CPU 被节流的状态，从而导致长时间的暂停和显着的延迟增加等实质性影响。在 Go 变得支持 CFS 之前，一种解决方案是依靠automaxprocs自动设置GOMAXPROCS为定义的配额。&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;了解如何使用 CPU 缓存对于优化受 CPU 限制的应用程序很重要，因为 L1 缓存比主内存快大约 50 到 100 倍。&lt;/li&gt;
&lt;li&gt;了解高速缓存行概念对于理解如何在数据密集型应用程序中组织数据至关重要。CPU 不会逐字获取内存；相反，它通常将内存块复制到 64 字节的缓存行。要充分利用每个单独的缓存行，利用好空间局部性。&lt;/li&gt;
&lt;li&gt;让 CPU 可以预测代码也是优化某些功能的有效方法。例如，单位或恒定步幅对于 CPU 是可预测的，但非单位步幅（例如，链表）是不可预测的。&lt;/li&gt;
&lt;li&gt;为避免关键步幅，从而只使用缓存的一小部分，请注意缓存是分区的。&lt;/li&gt;
&lt;li&gt;了解false sharing对并发程序的影响，伪共享因为cache line的同步会带来一些cpu 时钟周期的性能损失。&lt;/li&gt;
&lt;li&gt;使用指令级并行 (ILP) 来优化代码的特定部分，以允许 CPU 执行尽可能多的并行指令。识别数据危害是主要步骤之一。&lt;/li&gt;
&lt;li&gt;可以通过记住在 Go 中基本类型与它们自己的大小对齐来避免常见错误。例如，请记住，按大小降序重组结构的字段可以导致更紧凑的结构（更少的内存分配和可能更好的空间局部性）。&lt;/li&gt;
&lt;li&gt;在优化 Go 应用程序时，理解堆和栈之间的根本区别也应该是你的核心知识的一部分。栈分配几乎是免费的，而堆分配速度较慢并且依赖于 GC 来清理内存。&lt;/li&gt;
&lt;li&gt;减少分配也是优化 Go 应用程序的一个重要方面。这可以通过不同的方式完成，例如仔细设计 API 以防止共享，了解常见的 Go 编译器优化，以及使用sync.Pool.&lt;/li&gt;
&lt;li&gt;使用快速路径内联技术有效地减少调用函数的摊销时间。&lt;/li&gt;
&lt;li&gt;依靠分析和执行跟踪器来了解应用程序的执行方式和要优化的部分。&lt;/li&gt;
&lt;li&gt;了解如何调整 GC 可以带来多种好处，例如更有效地处理突然增加的负载。&lt;/li&gt;
&lt;li&gt;为帮助避免在 Docker 和 Kubernetes 中部署时出现 CPU 节流，请记住 Go 不支持 CFS。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;总共花了10天左右把 100-go-mistakes-and-how-to-avoid-them 这本书看完，对于一些文中不够升入的地方，进行挖掘了下，了解弄清楚了背后的原理，知其然知其所以然之后，有些mistake是一些共性的问题，而且对于文中每个mistake，都应去实践操作一下，熟悉利用好Go相关工具，编译，测试，构建等等，文中大部分是语言层面的，工程方面也有些，特别像最后介绍的在K8S docker中CPU对Go语言本身的影响，实际遇到之后才会印象更深，应该从错误中去总结，而不是总结之后继续犯错，如此折返，意义不大；从错误点中多挖掘底层逻辑多思考总结。&lt;/p&gt;
&lt;p&gt;原书地址： &lt;a href=&#34;https://learning.oreilly.com/library/view/100-go-mistakes/9781617299599/&#34;&gt;https://learning.oreilly.com/library/view/100-go-mistakes/9781617299599/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;TIPS： 文中对于channel 介绍的比较少，比如channel 在生产(发送)和消费(接受)之间，1:1,1:N,M:1,M:N场景下如何关闭; 还有GPM的调度模型的详细介绍，以及内存分配器(这块在每个版本中相对迭代比较多，最好结合当前开发生产环境中使用的Go版本对其源码分析) 没有详细涉及到，可参考这些资料扩展： &lt;a href=&#34;https://go101.org/article/channel-closing.html&#34;&gt;channel-closing&lt;/a&gt; , &lt;a href=&#34;https://www.google.com.hk/search?q=kavya%20golang#fpstate=ive&amp;amp;vld=cid:089b5108,vid:KBZlN0izeiY&#34;&gt;Understanding Channels&lt;/a&gt; , &lt;a href=&#34;https://medium.com/@ankur_anand/a-visual-guide-to-golang-memory-allocator-from-ground-up-e132258453ed&#34;&gt;Go Memory Allocator&lt;/a&gt; ，&lt;a href=&#34;https://www.ardanlabs.com/blog/2018/08/scheduling-in-go-part2.html&#34;&gt;scheduling-in-go&lt;/a&gt; , &lt;a href=&#34;https://github.com/golang/go/wiki/LearnConcurrency&#34;&gt;&lt;strong&gt;&lt;!-- raw HTML omitted --&gt;LearnConcurrency&lt;!-- raw HTML omitted --&gt;&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: 测试 82-90 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-11-testing/</link>
      <pubDate>Mon, 20 Feb 2023 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-11-testing/</guid>
      
        <description>&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;测试是项目生命周期的一个重要方面。它提供了无数的好处，例如建立对应用程序的信心、充当代码文档以及使重构更容易。与其他一些语言相比，Go 具有强大的编写测试原语。主要讨论测试过程变得脆弱、效率低下和准确性低的常见错误。这类问题属于工程规范实践，有些case同样适用于其他语言。&lt;/p&gt;
&lt;p&gt;Go 中提供 go test 工具来执行测试，可以查看具体的开发文档： &lt;strong&gt;&lt;a href=&#34;https://pkg.go.dev/cmd/go#hdr-Testing_flags&#34;&gt;https://pkg.go.dev/cmd/go#hdr-Testing_flags&lt;/a&gt;&lt;/strong&gt;  里面介绍了每个模式的具体使用方式，使用好这些测试模式flag，可以更快执行或更好地发现可能错误，进而保证代码质量，工程代码稳定性建设上的重要一环。Go中支持4种测试函数：单测函数，基准压测函数，模糊测试，以及打印输出样例测试。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;TestXxx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;BenchmarkXxx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;B&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;FuzzXxx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;f&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;F&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;...&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;ExampleXxx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;The output of\\nthis example.&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;// Output: The output of
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// this example.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;h3 id=&#34;82不对测试进行分类&#34;&gt;82.不对测试进行分类&lt;/h3&gt;
&lt;p&gt;功能测试大致分为单元测试，集成测试，以及端到端的测试，单元测试则是程序测试case覆盖率的保障，列举Go中3种常见的测试分类方法&lt;/p&gt;
&lt;h4 id=&#34;build-tags&#34;&gt;Build tags&lt;/h4&gt;
&lt;p&gt;build tags 的一些使用场景：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;测试环境使用 mock 服务；而正式环境使用真实数据&lt;/li&gt;
&lt;li&gt;免费版、专业版和企业版提供不同的功能&lt;/li&gt;
&lt;li&gt;不同操作系统的兼容性处理。通常用于跨平台，例如 windows，linux，mac 不同兼容处理逻辑。&lt;/li&gt;
&lt;li&gt;go 低版本的兼容处理&lt;/li&gt;
&lt;li&gt;对测试用例进行分类测试&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;通过在测试文件中加上对应的测试分类标签，在测试的时候方便对一类tag进行测试，而不需要跑全部测试用例, 比如打上 mock 标签进行用于 mock 一类测试&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;//go:build !&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;mock1 &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mock2&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt; mock3 &lt;span class=&#34;o&#34;&gt;||&lt;/span&gt; !&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;mock4 &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; mock5&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
// +build !mock1 !mock2 mock3 !mock4 !mock5
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;tips: 这个是为了举个例子，具体测试tag需要因场景逻辑打上，确保测试文件tag无歧义。&lt;/p&gt;
&lt;p&gt;从 Go 1.17 开始，语法&lt;code&gt;//+build foo&lt;/code&gt;被替换为&lt;code&gt;//go:build foo&lt;/code&gt;. 目前&lt;code&gt;gofmt&lt;/code&gt;同步两种形式以帮助迁移。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 默认仅运行包中tag为空的测试case&lt;/span&gt;
go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; -v .
&lt;span class=&#34;c1&#34;&gt;# 仅运行包中 mock3 的测试case&lt;/span&gt;
go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; --tags&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;mock3 -v .
&lt;span class=&#34;c1&#34;&gt;# 仅运行包中 mock1 &amp;amp;&amp;amp; mock2 的测试case&lt;/span&gt;
go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; --tags&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;mock1,mock2 -v .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;环境变量&#34;&gt;环境变量&lt;/h4&gt;
&lt;p&gt;使用build tag方式构建测试用，随着tag的增加，可能会隐藏掉其中的错误，而且需要去查看测试文件中的tag有哪些。环境变量这种方式是build tags 的补充吧，对于没有设置环境变量的情况下，明确显示哪些测试是跳过的测试，比如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; os.Getenv&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;INTEGRATION&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt; !&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;s2&#34;&gt;&amp;#34;true&amp;#34;&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;{&lt;/span&gt;
		t.Skip&lt;span class=&#34;o&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s2&#34;&gt;&amp;#34;skipping integration test&amp;#34;&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;o&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;tips: tag是测试文件粒度分类(Go 构建工具支持)，环境变量是测试代码粒度分类(手动代码逻辑)&lt;/p&gt;
&lt;h4 id=&#34;short-模式&#34;&gt;Short 模式&lt;/h4&gt;
&lt;p&gt;另一种对测试进行分类的方法与它们的速度有关。可能不得不将短期运行的测试与长期运行的测试区分开来。&lt;/p&gt;
&lt;p&gt;作为说明，假设有一组单元测试，其中一个是出了名的慢。想对慢速测试进行分类，这样就不必每次都运行它（尤其是在保存文件后触发），使用testing.Short区分如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;TestLongRunning&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Short&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Skip&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;skipping long-running test&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;// ...
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;运行测试是，通过-short 参数来执行跳过&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; -v -short .
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这三种方式可以组合使用，例如，项目包含长时间运行的单元测试，则使用构建标记或环境变量对测试进行分类（例如，作为单元测试，mock测试，或者集成测试）和使用短模式来跳过长时间运行的测试。&lt;/p&gt;
&lt;h3 id=&#34;83不启用--race&#34;&gt;83.不启用 -race&lt;/h3&gt;
&lt;p&gt;对于并发程序代码的测试，需要检测是否存在data race， 需要使用 -race 模式来构建测试，比如&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;race&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/...&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这种方法使启用竞争检测器，它可以检测代码以捕获潜在的数据竞争(没有打上!race标记的文件)。启用时，它对内存和性能有显着影响，因此必须在特定条件下使用，例如本地测试或 CI。在生产中，应该避免它（或者只在金丝雀发布的情况下使用)。&lt;/p&gt;
&lt;p&gt;竞争检测器无法捕捉到误报（明显的数据竞争并不是真实的）。因此，如果收到警告，就知道代码包含数据竞争。相反，它有时会导致漏报（缺少实际的数据竞争）。对于漏报的情况，可以尽可能多的迭代来检测。&lt;/p&gt;
&lt;h3 id=&#34;84不使用测试执行模式&#34;&gt;84.不使用测试执行模式&lt;/h3&gt;
&lt;h4 id=&#34;-parallel&#34;&gt;-parallel&lt;/h4&gt;
&lt;p&gt;默认情况下 go test 在不同的 package 之间是并行执行测试，在每个 package 内部是串行执行测试。如果想要在 package 内部开启并行测试，需要在测试函数中显式执行 t.Parallel() 告诉 go test 这个函数可以与其他测试并行执行，一旦开启并行测试，一定要确保测试函数之间的资源竞争的问题已经得到正确的解决。执行 go test -parallel n 来制定n个测试函数并行执行(需要再显示调用了t.Parrallel)。对于执行慢的测试函数，相互之间没有资源竞争，可以加入t.Parrallel 来同时执行，提高测试的执行速度。&lt;/p&gt;
&lt;h4 id=&#34;-shuffle&#34;&gt;-shuffle&lt;/h4&gt;
&lt;p&gt;从 Go 1.17 开始引入，可以随机化测试和基准测试的执行顺序， 设置为&lt;code&gt;on&lt;/code&gt;或&lt;code&gt;off&lt;/code&gt;启用或禁用随机测试；编写测试时的最佳做法是将它们隔离开来。例如，它们不应依赖于执行顺序或共享变量。这些隐藏的依赖关系可能意味着一个可能的测试错误，或者更糟的是，一个在测试期间不会被捕获的错误。&lt;/p&gt;
&lt;p&gt;应该对现有的测试标志保持谨慎，并随时了解最新 Go 版本的新功能。运行parallel测试或者将测试分再不同的包中，可以减少运行所有测试的总体执行时间。shuffle测试可以帮助发现隐藏的依赖关系，这些依赖关系可能意味着在以相同顺序运行测试时出现测试错误，甚至不可见的错误。&lt;/p&gt;
&lt;h3 id=&#34;85不使用表驱动测试&#34;&gt;85.不使用表驱动测试&lt;/h3&gt;
&lt;p&gt;这个在vscode, goland IDE中已经集成了，对应函数生成对应单测函数时，会自动给出表驱动测试模版，编写测试用例，用于覆盖函数分支场景；如果不是用表驱动测试的话， 会出现大量的冗余函数，而且表达含义也会相对模糊，直接放入一个测试函数中来编写用例测试即可，也便于对整个函数的测试覆盖。通过t.Run来执行这些测试用例，进行期望值比较，同时也可以使用t.Parallel() 通过parallel 模式来加速测试，以及通过shuffle来随机测试。&lt;/p&gt;
&lt;h3 id=&#34;86在单元测试中使用timesleep&#34;&gt;86.在单元测试中使用time.Sleep&lt;/h3&gt;
&lt;p&gt;在测试并发编程时，可能存在竞争条件race condition 的场景，导致程序的执行顺序不同，进入影响测试的准确性，如果使用time.Sleep 之后来断言值， 可能会有不同的结果，是不确定性的，所以，尽量使用管道同步的方式来进行断言测试；如果同步不可能做到的话， 可以重试进行断言，比如常用的testify 测试包，使用Eventually函数实现了最终应该成功的断言，这比使用被动睡眠更好的选择来消除测试中的非确定性。&lt;/p&gt;
&lt;h3 id=&#34;87没有有效地处理时间-api&#34;&gt;87.没有有效地处理时间 API&lt;/h3&gt;
&lt;p&gt;对于函数中有time.Now()获取当前时间，而测试是也依赖当前时间的处理，导致那个时间点可能会存在差异，一种方式是提供全局共享变量，如果使用并行测试的，全部共享变量会引入数据竞争，导致无法并行测试，所以最好的方式，修改下所要测试的函数，去掉time.Now()的依赖，使用time.Time类型作为传入参数，有函数使用方一起来定义，这样可方便测试。&lt;/p&gt;
&lt;h3 id=&#34;88不使用测试实用程序包&#34;&gt;88.不使用测试实用程序包&lt;/h3&gt;
&lt;p&gt;httptest 和 iotest 是两个常用的包，应该利用起来，构造于http 和 io 相关函数的测试。&lt;/p&gt;
&lt;h4 id=&#34;httptest&#34;&gt;httptest&lt;/h4&gt;
&lt;p&gt;httptest 包不需要通过建立网络连接就可以进行测试，主要用来测试服务端的http api handler 函数 以及 客户端的http caller函数。具体查看开发文档：https://pkg.go.dev/net/http/httptest&lt;/p&gt;
&lt;p&gt;对于测试服务中api Handler的场景，只需要通过httptest.NewRequest 来构建api的请求数据的Reader，以及使用httptest.NewRecorder 来创建一个往请求api中写入响应数据的Writer, 这样在写测试用例时候， 直接模拟接口请求数据，编写相关的测试case,  测试的api handler 返回的数据 可以从Writer中获取到，进而可以做接口响应数据的断言假设，比如 返回状态码，响应body数据， 响应头中的数据。&lt;/p&gt;
&lt;p&gt;对于测试客户端中相关的http client caller函数， 通过httptest.NewServer建立对应api handler服务, 客户端相关的http client &lt;a href=&#34;http://xn--callerhttp-uh4py1d60ohkhow7ewtwc.Client.Do&#34;&gt;caller函数可以使用http.Client.Do&lt;/a&gt; 对server.URL进行调用了，进而可以对返回的值进行断言测试。还可以使用httptest.NewTLSServer 建立一个TLS的测试服务。&lt;/p&gt;
&lt;p&gt;grpc也有对应的测试库grpc/test 库，无需建立网络连接即可测试，具体查看开发文档：https://pkg.go.dev/google.golang.org/grpc/test&lt;/p&gt;
&lt;h4 id=&#34;iotest&#34;&gt;iotest&lt;/h4&gt;
&lt;p&gt;该iotest包 ( &lt;a href=&#34;https://pkg.go.dev/testing/iotest&#34;&gt;https://pkg.go.dev/testing/iotest&lt;/a&gt; ) 实现了io Reader ，Writer， Closer 等接口， 用于测试使用io 相关接口的方法测试；&lt;/p&gt;
&lt;h3 id=&#34;89编写不准确的基准&#34;&gt;89.编写不准确的基准&lt;/h3&gt;
&lt;p&gt;对于性能优化，不能盲猜，需要编写基准压测来 分析评估 具体性能，然而编写基准测试并不简单。编写不准确的基准并根据它们做出错误的假设可能非常简单。使用go test -bench &lt;code&gt;regexp&lt;/code&gt; 匹配对应BenchmarkXxxx函数进行基准压测，默认运行1s, 运行时间通过-benchtime 来调整，其他性能分析的参数见开发文档。以下几种常见编写不准确基准压测的情况：&lt;/p&gt;
&lt;h4 id=&#34;不重置或暂停定时器&#34;&gt;不重置或暂停定时器&lt;/h4&gt;
&lt;p&gt;在基准压测时，可能会执行一个耗时长的初始准备逻辑，比如准备大量的数据用于基准压测，这个时候需要引入 testing.B.ResetTimer() 来重置时间，在开始基准压测，从测试结果中丢弃这部分耗时设置； 还有一种情况是在基准压测的循环里，这需要使用testing.B.StopTimer()停止时间，处理完准备逻辑，在使用testing.B.StartTimer()开始时间来处理基准测试函数。&lt;/p&gt;
&lt;h4 id=&#34;对微基准做出错误的假设&#34;&gt;对微基准做出错误的假设&lt;/h4&gt;
&lt;p&gt;对于基准测试，不能只用一轮或几轮基准实验，就做出了假设；基准测试受当前机器运行时环境的影响，cpu，内存负载情况等；所以在进行基准压测试，如果测试的值有所偏失，应该按照概率论中的大数定律，将压测的时间放长(-benchtime 调整)，而且测试的次数可以增加些(-count 调整)， 将这些性能数据，通过benchstat &lt;a href=&#34;https://pkg.go.dev/golang.org/x/perf/cmd/benchstat&#34;&gt;https://pkg.go.dev/golang.org/x/perf/cmd/benchstat&lt;/a&gt; 工具来 对比分析 前后benchmark的统计数据, 如果对比结果误差很小，则说明性能无差异。基准测试必须基于在合理环境中通过多次样本取证进行A/B 比较之后才能给出比较正确的结果。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;install&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;golang&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;org&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;perf&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;cmd&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchstat&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;@&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;latest&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;NONE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bench&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;BenchmarkAtomicStoreInt32&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchmem&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;89&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchmark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;wrong&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;assumptions&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;tee&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;smp1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;txt&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;NONE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bench&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;BenchmarkAtomicStoreInt32&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchmem&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;89&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchmark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;wrong&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;assumptions&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;tee&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;smp2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;txt&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;benchstat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;smp1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;txt&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;smp2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;txt&lt;/span&gt;

&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;test&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;NONE&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;bench&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;BenchmarkAtomicStore&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;count&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchmem&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;11&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;89&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;benchmark&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;wrong&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;assumptions&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;|&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;tee&lt;/span&gt;  &lt;span class=&#34;nx&#34;&gt;smp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;txt&lt;/span&gt;
&lt;span class=&#34;nx&#34;&gt;benchstat&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;smp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;txt&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;不注意编译器优化&#34;&gt;不注意编译器优化&lt;/h4&gt;
&lt;p&gt;这个case 在Go中有对应issue（https://github.com/golang/go/issues/14813）; benchmark的函数代码比较简单，被内联到基准压测文件中，导致测试为空的，这样导致空的基准压测在执行，每次op时间相当于一个时钟周期时间，如何避免编译器优化欺骗基准测试结果的模式：&lt;/p&gt;
&lt;p&gt;将被测函数的结果分配给局部变量，然后将最新结果分配给全局变量，先分配局部变量在栈上，不影响测试，而将局部变量复制给全局变量，分配在堆上，以防编译器优化进行inline 处理。&lt;/p&gt;
&lt;p&gt;还有一种方式是直接使用//go:noinline 标记函数，在编译阶段防止inline。&lt;/p&gt;
&lt;h4 id=&#34;被观察者效应愚弄&#34;&gt;被观察者效应愚弄&lt;/h4&gt;
&lt;p&gt;在基准压测一个CPU-Bound的函数时，需要注意cpu cache 局部性原理对基准压测的影响；为了防止cpu cache对基准压测的影响，可以在每次测试前，创建一个新的测试数据用于测试，比如基准压测矩阵运算函数，在每次测试前，新建一个测试矩阵数据。&lt;/p&gt;
&lt;h3 id=&#34;90没有探索所有的-go-测试功能&#34;&gt;90.没有探索所有的 Go 测试功能&lt;/h3&gt;
&lt;p&gt;工欲善其事必先利其器，充分掌握go test工具有助于写出高质量的代码。&lt;/p&gt;
&lt;h4 id=&#34;代码覆盖率&#34;&gt;代码覆盖率&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;&lt;span class=&#34;c1&#34;&gt;# 输出测试覆盖文件&lt;/span&gt;
go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; -coverprofile&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;coverage.out ./...
&lt;span class=&#34;c1&#34;&gt;# 分析测试覆盖文件&lt;/span&gt;
go tool cover -html&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;coverage.out
&lt;span class=&#34;c1&#34;&gt;# 一个包在另外一个包中会测试到，需要表明测试覆盖到的包&lt;/span&gt;
go &lt;span class=&#34;nb&#34;&gt;test&lt;/span&gt; -coverpkg&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;./... -coverprofile&lt;span class=&#34;o&#34;&gt;=&lt;/span&gt;coverage.out ./...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;tips: 在追踪代码覆盖率时要保持谨慎。拥有 100% 的测试覆盖率并不意味着应用程序没有错误；需正确推理测试涵盖的内容。&lt;/p&gt;
&lt;h4 id=&#34;从不同的包进行测试&#34;&gt;从不同的包进行测试&lt;/h4&gt;
&lt;p&gt;这种在业务功能函数测试，或者对外部进行测试， 关注包的公开api行为而不是内部的具体实现细节，专注于测试暴露的行为。 常用的测试如BDD 开发， 只关注包的公开行为， 比如&lt;a href=&#34;https://onsi.github.io/ginkgo/&#34;&gt;ginkgo&lt;/a&gt; ；编写的测试用例文件可以不用和测试函数在同一个包内，可以单独定义测试文件夹，对不同包来进行测试用例的开发。&lt;/p&gt;
&lt;h4 id=&#34;helper功能函数&#34;&gt;helper功能函数&lt;/h4&gt;
&lt;p&gt;在进行测试是，需要测试前的准备，这些准备工作逻辑helper功能函数，用于初始化一些对象来测试，参数需要传入*testing.T,  在初始逻辑中判读初始的错误情况，如果错误直接调用t.Fatal退出即可，只返回对应测试对象，这样可以方便复用，无需在处理错误，方便其他测试场景使用。这个属于代码质量问题啦。&lt;/p&gt;
&lt;h4 id=&#34;安装setup和拆卸teardown&#34;&gt;安装(setup)和拆卸(teardown)&lt;/h4&gt;
&lt;p&gt;如果单个测试初始执行完测试后需要清理一些初始资源，可以使用 testing.T.Cleanup函数来做单测的收尾工作；多个调用入栈操作，单测完出栈执行。&lt;/p&gt;
&lt;p&gt;如果测试文件都依赖于初始化之后才开始测试的话， 可以放在全部测试开始之前的位置进行测试的setup；在全部测试结束后对初始化的资源进行释放teardown； 可以通过在TestMain中定义整体逻辑如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;TestMain&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;M&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nf&#34;&gt;setupHelper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;code&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Run&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// run all test func
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nf&#34;&gt;teardownHelper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; 
	&lt;span class=&#34;nx&#34;&gt;os&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Exit&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;code&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;initHelper&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Cleanup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Cleanup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;})&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// first to cleanup
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;// init
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; 
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这种方式在测试开发框架包中经常使用到，比如ginkgo中的BeforeSuite和AfterSuite函数，在测试前后执行。&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;使用构建标志、环境变量或 -short模式对测试进行分类可以使测试过程更加高效。可以使用构建标志或环境变量（例如，单元测试与集成测试）创建测试类别，并区分短期运行测试和长期运行测试以确定要执行的测试类型。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;race&lt;/code&gt;强烈建议在编写并发应用程序时启用该标志。这样做可以捕捉到可能导致软件错误的潜在数据竞争；开启race检测会消耗内存，一般在开发测试，CI, 金丝雀发布(预发环境)的时候使用。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;parallel&lt;/code&gt;标志是加速测试的有效方法，尤其是长时间运行的测试。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;shuffle&lt;/code&gt;标志帮助确保测试套件不依赖于可能隐藏错误的错误假设。&lt;/li&gt;
&lt;li&gt;表驱动测试是将一组类似测试分组以防止代码重复并使未来更新更易于处理的有效方法。&lt;/li&gt;
&lt;li&gt;避免time.Sleep使用同步来使测试更稳定、更健壮。使用channel来进行同步，如果无法同步，请考虑重试方法。&lt;/li&gt;
&lt;li&gt;了解如何使用时间 API 处理函数是使测试不那么不稳定的另一种方法。可以使用标准技术，例如将时间作为隐藏依赖项的一部分处理或要求客户提供时间。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;httptest&lt;/code&gt;包有助于处理 HTTP 应用程序。它提供了一组实用程序来测试客户端和服务器。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;iotest&lt;/code&gt;包有助于编写&lt;code&gt;io.Reader&lt;/code&gt;和测试应用程序是否容错。&lt;/li&gt;
&lt;li&gt;关于基准：
&lt;ul&gt;
&lt;li&gt;使用时间方法来保持基准的准确性。&lt;/li&gt;
&lt;li&gt;在处理微基准时，增加&lt;code&gt;benchtime&lt;/code&gt;或使用诸如&lt;code&gt;benchstat&lt;/code&gt;此类的工具会有所帮助。&lt;/li&gt;
&lt;li&gt;如果最终运行应用程序的系统与运行微基准测试的系统不同，请注意微基准测试的结果。&lt;/li&gt;
&lt;li&gt;确保被测函数会产生副作用，以防止编译器优化导致基准测试结果上有误差。&lt;/li&gt;
&lt;li&gt;为防止观察者效应，强制基准重新创建 CPU-Bound函数使用的数据。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;使用带标志的代码覆盖率&lt;code&gt;coverprofile&lt;/code&gt;可以快速查看代码的哪一部分需要更多关注。&lt;/li&gt;
&lt;li&gt;将单元测试放在不同的包中，以强制编写专注于暴露行为而非内部的测试。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;testing.T&lt;/code&gt;变量而不是经典变量来处理错误&lt;code&gt;if err != nil&lt;/code&gt;使代码更短且更易于阅读。&lt;/li&gt;
&lt;li&gt;可以使用设置安装和拆卸功能来配置复杂的环境，例如在集成测试的情况下。&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: 标准库 75-81 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-10-standard-lib/</link>
      <pubDate>Sun, 19 Feb 2023 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-10-standard-lib/</guid>
      
        <description>&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;从程序中产生的错误中大多是使用姿势的不对，以及没有仔细阅读标准库相关包的开发文档，未查看源码导致，但是没有实践过这些问题，即使熟读文档和源码也可能避免不了。笔记中会以书中的mistake为切入点，结合源码升入分析其背后产生的原因，以及提出解决方案来避免。&lt;/p&gt;
&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;h3 id=&#34;75提供错误的持续时间&#34;&gt;75.提供错误的持续时间&lt;/h3&gt;
&lt;p&gt;记住使用&lt;code&gt;time.Duration&lt;/code&gt;API 和提供&lt;code&gt;int64&lt;/code&gt;一个时间单位, 默认最小时间单位是微妙&lt;/p&gt;
&lt;h3 id=&#34;76timeafter-和内存泄漏-重要&#34;&gt;76.time.After 和内存泄漏 （重要）&lt;/h3&gt;
&lt;p&gt;常见问题之一，将time.After函数进行循环调用，导致内存泄露。&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;event&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ch&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
			&lt;span class=&#34;nf&#34;&gt;handle&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;event&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;After&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Hour&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
			&lt;span class=&#34;nx&#34;&gt;log&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;warning: no messages received&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
		&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;通过time.After源码可以看出，每次会通过time.NewTimer新建一个timer, 但是time.After返回的是一个C ← chan Time 只读channel，不能释放掉每次新建的timer, 可以使用Stop，如果一直循环使用，Go 1.15 中，每次调用使用大约 200 字节的内存，如果设置的时间间隔小，比如每小时500w条，则在一小时消耗1G左右的内存空间。&lt;/p&gt;
&lt;p&gt;那如果直接使用time.NewTimer来处理，需要处理好Stop和Reset的情况：&lt;/p&gt;
&lt;p&gt;一种方式是直接每次循环中NewTimer, 然后使用Stop方法从最小堆timer数组中删除底层的运行时timer(如果timer 没有expire 到期 以及有复用timer reuse active timer)，这样可以防止内存泄露，但是这些timer结构对象需要GC来标记扫描释放，带来了额外的GC压力以及最小堆timer管理压力；这里需要注意Stop方法的使用，按照 &lt;a href=&#34;https://golang.org/pkg/time/#Timer.Stop&#34;&gt;Timer.Stop 文档&lt;/a&gt; 的使用说明，每次调用 Stop 后需要判断返回值，如果返回 false（表示 Stop 失败，Timer 已经在 Stop 前到期）则需要排掉（drain）一次 channel 中的Time数据(C 是长度为1的缓冲channel)：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Stop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;C&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但是如果之前程序已经从 channel 中接收过事件，那么上述 &lt;code&gt;&amp;lt;-t.C&lt;/code&gt; 就会发生阻塞。可能的解决办法是借助 select 进行 &lt;strong&gt;非阻塞&lt;/strong&gt; 排放（draining）：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;!&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Stop&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;C&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// try to drain the channel
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;k&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;但是因为 channel 的发送和接收发生在不同的 goroutine，所以 &lt;a href=&#34;https://github.com/golang/go/issues/14383&#34;&gt;存在竞争条件&lt;/a&gt;（race condition），最终可能导致 channel 中的事件未被排掉。因为sendTimer 和 操作Stop函数是在两个goroutine中执行，当timer刚好到期，已从最小堆中删除，操作Stop函数返回false,  在执行 ←t.C 接受操作和 sendTime 发送操作 分别在两个goroutine中执行相互之间执行是无序的，可能会发生先从t.C接受数据，没有，由于是非阻塞继续执行，这个时候sendTime发送一条Time数据到C中，后面执行Reset虽然重置一个Timer, 但是在select + case ←timer.C时，C中有数据选中直接执行了，和通过Reset重置的一个Timer间隔时间执行的预期期望不同，这样存在race condition，但是这种情况出现机率比较低，可参考 &lt;a href=&#34;https://github.com/golang/go/issues/11513#issuecomment-157062583&#34;&gt;Russ Cox 的回复&lt;/a&gt; ，目前 Timer 可能合理的使用方式是：程序需要维护一个状态变量(在同一个goroutine中)，用于记录它是否已经从 channel 中接收过事件，进而作为 Stop 中 draining 操作的判断依据。可以订阅&lt;a href=&#34;https://groups.google.com/g/golang-dev/c/c9UUfASVPoU&#34;&gt;golang-dev&lt;/a&gt;组查看相关进展。&lt;/p&gt;
&lt;p&gt;另外一种方式是把 NewTimer 放在循环外，在for循环中通过Reset函数来复用原有Timer结构，按照 &lt;a href=&#34;https://golang.org/pkg/time/#Timer.Reset&#34;&gt;Timer.Reset 文档&lt;/a&gt; 的使用说明，要正确地 Reset Timer，首先需要正确地 Stop Timer；因此 Reset 的问题跟 Stop 基本相同。&lt;/p&gt;
&lt;p&gt;tips： 具体详情见源码客观分析：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/time/sleep.go&#34;&gt;go1.20/src/time/sleep.go&lt;/a&gt; (time标准中提供使用的Timer)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/runtime/time.go&#34;&gt;go1.20/src/runtime/time.go&lt;/a&gt; (运行时的timer)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/runtime/runtime2.go&#34;&gt;go1.20/src/runtime/runtime2.go&lt;/a&gt; , &lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/runtime/proc.go&#34;&gt;go1.20/src/runtime/proc.go&lt;/a&gt;(p结构上最小四叉堆 timer数组, 以及运行时相关timer的调度；调用流程：findRunnable/stealWork → checkTimers → runtimer → runOneTimer → f (sendTime or goFunc) , lock free的方式调用f, CAS原子操作timer的状态)&lt;/p&gt;
&lt;p&gt;每次新生成Timer的时候，会往p上的最小堆上添加timer(O(logN))，将等待可读事件放入netpoll异步事件中监听，netpoll是在程序启动时初始化绑定一个单独的M进行事件轮训；Go1.14之前使用timerproc函数会调用一些系统调用来来让 goroutine 进入睡眠状态并唤醒 goroutine，系统调用意味着它为此生成OS线程，如果创建timer比较多，那就会发生比较多的系统调用，大大降低性能；之后改成异步事件轮训机制netpoll的方式多路复用，只需要一个OS线程来监听事件即可；系统调用因系统平台而异，通过runtime.nanotime1函数进行了封装；&lt;/p&gt;
&lt;p&gt;如果时间到了，将最小堆顶timer删除(O(logN))，通过netpoll 异步事件机制 将 可执行的G调度到runnext中，然后绑定M运行f；&lt;/p&gt;
&lt;h3 id=&#34;77常见的-json-处理错误-重要&#34;&gt;77.常见的 JSON 处理错误 (重要)&lt;/h3&gt;
&lt;h4 id=&#34;case1-类型嵌入导致的意外行为&#34;&gt;case1 类型嵌入导致的意外行为&lt;/h4&gt;
&lt;p&gt;需要了解json.Marshal 方法，在对结构类型对象进行Marshal操作时，如果实现了json.Marshaler接口方法MarshalJSON， 则会调用对应MarshalJSON方法进行encode操作，可以看具体源码： &lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/runtime/proc.go&#34;&gt;go1.20/src/encoding/json/encode.go&lt;/a&gt; （调用流程：Marshal→ marshal → reflectValue → valueEncoder → typeEncoder → newTypeEncoder → marshalerEncoder → MarshalJSON)  ; 所以在json.Marshal操作的时候需要注意结构体的嵌入成员是否实现了json.Marshaler接口方法MarshalJSON， 比如： time.Time 实现了MarshalJSON这个方法； 如果不想直接使用组合嵌入成员的方法，则将其定义为对应类型成员，或者实现MarshalJSON方法覆盖嵌入成员的实现；&lt;/p&gt;
&lt;p&gt;tips: 对结构类型对象进行UnMarshal操作也是同样情况。&lt;/p&gt;
&lt;h4 id=&#34;case2-json-和单调时钟&#34;&gt;case2 JSON 和单调时钟&lt;/h4&gt;
&lt;p&gt;对包含一个time.Time类型的结构encode或decode，有时会遇到意想不到的比较错误。&lt;/p&gt;
&lt;p&gt;首先需要弄清楚操作系统处理两种不同的时钟类型：wall clock(挂钟)和 monotonic clock(单调时钟)。挂钟用于确定一天中的当前时间。此时钟可能会有所变化。例如，如果时钟使用同步网络时间协议 (NTP)，它可以及时向后或向前跳转。不应该使用挂钟测量持续时间，因为可能会遇到奇怪的行为，例如负持续时间(润秒重置的情况)。这就是操作系统提供第二种时钟类型的原因：单调时钟。单调时钟保证时间总是向前移动并且不受时间跳跃的影响。它可能会受到频率调整的影响（例如，如果服务器检测到本地石英钟的移动速度与 NTP 服务器不同），但不会受到时间跳跃的影响。&lt;/p&gt;
&lt;p&gt;以前Go Time包的相关时间读取函数实现仅读取系统挂钟，从不读取单调时钟，从而在时钟重置时导致测量不正确。比如 一个 Go 程序在闰秒期间测量负的经过时间导致&lt;a href=&#34;https://blog.cloudflare.com/how-and-why-the-leap-second-affected-cloudflare-dns/&#34;&gt;CloudFlare 最近的 DNS 中断&lt;/a&gt;. 维基百科&lt;a href=&#34;https://en.wikipedia.org/wiki/Leap_second#Examples_of_problems_associated_with_the_leap_second&#34;&gt;与闰秒相关的问题示例列表&lt;/a&gt;现在包括 CloudFlare 的中断，并将 Go 的时间 API 列为根本原因。除了闰秒问题之外，Go 还扩展到非生产环境中的系统，这些环境中的时钟可能不太好调节，因此时钟重置更频繁。Go 必须优雅地处理时钟重置。Go语言作者Russ Cox提出了提案设计**&lt;a href=&#34;https://github.com/golang/proposal/blob/master/design/12914-monotonic.md&#34;&gt;Proposal: Monotonic Elapsed Time Measurements in Go&lt;/a&gt;**  (golang的开发规范和提案设计文档值得借鉴学习的，背景原因，验证评估影响面，尽量向前兼容，提案通过，再安排开发计划)； 将monotonic clock 单调时钟引入time.Time结构体中，具体CR: &lt;a href=&#34;https://go-review.googlesource.com/c/go/+/36255&#34;&gt;https://go-review.googlesource.com/c/go/+/36255&lt;/a&gt; ， HN也有对应讨论： &lt;a href=&#34;https://news.ycombinator.com/item?id=13566110&#34;&gt;https://news.ycombinator.com/item?id=13566110&lt;/a&gt; ;&lt;/p&gt;
&lt;p&gt;tips： 测量持续时间，使用单调时钟；仅对&lt;strong&gt;本地持续时间测量&lt;/strong&gt;有效；两个不同服务器的单调时钟根据定义是不同步的。因此，基于这些时钟测量分布式执行将不准确；这就涉及到分布式时钟同步的问题了。&lt;/p&gt;
&lt;p&gt;ok了解了背景，回归正题，比如对一个结构体有time.Time类型成员，time.Time可能同时包含一个挂钟和一个单调时间，使用time.Now方法返回的时间就包括挂钟读数和单调时钟读数，具体见time包开发文档：https://pkg.go.dev/time#section-documentation; 以及查看源码客观分析：&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/time/time.go&#34;&gt;go1.20/src/time/time.go&lt;/a&gt; （Now→time.now→runtime.now in assembly → 如果可以使用vdso 调用 runtime·vdsoClockgettimeSym 减少系统调用提升性能，否则执行系统调用SYSCALL SYS_clock_gettime(228) 指令，见：&lt;strong&gt;&lt;a href=&#34;https://github.com/torvalds/linux/blob/master/arch/x86/entry/syscalls/syscall_64.tbl&#34;&gt;linux系统调用指令集&lt;/a&gt;&lt;/strong&gt;）。time.Now返回的Duration值打印如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;mi&#34;&gt;2023&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mo&#34;&gt;02&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;19&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;15&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;37&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;08.218505&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0800&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;CST&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;m&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;=&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;+&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;0.000118444&lt;/span&gt;
&lt;span class=&#34;o&#34;&gt;------------------------------------&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;--------------&lt;/span&gt;
             &lt;span class=&#34;nx&#34;&gt;Wall&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;               &lt;span class=&#34;nx&#34;&gt;Monotonic&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在执行json.UnMarshal 解码包涵time.Time类型公开成员结构体进行格式化解析时， 也会调用time.Time的UnMarshalJSON函数，最终会调用Time.stripMono, 去掉Monotonic time；导致前后结构体对象不一致，一个从time.Now中返回有Monotonic time，解析后的没有；通过Time.Truncate方法，去掉Monotonic time，可以解决；需要注意带有time.Time的结构体在encode/decode时，前后对象会不一致的情况；&lt;/p&gt;
&lt;h4 id=&#34;case3-any-map&#34;&gt;case3 any map&lt;/h4&gt;
&lt;p&gt;any是空接口interface{}的别名，在对map[string]any类型对象进行 json.UnMarshal时，json字符串中的整数类型会解析成默认的float64类型，这样可能会导致数据判断时出现问题，对类型转换做出错误的假设可能会导致 goroutine panic。&lt;/p&gt;
&lt;h3 id=&#34;78常见的-sql-错误&#34;&gt;78.常见的 SQL 错误&lt;/h3&gt;
&lt;p&gt;该&lt;code&gt;database/sql&lt;/code&gt;包提供SQL（或类似 SQL）数据库的标准通用接口；依赖具体数据操作，由三方来实现；接口与实现分离的很好例子；&lt;/p&gt;
&lt;p&gt;tips：在设计通用中台和平台项目中的模块时，经常需要将抽象与实现分离，驱动化设计，方便具体领域场景的定制化开发。&lt;/p&gt;
&lt;p&gt;具体查看开发文档：https://pkg.go.dev/database/sql；在使用这个包时看到一些模式或错误也很常见；深入研究五个常见错误case。&lt;/p&gt;
&lt;h4 id=&#34;case1-忘记-sqlopen-不一定建立到数据库的连接-工程规范&#34;&gt;case1 忘记 sql.Open 不一定建立到数据库的连接 (工程规范)&lt;/h4&gt;
&lt;p&gt;Open 可能只是验证其参数而不创建与数据库的连接。要验证数据源名称是否有效，请调用 Ping。在使用的时候，和数据库进行交互的时候才建立连接。比如go-redis &lt;a href=&#34;https://github.com/redis/go-redis/issues/2085&#34;&gt;issues-2085&lt;/a&gt; , 这个issue是因为使用go-redis v8 版本 通过ping请求访问 7.0 redis redis-cluster， v8版本还不支持新的协议返回的数据导致，需要升级使用go-redis v9版本来支持，所以使用ping功能即可以测试生成有效连接，而且可以验证客户端和服务端协议的一致性。&lt;/p&gt;
&lt;h4 id=&#34;case2-忘记使用连接池-工程规范&#34;&gt;case2 忘记使用连接池 (工程规范)&lt;/h4&gt;
&lt;p&gt;应为数据库是底层存储数据资源，如果不限制使用有限的底层数据库连接资源，会增加底层数据库服务的负载；需要设置连接池，进行连接复用，以及结合数据库服务能力限制设置最大连接数，具体参数：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;SetMaxOpenConns&lt;/code&gt;最大限度打开的数据库连接数（默认值&lt;code&gt;unlimited&lt;/code&gt;）；设置&lt;code&gt;SetMaxOpenConns&lt;/code&gt;对于生产级应用程序很重要。因为默认值是无限的，应该设置它以确保它适合底层数据库可以处理的内容。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SetMaxIdleConns&lt;/code&gt;最大限度空闲连接数（默认值&lt;code&gt;2&lt;/code&gt;）；如果应用程序生成大量并发请求，则应增加&lt;code&gt;SetMaxIdleConns&lt;/code&gt;(default: )的值。&lt;code&gt;2&lt;/code&gt;否则，应用程序可能会经历频繁的重新连接。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SetConnMaxIdleTime&lt;/code&gt;最大限度连接关闭前可以空闲的时间量（默认值&lt;code&gt;unlimited&lt;/code&gt;）；如果应用程序可能面临大量请求，那么设置就很重要。当应用程序返回到更和平的状态时，希望确保创建的连接最终被释放。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;SetConnMaxLifetime&lt;/code&gt;最大限度连接在关闭之前可以保持打开状态的时间（默认值&lt;code&gt;unlimited&lt;/code&gt;）；如果连接到负载平衡的数据库服务器，设置会很有帮助。在这种情况下，要确保应用程序永远不会使用连接太久。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果应用程序面临不同的用例，可以使用多个连接池。这些值需要根据不同环境进行配置，对这些值进行可配置化管理，或者放在配置中心。&lt;/p&gt;
&lt;h4 id=&#34;case3-不使用prepare语句-工程规范&#34;&gt;case3 不使用Prepare语句 (工程规范)&lt;/h4&gt;
&lt;p&gt;生产环境中，应该使用Prepare对sql 进行预处理，以防sql 注入，并且重复的sql语句不需要重新解析处理。&lt;/p&gt;
&lt;h4 id=&#34;case4-错误处理空值---工程规范&#34;&gt;case4 错误处理空值   (工程规范)&lt;/h4&gt;
&lt;p&gt;在设计数据库表时，如果允许字段为NULL的话；查询这个字段scan row时，需要考虑NULL的情况，如果直接使用类型，则会报错； 解决方法，使用指针类型，以及sql包中封装的类型sql.NullXXX&lt;/p&gt;
&lt;p&gt;比指针类型更清楚地表达了意图。&lt;/p&gt;
&lt;h4 id=&#34;case5-不处理行迭代错误--工程规范&#34;&gt;case5 不处理行迭代错误  (工程规范)&lt;/h4&gt;
&lt;p&gt;这是要牢记的最佳实践：因为&lt;code&gt;rows.Next&lt;/code&gt;可以在遍历所有行或准备下一行时发生错误时停止，所以应该在迭代后使用&lt;code&gt;rows.Err&lt;/code&gt;进行检查。&lt;/p&gt;
&lt;h3 id=&#34;79不关闭临时资源&#34;&gt;79.不关闭临时资源&lt;/h3&gt;
&lt;p&gt;开发者经常在代码中的某个点关闭申请的临时资源，以避免磁盘或内存，连接等资源泄漏。结构通常实现&lt;code&gt;io.Closer&lt;/code&gt;接口表示必须关闭临时资源。列举3个不关闭临时资源的case:&lt;/p&gt;
&lt;h4 id=&#34;case1-http-response-body-重要&#34;&gt;case1 HTTP Response body （重要）&lt;/h4&gt;
&lt;p&gt;如果使用Go语言编写HTTP协议相关的代码，经常会遇到的问题，忘记关闭返回的http.Response.Body,  导致资源泄露，其实开发文档中已经给出了说明 &lt;a href=&#34;https://pkg.go.dev/net/http#Response.Body&#34;&gt;https://pkg.go.dev/net/http#Response.Body&lt;/a&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;http&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Client&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Transport&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;guarantee&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;that&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Body&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;always&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;non&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;even&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;on&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;responses&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;without&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;body&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;or&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;responses&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;with&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;a&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;zero&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;length&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;  &lt;span class=&#34;nx&#34;&gt;It&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;caller&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;responsibility&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;close&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Body&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;  &lt;span class=&#34;nx&#34;&gt;The&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;default&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;HTTP&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;client&lt;/span&gt;&lt;span class=&#34;err&#34;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Transport&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;may&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;reuse&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;HTTP&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;/&lt;/span&gt;&lt;span class=&#34;mf&#34;&gt;1.&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;keep-alive&amp;#34;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;TCP&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;connections&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;the&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Body&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;is&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;not&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;read&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;to&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;completion&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;and&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;closed&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;http客户端和传输保证Body总是非空的，即使响应没有Body或者响应的Body长度为零。关闭Body是调用者的责任。如果&lt;strong&gt;Body没有读到完成并且关闭，缺省HTTP客户端的传输(DefaultTransport 默认打开了Keep-Alive)不能复用HTTP/1.x &amp;ldquo;keep-alive&amp;quot;tcp 连接&lt;/strong&gt;。并且查看源码分析：&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/net/http/client.go&#34;&gt;go1.20/src/net/http/client.go&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/net/http/transport.go&#34;&gt;go1.20/src/net/http/transport.go&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/net/http/transfer.go&#34;&gt;go1.20/src/net/http/transfer.go&lt;/a&gt; (body Read from bufio Read)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/bufio/bufio.go&#34;&gt;go1.20/src/bufio/bufio.go&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;调用流程：初始化Client, 调用 Client.Do/do (Get/Post/Head方法NewRequest之后都会调用Do方法）→ Client.send → send →  Transport.RoundTrip 接口方法 →  Transport.roundTrip&lt;/p&gt;
&lt;p&gt;→ Transport.getConn → Transport.queueForDial -》 go Transport.dialConnFor → go persistConn.readLoop （将连接响应数据写入transferReader Body中, 发送responseAndError给roundTrip） 和  go persistConn.writeLoop  (往连接中写请求数据,将writeErr结果分别发送一份到writeErrCh中，由readLoop接收处理，发送一份给roundTrip处理)&lt;/p&gt;
&lt;p&gt;→ persistConn.roundTrip (发送persistConn.requestAndChan 到 reqch中,用于readLoop接收；发送writeRequest到writech中，由writeLoop 接收；从writeErrCh 处理write错误；从responseAndError chan中处理read错误)&lt;/p&gt;
&lt;p&gt;整体过程是一个建立长连接(KeepAlive开启), 并在长连接中通过读写管道和错误结果管道来协同处理，管道是可缓冲的，长度是1个buffer，刚好用于存放一个数据，发送和接收等待管道中的数据进行处理。&lt;/p&gt;
&lt;p&gt;在KeepAlive开启的情况下，长连接如果不关闭Response.Body，并且不读取Body中的数据，不会复用原有长连接，通过上面分析，会导致协程泄露；如下代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;go nums&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;runtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;NumGoroutine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;resp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;http&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Get&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;&amp;lt;http://www.baidu.com&amp;gt;&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;resp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;resp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Body&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
			&lt;span class=&#34;c1&#34;&gt;//_, _ = ioutil.ReadAll(resp.Body)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;			&lt;span class=&#34;c1&#34;&gt;//_ = resp.Body.Close()
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;		&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;go nums&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;runtime&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;NumGoroutine&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;如果复用的话，这里请求是串行处理，会复用同一个连接，所以只会有3个协程在工作；如果不能复用连接的话,每处理一个请求会新开连接，导致协程泄露。Client不初始化，Transport默认是开启keep-alive；&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// DefaultTransport is the default implementation of Transport and is
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// used by DefaultClient. It establishes network connections as needed
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// and caches them for reuse by subsequent calls. It uses HTTP proxies
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// as directed by the $HTTP_PROXY and $NO_PROXY (or $http_proxy and
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// $no_proxy) environment variables.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;DefaultTransport&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;RoundTripper&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Transport&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;Proxy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ProxyFromEnvironment&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;DialContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;defaultTransportDialContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;net&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Dialer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;Timeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;   &lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Second&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;KeepAlive&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;30&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Second&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}),&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;ForceAttemptHTTP2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;     &lt;span class=&#34;kc&#34;&gt;true&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;MaxIdleConns&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;          &lt;span class=&#34;mi&#34;&gt;100&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;IdleConnTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;       &lt;span class=&#34;mi&#34;&gt;90&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Second&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;TLSHandshakeTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;   &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Second&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;ExpectContinueTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Second&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;生产环境中，使用tcp连接资源都是需要根据调用 资源服务放的系统负载吞吐能力来配置的。也是需要配置化。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果在没有读取的情况下也没有关闭Body，会发生协程泄露，同时tcp连接也不会复用,本质上是连接资源未释放至连接池中，存在连接泄露。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;还需要记住的重要事情是，如开发文档net/http中提到的，当关闭 Response Body时，是否复用连接，这取决于是否从中读取完body中的值：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果在没有读取的情况下关闭Body，虽然不会发生协程泄露，但是默认的 HTTP 传输可能会关闭连接。&lt;/li&gt;
&lt;li&gt;如果在读取后关闭Body，默认的 HTTP 传输不会关闭连接；因此，它可以重复使用。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所以不管如何，最好的方式是都应该关闭Response Body,  尽管Body没有数据，或者已经读取完了，都应该关闭。&lt;/p&gt;
&lt;p&gt;tips: 是否连接复用的判定，可以通过tcpdump 或者 wireshark 来抓包，通过是否使用同一个连接四元组来确定是否复用了同一连接。可以使用类似如下命令：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-bash&#34; data-lang=&#34;bash&#34;&gt;tcpdump -i utun2 -tnn dst host www.baidu.com //per host pool
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;case2-sqlrows&#34;&gt;case2 sql.Rows&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;sql.Rows&lt;/code&gt;是用作 SQL 查询结果的结构。因为这个结构实现了&lt;code&gt;io.Closer&lt;/code&gt;，所以它必须被关闭。忘记关闭行意味着连接泄漏，这会阻止数据库连接被放回连接池。&lt;/p&gt;
&lt;h4 id=&#34;case3-osfile&#34;&gt;case3 os.File&lt;/h4&gt;
&lt;p&gt;如果最终没有关闭一个&lt;code&gt;os.File&lt;/code&gt;，它本身不会导致泄漏：文件将在&lt;code&gt;os.File&lt;/code&gt;垃圾收集时自动关闭。但是，最好&lt;code&gt;Close&lt;/code&gt;显式调用，因为不知道下一次 GC 何时会被触发（除非手动运行它）。&lt;/p&gt;
&lt;p&gt;总结本节，已经看到关闭临时资源从而避免泄漏的重要性。临时资源必须在正确的时间和特定情况下关闭。事先并不总是清楚什么必须关闭。只能通过仔细阅读 API 文档和/或通过经验来获取这些信息。但是应该记住，如果一个结构实现了&lt;code&gt;io.Closer&lt;/code&gt;接口，最终必须调用&lt;code&gt;Close&lt;/code&gt;方法。最后但并非最不重要的一点是，了解如果闭包失败该怎么办非常重要：是否足以记录一条消息，或者是否也应该传播它？适当的操作取决于具体错误err是否需要处理。&lt;/p&gt;
&lt;h3 id=&#34;80在回复-http-请求后忘记返回语句-凑数&#34;&gt;80.在回复 HTTP 请求后忘记返回语句 （凑数）&lt;/h3&gt;
&lt;p&gt;如果有适当的覆盖率，这样的问题可以而且应该在测试期间被发现。这个属于err≠nil, 需要check遇到错误不为nil，是否直接return返回。这总低级错误，可以交给测试用例来覆盖到。&lt;/p&gt;
&lt;h3 id=&#34;81使用默认的-http-客户端和服务器-工程规范&#34;&gt;81.使用默认的 HTTP 客户端和服务器 (工程规范)&lt;/h3&gt;
&lt;p&gt;在讨论http包的时候提到, 如果不初始化http.Client，Client结构中的RoundTripper会默认使用DefaultTransport, 而DefaultTransport 只能用于开发测试时使用；对于生产环境， 需要更具依赖的资源服务进行配置，保证其配置过大的连接数而超出资源服务的负载能力，以及在网络不稳定情况下，连接超时，读写超时的设定，以便是否重试，这样不会一直hang住连接不释放，并发场景下，会导致服务负载增加， 连接过多导致服务拒绝。所以对于网络tcp请求，都需要根据具体的生产情况进行合理配置，而且是可配置化， 或者引入配置中心动态下发配置。对于服务端的tcp连接配置也是如此，也需要配置读写超时时间，进行可配置化管理。&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;对接受&lt;code&gt;time.Duration&lt;/code&gt;. 即使允许传递整数，也要尽量使用时间 API 来防止任何可能的混淆。&lt;/li&gt;
&lt;li&gt;避免调用&lt;code&gt;time.After&lt;/code&gt;重复函数（例如循环或 HTTP 处理程序）可以避免峰值内存消耗。由创建的资源&lt;code&gt;time.After&lt;/code&gt;只有在定时器到期时才会被释放。&lt;/li&gt;
&lt;li&gt;在 Go 结构中使用嵌入式字段时要小心。这样做可能会导致偷偷摸摸的错误，例如&lt;code&gt;time.Time&lt;/code&gt;实现&lt;code&gt;json .Marshaler&lt;/code&gt;接口的嵌入式字段，从而覆盖默认的封送处理行为。&lt;/li&gt;
&lt;li&gt;比较两个&lt;code&gt;time.Time&lt;/code&gt;结构时，回想一下它&lt;code&gt;time.Time&lt;/code&gt;同时包含一个挂钟和一个单调时钟，并且使用运算符的比较&lt;code&gt;==&lt;/code&gt;是在两个时钟上完成的。&lt;/li&gt;
&lt;li&gt;为避免在解组 JSON 数据时提供地图时出现错误假设，请记住&lt;code&gt;float64&lt;/code&gt;默认情况下会将数字转换为。&lt;/li&gt;
&lt;li&gt;如果需要测试配置并确保数据库可访问，请调用&lt;code&gt;Ping&lt;/code&gt;or方法。&lt;code&gt;PingContext&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;配置生产级应用程序的数据库连接参数。&lt;/li&gt;
&lt;li&gt;使用 SQL 预处理语句可以使查询更高效、更安全。&lt;/li&gt;
&lt;li&gt;使用指针或类型处理表中可为空的列&lt;code&gt;sql.NullXXX&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;调用行后迭代&lt;code&gt;Err&lt;/code&gt;的方法&lt;code&gt;sql.Rows&lt;/code&gt;以确保您在准备下一行时没有遗漏任何错误。&lt;/li&gt;
&lt;li&gt;最终关闭所有实现的结构&lt;code&gt;io.Closer&lt;/code&gt;以避免可能的泄漏。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;return&lt;/code&gt;为避免 HTTP 处理程序实现中的意外行为，如果您希望处理程序在 之后停止，请确保您没有错过该语句&lt;code&gt;http.Error&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;对于生产级应用程序，不要使用默认的 HTTP 客户端和服务器实现。这些实现缺少在生产中应该强制执行的超时和行为。&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: 并发实践 61-74 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-09-concurrency-practice/</link>
      <pubDate>Sat, 18 Feb 2023 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-09-concurrency-practice/</guid>
      
        <description>&lt;h2 id=&#34;引言&#34;&gt;引言&lt;/h2&gt;
&lt;p&gt;这里主要介绍并发实践中遇到的问题，这些问题在golang开源项目中也经常会出现，如果编写并发也会一直伴随在开发当中出现，也有工程实践相关的论文进行统计归纳总结(PS: 用这种方式发个论文还是比较轻松的~)：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;a href=&#34;https://songlh.github.io/paper/go-study.pdf&#34;&gt;Understanding Real-World Concurrency Bugs in Go&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;tips: 作者对golang和rust都有研究，结合相关的代码都可以一起学习下, 语言方面的小细节&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2204.00764.pdf&#34;&gt;&lt;strong&gt;A Study of Real-World Data Races in Golang&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Go 官方提供race工具来检查并发场景下的数据竞争问题： &lt;a href=&#34;https://go.dev/doc/articles/race_detector&#34;&gt;https://go.dev/doc/articles/race_detector&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/google/sanitizers/wiki/ThreadSanitizerGoManual&#34;&gt;https://github.com/google/sanitizers/wiki/ThreadSanitizerGoManual&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;注：Go要使用-race，需启用CGO，依赖sanitizers；一般用于开发测试进行检测&lt;/p&gt;
&lt;p&gt;如果想更加深入的了解并发并行，可以一起学习这本书： &lt;a href=&#34;https://mirrors.edge.kernel.org/pub/linux/kernel/people/paulmck/perfbook/perfbook.html&#34;&gt;&lt;strong&gt;Is Parallel Programming Hard, And, If So, What Can You Do About It?&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;h3 id=&#34;61传播不适当的context&#34;&gt;61.传播不适当的context&lt;/h3&gt;
&lt;p&gt;传播context应该谨慎进行。比如文中中通过一个基于与 http.Request关联的context处理异步操作的示例来说明这一点。因为一旦服务接口返回响应，这次请求会话的context就会被cancel，使用 http.Request关联的context的异步操作也可能会意外停止(请求已经结束，但是异步操作还没有执行完)。遇到这种情况，可以为特殊情况创建实现context.Context接口的自定义context结构，这个结构将原来的ctx context.Context作为成员wrap一层，实现主要的传递功能Value方法, 这样在服务的请求回话结束之后，异步操作可以继续执行完成。&lt;/p&gt;
&lt;p&gt;tips：生产环境下，请求接口下的异步操作，必须避免因goroutine协程处理hang住，导致泄露，一般引入执行超时机制。&lt;/p&gt;
&lt;h3 id=&#34;62在不知道何时停止的情况下启动-goroutine-重要&#34;&gt;62.在不知道何时停止的情况下启动 goroutine (重要)&lt;/h3&gt;
&lt;p&gt;Goroutines 启动起来既简单又便宜——如此简单和便宜，以至于不考虑停止一个新的 goroutine，这可能会导致泄漏。不知道何时停止 goroutine 是一个设计问题，也是 Go 中常见的并发错误。了解原因以及如何预防它。&lt;/p&gt;
&lt;p&gt;首先，量化一下 goroutine 泄漏的含义。在内存方面，一个 goroutine 以 2 KB 的最小堆栈大小开始，它可以根据需要增长和收缩（最大堆栈大小在 64 位上为 1 GB，在 32 位上为 250 MB）。在内存方面，goroutine 还可以保存分配给堆的变量引用。同时，goroutine 可以保存 HTTP 或数据库连接、打开的文件和网络套接字等资源，这些资源最终应该正常关闭。如果一个 goroutine 被泄露，那么这些资源也会被泄露。&lt;/p&gt;
&lt;p&gt;goroutine 是一种资源，就像任何其他资源一样，最终必须关闭以释放内存或其他资源(通常通过cancel 信号量，ctx.Done方式让这些goroutine任务退出释放资源)。在不知道何时停止的情况下启动 goroutine 是一个设计问题。每当一个 goroutine 启动时，应该对它何时停止有一个明确的计划。如果一个 goroutine 创建资源并且它的生命周期与应用程序的生命周期绑定，那么在退出应用程序之前，等待这个 goroutine 完成可能更安全。这样可以确保资源可以被释放。&lt;/p&gt;
&lt;h3 id=&#34;63不注意-goroutines-和循环变量-重要&#34;&gt;63.不注意 goroutines 和循环变量 (重要)&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;_&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;range&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;      
    &lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
        &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Print&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
    &lt;span class=&#34;p&#34;&gt;}()&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;这个是Go新手经常会遇到问题，也是老生常谈的问题了，如果希望每个闭包都访问goroutine创建时的值，有什么解决方案？有两种方法: 每次迭代中，创建一个局部新变量i，并将i复制给新i；另外一种方法是不再依赖闭包，而是使用实际函数进行传参值拷贝，本质上一样。&lt;/p&gt;
&lt;h3 id=&#34;64使用-select-和-channels-期待确定性行为-重要&#34;&gt;64.使用 select 和 channels 期待确定性行为 （重要）&lt;/h3&gt;
&lt;p&gt;这里主要了解select语义的工作原理，可以从官方文档中进行了解：https://go.dev/ref/spec#Select_statements&lt;/p&gt;
&lt;p&gt;如果一个或多个通信可以继续进行，则通过统一的伪随机选择一个可以继续进行的通信。否则，如果存在默认情况，则选择该情况。如果没有默认情况，则“select”语句将阻塞，直到至少有一个通信可以继续进行。&lt;/p&gt;
&lt;p&gt;tips: 当使用无缓冲channel时，写入不想阻塞，使用select + case 写chan + default的方式来处理时非常好的办法，可以避免死锁的情况，比如 &lt;code&gt;fatal error: all goroutines are asleep - deadlock!&lt;/code&gt;这个错误经常会遇到，这个是全部在执行的goroutine都进入了等待状态，Go 语言死锁检测会发现当前的 Goroutine 已经不可能被唤醒，就会直接报错退出；常见于 一组协程处理数据其中一个协程进入一直等待状态，调用sync.WaitGroup Wait方法(底层通过信号量值机制semacquire1)等待协程执行完成，这样出现相互等待，导致deadlock。&lt;/p&gt;
&lt;h3 id=&#34;65不使用通知channel&#34;&gt;65.不使用通知channel&lt;/h3&gt;
&lt;p&gt;无数据channel应该用 &lt;code&gt;chan struct{}&lt;/code&gt; 作为通知channel， struct{}{}不占内存空间。&lt;/p&gt;
&lt;h3 id=&#34;66不使用nil--channel&#34;&gt;66.不使用nil  channel&lt;/h3&gt;
&lt;p&gt;接受或发送到 nil 通道是一种阻塞行为，而且这种行为并非无用。正如文中合并两个通道的示例中看到的那样，即使close 通道， 接受方还是可以读取数据，通过返回的第二个参数判断是否关闭，关闭了将通道设置为nil，这样利用select不会选择阻塞的nil通道，可以使用 nil 通道来实现一个优雅的状态机，所以 nil 通道在某些情况下很有用，并且在处理并发代码时应该成为 Go 开发人员工具集的一部分。&lt;/p&gt;
&lt;h3 id=&#34;67对channel大小感到困惑&#34;&gt;67.对channel大小感到困惑&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;无缓冲通道支持同步。可以保证两个 goroutine 将处于已知状态：一个接收消息，另一个发送消息。&lt;/li&gt;
&lt;li&gt;缓冲通道不提供任何强同步。实际上，生产者 goroutine 可以发送一条消息，然后在通道未满时继续执行。唯一的保证是 goroutine 在消息发送之前不会收到消息。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;必须牢记这一基本区别。两种通道类型都支持通信，但只有一种提供同步。如果需要同步，必须使用无缓冲通道，无缓冲通道也可能更容易推理；缓冲通道可能导致模糊的死锁，这在无缓冲通道中会立即显现出来。在通知channel的情况下，通知是通过关闭channel ( &lt;code&gt;close(ch)&lt;/code&gt;) 处理的，使用缓冲通道不会带来任何好处，close channel后，还可以继续从channel中读取数据。&lt;/p&gt;
&lt;p&gt;使用缓冲通道的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;在使用类似工作池的模式下，创建的goroutine轮训从共享通道获取数据执行；可以将缓冲通道大小与创建的 goroutines 数量联系起来。&lt;/li&gt;
&lt;li&gt;当使用通道来解决速率限制问题时。如果需要通过限制请求数量来强制资源利用，应该根据限制设置缓冲通道大小。例如，errorgroup 中的 sem chan struct{}(token) 就是用来设置最大执行的goroutine数目。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;决定一个准确缓冲通道大小不是一个容易的问题。首先，它是 CPU 和内存之间的平衡。值越小，可以面对的 CPU 争用越多；但是这个值越大，需要分配的内存就越多；需要基于场景下，基准压测来衡量。&lt;/p&gt;
&lt;h3 id=&#34;68忘记字符串格式化可能产生的副作用&#34;&gt;68.忘记字符串格式化可能产生的副作用&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;数据竞争(data race), 文中举了一个etcd 例子中 一个goroutine通过&lt;code&gt;fmt.Sprintf(&amp;quot;%v&amp;quot;, ctx)&lt;/code&gt; 格式化成key, 对key进行watch操作， 通过ctx中的String方法读取ctx中的元数据进行格式化；另一个goroutine 通过context.WithValue 写入，这样产生了data race。修复 ( &lt;a href=&#34;https://github.com/etcd-io/etcd/pull/7816&#34;&gt;https://github.com/etcd-io/etcd/pull/7816&lt;/a&gt; ) pr中, 直接实现wrap一层自定义ctx，不依赖通过context.WithValue写入改变值的ctx；&lt;/li&gt;
&lt;li&gt;死锁(deadlock)，如果一个结构体的格式化String函数中使用了互斥锁，则对结构体对象格式化时，要考虑对应互斥锁的范围，如果上锁范围包括了格式化代码，则会重复上锁，导致相互等待，进而出现deadlock；&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;69使用append操作产生数据竞争-重要&#34;&gt;69.使用append操作产生数据竞争 (重要)&lt;/h3&gt;
&lt;p&gt;发生数据竞争(data race)的情况是多个并发goroutines至少有一个写操作发生在一个共享空间中；对于slice切片结构，append在扩容的时候是否重新分配了内存空间，如果发生扩容则在在切片副本上使用，而不是原始切片，这样就不会发生数据竞争；更合理情况是直接在goroutine中进行copy一份切片副本进行append操作。&lt;/p&gt;
&lt;p&gt;多个goroutines 并发访问 slice和map时，发生数据竞争的情况：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;使用至少一个更新值的 goroutine 访问同一个切片索引是一种数据竞争；goroutines 访问相同的内存位置。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;无论操作如何访问不同的切片索引都不是数据竞争；不同的索引意味着不同的内存位置。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;使用至少一个goroutine更新访问同一个map（不管它是相同的还是不同的key）是一种数据竞争。为什么这与切片数据结构不同？map底层结构是个桶数组，每个桶都是一个指向键值对数组的指针；哈希算法用于确定桶的数组索引。因为该算法在map初始化期间包含一些随机性，所以一次执行可能导致相同的数组索引(相同bucket)，而另一次执行可能不会。竞争检测器通过发出警告来处理这种情况，而不管实际的数据竞争是否发生。&lt;/p&gt;
&lt;p&gt;tips: 与slice不同，go在map实现中内置了对并发读写的检测，即便不加入-race，一旦发现存在数据竞争(至少有一个写操作)直接fatal error。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;70对slice和map使用mutex不准确-重要&#34;&gt;70.对slice和map使用mutex不准确 （重要）&lt;/h3&gt;
&lt;p&gt;在数据既可变又共享的并发上下文中工作时，通常使用mutex对操作数据的临界区域进行同步互斥访问；&lt;/p&gt;
&lt;p&gt;具体map的内部结构在https://github.com/golang/go/blob/go1.20/src/runtime/map.go hmap查看源码(通过测试用例代码了解)；map是一个&lt;code&gt;runtime.hmap&lt;/code&gt;主要包含元数据（counter,flags,B等）以及2个指向数据桶(bucket)的指针的结构。所以对与map变量之间赋值操作&lt;code&gt;mp:=m&lt;/code&gt;不复制底层实际数据(buckets)。这个和slice切片的原理是一样，只不过需要注意append扩容情况，而map扩容的是底层buckets数据。&lt;/p&gt;
&lt;p&gt;了解了slice和map的结构，对于mutex保护操作共享的slice或者map的临界区间很有帮助，对于map遍历操作进行互斥访问，如果遍历处理的时间长，考虑到性能问题，可以深拷贝一份出来进行耗时的计算操作；&lt;/p&gt;
&lt;p&gt;在考虑使用mutex对slice或map进行互斥访问时，需要考虑好互斥的临界区域。&lt;/p&gt;
&lt;h3 id=&#34;71滥用-syncwaitgroup--重要&#34;&gt;71.滥用 sync.WaitGroup  （重要）&lt;/h3&gt;
&lt;p&gt;sync.WaitGroup是Go并发程序常用的用于等待一组goroutine退出的机制。通过Add和Done方法实现内部计数的调整。而Wait方法用于等待，直到内部计数器为0才会返回。文中提到的例子是比较经典的坑，在论文&lt;a href=&#34;https://arxiv.org/pdf/2204.00764.pdf&#34;&gt;&lt;strong&gt;A Study of Real-World Data Races in Golang&lt;/strong&gt;&lt;/a&gt;中也有提到&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;wg&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;sync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;WaitGroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
	&lt;span class=&#34;kd&#34;&gt;var&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uint64&lt;/span&gt;

	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
			&lt;span class=&#34;nx&#34;&gt;wg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Add&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
			&lt;span class=&#34;nx&#34;&gt;atomic&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;AddUint64&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
			&lt;span class=&#34;nx&#34;&gt;wg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Done&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
		&lt;span class=&#34;p&#34;&gt;}()&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

	&lt;span class=&#34;nx&#34;&gt;wg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Wait&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;v&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;在&lt;code&gt;sync.WaitGroup&lt;/code&gt;结构中拥有一个默认初始化为 0的计数器。可以使用&lt;code&gt;Add(int)&lt;/code&gt;方法递增此计数器，使用&lt;code&gt;Done()&lt;/code&gt;或使用Add负值来递减此计数器。如果想要等到计数器为0，则使用&lt;code&gt;Wait()&lt;/code&gt;阻塞等待并释放goroutine资源，这部分内容在 &lt;a href=&#34;https://weedge.github.io/post/notions/go-tips/go-tips-09-concurrency-practice/#64%E4%BD%BF%E7%94%A8-select-%E5%92%8C-channels-%E6%9C%9F%E5%BE%85%E7%A1%AE%E5%AE%9A%E6%80%A7%E8%A1%8C%E4%B8%BA-%E9%87%8D%E8%A6%81&#34;&gt;#64&lt;/a&gt; tips中也有提到，具体见源码客观分析：https://github.com/golang/go/blob/go1.20/src/sync/waitgroup.go (结合测试用例看疗效更好)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/runtime/sema.go&#34;&gt;https://github.com/golang/go/blob/go1.20/src/runtime/sema.go&lt;/a&gt; (Semaphore实现，&lt;a href=&#34;https://swtch.com/semaphore.pdf&#34;&gt;类似Linux的futex机制&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;了解了WaitGroup,  不难理解例子中的代码问题，将wg.Add(1)放在了goroutine执行的函数中，而没有像正确方法那样，将Add(1)放在goroutine创建启动之前，这样会导致对WaitGroup内部计数器形成了数据竞争，很可能因goroutine调度问题，Add(1)还未来的及调用，从而导致Wait提前返回，这组goroutine中还有在执行中的。&lt;/p&gt;
&lt;p&gt;在 论文&lt;a href=&#34;https://arxiv.org/pdf/2204.00764.pdf&#34;&gt;A Study of Real-World Data Races in Golang&lt;/a&gt; 中 还提到一个问题，就是goroutine中有多个defer 操作，defer Done 操作首先执行了，导致其他defer操作可能还未执行，Wait就已经返回了，导致后面依赖defer操作中的结果,进行判断处理的逻辑会出错。&lt;/p&gt;
&lt;p&gt;tips: 上一节tips中有提到cpu有使用&lt;em&gt;内存屏障(memory barrier)&lt;/em&gt;（也称为&lt;em&gt;内存栅栏(memory fence)&lt;/em&gt;）来确保顺序。Go 为实现内存屏障定义了语言层面的内存模型规范，这里在使用的&lt;code&gt;sync.WaitGroup&lt;/code&gt;，&lt;code&gt;wg.Add&lt;/code&gt; 和 &lt;code&gt;wg.Wait&lt;/code&gt;之间存在 happens-before 关系。&lt;/p&gt;
&lt;p&gt;这个是Go开发人员常见错误。使用&lt;code&gt;sync.WaitGroup&lt;/code&gt;，&lt;code&gt;Add&lt;/code&gt;操作必须在父 goroutine 中启动 goroutine 之前完成，而&lt;code&gt;Done&lt;/code&gt;操作必须在 goroutine 内完成。&lt;/p&gt;
&lt;h3 id=&#34;72忘记-synccond&#34;&gt;72.忘记 sync.Cond&lt;/h3&gt;
&lt;p&gt;在同步原语&lt;code&gt;sync&lt;/code&gt;包中，&lt;code&gt;sync.Cond&lt;/code&gt;可能是最少使用和理解的。但是，它提供了无法通过channel实现的功能。实现类似pub/sub 的多通道广播机制，可以认为pub/sub机制是包括了单通道广播的，sync.Cond的内部实现，其结构中L Locker 用来互斥访问条件逻辑，如果条件不成立，则检测是否copy，copy则直接panic, 否则添加到通知列表中，进行等待；如果条件成立，则执行对应逻辑。唤醒方式分为两种：Signal() 唤醒等待队中的一个goroutine来执行判断； Broadcast 唤醒等待队列中的全部goroutine来执行对应判断逻辑；具体见源码客观分析：https://github.com/golang/go/blob/go1.20/src/sync/cond.go (结合测试用例看疗效更好)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/go/blob/go1.20/src/runtime/sema.go&#34;&gt;https://github.com/golang/go/blob/go1.20/src/runtime/sema.go&lt;/a&gt; (Semaphore实现，&lt;a href=&#34;https://swtch.com/semaphore.pdf&#34;&gt;类似Linux的futex机制&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;对于Signal()方式，和使用 channel chan struct{} 非阻塞发送消息一样&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;nx&#34;&gt;ch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;make&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;chan&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{})&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ch&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}{}:&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;default&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;73不使用errorgroup&#34;&gt;73.不使用errorgroup&lt;/h3&gt;
&lt;p&gt;errorgroup这个包是google对go的一个扩展包：&lt;a href=&#34;https://pkg.go.dev/golang.org/x/sync/errgroup&#34;&gt;golang.org/x/sync/errgroup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;tips: &lt;code&gt;golang.org/x&lt;/code&gt;是一个提供标准库扩展的库。为sync包扩展了一个包：errgroup&lt;/p&gt;
&lt;p&gt;实现逻辑简单，主要是错误处理，如果其中有一个goroutine执行错误，则只记录第一次goroutine执行的错误，通过context告知了cancel状态，这个需要通过select+ctx.Done() 感知到；并且通知对应使用Wait()等待全部goroutine执行完成，并且返回记录的错误； 后面加入sem chan struct{}(token)，用来限制最大执行goroutine数，通过SetLimit来设置，并且提供了TryGo 非阻塞执行。&lt;/p&gt;
&lt;p&gt;如果想加入goroutine的执行超时时间，也是可以做到，只需在使用errgroup前，使用cancelCtx就行，如下代码：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;TestErrGroupWithTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;t&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;testing&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;T&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;cancel&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;WithTimeout&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;TODO&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(),&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Second&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;defer&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;cancel&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;errgroup&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;WithContext&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;;&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;index&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Go&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
			&lt;span class=&#34;k&#34;&gt;select&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
			&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;After&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Duration&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Second&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;):&lt;/span&gt;
				&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;finished:%d\\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
				&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt;
			&lt;span class=&#34;k&#34;&gt;case&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;&amp;lt;-&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Done&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;():&lt;/span&gt;
				&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;canceled:%d\\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;index&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
				&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Err&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
			&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
		&lt;span class=&#34;p&#34;&gt;})&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;if&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;group&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Wait&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;();&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;!=&lt;/span&gt; &lt;span class=&#34;kc&#34;&gt;nil&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;err&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;当然如果想获取goroutine执行的全部错误则需要额外的错误数组来支持，Go中的函数返回错误必须为nil。&lt;/p&gt;
&lt;h3 id=&#34;74复制同步类型-重要&#34;&gt;74.复制同步类型 （重要）&lt;/h3&gt;
&lt;p&gt;sync包提供基本同步原语，例如 mutex, rwmutex, condition variable，waitgroup，pool，map等。对于所有这些结构体，有一个硬性规则要遵循：它们永远不应该被复制。以下是一个常见的错误：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Counter&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;mu&lt;/span&gt;       &lt;span class=&#34;nx&#34;&gt;sync&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Mutex&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;// mu      *sync.Mutex
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;counters&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;NewCounter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Counter&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Counter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;counters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;:&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;map&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}}&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;// return Counter{counters: map[string]int{}, mu: &amp;amp;sync.Mutex{}}
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Counter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;Increment1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;mu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;defer&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;mu&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;c&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;counters&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;++&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;c&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Counter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;Increment2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;name&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;// Same code
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;main&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;counter&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;NewCounter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;

	&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Increment1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;foo&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}()&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;go&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;counter&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Increment1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;bar&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;p&#34;&gt;}()&lt;/span&gt;

	&lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Sleep&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;time&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Millisecond&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;结构体接受者采用值传递，如果两个协程同时使用counter, 会复制一份结构，也会复制互斥锁，导致上锁失败，并发场景运行时出现data race,  data race可以 -race 进行检测；&lt;/p&gt;
&lt;p&gt;通过linter类型工具检查，比如静态编译检查vet，可以直接检查出来进行提示，&lt;code&gt;passes lock by value&lt;/code&gt; or &lt;code&gt;assignment copies lock value to&lt;/code&gt; ；一般IDE开发工具安装了静态检查工具就可以检查出来提示(如果不扫描里面的noCopy成员，则扫不出来错误进行提示)，最好的办法直接使用 go vet 在CI阶段检查，进而保证代码质量；&lt;/p&gt;
&lt;p&gt;这个noCopy的检测是怎么做到的呢？只要是实现了Locker 接口的Lock()和Unlock()方法的结构体，或者结构体成员实现了Locker接口，则可以通过go vet功能，来检查代码中该对象是否有被copy；比如自定义的结构体包涵值传递成员noCopy，noCopy结构体实现了Locker接口，则通过go vet检查是否copy&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// noCopy may be added to structs which must not be copied
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// after the first use.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// See **&amp;lt;https://golang.org/issues/8005#issuecomment-190753527**&amp;gt;
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// for details.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;//
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// Note that it must not be embedded, due to the Lock and Unlock methods.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;noCopy&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;

&lt;span class=&#34;c1&#34;&gt;// Lock is a no-op used by -copylocks checker from `go vet`.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;noCopy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;Lock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt;   &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;noCopy&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;Unlock&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;MyStruct&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
   &lt;span class=&#34;nx&#34;&gt;noValCopy&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;noCopy&lt;/span&gt;
   &lt;span class=&#34;c1&#34;&gt;// Copy *noCopy
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;每当多个 goroutine 访问一个同步共享元素，必须确保它们都依赖于同一个实例。此规则适用于定义的所有同步类型。可以使用指针解决这个问题，结构传递者对象是指针，或者结构成员中的同步共享元素是指针类型。本质上是值传递和指针传递的问题。&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;了解context何时可以取消在传播它时需要注意，避免取消导致未执行完：例如，HTTP 处理程序在发送响应后取消context。&lt;/li&gt;
&lt;li&gt;避免泄漏意味着要注意，无论何时启动 goroutine，都应该有一个最终停止它的计划。&lt;/li&gt;
&lt;li&gt;为了避免 goroutines 和循环变量的错误，创建局部变量或调用函数而不是闭包。&lt;/li&gt;
&lt;li&gt;如果多个选项是可能的，那么理解&lt;code&gt;select&lt;/code&gt;多通道随机选择案例可以防止做出可能导致微妙的并发错误。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;chan struct{}&lt;/code&gt;类型发送通知。&lt;/li&gt;
&lt;li&gt;使用 nil channel应该成为并发工具集的一部分，从select语句中移除操作channel 的 case。&lt;/li&gt;
&lt;li&gt;考虑到问题，仔细决定要使用的正确channel类型。只有无缓冲通道才能提供强大的同步保证。&lt;/li&gt;
&lt;li&gt;应该有充分的理由为缓冲通道指定通道大小。&lt;/li&gt;
&lt;li&gt;意识到字符串格式可能会导致调用现有函数意味着要注意可能的死锁和其他数据竞争。&lt;/li&gt;
&lt;li&gt;并发 append并不总是没有数据竞争；因此，不应在共享切片上同时使用它。&lt;/li&gt;
&lt;li&gt;了解slice和map结构体，具体底层数据结构；对防止常见的数据竞争处理有所帮助。&lt;/li&gt;
&lt;li&gt;要准确使用&lt;code&gt;sync.WaitGroup&lt;/code&gt;，&lt;code&gt;Add&lt;/code&gt;在启动 goroutine 之前调用该方法。&lt;/li&gt;
&lt;li&gt;&lt;code&gt;sync.Cond&lt;/code&gt;可以使用 广播方式向多个 goroutines 发送重复的通知(唤醒)，也可以单播方式想一个goroutine发送通知(唤醒)。&lt;/li&gt;
&lt;li&gt;可以同步一组 goroutines 并使用&lt;code&gt;errgroup&lt;/code&gt;包处理错误和context。&lt;/li&gt;
&lt;li&gt;同步原语类型或者自定类型结构不应copy。&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: 并发概念 55-60 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-08-concurrency-foundations/</link>
      <pubDate>Fri, 17 Feb 2023 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-08-concurrency-foundations/</guid>
      
        <description>&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;h3 id=&#34;55混淆并发和并行&#34;&gt;55.混淆并发和并行&lt;/h3&gt;
&lt;p&gt;这个在处理大数据的场景中经常可以看到，可以这么抽象，比如将一个job 分成 很多的 task 事件， 比如 读取文件 task, 切割文件task, map key task, shuffle key task，reduce key task，sink task 等等，如果这个job 串行执行，同步处理task, 效率会很低，cpu资源也不会充分利用，比如文件io,网络io，系统缺页中断都会反生系统调用(同步或者异步)，这样cpu可能空闲出来了，串行执行的话， 需要等待这次系统调用处理完之后才能继续使用cpu, 所以处理起来很慢，吞吐量很低； 如果改成并发(取决于操作系统调度，基于时间片轮训抢占式调度)，将job进程分成的多个task事件一同工作，如果某个task发生了系统中断，则可以让出cpu给另外一个task来执行，比如读取文件io.Reader，sink io.Writer写入文件时产生了系统中断，则可以保存上下文让出cpu给其他task来执行，这样可以充分利用cpu资源，提高吞吐(这里task不能太多,涉及到上下文切换，反而会降低吞吐，需要需要用户合理编排运行时结构)；当cpu利用上了，那就使用多核cpu来同时处理，进一步提高吞吐(多核涉及到底层 &lt;a href=&#34;https://fgiesen.wordpress.com/2014/07/07/cache-coherency/&#34;&gt;&lt;strong&gt;cpu cache一致性&lt;/strong&gt;&lt;/a&gt; 问题)；单机吞吐上来了，如果数据量非常大，单机优化已经无法存放这么多数据了，那就copy多台机器分布式进行处理(单机变多机，协同和网络问题)；第一次提升使用的就是将job切成多个task一起来处理，就是使用并发机制充分cpu资源；第二次提升则是使用多核，增加cpu资源，将多个task分配到cpu上同时一起做(执行)，即所谓的并行，这样可以单机垂直扩容提升吞吐了；即使存在摩尔定律，但是单机还是有限制；数据无极限，那处理也需要无极限，copy多台机器，组成集群，将单机任务分发到多集群上进行调度执行，充分利用并发并行，利用计算和存储资源，水平扩容，这样就没有资源上的限制了(需要考虑资源的充分利用，因为成本上去了嘛；当然&lt;a href=&#34;https://www.intel.com/content/www/us/en/products/docs/processors/what-is-a-gpu.html&#34;&gt;GPU&lt;/a&gt;的利用应该同样适用，并行能力更强，但是单核计算能力相对cpu弱)。在并发并行处理时，task之间必然会存在协同关系，彼此分工合作，则需要沟通，共同处理共享资源，存在竞争，CSP理论中提倡通过沟通来共享资源，在Go中通过channel来协同，也有相关sync库来处理同步；分布式多机沟通则通过rpc和消息队列；其中涉及到分布式调度和计算。 这种并发和并行模式在开店做生意，银行排队，工厂流水线中都可以看到相同的处理模式。&lt;/p&gt;
&lt;p&gt;回到正题，引用Go设计者的一句话概括：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;Concurrency is about dealing with lots of things at once. Parallelism is about doing lots of things at once.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;—Rob Pike&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;并发是一次处理很多事情，并行是一次执行做很多事情；&lt;/p&gt;
&lt;p&gt;并发和并行是不同的。并发是关于结构的，可以通过引入分离并发线程可以处理的不同步骤，将顺序实现更改为并发实现。同时，并行性是关于执行的，可以通过添加更多并行线程在步骤级别使用它。理解这两个概念是成为一名熟练的 Gopher 的基础。&lt;/p&gt;
&lt;p&gt;附：&lt;strong&gt;&lt;a href=&#34;https://go.dev/blog/waza-talk&#34;&gt;Concurrency is not parallelism&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;
&lt;h3 id=&#34;56认为并发总是更快&#34;&gt;56.认为并发总是更快&lt;/h3&gt;
&lt;p&gt;在考虑并发性时，有两种类型的工作负载需要理解。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CPU-Bound&lt;/strong&gt;：是一种永远不会造成 Goroutines 自然地进入和退出等待状态的情况的工作负载。是不断进行计算的job。将 Pi 计算到第 N 位的线程将受 CPU-Bound。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;IO-Bound&lt;/strong&gt;：是一种导致 Goroutines 自然进入等待状态的工作负载。包括请求通过网络访问资源，或对操作系统进行系统调用(同步/异步)，或等待事件发生。需要读取文件的 Goroutine 是 IO-Bound。将导致 Goroutine 等待的同步事件（互斥锁、原子）包含在该类别中。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;对于受CPU-Bound的工作负载，需要并行性来利用并发性。处理多个 Goroutines 的单个操作系统/硬件线程效率不高，因为 Goroutines 不会作为其工作负载的一部分进入和退出等待状态。拥有比操作系统/硬件线程更多的 Goroutine 会减慢工作负载的执行速度，因为将 Goroutine 移入和移出操作系统线程会产生延迟成本（花费的时间）。上下文切换正在为工作创建一个“Stop The World”事件，因为在切换期间任何工作负载都没有被执行，否则它可能会被执行。&lt;/p&gt;
&lt;p&gt;对于受IO-Bound的工作负载，不需要并行性来使用并发。单个操作系统/硬件线程可以高效地处理多个 Goroutines，因为 Goroutines 作为其工作负载的一部分自然地进入和退出等待状态。拥有比操作系统/硬件线程更多的 Goroutine 可以加快工作负载的执行速度，因为将 Goroutine 移入和移出操作系统线程的延迟成本不会产生“Stop The World”事件。工作负载自然停止，这允许不同的 Goroutine 有效地利用相同的操作系统/硬件线程，而不是让操作系统/硬件线程闲置。&lt;/p&gt;
&lt;p&gt;怎么知道每个硬件线程有多少 Goroutines 提供最佳吞吐量？Goroutines 太少，有更多的空闲时间；太多的 Goroutines 有更多的上下文切换延迟时间。如果不确定是否并发会更快，正确的方法可能是从一个简单的顺序版本开始，然后使用分析和基准测试，进行调优。&lt;/p&gt;
&lt;p&gt;附： &lt;a href=&#34;https://www.ardanlabs.com/blog/2018/12/scheduling-in-go-part3.html&#34;&gt;&lt;strong&gt;Scheduling In Go : Part III - Concurrency&lt;/strong&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;57对何时使用channel或mutex感到困惑&#34;&gt;57.对何时使用channel或mutex感到困惑&lt;/h3&gt;
&lt;p&gt;channel最适合Goroutine之间传递数据所有权、分配工作单元和传达异步结果等情况，通过沟通来共享资源；&lt;/p&gt;
&lt;p&gt;想要共享状态或访问共享资源时，sync包中的mutex互斥锁同步原语会确保对该资源的独占访问。虽然channel也可以保证共享资源的互斥访问，但是与mutex相比，channel 会导致性能下降；当只需要锁定少量共享资源时，使用 mutex 非常有用。&lt;/p&gt;
&lt;h3 id=&#34;58不理解竞争race问题&#34;&gt;58.不理解竞争race问题&lt;/h3&gt;
&lt;p&gt;当则编写的并发应用程序中工作时，了解数据竞争 data race 不同于竞争条件 data condition 是很重要的。当多个 goroutine 同时访问同一内存位置并且其中至少一个正在写入时，就会发生数据竞争。数据竞争意味着意外行为。但是，无数据竞争的应用程序并不一定意味着确定性结果。一个应用程序可以没有数据竞争，但仍然有依赖于不受控制的事件的行为（例如 goroutine 执行，消息发布到通道的速度，或者对数据库的调用持续多长时间），这是一个竞争条件。理解这两个概念对于精通并发应用程序的设计至关重要。&lt;/p&gt;
&lt;h4 id=&#34;go-内存模型&#34;&gt;Go 内存模型&lt;/h4&gt;
&lt;p&gt;Go 内存模型是一种规范，它定义了在不同的 goroutine 中写入相同变量后可以保证从一个 goroutine 中的变量读取的条件. 换句话说，Go开发人员应牢记内存模型规范，避免做出可能导致数据竞争、竞争条件的错误假设。具体细节：&lt;a href=&#34;https://research.swtch.com/gomm&#34;&gt;https://research.swtch.com/gomm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;tips: 由于多核处理器cpu之间独立的L1/L2 cache，会出现cache line不一致的问题，为了解决这个问题，有相关协议模型，比如MESI协议来保证cache数据一致，同时由于CPU对「缓存一致性协议」进行的异步优化，对写和读分别引入了「store buffer」和「invalid queue」，很可能导致后面的指令查不到前面指令的执行结果（各个指令的执行顺序非代码执行顺序），这种现象很多时候被称作「CPU乱序执行」，为了解决乱序问题（也可以理解为可见性问题，修改完没有及时同步到其他的CPU），又引出了「内存屏障」的概念；内存屏障可以分为三种类型：写屏障，读屏障以及全能屏障（包含了读写屏障），屏障可以简单理解为：在操作数据的时候，往数据插入一条”特殊的指令”。只要遇到这条指令，那前面的操作都得「完成」。CPU当发现写屏障指令时，会把该指令「之前」存在于「store Buffer」所有写指令刷入高速缓存。就可以让CPU修改的数据马上暴露给其他CPU，达到「写操作」可见性的效果。读屏障也是类似的：CPU当发现读屏障的指令时，会把该指令「之前」存在于「invalid queue」所有的指令都处理掉。通过这种方式就可以确保当前CPU的缓存状态是准确的，达到「读操作」一定是读取最新的效果。由于不同CPU架构的缓存体系不一样、缓存一致性协议不一样、重排序的策略不一样、所提供的内存屏障指令也有差异，所以一些语言c++/java/go/rust 都有实现自己的内存模型，应该相互都有些借鉴吧。&lt;/p&gt;
&lt;h3 id=&#34;59不了解工作负载类型的并发影响&#34;&gt;59.不了解工作负载类型的并发影响&lt;/h3&gt;
&lt;p&gt;上文提到到工作负载分两种：CPU-Bound 和 IO-Bound 已经说明了一些问题，文中使用的工作池，也是依赖于使用场景的工作负载类型是CPU-Bound还是 IO-Bound ; 如果 worker 执行的工作负载是 I/O-bound，则该值主要取决于外部系统。相反，如果工作量是受 CPU 限制，goroutine 的最佳数量接近于可用线程的数量。在设计并发应用程序时，了解工作负载类型（I/O 或 CPU）至关重要。&lt;/p&gt;
&lt;p&gt;大多数情况下，应该通过基准来验证假设。并发不是直截了当的，很容易做出草率的假设，结果证明是无效的。&lt;/p&gt;
&lt;h3 id=&#34;60误解-go-context&#34;&gt;60.误解 Go Context&lt;/h3&gt;
&lt;p&gt;文中主要是介绍了各种context的使用场景，&lt;code&gt;WithCancel&lt;/code&gt; ，&lt;code&gt;WithTimeout&lt;/code&gt;，&lt;code&gt;WithDeadline&lt;/code&gt;，&lt;code&gt;WithValue&lt;/code&gt;，以及1.20新加入的 &lt;code&gt;WithCancelCause&lt;/code&gt;返回CancelCauseFunc 可以记录Cancel导致的错误原因，通过&lt;code&gt;Cause&lt;/code&gt;获取到；具体可以在开发文档中学习即可： &lt;a href=&#34;https://pkg.go.dev/context&#34;&gt;https://pkg.go.dev/context&lt;/a&gt; ;&lt;/p&gt;
&lt;p&gt;使用Context的程序应该遵循这些规则，以保持接口在包之间的一致性，并启用静态分析工具来检查context传播：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;传递 Context 时，而应该显式地传入函数，并且放在参数列表第一个位置，通常命名为 ctx；&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;DoSomething&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ctx&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Context&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;arg&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;Arg&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;error&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;// ... use ctx ...
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;
&lt;li&gt;不要传递 nil 的 Context，在不确定的时候应该传递 &lt;code&gt;context.TODO()&lt;/code&gt;；而不是传递空上下文&lt;code&gt;context.Background&lt;/code&gt;。&lt;code&gt;context.TODO()&lt;/code&gt;返回一个空上下文，但在语义上，它表示要使用的上下文不清楚或尚不可用（例如，尚未由父级传播）。&lt;/li&gt;
&lt;li&gt;使用 context 的 Value 相关方法时只应该用于传递和请求相关的元数据(metadata)，不要用它传递一些可选参数；比如traceId, spanId, 建设微服务经常会用到。&lt;/li&gt;
&lt;li&gt;WithValue中的key, 必须可比较的，并且不应是字符串类型或任何其他内置类型，以避免使用context的包之间发生冲突；最佳做法是创建一个未导出的自定义类型；比如在包中定义 &lt;code&gt;type favContextKey string&lt;/code&gt; ，即使另一个包也用&lt;code&gt;favContextKey&lt;/code&gt; 这个名字，不是同一个key了。这个在http中间件里经常出现，记录在访问日志中记录相关信息。&lt;/li&gt;
&lt;li&gt;同一个 context 可以传递到不同的 goroutine 中，且在多个 goroutine 可以安全访问。&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;了解并发和并行之间的根本区别是 Go 开发人员知识的基石。并发是关于结构的，而并行是关于执行的。&lt;/li&gt;
&lt;li&gt;要成为熟练的开发人员，必须承认并发并不总是更快。涉及最小工作负载并行化的解决方案不一定比顺序实施更快。对顺序解决方案与并发解决方案进行基准测试应该是验证假设的方法。&lt;/li&gt;
&lt;li&gt;在channel和mutex之间做出决定时，了解 goroutine 交互也很有帮助。通常，对于共享资源变量， goroutine竞争访问时， 需要同步，使用同步机制sync包中mutex；对于 goroutine之间需要协调和编排，则使用channel。&lt;/li&gt;
&lt;li&gt;精通并发也意味着理解数据竞争和竞争条件是不同的概念。当多个 goroutine 同时访问同一内存位置并且其中至少一个正在写入时，就会发生数据竞争。同时，无数据竞争并不一定意味着确定性执行。当行为取决于无法控制的事件的顺序或时间时，这就是竞争条件。&lt;/li&gt;
&lt;li&gt;了解 Go 内存模型以及在排序和同步方面的底层保证对于防止可能的数据竞争和竞争条件至关重要。&lt;/li&gt;
&lt;li&gt;创建一定数量的 goroutine 时，请考虑工作负载类型。创建 CPU-bound goroutines 意味着将这个数字限制在变量附近&lt;code&gt;GOMAXPROCS&lt;/code&gt;（默认情况下基于主机上的 CPU 核心数）。创建 I/O-bound goroutines 取决于其他因素，例如外部系统。&lt;/li&gt;
&lt;li&gt;Go Context也是 Go 并发的基石之一。Context允许携带截止日期、取消信号、键值元数据列表(metadata)。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: 错误管理 48-54 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-07-error-management/</link>
      <pubDate>Thu, 16 Feb 2023 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-07-error-management/</guid>
      
        <description>&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;h3 id=&#34;48panic&#34;&gt;48.panic&lt;/h3&gt;
&lt;p&gt;Go 新手对错误处理感到困惑是很常见的。在 Go 中，错误通常由返回的函数或方法管理类型&lt;code&gt;error&lt;/code&gt;作为最后一个参数（这个是代码风格，error可以作为第一个参数）；先了解下panic调用时的情况：&lt;/p&gt;
&lt;p&gt;一旦&lt;code&gt;panic&lt;/code&gt;被调用，它就会停止当前函数的执行并向上调用栈，直到当前 goroutine 出栈返回或被&lt;code&gt;recover&lt;/code&gt;捕获；值得注意点是当前协程函数中panic了，如果有defer函数还是会执行，所以一般使用defer func(){recover()} 的形式来防止协程panic,  而且只能recover住当前协程panic, 这是因为当前协程未使用recover时已经出栈返回，函数栈帧已经无效了，调用者是没法recover的。&lt;/p&gt;
&lt;p&gt;panic一般使用在程序启动时，一个依赖项未能初始化它时，可以使用，但是一般的做法是打印fatal日志退出；在服务启动之后，不能panic，一般记录错误日志，并且在服务运行过程中，需要对当前协程 panic recover住，以防常见的空指针访问数据，服务down掉的情况。&lt;/p&gt;
&lt;h3 id=&#34;49忽略何时error-wrap&#34;&gt;49.忽略何时error wrap&lt;/h3&gt;
&lt;p&gt;在处理错误时，需要向错误添加额外的上下文和/或将错误标记为特定类型。分为三种error情况进行使用：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果需要标记错误，应该创建一个自定义错误类型，比如errorCode。&lt;/li&gt;
&lt;li&gt;如果只想添加额外的上下文，应该使用&lt;code&gt;fmt.Errorf %w&lt;/code&gt;格式指令生成wrapError类型错误，因为它不需要创建新的错误类型；wrapError会产生潜在的耦合，它使源错误通过Unwrap可供调用者使用。&lt;/li&gt;
&lt;li&gt;如果不想使用源错误追溯，不应该使用wrapError，而是错误转换，例如使用&lt;code&gt;fmt.Errorf %v&lt;/code&gt;格式指令生成新的errorString类型错误&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;50不准确地检查error类型-重要&#34;&gt;50.不准确地检查error类型 (重要)&lt;/h3&gt;
&lt;p&gt;这个其实就是弄懂Go1.13引入的wrapError类型错误，这个错误类型因为是层层包裹源错误，如果将以前老的代码返回的错误重构成wrapError的话，在调用的地方判断err的时候 需要用 error.Is 错误值和 error.As 错误类型 函数进行判断，Is是从error 链中递归地Unwrap err遍历是否有对应目标error值,  As是从error 链中递归地Unwrap err并查看其中一个错误是否是特定error类型；这两个函数都是用了反射，如果错误链路长的话，会有一些性能折损。&lt;/p&gt;
&lt;h3 id=&#34;51检查error值不准确-重要&#34;&gt;51.检查error值不准确 （重要）&lt;/h3&gt;
&lt;p&gt;这里介绍的是wrapError类型错误在==比较错误值时，应该采用error.Is来判断。&lt;/p&gt;
&lt;h3 id=&#34;52处理error两次&#34;&gt;52.处理error两次&lt;/h3&gt;
&lt;p&gt;这个在工程项目中，使用Go开发，打日志经常出现错误打印多条的情况，对于并发服务，如果不用logId,traceId来辅助定位，一般很难定位到一次逻辑交互的多条日志信息。这里的处理方式将多条错误通过wrap的方式 一条打印出整条逻辑链路的错误信息出来。工程实践小细节吧，如果考虑性能影响，需要折中考虑了。&lt;/p&gt;
&lt;h3 id=&#34;53不处理错误-工程规范&#34;&gt;53.不处理错误 (工程规范）&lt;/h3&gt;
&lt;p&gt;忽略错误都应该使用_标识符显式标示，在不处理错误的函数调用地方，加上对应注释上下文逻辑说明为什么可以忽略。。。&lt;/p&gt;
&lt;h3 id=&#34;54不处理延迟错误&#34;&gt;54.不处理延迟错误&lt;/h3&gt;
&lt;p&gt;如果函数返回的错误需要考虑defer函数中的函数调用是否返回错误，则在defer闭包函数中先判断函数中的err是否不为nil, 是则直接闭包函数返回，否则将defer 闭包函数中处理的逻辑函数错误赋值给err。如果想忽略它，使用_标识符标示。&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;panic&lt;/code&gt;是 Go 中处理错误的一个选项。它应该只在不可恢复的情况下谨慎使用：例如，发出程序员错误信号或加载强制依赖项失败时。&lt;/li&gt;
&lt;li&gt;包装错误允许标记错误和/或提供额外的上下文。但是，错误包装会产生潜在的耦合，因为它使源错误可供调用者使用。如果想防止这种情况发生，请不要使用错误包装。&lt;/li&gt;
&lt;li&gt;如果使用 Go 1.13 &lt;code&gt;fmt.Errorf %w&lt;/code&gt;指令返回wrapError类型错误，则必须分别使用&lt;code&gt;errors.As&lt;/code&gt; 或者&lt;code&gt;errors.Is&lt;/code&gt;将错误与类型或值进行比较。&lt;/li&gt;
&lt;li&gt;要传达预期的错误，请使用错误哨兵（错误值）。意外错误应该是特定的错误类型。&lt;/li&gt;
&lt;li&gt;在大多数情况下，一个错误应该只处理一次。记录错误就是处理错误。因此，必须在记录或返回错误之间做出选择。在许多情况下，错误包装是解决方案，因为它允许为错误提供额外的上下文并返回源错误。&lt;/li&gt;
&lt;li&gt;忽略错误，无论是在函数调用期间还是在函数中&lt;code&gt;defer&lt;/code&gt;，都应该使用_标识符显式标示。否则，未来的读者可能会混淆这是故意的还是失误。&lt;/li&gt;
&lt;li&gt;在许多情况下，不应该忽略函数返回的错误&lt;code&gt;defer&lt;/code&gt;。根据上下文，直接处理它或将其传播给调用者。如果想忽略它，使用_标识符标示。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: 函数和方法 42-47 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-06-functions-methods/</link>
      <pubDate>Wed, 15 Feb 2023 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-06-functions-methods/</guid>
      
        <description>&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;h3 id=&#34;42结构体方法不知道使用哪种类型的接收者&#34;&gt;42.结构体方法不知道使用哪种类型的接收者&lt;/h3&gt;
&lt;p&gt;文中说了很多，感觉为了凑数，主要就是围绕着值传递还是指针传递，值传递给接收者，如果结构体中没有指针类型成员，则不会改变接收者的数据；如有指针传递，则会改变。选择哪种传递方式，主要取决于结构体中的成员是否都是只读操作，如果是只读，使用值传递，否则使用指针传递。至于是否大结构体数据，这个由结构体中的成员来决定，是否有指针成员；&lt;/p&gt;
&lt;h3 id=&#34;43从不使用命名结果参数--建议&#34;&gt;43.从不使用命名结果参数  (建议)&lt;/h3&gt;
&lt;p&gt;主要是为了函数/结构体方法返回的值，更具代码可读性，数据类型本身不能表示具体含义，除非type 别名； 在大多数情况下，在接口定义的上下文中使用命名结果参数可以提高可读性而不会导致任何副作用。但是在方法实现的上下文中没有严格的规则。 当有明显的好处时，应该谨慎使用命名结果参数。&lt;/p&gt;
&lt;h3 id=&#34;44具有命名结果参数的意外副作用-建议&#34;&gt;44.具有命名结果参数的意外副作用 （建议）&lt;/h3&gt;
&lt;p&gt;如果使用命名的结构参数，声明了结果的变量名，在函数方法体内进行初始定义，使用时注意不用被同名覆盖，特别是在处理错误逻辑时，错误的返回情况，所以 使用命名结果参数时保持谨慎，以避免潜在的副作用 。&lt;/p&gt;
&lt;h3 id=&#34;45返回一个-nil-接口-重要&#34;&gt;45.返回一个 nil 接口 (重要)&lt;/h3&gt;
&lt;p&gt;在处理自定义实现error接口的错误体结构，判断错误时需要注意的地方，如果接口error 为未赋值的自定义错误体结构，虽然错误体结构为nil，但是interface error不为nil, 其interface error 内部指向的错误体结构为nil， 所以需要判断erro为nil时， 直接返回nil值, 而不是为nil的错误体结构体指针；这个是Go中经常会遇到的坑。这种情况也可能发生在任何使用指针接收者实现的接口，需要保持谨慎。&lt;/p&gt;
&lt;h3 id=&#34;46使用文件名作为函数输入&#34;&gt;46.使用文件名作为函数输入&lt;/h3&gt;
&lt;p&gt;这个是属于设计问题了，函数操作的是共性数据时，应该采用接口作为函数的输入，以便解耦具体实现，方便测试和扩展，比如文中所提到扫描数据内容的行数，属于读操作，可以使用&lt;code&gt;io.Reader&lt;/code&gt; 接口作为参数，如果是写操作，使用io.Writer 等等，io包中封装了不同接口组合; bufio包中有对应方法接受接口参数进行读写操作；这样数据源只要实现对应读写接口方法即可。&lt;/p&gt;
&lt;h3 id=&#34;47忽略defer参数和接收者的计算方式-重要&#34;&gt;47.忽略defer参数和接收者的计算方式 (重要)&lt;/h3&gt;
&lt;p&gt;在传递defer 函数参数时，函数的参数是值拷贝传递，传入的值为当前值，比如defer f(a) 在f的定义中,传入参数对a值进行了值拷贝，所以外部a值怎么变，已经和defer函数中的参数值已经没有关系了，如果想继续使用的话， 提供了两种方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;defer 函数参数采用指针传递，比如f(&amp;amp;a)，这样指向同一地址空间，需要函数传入指针类型，这个对于已有封装好的函数是不可行的。&lt;/li&gt;
&lt;li&gt;使用闭包函数，defer func(){f(a)}() 这样可以引用到在return之前a的最终值，如果改成 defer func(a int){f(a)}(a), 则和原来值传递的情况一样。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;注意的地方，如果defer的是结构体实例的方法，比如 defer s.f() ，如果s是指针传递，则后续结构体实例s中的成员有变化，也会影响到defer s.f(); 如果采用值传递给接受者s, 则是当前s的值拷贝，后续怎么变都不影响；&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;应该根据类型、是否必须改变、是否包含无法复制的字段以及对象有多大等因素来决定是使用值还是指针接收器。如有疑问，请使用指针接收器。&lt;/li&gt;
&lt;li&gt;使用命名结果参数是提高函数/方法可读性的有效方法，尤其是在多个结果参数具有相同类型的情况下。在某些情况下，这种方法也很方便，因为命名的结果参数被初始化为它们的零值。但要注意潜在的副作用。&lt;/li&gt;
&lt;li&gt;返回接口时，注意不要返回一个 nil 指针，而是一个显式的 nil 值。否则，可能会导致意想不到的后果，因为调用者将收到一个非零值。&lt;/li&gt;
&lt;li&gt;将函数设计为接收&lt;code&gt;io.Reader&lt;/code&gt;类型而不是文件名可以提高函数的可重用性并使测试更容易。&lt;/li&gt;
&lt;li&gt;传递指向函数的指针&lt;code&gt;defer&lt;/code&gt;和将调用封装在闭包中是克服接收者参数立即求值的两种解决方案。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: string 36-41 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-05-strings/</link>
      <pubDate>Tue, 14 Feb 2023 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-05-strings/</guid>
      
        <description>&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;p&gt;在 Go 中，string是一种不可变的数据结构，包含以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;指向不可变字节序列的指针，指向一个byte类型的数组&lt;/li&gt;
&lt;li&gt;此序列中的总字节数&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;string在Go中的内部结构是&lt;code&gt;reflect.StringHeader&lt;/code&gt;位于&lt;code&gt;reflect/value.go&lt;/code&gt;&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;c1&#34;&gt;// StringHeader is the runtime representation of a string.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// It cannot be used safely or portably and its representation may
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// change in a later release.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// Moreover, the Data field is not sufficient to guarantee the data
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// it references will not be garbage collected, so programs must keep
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;// a separate, correctly typed pointer to the underlying data.
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;StringHeader&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;Data&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;uintptr&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;Len&lt;/span&gt;  &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;c1&#34;&gt;//uintptr  an unsigned integer large enough to store the uninterpreted bits of a pointer value
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;已通过unsafe.Poniter显示的将 string转换成&lt;code&gt;reflect.StringHeader&lt;/code&gt; 结构，进而可以获取结构中的Data指正，然后通过unsafe.Poniter显示转成数组，比如[5]byte， 数组大小不一定等于原始string长度，即使越界访问，因为是只读，如果写的话会出现panic，所以可以越界这样获取； 代码如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;ViewStringStruct&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;()&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;s&#34;&gt;&amp;#34;hello&amp;#34;&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;sh&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;reflect&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;StringHeader&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;0x%x\\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;sh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;sh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Len&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// 5
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;ptr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;sh&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Data&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;//arrPtr := (*[]byte)(ptr) // panic
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;//arrPtr := (*[3]byte)(ptr)
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;c1&#34;&gt;//arrPtr := (*[100]byte)(ptr) // access violation, string just only read, so is ok
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;arrPtr&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;5&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;ptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Println&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;arrPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;c1&#34;&gt;// [104 101 108 108 111]
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;	&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;%s\\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;arrPtr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
	&lt;span class=&#34;c1&#34;&gt;//arrPtr[3] = 100 // panic, string cann&amp;#39;t change
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;[]byte 和 string的相互转换，在读取字符串的场景下经常使用到：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;String&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;b&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;b&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;kd&#34;&gt;func&lt;/span&gt; &lt;span class=&#34;nf&#34;&gt;Str2Bytes&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;kt&#34;&gt;string&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uintptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;h&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uintptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;],&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;x&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]}&lt;/span&gt;
	&lt;span class=&#34;k&#34;&gt;return&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;byte&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;h&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h3 id=&#34;36不理解rune的概念-重要&#34;&gt;36.不理解rune的概念 （重要）&lt;/h3&gt;
&lt;p&gt;字符集和编码之间的区别：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;字符集(charset)是一组字符。例如，Unicode 字符集包含 2^21 个字符。&lt;/li&gt;
&lt;li&gt;编码(encoding)是字符列表的二进制转换。例如，UTF-8 是一种编码标准，能够将所有 Unicode 字符编码为可变字节数（从 1 到 4 字节）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;UTF-8 将字符编码为 1 到 4 个字节，因此最多为 32 位, rune 是 int32的别名；需要清楚以下概念：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;字符集是一组字符，而编码描述了如何将字符集转换为二进制。&lt;/li&gt;
&lt;li&gt;在 Go 中，string引用任意字节的不可变切片。&lt;/li&gt;
&lt;li&gt;Go 源代码使用 UTF-8 编码。因此，所有字符串文字都是 UTF-8 字符串。但是因为字符串可以包含任意字节，如果它是从其他地方（不是源代码）获得的，则不能保证它是基于 UTF-8 编码的。&lt;/li&gt;
&lt;li&gt;rune对应于 Unicode 码位(code point)的概念，请参考：&lt;a href=&#34;https://en.wikipedia.org/wiki/Code_point&#34;&gt;code point&lt;/a&gt;，由单个值表示。&lt;/li&gt;
&lt;li&gt;使用 UTF-8，可以将 Unicode 码位(code point)编码为 1 到 4 个字节。&lt;/li&gt;
&lt;li&gt;在 Go 中使用&lt;code&gt;len&lt;/code&gt;字符串返回字节数，而不是rune数。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果想准确获取到有符文(rune)字符串的长度，可以使用&lt;code&gt;utf8.RuneCountInString&lt;/code&gt; 函数&lt;/p&gt;
&lt;h3 id=&#34;37不准确的字符串迭代&#34;&gt;37.不准确的字符串迭代&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;range&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
    &lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;position %d: %c\\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;i&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上代码，没有遍历每个rune，而是迭代rune的每个起始索引；&lt;/p&gt;
&lt;p&gt;如果想遍历字符串的符文(rune)，可以使用&lt;code&gt;range&lt;/code&gt;直接在字符串上循环，必须记住，**索引对应的不是符文索引，而是符文字节序列的起始索引；**因为一个符文可以由多个字节组成，如果要访问符文本身，应该使用 的值变量&lt;code&gt;range&lt;/code&gt;，而不是字符串中的索引;&lt;/p&gt;
&lt;p&gt;如果想获取第i个字符串的符文(rune)，在大多数情况下应该将字符串转换为一段 runes。&lt;/p&gt;
&lt;h3 id=&#34;38滥用-trim-函数&#34;&gt;38.滥用 trim 函数&lt;/h3&gt;
&lt;p&gt;Go中的strings包，开发者可能经常混淆使用TrimRight 和 TrimSuffix， 或者 TrimLeft 和 TrimPrefix&lt;/p&gt;
&lt;p&gt;TrimRight向后遍历每个符文；如果符文是提供的集合的一部分，则该函数将其删除。如果不是，该函数将停止迭代并返回剩余的字符串。TrimLeft 向前遍历同理。  Trim 函数 两边遍历也是一样。&lt;/p&gt;
&lt;p&gt;如果想匹配整体的字符串进行删除的话， 应该使用 TrimSuffix 和 TrimPrefix，如果两边移除分别调用这两个方法。&lt;/p&gt;
&lt;h3 id=&#34;39优化不足的字符串连接&#34;&gt;39.优化不足的字符串连接&lt;/h3&gt;
&lt;p&gt;如果使用 s += str 的方式连接字符串，会有性能问题，因为字符的数据是不可变的，每次字符串 + 连接操作都会重新分配一次内存空间(allocator)；&lt;/p&gt;
&lt;p&gt;应该使用 strings.Builder 结构来拼接字符串， Builder结构中有一个byte切片 buf []byte用于数据拼接，WriteString 内部使用append来操作，前面提到append操作会出发自动扩容，这样不用每次拼接的时候分配一次新的内存空间，提高了性能； 如果可以获取到拼接字符串的长度，那就可以直接通过 Grow函数来一次初始化拼接buf byte切片内存空间，这样性能可以得到进一步的提升(与 21. 切片初始化效率低下 分析一样)。类似WriteString方法对应string 类型，还有一下三总方法：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;字节切片使用&lt;code&gt;Write&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;单字节使用&lt;code&gt;WriteByte&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;单个符文使用&lt;code&gt;WriteRune&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当然如果拼接的短字符串就那么几个，则没有必要使用strings.Builder 结构来拼接字符串，性能提升可以忽略，但是代码量可读性方面就降低了，可读性不如使用运算符&lt;code&gt;+=&lt;/code&gt;或&lt;code&gt;fmt.Sprintf&lt;/code&gt;。&lt;/p&gt;
&lt;h3 id=&#34;40无用的字符串转换&#34;&gt;40.无用的字符串转换&lt;/h3&gt;
&lt;p&gt;比如 string 转[]byte,  []byte 转string， 如果是直接 []byte(string) 或者 string([]byte)，转换都会有额外的内存分配，而且转换后的string是不可变的； 所以在进行字符串操作的时候，尽量都使用[]byte类型，避免转换string带来的额外操作，&lt;code&gt;strings&lt;/code&gt;包也有替代品包&lt;code&gt;bytes&lt;/code&gt;，大多数 I/O Buffer 都是操作 &lt;code&gt;[]byte&lt;/code&gt;，字符串的拼接Builder结构也是对[]byte的操作。&lt;/p&gt;
&lt;h3 id=&#34;41子字符串和内存泄漏&#34;&gt;41.子字符串和内存泄漏&lt;/h3&gt;
&lt;p&gt;在 Go 中使用子字符串操作时，字符串的结构可知：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;提供的间隔是基于字节数，而不是符文数。&lt;/li&gt;
&lt;li&gt;子字符串操作可能会导致内存泄漏，因为生成的子字符串将与初始字符串共享相同的底层数组。&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;防止这种情况发生的解决方案是手动执行字符串复制，或者从 Go 1.18 开始引入&lt;code&gt;strings.Clone&lt;/code&gt;。&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;了解符文对应于 Unicode 码位(code point)的概念，它可以由多个字节组成，应该是 Go 开发人员准确处理字符串的核心知识的一部分。&lt;/li&gt;
&lt;li&gt;使用&lt;code&gt;range&lt;/code&gt;运算符迭代字符串会迭代符文，其索引对应于符文字节序列的起始索引。要访问特定的符文索引（例如第三个符文），请将字符串转换为&lt;code&gt;[]rune&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;strings.TrimRight&lt;/code&gt;/&lt;code&gt;strings.TrimLeft&lt;/code&gt;删除给定集合中包含的所有向后/向前符文返回，而&lt;code&gt;strings.TrimSuffix&lt;/code&gt;/&lt;code&gt;strings.TrimPrefix&lt;/code&gt;删除提供后缀/前缀的字符串&lt;code&gt;返回&lt;/code&gt;。&lt;/li&gt;
&lt;li&gt;应该连接字符串列表&lt;code&gt;strings.Builder&lt;/code&gt;以防止在每次迭代期间分配新字符串。&lt;/li&gt;
&lt;li&gt;记住&lt;code&gt;bytes&lt;/code&gt;包提供与包相同的操作&lt;code&gt;strings&lt;/code&gt;可以帮助避免额外的字节/字符串转换。&lt;/li&gt;
&lt;li&gt;使用副本而不是子字符串可以防止内存泄漏，因为子字符串操作返回的字符串将由相同的字节数组支持。&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>Go tips-笔记: 控制语句 30-35 mistakes</title>
      <link>https://weedge.github.io/post/notions/go-tips/go-tips-04-control-structures/</link>
      <pubDate>Tue, 14 Feb 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/notions/go-tips/go-tips-04-control-structures/</guid>
      
        <description>&lt;h2 id=&#34;笔记&#34;&gt;笔记&lt;/h2&gt;
&lt;h3 id=&#34;30忽略了元素在-for-range循环中被复制-重要&#34;&gt;30.忽略了元素在 for range循环中被复制 (重要)&lt;/h3&gt;
&lt;p&gt;需要注意，&lt;code&gt;range&lt;/code&gt;循环中的值元素是一个复制的副本。因此，如果值是需要改变结构，只会更新副本，而不是元素本身，除非修改的值或字段是指针。在经典for循环或者for range循环中，通过索引访问元素来进行修改。&lt;/p&gt;
&lt;h3 id=&#34;31忽略了参数在for-range循环中的计算方式-重要&#34;&gt;31.忽略了参数在for range循环中的计算方式 (重要)&lt;/h3&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; class=&#34;chroma&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span class=&#34;kd&#34;&gt;type&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;slice&lt;/span&gt; &lt;span class=&#34;kd&#34;&gt;struct&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;array&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;Pointer&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;len&lt;/span&gt;   &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;
	&lt;span class=&#34;nx&#34;&gt;cap&lt;/span&gt;   &lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;

&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;[]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;int&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;2&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;span class=&#34;k&#34;&gt;for&lt;/span&gt; &lt;span class=&#34;k&#34;&gt;range&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;{&lt;/span&gt;
		&lt;span class=&#34;c1&#34;&gt;// debug check slice array ptr (bp[0]), 
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;		&lt;span class=&#34;c1&#34;&gt;// if append happen slicegrow, array ptr change -&amp;gt; new array
&lt;/span&gt;&lt;span class=&#34;c1&#34;&gt;&lt;/span&gt;		&lt;span class=&#34;nx&#34;&gt;bp&lt;/span&gt; &lt;span class=&#34;o&#34;&gt;:=&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;*&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;3&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;]&lt;/span&gt;&lt;span class=&#34;kt&#34;&gt;uintptr&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;unsafe&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Pointer&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;o&#34;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s1&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;))&lt;/span&gt;
		&lt;span class=&#34;nx&#34;&gt;fmt&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;.&lt;/span&gt;&lt;span class=&#34;nf&#34;&gt;Printf&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;s&#34;&gt;&amp;#34;0x%x\\n&amp;#34;&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;nx&#34;&gt;bp&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;[&lt;/span&gt;&lt;span class=&#34;mi&#34;&gt;0&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;])&lt;/span&gt;

    &lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt; &lt;span class=&#34;p&#34;&gt;=&lt;/span&gt; &lt;span class=&#34;nb&#34;&gt;append&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;(&lt;/span&gt;&lt;span class=&#34;nx&#34;&gt;s&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;,&lt;/span&gt; &lt;span class=&#34;mi&#34;&gt;10&lt;/span&gt;&lt;span class=&#34;p&#34;&gt;)&lt;/span&gt;
&lt;span class=&#34;p&#34;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;notice&lt;/strong&gt;： 这段代码在原文中分析过程是有误的，但不影响整体结果；range s 之后会发生值拷贝出现copy s, 在append之前，copy s 和 s的array ptr指向同一地址空间；当发生append之后，s 发生来扩容，s的ptr指向了新的地址空间，copy s还是指向原来的地址空间，两者的ptr指向的地址空间已经不同了；&lt;/p&gt;
&lt;p&gt;对于ch chan 同理 ， range ch 之后会发生值拷贝出现copy ch；对copy ch进行遍历;&lt;/p&gt;
&lt;p&gt;对应数组arr […]int{1,2,3} 也是同理，range arr 之后会发生值拷贝出现copy arr; 对copy arr进行遍历， 如果想想改变对应arr的值，可以使用下标访问，或者 range &amp;amp;arr 之后 反生copy 数组引用&amp;amp;arr 指向同一地址空间;&lt;/p&gt;
&lt;h3 id=&#34;32忽略了在for-range中使用指针元素的影响--重要&#34;&gt;32.忽略了在for range中使用指针元素的影响  (重要)&lt;/h3&gt;
&lt;p&gt;由于 for _, val := range   &amp;amp;val的地址是一个常量，每次迭代指向不同的值，但是地址是同一个，所以在使用&amp;amp;val， 需要特别注意，如果存放&amp;amp;val值，循环迭代完之后，&amp;amp;val指向最后一个元素；如何解决呢， 两个主要的解决方案： 1. 值拷贝，然后赋予地址；2. 直接只用下标对应值的地址；&lt;/p&gt;
&lt;h3 id=&#34;33在map迭代期间做出错误的假设-重要&#34;&gt;33.在map迭代期间做出错误的假设 (重要)&lt;/h3&gt;
&lt;p&gt;一种是错误的有序性假设， map是无序的，每次循环是随机获取key，就是说，插入顺序和读取的顺序不一致，每次循环读取的顺序都不同；应该清楚这些map无序行为，这样代码就不会基于错误的假设；&lt;/p&gt;
&lt;p&gt;那么为什么 Go 有这样一种令人惊讶的方式来遍历map呢？这是语言设计者有意识的选择。他们想添加某种形式的随机性，以确保开发人员在使用map时永远不会依赖任何顺序假设（请参阅http://mng.bz/M2JW）；&lt;/p&gt;
&lt;p&gt;一种是迭代map时插入k/v，在 Go 中，允许在迭代期间更新map（插入或删除元素）；它不会导致编译错误或运行时错误。但是，在迭代期间在map中添加条目时，应该考虑这种情况，以避免出现不确定的结果。出现的情况：&lt;/p&gt;
&lt;p&gt;在Go中，&lt;em&gt;如果在迭代过程中创建了map条目，则可以在迭代过程中产生或跳过。对于创建的每个条目以及从一个迭代到下一个迭代，选择可能会有所不同。&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;必须牢记这种行为，以确保代码不会产生不可预测的输出。如果想在迭代map的同时更新map并确保添加的条目不是迭代的一部分，一种解决方案是copy map，迭代map, 在用新的copy map中添加条目；&lt;/p&gt;
&lt;p&gt;总而言之，当使用map时，不应该依赖以下内容：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;按键排序的数据&lt;/li&gt;
&lt;li&gt;保留插入顺序&lt;/li&gt;
&lt;li&gt;确定性迭代顺序&lt;/li&gt;
&lt;li&gt;在添加元素的同一迭代中生成的元素&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;记住这些行为应该有助于避免基于错误假设的常见错误。&lt;/p&gt;
&lt;h3 id=&#34;34忽略-break-语句是如何工作的&#34;&gt;34.忽略 break 语句是如何工作的&lt;/h3&gt;
&lt;p&gt;在Go中， 一个基本规则是&lt;code&gt;break&lt;/code&gt;语句终止的执行最里面的&lt;code&gt;for&lt;/code&gt;, &lt;code&gt;switch&lt;/code&gt;, 或&lt;code&gt;select&lt;/code&gt;语句。&lt;/p&gt;
&lt;p&gt;如何编写代码来打破循环呢？ 最惯用的方法是使用标签， 从对应的标签代码块中break; 或者对标签块代码封装成函数，直接return;&lt;/p&gt;
&lt;h3 id=&#34;35在循环中使用-defer&#34;&gt;35.在循环中使用 defer&lt;/h3&gt;
&lt;p&gt;使用&lt;code&gt;defer&lt;/code&gt;时，必须记住它会在周围函数返回时安排函数调用。因此，&lt;code&gt;defer&lt;/code&gt;在循环内调用将堆叠所有调用：它们不会在每次迭代期间执行，例如，如果循环未终止，这可能会导致内存泄漏。解决这个问题最方便的方法是在每次迭代中引入另一个函数来调用。但是，如果性能至关重要，那么一个缺点就是函数调用增加的开销。如果有这样的情况并且想要防止这种开销，应该在循环之前摆脱&lt;code&gt;defer&lt;/code&gt;并手动处理延迟调用。&lt;/p&gt;
&lt;h2 id=&#34;概括&#34;&gt;概括&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;循环中的值元素&lt;code&gt;range&lt;/code&gt;是一个副本。因此要改变一个结构，例如，通过其索引或通过经典&lt;code&gt;for&lt;/code&gt;循环访问它（除非修改的元素或字段是指针）。&lt;/li&gt;
&lt;li&gt;了解传递给运算符的表达式&lt;code&gt;range&lt;/code&gt;在循环开始之前仅计算一次可以帮助避免常见错误，例如通道或切片迭代中的低效赋值。&lt;/li&gt;
&lt;li&gt;使用局部变量或使用索引访问元素，可以防止在循环内复制指针时出错。&lt;/li&gt;
&lt;li&gt;为确保在使用map时可预测输出，请记住map数据结构
&lt;ul&gt;
&lt;li&gt;不按键排序数据&lt;/li&gt;
&lt;li&gt;不保留插入顺序&lt;/li&gt;
&lt;li&gt;没有确定的迭代顺序&lt;/li&gt;
&lt;li&gt;不保证在迭代期间添加的元素将在本次迭代中生成&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;break&lt;/code&gt;语句终止的执行最里面的&lt;code&gt;for&lt;/code&gt;, &lt;code&gt;switch&lt;/code&gt;, 或&lt;code&gt;select&lt;/code&gt;语句，使用标签，可以从对应的标签代码块中break。&lt;/li&gt;
&lt;li&gt;提取函数内部的循环逻辑会导致&lt;code&gt;defer&lt;/code&gt;在每次迭代结束时执行一条语句。&lt;/li&gt;
&lt;/ul&gt;
</description>
      
    </item>
    
  </channel>
</rss>

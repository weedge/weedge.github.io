<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>时间飘过</title>
    <link>https://weedge.github.io/</link>
    <description>Recent content on 时间飘过</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 02 Dec 2021 12:26:23 +0800</lastBuildDate>
    
        <atom:link href="https://weedge.github.io/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>About</title>
      <link>https://weedge.github.io/about/</link>
      <pubDate>Sun, 20 Jan 2013 21:38:52 +0800</pubDate>
      
      <guid>https://weedge.github.io/about/</guid>
      
        <description>&lt;p&gt;简单的木头人，简单，呆木，喜欢自言自语，愚人自扰型。时间飞逝，仅仅记录，留住某人某事，某些好玩的技术，KISS and just do IT.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;对自己一定要有信心，每个人都有自己的节奏，不能因为一次次小小挫折而一蹶不振，生活本非如意，何须过度纠结～&lt;/p&gt;
&lt;p&gt;不以物喜，不以己悲； 上善若水～ inner peace～ 足已&lt;/p&gt;
&lt;p&gt;念经～～敲木鱼～&lt;/p&gt;
&lt;/blockquote&gt;
</description>
      
    </item>
    
    <item>
      <title>pool</title>
      <link>https://weedge.github.io/post/pool/</link>
      <pubDate>Thu, 02 Dec 2021 12:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/pool/</guid>
      
        <description>&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;平常想到不浪费资源的方法，是对资源进行复用，减少资源消耗和浪费(小时候大人经常在吃饭时说的那句话)；在计算机工程领域，存在大量消耗资源的场景，多路复用和池化是最常用的性能优化手段；多路复用存在系统调用，由系统内核层面去支持优化(I/O多路复用select/poll/epoll/kqueue)，而池化可以应用用户使用层面来优化；池化(&lt;a href=&#34;https://en.wikipedia.org/wiki/Pool_(computer_science)&#34;&gt;pool&lt;/a&gt;)是一种资源复用优化技术，减少资源回收处理，提高资源利用率，资源最好是固定大小，如果在复用资源过程中，资源在逐渐增大，一直复用，也会导致资源消耗过多，到了一定大小之后，通过系统释放掉；在程序启动的时候提前申请加载好资源放到池子中，运行时根据不同的调度管理资源策略从池子中获取准备好的资源，或者运行时新建资源放入池子中，用户程序中进行自定义处理操作，操作完之后将资源重新放入池子中复用，有些资源可以动态扩缩； 资源主要是程序运行时对象，当然这些操作资源实际都是分配在虚拟内存空间的内核空间和用户空间中，比如，&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B&#34;&gt;进程&lt;/a&gt;(process &lt;a href=&#34;https://en.wikipedia.org/wiki/Process_control_block&#34;&gt;PCB&lt;/a&gt; 内核态)、&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%9F%B7%E8%A1%8C%E7%B7%92&#34;&gt;线程&lt;/a&gt;(thread &lt;a href=&#34;https://en.wikipedia.org/wiki/Thread_control_block&#34;&gt;TCB&lt;/a&gt; 内核态)、&lt;a href=&#34;https://zh.wikipedia.org/zh-hans/%E5%8D%8F%E7%A8%8B&#34;&gt;协程&lt;/a&gt;(coroutine 用户态)为载体的工作任务(work task 在用户态分配栈空间)；内存对象(heap object)，长链接(tcp connect) 等；主要对这些资源对象进行池化技术进行介绍，了解池化对应场景。&lt;/p&gt;
&lt;h2 id=&#34;工作任务池worker-pool&#34;&gt;工作任务池（worker pool)&lt;/h2&gt;
&lt;p&gt;程序中的工作任务是一些运行逻辑，通过进程，线程，或者协程为载体获取系统资源来运行；如果运行的资源对象特别多，这些资源对象在内存中分配空间，这就导致资源消耗过多，甚至可能导致OOM，同时处理任务完成之后，这些资源需要回收，也会消耗大量的cpu时间；所以在这些高耗进程/线程，或者协程资源的工作任务场景下(比如大量的请求任务)，需要用池化技术进行复用管理，提高利用率，减少请求耗时；对此分别介绍进程池，线程池，协程池，以及开源组件服务中的实现。&lt;/p&gt;
&lt;h3 id=&#34;进程池process-pool&#34;&gt;进程池(process pool)&lt;/h3&gt;
&lt;p&gt;早期的操作系统是以&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E8%A1%8C%E7%A8%8B&#34;&gt;进程&lt;/a&gt;作为资源分配和调度的基本单位，比如早期linux2.4以及之前的版本，进程是程序的基本执行实体；在面向线程设计的系统（如当代多数操作系统、&lt;a href=&#34;https://zh.wikipedia.org/wiki/Linux&#34;&gt;Linux&lt;/a&gt; 2.6及更新的版本）中，进程本身不是基本执行单位，而是&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E5%9F%B7%E8%A1%8C%E7%B7%92&#34;&gt;线程&lt;/a&gt;的容器，将资源分配和调度运行进行了分离设计；引入线程后，进程中可以有多个线程，并且共享线程资源；这里介绍进程池，一个进程中只有一个线程作为调度运行单位；在使用PHP语言进行web服务端开发的时候，常规操作用LAMP/LNMP组合，其中使用Apache/Nginx作为web服务器将请求路由到对应后端服务模块处理，然后将处理的响应结果返回；后端服务模块通过实现通用网关接口协议(CGI)应用(app)进程来处理请求, 如果仅仅是单个请求处理从路由模块转发的请求，吞吐量是很低的(一个请求一个进程的方式(fork-and-exec模式)，实现简单，甚至可以用shell脚本来作为CGI进程处理，早期90年之前互联网用户不多)；随着互联网的发展，fork-and-exec模式，进程创建和消除开销变大，成了诟病，&lt;a href=&#34;https://en.wikipedia.org/wiki/FastCGI&#34;&gt;FastCGI&lt;/a&gt;接口协议在90年代中期提出来，FastCGI服务器使用持久进程来处理一系列请求，及每个单独的 FastCGI 进程可以在其生命周期内处理许多请求，从而避免每个请求进程创建和终止的开销(另外还有SCGI,WSGI协议,都是定义通用的接口协议，将web服务器和应用服务器进行解耦，比如apache/nginx都有对应的协议模块和应用服务器php-fpm/uWSGI(python)相关接口协议进程进行交互，编写语言大多是解释性语言，进程运行时动态加载解释执行)。&lt;/p&gt;
&lt;h4 id=&#34;php-fpm-worker-process-pool&#34;&gt;php-fpm worker process pool&lt;/h4&gt;
&lt;p&gt;php解释性语言作为后端服务模块的开发语言，支持FastCGI，并且对支持FastCGI接口协议的进程进行管理，通过SAPI(Server Application Programme Interface)模块中的FPM(FastCGI Process Manager)实现；在初始启动php-fpm时，通过主进程监听不同服务端口，不同服务端口初始对应的FastCGI工作进程池；运行时，主进程(父进程)和工作进程(子进程)通过双向信号管道(pipe)进行通信，实现主进程对工作进程的控制管理，以及工作进程通过标准输出管道(stdout pipe)和标准错误管道(stderr pipe)，将结果和错误返回给主进程；主进程和工作进程通过共享内存的方式(内部记分板结构scoreboard)，实现工作进程运行时的监控(工作进程状态), 主进程会定时轮训检查工作进程数目，根据进程池管理策略来处理是否扩缩容，检查工作进程处理请求是否超时，整体流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/fpm-worker-pool.drawio.png&#34; alt=&#34;fpm-worker-pool&#34;&gt;&lt;/p&gt;
&lt;p&gt;具体代码见&lt;a href=&#34;https://github.com/php/php-src/tree/master/sapi/fpm&#34;&gt;php-fpm&lt;/a&gt;；php语言是线程安全的，使用 &lt;code&gt;TSRM&lt;/code&gt; 机制分配和使用变量时会有额外的损耗，所以一般不需要多线程的 PHP 环境；而且工作进程处理请求时加载php脚本解析成opcode, 然后通过ZendVM解释器调用opcode对应的机器指令，最终完成php脚本的运行，由于每次处理请求都需要解析成opcode,会有性能损耗，所以引入opcache来缓存解析后的opcode；php-fpm的运行机制是采用多进程方式来处理请求，每个woker进程处理请求时所占内存大小在10M+，可以通过&lt;code&gt;ps aux | grep php | grep -v grep | grep -v master | awk &#39;{sum+=$6; cn+=1} END {print sum/cn}&#39;&lt;/code&gt;获取worker进程消耗内存平均值，所以fpm引入工作进程池来防止过度消耗内存，而且可以服用工作进程来处理请求，内存资源紧的场景池中开启动态扩缩worker进程，反之采用静态方式池中一次初始pm.max_children 这么多worker进程，减少扩缩管理开销。&lt;/p&gt;
&lt;p&gt;php多进程(进程单个线程)编程相对多线程(进程多个线程)编程要简单些，多线程需要考虑共享所在进程资源同步的问题，处于安全隔离考虑，进程多线程中如果某个线程出错，整个进程就挂了，而多进程资源相互隔离，如果一个进程挂了，不影响其他进程处理任务；而且解释语言相对c/c++编译成机器码执行语言开发效率要高很多，运行时加载，无需重启服务(当然c/c++编译型语言也支持动态库加载至内存提供相关接口调用，进行热加载而无需重启服务，但是不可能每次新开发一个功能都以*.so动态库的形式提供吧，所以需求更新迭代快的场景，像游戏领域的服务器，网关服务器，甚至大数据任务算子，大多都是通过引入解释型脚本语言(lua/js/perl/python/php)编写业务逻辑，进行热加载)；&lt;/p&gt;
&lt;p&gt;但是多进程毕竟比多线程要消耗更多的系统资源；而且如果存在多进程单线程的&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8&#34;&gt;cpu&lt;/a&gt;切换，是从一个进程到另一个进程，而单进程多线程的&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8&#34;&gt;cpu&lt;/a&gt;切换则只在一个进程内，每个进程/线程都有自己的上下文堆栈保存，进程间的cpu切换消耗更大一些；多线程上下文的切换涉及程序计数器、堆栈指针和程序状态字等一系列的寄存器置换、程序堆栈重置甚至是 CPU 高速缓存、TLB 快表的汰换；进程间的上线文切换还涉及整个进程地址空间。&lt;/p&gt;
&lt;h3 id=&#34;线程池thread-poolhttpsenwikipediaorgwikithread_pool&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Thread_pool&#34;&gt;线程池(thread pool)&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;线程是操作系统调度运行的最小单元，随着计算机&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%B8%AD%E5%A4%AE%E5%A4%84%E7%90%86%E5%99%A8&#34;&gt;cpu&lt;/a&gt;核数的增加，多线程技术可以充分利用多个cpu核进行并行处理，提高吞吐；对于在单cpu单核的计算机上，使用多线程技术，也可以把进程中负责I/O处理、人机交互而常被阻塞的部分，与密集计算的部分分开来执行，编写专门的workhorse线程执行密集计算，虽然多任务比不上多核，但因为具备多线程的能力，从而提高了程序的执行效率。而多线程的频繁建立和销毁，以及多线程上下文的切换，会导致整体执行的延迟，对于高性能的服务组件，针对io密集型场景，引入线程池来进行优化；而业务场景，为了提高业务的接口吞吐量，也引入了线程池进行优化；&lt;/p&gt;
&lt;h4 id=&#34;nginx-thread-pool&#34;&gt;nginx thread pool&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&#34;&gt;nginx是多工作进程(cpu核数)+事件模型&lt;/a&gt;（如果是IO密集型 worker进程数在1.5-2倍cpu核数），通过工作进程单线程的事件模型(比喻成grandmaster😄)能够很快处理用户的请求(epoll事件机制)，但是为了解决重阻塞型IO密集型的工作任务问题，nginx 1.7.12引入了&lt;a href=&#34;https://www.nginx.com/blog/thread-pools-boost-performance-9x/&#34;&gt;thread pool 线程池技术&lt;/a&gt;，主要是针对linux系统，解决不支持异步IO的场景(FreeBSD系统的异步IO支持使用内存做为文件缓存)；&lt;/p&gt;
&lt;p&gt;比如产生磁盘io的系统调用read(),sendfile(),aio_write()(Linux上的在编写一些临时文件,在nginx1.9.13加入&lt;a href=&#34;https://github.com/nginx/nginx/commit/348f705c000bdbfbee74d6f0111a03697f8ffa4f&#34;&gt;commit 348f705&lt;/a&gt;)这些阻塞操作场景，工作进程处理这些操作的时候，将其放入线程池中来处理，常见的直播/点播回放场景中，会有拉流操作，从最近CDN服务节点上获取视频流进行播放；像视频流文件，或者其他大文件，这些请求资源是没法放入系统内存&lt;a href=&#34;https://zhuanlan.zhihu.com/p/35448479&#34;&gt;页面缓存&lt;/a&gt;中，导致事件模型被文件操作卡住，没法正常的响应链接，引入 thread pool 来缓解这个问题；流程如下：&lt;/p&gt;
&lt;p&gt;工作进程中的主线程决定要发起文件系统操作时，将会建立一个特殊的任务，并将该任务丢到任务队列中；而线程池中的空闲线程会不断的执行该队列的文件任务，而后将执行好的结果返回，主线程循环处理结果，继续后续操作。经过这个优化，主线程不会再被阻塞住，如图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/nginx-thread-pool.drawio.png&#34; alt=&#34;thread-pools-worker-process-event-cycle&#34;&gt;&lt;/p&gt;
&lt;p&gt;thread pool整体实现代码见&lt;a href=&#34;https://github.com/nginx/nginx/commit/305fc021db799c87d751f0f1f5e99afee7bb2b3b&#34;&gt;commit 305fc02&lt;/a&gt; ；最近有个&lt;a href=&#34;https://github.com/nginx/nginx/commit/83e92a2edd6bf7c6867b653284ac44962c4e33c9&#34;&gt;commit 83e92a2&lt;/a&gt; 解决http2 等待 sendfile 完成 请求hang住的情况，就是利用线程池的异步方式(aio)来处理的。&lt;/p&gt;
&lt;h4 id=&#34;redis-thread-pool&#34;&gt;redis thread pool&lt;/h4&gt;
&lt;p&gt;redis处理命令核心逻辑是单进程单线程模式，redis关注的是网络IO，以及内存操作，如果是单进程多线程处理必然会有同一个内存结构会有多个线程处理，加锁处理，线程等待以及多线程上下文切换开销的问题，执行效率不如单线程高效；网络IO事件直接通过IO多路复用事件模型(AE)来解决, 而且逻辑简单可维护；&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;为了提高处理性能，Redis v4.0 将磁盘io和内存释放free工作采用几个线程异步处理bio(3个)；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;fsync内存异步持久落盘操作和close异步关闭文件操作；&lt;/p&gt;
&lt;p&gt;由于内存中大ke同步删除会耗时高从而阻塞核心逻辑，所以将这些内存释放采用lazyfree机制优化异步化处理，包括两类：一类是主动释放&lt;code&gt;unlink&lt;/code&gt; &lt;code&gt;flushall async&lt;/code&gt; ；一类是被动释放, 分为4种场景，按需求场景进行打开优化(默认是关闭的)：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-shell&#34; data-lang=&#34;shell&#34;&gt;lazyfree-lazy-eviction no
lazyfree-lazy-expire no
lazyfree-lazy-server-del no
slave-lazy-flush no
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;​	lazyfree-lazy-eviction：针对redis内存使用达到maxmeory，并设置有淘汰策略时；在被动淘汰键时，是否采用lazy free机制； 具体流程见&lt;a href=&#34;https://weedge.github.io/post/lru/#%E8%BF%91%E4%BC%BClru%E7%AE%97%E6%B3%95&#34;&gt;redis 近似lru算法&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;​	lazyfree-lazy-expire：针对设置有TTL的键，达到过期后，被redis清理删除时是否采用lazy free机制；可开启&lt;/p&gt;
&lt;p&gt;​	lazyfree-lazy-server-del：针对有些指令在处理已存在的键时，会带有一个隐式的DEL键的操作，比如&lt;code&gt;rename&lt;/code&gt;操作，如果key存在会先删除这个key/value, 如果是大key场景会阻塞；可开启&lt;/p&gt;
&lt;p&gt;​	slave-lazy-flush：针对slave进行全量数据同步，slave在加载master的RDB文件前，会运行flushall来清理自己的数据场景，开启可减少全量同步耗时，从而减少主库因输出缓冲区爆涨引起的内存使用增长；可开启&lt;/p&gt;
&lt;p&gt;​	还有一个配置 &lt;code&gt;lazyfree-lazy-user-del no&lt;/code&gt;， 针对老用户/代码使用&lt;code&gt;del&lt;/code&gt;主动删除是否异步处理，开启和&lt;code&gt;unlink&lt;/code&gt;一样；&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;为了提高处理IO能力，Redis v6.0 正式在网络模型中实现 I/O 多线程，流程如下：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	客户端和主线程建立连接，主线程将请求封装成client结构放入LIFO读入队列(clients_pending_read)，主线程然后把LIFO读入队列中的client数据RR均匀分配给主线程和I/O多线程的本地队列(io_threads_list[id])；&lt;/p&gt;
&lt;p&gt;​	主线程和I/O多线程解析命令，写入查询缓存区(querybuf)；&lt;/p&gt;
&lt;p&gt;​	主线程忙轮训等待I/O多线程全部解析处理完之后，遍历LIFO读入队列(clients_pending_read)中的client, 处理执行命令核心逻辑(processCommand)，注意这里并不是I/O多线程来处理；主线程处理完命令后，将响应数据写入client写出缓存区(buf/reply)，然后把client放入LIFO 写出队列(clients_pending_write)，同样主线程然后把LIFO写出队列(clients_pending_write)中的client数据RR均匀分配给主线程和I/O多线程的本地队列(io_threads_list[id])；&lt;/p&gt;
&lt;p&gt;​	主线程和I/O多线程回写响应数据给客户端；&lt;/p&gt;
&lt;p&gt;​	主线程忙轮训等待I/O多线程全部回写响应数据给客户端 处理完之后，最后在遍历LIFO写出队列(clients_pending_write)，检查是否还有 client 的写出缓冲区(buf/reply)中有残留数据，如果有，为 client 注册一个命令回复器 sendReplyToClient，等待client可写之后在事件循环中继续回写残余的响应数据。&lt;/p&gt;
&lt;p&gt;处理流程和以前的单线程reactor模式差不多，主要区别是对读写IO优化(异步多线程处理)； 读入请求命令读取解析和写出响应数据给客户端，增加了I/O多线程来处理，以前的主线程处理的核心逻辑没有变，增加了和I/O多线程交互的读写LIFO队列(clients_pending_read / clients_pending_write)，有点像扇入扇出模式；尽量保持 &lt;strong&gt;less is more&lt;/strong&gt; 原则；&lt;/p&gt;
&lt;p&gt;而且redis v6.0为了高性能，网络IO多线程场景，和nginx一样也对多核CPU NUMA架构进行了亲和性处理(见setcpuaffinity.c中逻辑，&lt;a href=&#34;https://github.com/redis/redis/commit/1a0deab2a548fa306171f03439e858c00836fe69&#34;&gt;commit 1a0deab2&lt;/a&gt;)，充分利用CPU本地缓存，并行处理；另外redis v6.0还有一些性能优化骚操作，无锁化处理，看代码时会发现用到了mutex lock，通过 pthread_mutex_lock 给 io_threads_mutex[i] (0&amp;lt;=i&amp;lt;128) 上锁，其实目的是主线程用来通知I/O线程使用的，最终还是通过io_threads_pending[i] 原子化操作(atomic_load_explicit)获取判读是否等待；每个处理I/O线程都有自己的本地队列io_threads_list[i] 用于处理封装的client结构，I/O线程之间互不干涉；而且主线程和I/O子线程处理本地队列 io_threads_list[i] 以及io_threads_op 通过控制主线程和 I/O 线程交错访问来规避共享数据竞争(data race)问题。&lt;/p&gt;
&lt;p&gt;THREADED I/O 核心操作变量如下：&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-c&#34; data-lang=&#34;c&#34;&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;/* ==========================================================================
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt; * Threaded I/O
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt; * ========================================================================== */&lt;/span&gt;

&lt;span style=&#34;color:#4c8317&#34;&gt;#define IO_THREADS_MAX_NUM 128
&lt;/span&gt;&lt;span style=&#34;color:#4c8317&#34;&gt;#define IO_THREADS_OP_READ 0
&lt;/span&gt;&lt;span style=&#34;color:#4c8317&#34;&gt;#define IO_THREADS_OP_WRITE 1
&lt;/span&gt;&lt;span style=&#34;color:#4c8317&#34;&gt;&lt;/span&gt;
pthread_t io_threads[IO_THREADS_MAX_NUM];
pthread_mutex_t io_threads_mutex[IO_THREADS_MAX_NUM];
redisAtomic &lt;span style=&#34;color:#0aa&#34;&gt;unsigned&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;long&lt;/span&gt; io_threads_pending[IO_THREADS_MAX_NUM];
&lt;span style=&#34;color:#0aa&#34;&gt;int&lt;/span&gt; io_threads_op;      &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;/* IO_THREADS_OP_WRITE or IO_THREADS_OP_READ. */&lt;/span&gt;

&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;/* This is the list of clients each thread will serve when threaded I/O is
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt; * used. We spawn io_threads_num-1 threads, since one is the main thread
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt; * itself. */&lt;/span&gt;
list *io_threads_list[IO_THREADS_MAX_NUM];
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;以上通过引入多线程来改善redis中I/O处理性能，这些优化都可以根据需求场景进行配置，也有具体说明 见: &lt;a href=&#34;https://github.com/redis/redis/blob/unstable/redis.conf&#34;&gt;redis.conf&lt;/a&gt; (LAZY FREEING, THREADED I/O)；功能按需配置，&lt;strong&gt;可配置功能说明&lt;/strong&gt; 配置文档原则 (开源软件配置文件一般都会有详细说明可了解)；&lt;/p&gt;
&lt;h4 id=&#34;java-thread-pool&#34;&gt;java thread pool&lt;/h4&gt;
&lt;p&gt;java多线程编程，也有相关的线程池(ThreadPoolExecutor，子类ScheduledThreadPoolExecutor - 利用延迟工作队列(最小堆)实现定时任务线程池)提供使用；使用ThreadPoolExecutor可以满足两种场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;并行执行子任务，提高响应速度。这种情况下，应该使用同步队列，没有什么任务应该被缓存下来，而是应该立即执行;&lt;/li&gt;
&lt;li&gt;并行执行大批次任务，提升吞吐量。这种情况下，应该使用有界队列，使用队列去缓冲大批量的任务，队列容量必须声明，防止任务无限制堆积；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://p0.meituan.net/travelcube/77441586f6b312a54264e3fcf5eebe2663494.png&#34; alt=&#34;ThreadPoolExecutor运行流程&#34;&gt;&lt;/p&gt;
&lt;p&gt;ThreadPoolExecutor具体的使用介绍可以参考美团的这片文章：&lt;a href=&#34;https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html&#34;&gt;Java线程池实现原理及其在美团业务中的实践&lt;/a&gt;，引用 ThreadPoolExecutor 运行流程如上图；文中有有实际的案例和参数配置解决方案，可以借鉴；在使用java线程池对接口吞吐量进行优化时，如果参数使用不当，线程池最大线程数过小，可能导致接口服务降级；消费线程过小任务队列过长，积压任务，可能导致请求超时的情况；针对这些场景，提出解决方案：增加线程池监控，通过配置中心，手动来调整java线程池参数, 进行动态配置化管理，这个思路其实也是服务基础稳定性的常用思路，做好监控报警，配置化及时人工响应。(美团的&lt;a href=&#34;https://mp.weixin.qq.com/s/C81f0_arbs23KGcaIwi56w&#34;&gt;复盘机制&lt;/a&gt;值得学习)&lt;/p&gt;
&lt;h4 id=&#34;thread-pool-小结&#34;&gt;thread pool 小结&lt;/h4&gt;
&lt;p&gt;引入线程池其实本质上还是对多线程的有效管理，充分利用多核进行并行处理，减少线程间的上下文切换开销；以上实现的线程池本质上都是通过多线程异步优化IO任务，通过线程池来管理线程，通过参数进行调优，充分利用多核cpu硬件资源，并行处理，吞吐最大化(ps: redis和nginx的源码值得一撸)。 但是用户应用层使用线程池需要对线程数目进行调整，那可否从用户应用层面来封装一层进行调度管理呢？ 答案是有的，像GO语言，现在的内部运行时runtime 通过G-P-M调度模型来有效管理，Go 语言的调度模型通过使用与 CPU 数量相等的线程减少线程频繁切换的内存开销，同时在每一个线程上执行额外开销更低的 Goroutine 协程来降低操作系统和硬件的负载，用户应用层面不需要考虑多线程编程的细节，重点关注Goroutine 协程的使用优化，了解G-P-M模型，运行时&lt;a href=&#34;http://www1.cs.columbia.edu/~aho/cs6998/reports/12-12-11_DeshpandeSponslerWeiss_GO.pdf&#34;&gt;调度机制&lt;/a&gt;。(享受一波语言,工具福利时，&lt;strong&gt;注意系统阻塞调用时的线程泄露,以及异步阻塞时的协程泄漏, race检查,性能测试,pprof/trace分析,逃逸分析,GC&lt;/strong&gt;等)&lt;/p&gt;
&lt;h3 id=&#34;协程池coroutine-pool&#34;&gt;协程池(coroutine pool)&lt;/h3&gt;
&lt;p&gt;协程是运行在用户态的轻量线程，可以认为是用户应用层面的线程， 比线程分配的虚拟内存栈空间要小；创建一个线程所占虚拟内存栈空间大小，在linux下通过&lt;code&gt;pmap &lt;/code&gt;+pid 查看stack大小， 在macOS下通过&lt;code&gt;vmmap -interleaved&lt;/code&gt;+pid 查看stack大小，大小由&lt;code&gt;ulimit -s&lt;/code&gt; 控制，线程栈空间一般在8M~10M左右，如果使用不当会栈溢出；而协程分配空间是由实现协程语言来决定，像GO实现的goroutine协程初始创建栈空间大小是2k(go 1.4+ 采用连续堆栈策略，以前是分段栈策略)，最大限制的默认值在64位系统上是1GB（&lt;a href=&#34;https://github.com/golang/go/blob/f296b7a6f045325a230f77e9bda1470b1270f817/src/runtime/proc.go#L120&#34;&gt;不同的架构最大数会不同&lt;/a&gt;）；编译期间插入检查，调用时如果满足了扩容条件(根据被调用函数栈帧的大小来判断是否需要扩容，通过 stackguard0 来判断是否要进行栈增长)，扩容两倍空间，如果协程所使用的栈空间小于1/4时，缩容成一半空间；(具体细节见：&lt;a href=&#34;https://draveness.me/golang/docs/part3-runtime/ch07-memory/golang-stack-management/&#34;&gt;栈空间管理&lt;/a&gt; &lt;a href=&#34;https://kirk91.github.io/posts/2d571d09/&#34;&gt;推送场景: 聊一聊goroutine stack&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;尽管goroutine协程比线程分配栈空间小，但是 大量的 goroutine 还是很耗资源的，而且大量的 goroutine 对于调度和垃圾回收的耗时还是会有影响的，因此，goroutine 并不是越多越好，所以使用协程池来优化；&lt;/p&gt;
&lt;p&gt;GO中管理协程池的开发方案还是比较多的，大都是和线程池任务工作模型差不多，任务队列用的是GO中的runtime/channel,  池化管理用的是GO中的sync.Pool；相对线程池thread pool的实现要简单些，因为底层GO runtime的调度模型已经做了大部分的优化。&lt;a href=&#34;https://time.geekbang.org/column/article/301716&#34;&gt;Pool：性能提升大杀器&lt;/a&gt; 中介绍了GO中sync.Pool的实现，以及协程池的三方开源方案实现，worker的作用，引用如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;有些是在后台默默执行的，不需要等待返回结果；&lt;/p&gt;
&lt;p&gt;有些需要等待一批任务执行完；&lt;/p&gt;
&lt;p&gt;有些 Worker Pool 的生命周期和程序一样长；&lt;/p&gt;
&lt;p&gt;有些只是临时使用，执行完毕后，Pool 就销毁了。&lt;/p&gt;
&lt;p&gt;大部分的 Worker Pool 都是通过 Channel 来缓存任务的，因为 Channel 能够比较方便地实现并发的保护，有的是多个 Worker 共享同一个任务 Channel，有些是每个 Worker 都有一个独立的 Channel。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这里介绍一个实现的 &lt;a href=&#34;https://github.com/weedge/lib/tree/main/pool/workerpool&#34;&gt;workerpool&lt;/a&gt;   通过channel 存放任务，多个 Worker 共享同一个任务 Channel，通过多个协程来消费池中的任务执行，协程根据提交的任务数动态扩缩协程；任务可以定义输入，输出，超时时间；通过channel 返回是否超时; 可用于批量任务并发执行场景，适用于大量批量耗时相对比较高的任务；在实际工作中，比如组织引擎中树中组织节点的生成，有些任务超时了，使用方可以重新放入队列中，或者出错报警等操作。扩缩协程实现有点粗糙，待改进， 执行流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/lib/main/pool/workerpool/workerpool.png&#34; alt=&#34;workerpool&#34;&gt;&lt;/p&gt;
&lt;p&gt;还有协程池的实现方式，是为了应对突发流量，比如 &lt;a href=&#34;https://github.com/gammazero/workerpool.git&#34;&gt;gammazero/workerpool&lt;/a&gt;  实现用到3个队列，一个用于提交任务的任务队列(buffer channel length 1，发送任务非阻塞)、一个等待队列（buf[] interface{} head,tail，为了应对突发流量设置的buff，无限制，BUFF加成)、 一个工作队列(block channel，用阻塞chan是为了让消费的worker先启动)；未使用sync.Pool，通过dispatch协程来管理工作协程， 定时(idleTimeout)检查工作队列是否有任务(idle), 以及有工作协程(workerCount&amp;gt;1)，发送空任务(nil) 结束工作协程；这个检查是否有空闲工作协程机制比较简单，每到定时时间操作一次，回收频率可以调整，idleTimeout默认2秒；整体实现就300行左右，这个和ThreadPoolExecutor有些类似，流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/go-workerpool.drawio.png&#34; alt=&#34;go-workerpool&#34;&gt;&lt;/p&gt;
&lt;p&gt;以上的workerpool 都有缓冲队列，如果服务进程重启，需要平滑停止服务，就是在收到TERM信号时，需要调用workerpool提供的Wait(GroupWait/StopWait)接口来等待剩余的任务执行完成，这种任务如果是用户请求任务，一般都是短任务，处理时间不会很长，像Pod 中的 docker container销毁的时候都会等待一段时间才会回收掉；如果是长时间任务，比如cron job 则需要落库存放任务状态，在任务提交之前通过任务表来记录，因为进程本地记录是不可行的，如果容器化部署在Pod中，每次部署的Node会不同；请根据需求场景选择workerpool 哦～&lt;/p&gt;
&lt;h3 id=&#34;小结&#34;&gt;小结&lt;/h3&gt;
&lt;p&gt;线程作为cpu执行调度的最小单元，而进程作为资源分配最小单元，进程中有多个线程，共享其进程资源，作为线程的容器，相互隔离不同进程之间的线程，所以nginx/fpm 都是多进程(单线程)+reactor多路复用的方式处理网络IO请求； php-fpm 为了有效控制请求进程所占资源过多消耗内存的情况，引入工作进程池来防止过度消耗内存，而且可以复用工作进程来处理请求；nginx 为了优化系统调用时阻塞io，使用线程池来异步化处理处理阻塞io事件；redis 引入多线程来解决磁盘IO,释放内存空间，以及网络IO读写的性能问题，nginx和re dis 引入多线程都需要编译配置，其中nginx和redis中的网络IO优化细节值得学习的；协程创建分配栈空间比线程更小，Golang中通过可增长栈空间，运行时runtime 通过G-P-M调度模型来将 goroutine 多路复用到线程，如果协程过多，也会影响调度以及GC标记清除效率，所以在消耗大量协程的场景下，引入协程池来复用，因为golang runtime调度机制不错以及channel的实现，协程池实现方案很多，golang社区活跃，玩的花(慢慢就学费了哈哈😄)，最好结合需求场景来分析。&lt;/p&gt;
&lt;h2 id=&#34;内存池memory-poolhttpsenwikipediaorgwikimemory_pool&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Memory_pool&#34;&gt;内存池(memory pool)&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&#34;nginx-pool&#34;&gt;nginx pool&lt;/h3&gt;
&lt;h2 id=&#34;连接池connection-poolhttpsenwikipediaorgwikiconnection_pool&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Connection_pool&#34;&gt;连接池(connection pool)&lt;/a&gt;&lt;/h2&gt;
&lt;h3 id=&#34;envoy-connectionpool&#34;&gt;envoy ConnectionPool&lt;/h3&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial&#34;&gt;Introduction to Parallel Computing Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sourceware.org/git/?p=glibc.git;a=blob;f=nptl/pthread_create.c;hb=627f5ede70d70c77bdaf857db07404e8bf7f60af#l619&#34;&gt;glibc pthread_create&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/torvalds/linux/blob/master/kernel/fork.c&#34;&gt;linux v2.6.38+ fork.c&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://makelinux.github.io/kernel/map/&#34;&gt;Linux 2.6.36 kernel map&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nginx.com/blog/thread-pools-boost-performance-9x/&#34;&gt;nginx-thread-pools-boost-performance-9x&lt;/a&gt; &lt;a href=&#34;https://segmentfault.com/a/1190000010008012&#34;&gt;翻译&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.nginx.com/blog/inside-nginx-how-we-designed-for-performance-scale/&#34;&gt;inside-nginx-how-we-designed-for-performance-scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.aosabook.org/en/nginx.html&#34;&gt;AOSA-nginx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://antirez.com/news/93&#34;&gt;Lazy Redis is better Redis&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redis.io/topics/benchmarks&#34;&gt;How fast is Redis?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html&#34;&gt;Java线程池实现原理及其在美团业务中的实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www1.cs.columbia.edu/~aho/cs6998/reports/12-12-11_DeshpandeSponslerWeiss_GO.pdf&#34;&gt;Analysis of the Go runtime scheduler&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.bilibili.com/video/BV1Bq4y1q7Pi&#34;&gt;Golang操作系统调度原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=f6kdp27TYZs&#34;&gt;Google I/O 2012 - Go Concurrency Patterns &lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/watch?v=QDDwwePbDtw&#34;&gt;Google I/O 2013 - Advanced Go Concurrency Patterns&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tonybai.com/2017/06/27/an-intro-about-go-portability/&#34;&gt;也谈Go的可移植性&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://9p.io/sys/doc/asm.html&#34;&gt;A Manual for the Plan 9 assembler&lt;/a&gt; &lt;a href=&#34;https://github.com/cch123/golang-notes/blob/master/assembly.md&#34;&gt;plan9 assembly 完全解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/301716&#34;&gt;Pool：性能提升大杀器&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>深入理解Linux的Page Cache 「转载的哦」</title>
      <link>https://weedge.github.io/%E8%BD%AC%E8%BD%BD/page-cache/</link>
      <pubDate>Fri, 26 Nov 2021 11:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/%E8%BD%AC%E8%BD%BD/page-cache/</guid>
      
        <description>&lt;blockquote&gt;
&lt;p&gt;from: 互联网，了解下备个份而已啦～！unix 请看个 man&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;1page-cache&#34;&gt;1、Page Cache&lt;/h2&gt;
&lt;h3 id=&#34;11-page-cache-是什么&#34;&gt;1.1 Page Cache 是什么？&lt;/h3&gt;
&lt;p&gt;为了理解 Page Cache，我们不妨先看一下 Linux 的文件 I/O 系统，如下图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2F2654c391j00r32mky000qc000hs00f6g.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;linux-io&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，红色部分为 Page Cache。可见 Page Cache 的本质是由 Linux 内核管理的内存区域。我们通过 mmap 以及 buffered I/O 将文件读取到内存空间实际上都是读取到 Page Cache 中。&lt;/p&gt;
&lt;h3 id=&#34;12-如何查看系统的-page-cache&#34;&gt;1.2 如何查看系统的 Page Cache？&lt;/h3&gt;
&lt;p&gt;通过读取 /proc/meminfo 文件，能够实时获取系统内存情况：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;$ cat /proc/meminfo  
...  
Buffers:            1224 kB  
Cached:           111472 kB  
SwapCached:        36364 kB  
Active:          6224232 kB  
Inactive:         979432 kB  
Active(anon):    6173036 kB  
Inactive(anon):   927932 kB  
Active(file):      51196 kB  
Inactive(file):    51500 kB  
...  
Shmem:             10000 kB  
... 
SReclaimable:      43532 kB  
... 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;根据上面的数据，你可以简单得出这样的公式（等式两边之和都是 112696 KB）：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Buffers + Cached + SwapCached = Active(file) + Inactive(file) + Shmem + SwapCached 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;两边等式都是 Page Cache，即：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Page Cache = Buffers + Cached + SwapCached 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;通过阅读 1.4 以及 1.5 小节，就能够理解为什么 SwapCached 与 Buffers 也是 Page Cache 的一部分。&lt;/p&gt;
&lt;p&gt;题外话，小伙伴答案：&lt;/p&gt;
&lt;p&gt;内核计算源码（linux 2.6.19）：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2F419841c3j00r32mky000mc000hs009jg.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;内核算法：Cached = files - SwapCached - Buffers；&lt;/p&gt;
&lt;p&gt;Buffers + Cached + SwapCached = Active(file) + Inactive(file) + Shmem + SwapCached&lt;/p&gt;
&lt;p&gt;公式推出来的&lt;/p&gt;
&lt;p&gt;Cached = Active(file) + Inactive(file) + Shmem - Buffers ；&lt;/p&gt;
&lt;p&gt;由此可见，这个Cached 并不等于Active(file) + Inactive(file) ；&lt;/p&gt;
&lt;p&gt;这个cache包含很多 ：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;含有普通文件数据的页‘；&lt;/li&gt;
&lt;li&gt;含有目录的页；&lt;/li&gt;
&lt;li&gt;含有直接从块设备文件(跳过文件系统)读出的数据的页；&lt;/li&gt;
&lt;li&gt;含有用户态进程数据的页；&lt;/li&gt;
&lt;li&gt;属于特殊文件系统文件的页，如shm；&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;13-page-与-page-cache&#34;&gt;1.3 page 与 Page Cache&lt;/h3&gt;
&lt;p&gt;page 是内存管理分配的基本单位， Page Cache 由多个 page 构成。page 在操作系统中通常为 4KB 大小（32bits/64bits），而 Page Cache 的大小则为 4KB 的整数倍。&lt;/p&gt;
&lt;p&gt;另一方面，并不是所有 page 都被组织为 Page Cache。&lt;/p&gt;
&lt;p&gt;Linux 系统上供用户可访问的内存分为两个类型[2]，即：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;File-backed pages：文件备份页也就是 Page Cache 中的 page，对应于磁盘上的若干数据块；对于这些页最大的问题是脏页回盘；&lt;/li&gt;
&lt;li&gt;Anonymous pages：匿名页不对应磁盘上的任何磁盘数据块，它们是进程的运行是内存空间（例如方法栈、局部变量表等属性）；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;为什么 Linux 不把 Page Cache 称为 block cache，这不是更好吗？&lt;/p&gt;
&lt;p&gt;这是因为从磁盘中加载到内存的数据不仅仅放在 Page Cache 中，还放在 buffer cache 中。例如通过 Direct I/O 技术的磁盘文件就不会进入 Page Cache 中。当然，这个问题也有 Linux 历史设计的原因，毕竟这只是一个称呼，含义随着 Linux 系统的演进也逐渐不同。&lt;/p&gt;
&lt;p&gt;下面比较一下 File-backed pages 与 Anonymous pages 在 Swap 机制下的性能。&lt;/p&gt;
&lt;p&gt;内存是一种珍惜资源，当内存不够用时，内存管理单元（Memory Mangament Unit）需要提供调度算法来回收相关内存空间。内存空间回收的方式通常就是 swap，即交换到持久化存储设备上。&lt;/p&gt;
&lt;p&gt;File-backed pages（Page Cache）的内存回收代价较低。Page Cache 通常对应于一个文件上的若干顺序块，因此可以通过顺序 I/O 的方式落盘。另一方面，如果 Page Cache 上没有进行写操作（所谓的没有脏页），甚至不会将 Page Cache 回盘，因为数据的内容完全可以通过再次读取磁盘文件得到。&lt;/p&gt;
&lt;p&gt;Page Cache 的主要难点在于脏页回盘，这个内容会在第二节进行详细说明。&lt;/p&gt;
&lt;p&gt;Anonymous pages 的内存回收代价较高。这是因为 Anonymous pages 通常随机地写入持久化交换设备。另一方面，无论是否有更操作，为了确保数据不丢失，Anonymous pages 在 swap 时必须持久化到磁盘。&lt;/p&gt;
&lt;h3 id=&#34;14-swap-与缺页中断&#34;&gt;1.4 Swap 与缺页中断&lt;/h3&gt;
&lt;p&gt;Swap 机制指的是当物理内存不够用，内存管理单元（Memory Mangament Unit）需要提供调度算法来回收相关内存空间，然后将清理出来的内存空间给当前内存申请方。&lt;/p&gt;
&lt;p&gt;Swap 机制存在的本质原因是 Linux 系统提供了虚拟内存管理机制，每一个进程认为其独占内存空间，因此所有进程的内存空间之和远远大于物理内存。所有进程的内存空间之和超过物理内存的部分就需要交换到磁盘上。&lt;/p&gt;
&lt;p&gt;操作系统以 page 为单位管理内存，当进程发现需要访问的数据不在内存时，操作系统可能会将数据以页的方式加载到内存中。上述过程被称为缺页中断，当操作系统发生缺页中断时，就会通过系统调用将 page 再次读到内存中。&lt;/p&gt;
&lt;p&gt;但主内存的空间是有限的，当主内存中不包含可以使用的空间时，操作系统会从选择合适的物理内存页驱逐回磁盘，为新的内存页让出位置，选择待驱逐页的过程在操作系统中叫做页面替换（Page Replacement），替换操作又会触发 swap 机制。&lt;/p&gt;
&lt;p&gt;如果物理内存足够大，那么可能不需要 Swap 机制，但是 Swap 在这种情况下还是有一定优势：对于有发生内存泄漏几率的应用程序（进程），Swap 交换分区更是重要，这可以确保内存泄露不至于导致物理内存不够用，最终导致系统崩溃。但内存泄露会引起频繁的 swap，此时非常影响操作系统的性能。&lt;/p&gt;
&lt;p&gt;Linux 通过一个 swappiness 参数来控制 Swap 机制[2]：这个参数值可为 0-100，控制系统 swap 的优先级：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;高数值：较高频率的 swap，进程不活跃时主动将其转换出物理内存。&lt;/li&gt;
&lt;li&gt;低数值：较低频率的 swap，这可以确保交互式不因为内存空间频繁地交换到磁盘而提高响应延迟。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;最后，为什么 Buffers 也是 Page Cache 的一部分？&lt;/p&gt;
&lt;p&gt;这是因为当匿名页（Inactive(anon) 以及 Active(anon)）先被交换（swap out）到磁盘上后，然后再加载回（swap in）内存中，由于读入到内存后原来的 Swap File 还在，所以 SwapCached 也可以认为是 File-backed page，即属于 Page Cache。这个过程如图所示：(匿名页的被交换后也是 Page Cache)&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2F3c3bdceej00r32mkz000ac000hs0064g.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;15-page-cache-与-buffer-cache&#34;&gt;1.5 Page Cache 与 buffer cache&lt;/h3&gt;
&lt;p&gt;执行 free 命令，注意到会有两列名为 buffers 和 cached，也有一行名为 “-/+ buffers/cache”。&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;~ free -m  
             total       used       free     shared    buffers     cached  
Mem:        128956      96440      32515          0       5368      39900  
-/+ buffers/cache:      51172      77784  
Swap:        16002          0      16001 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;其中，cached 列表示当前的页缓存（Page Cache）占用量，buffers 列表示当前的块缓存（buffer cache）占用量。用一句话来解释：Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。&lt;/p&gt;
&lt;p&gt;Page Cache）占用量，buffers 列表示当前的块缓存（buffer cache）占用量。用一句话来解释：Page Cache 用于缓存文件的页数据，buffer cache 用于缓存块设备（如磁盘）的块数据。页是逻辑上的概念，因此 Page Cache 是与文件系统同级的；块是物理上的概念，因此 buffer cache 是与块设备驱动程序同级的。&lt;/p&gt;
&lt;p&gt;Page Cache 与 buffer cache 的共同目的都是加速数据 I/O：写数据时首先写到缓存，将写入的页标记为 dirty，然后向外部存储 flush，也就是缓存写机制中的 write-back（另一种是 write-through，Linux 默认情况下不采用）；读数据时首先读取缓存，如果未命中，再去外部存储读取，并且将读取来的数据也加入缓存。操作系统总是积极地将所有空闲内存都用作 Page Cache 和 buffer cache，当内存不够用时也会用 LRU 等算法淘汰缓存页。&lt;/p&gt;
&lt;p&gt;在 Linux 2.4 版本的内核之前，Page Cache 与 buffer cache 是完全分离的。但是，块设备大多是磁盘，磁盘上的数据又大多通过文件系统来组织，这种设计导致很多数据被缓存了两次，浪费内存。所以在 2.4 版本内核之后，两块缓存近似融合在了一起：如果一个文件的页加载到了 Page Cache，那么同时 buffer cache 只需要维护块指向页的指针就可以了。只有那些没有文件表示的块，或者绕过了文件系统直接操作（如dd命令）的块，才会真正放到 buffer cache 里。因此，我们现在提起 Page Cache，基本上都同时指 Page Cache 和 buffer cache 两者，本文之后也不再区分，直接统称为 Page Cache。&lt;/p&gt;
&lt;p&gt;下图近似地示出 32-bit Linux 系统中可能的一种 Page Cache 结构，其中 block size 大小为 1KB，page size 大小为 4KB。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2F49a9a869j00r32mkz000nc000hs00cag.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;Page Cache 中的每个文件都是一棵基数树（radix tree，本质上是多叉搜索树），树的每个节点都是一个页。根据文件内的偏移量就可以快速定位到所在的页，如下图所示。关于基数树的原理可以参见英文维基，这里就不细说了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2Fb103f4edj00r32mkz000pc000hs00axg.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;16-page-cache-与预读&#34;&gt;1.6 Page Cache 与预读&lt;/h3&gt;
&lt;p&gt;操作系统为基于 Page Cache 的读缓存机制提供预读机制（PAGE_READAHEAD），一个例子是：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;用户线程仅仅请求读取磁盘上文件 A 的 offset 为 0-3KB 范围内的数据，由于磁盘的基本读写单位为 block（4KB），于是操作系统至少会读 0-4KB 的内容，这恰好可以在一个 page 中装下。&lt;/li&gt;
&lt;li&gt;但是操作系统出于局部性原理会选择将磁盘块 offset [4KB,8KB)、[8KB,12KB) 以及 [12KB,16KB) 都加载到内存，于是额外在内存中申请了 3 个 page；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;下图代表了操作系统的预读机制：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://nimg.ws.126.net/?url=http%3A%2F%2Fdingyue.ws.126.net%2F2021%2F1124%2Fb5460636j00r32mkz0013c0010q00ayg.jpg&amp;amp;thumbnail=650x2147483647&amp;amp;quality=80&amp;amp;type=jpg&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;上图中，应用程序利用 read 系统调动读取 4KB 数据，实际上内核使用 readahead 机制完成了 16KB 数据的读取。&lt;/p&gt;
&lt;h2 id=&#34;2page-cache-与文件持久化的一致性可靠性&#34;&gt;2、Page Cache 与文件持久化的一致性&amp;amp;可靠性&lt;/h2&gt;
&lt;p&gt;现代 Linux 的 Page Cache 正如其名，是对磁盘上 page（页）的内存缓存，同时可以用于读/写操作。一切内存缓存都存在一致性问题：内存中的数据与磁盘中的数据不一致，例如用作分布式中间件缓存的 Redis 就与 MySQL 等数据库中的数据存在不一致。&lt;/p&gt;
&lt;p&gt;Linux 提供多种机制来保证数据一致性，但无论是单机上的内存与磁盘一致性，还是分布式组件中节点 1 与节点 2 、节点 3 的数据一致性问题，理解的关键是 trade-off：吞吐量与数据一致性保证是一对矛盾。&lt;/p&gt;
&lt;p&gt;首先，需要我们理解一下文件的数据。文件 = 数据 + 元数据。元数据用来描述文件的各种属性，也必须存储在磁盘上。因此，我们说保证文件一致性其实包含了两个方面：数据一致+元数据一致。&lt;/p&gt;
&lt;p&gt;文件的元数据包括：文件大小、创建时间、访问时间、属主属组等信息。&lt;/p&gt;
&lt;p&gt;我们考虑如下一致性问题：如果发生写操作并且对应的数据在 Page Cache 中，那么写操作就会直接作用于 Page Cache 中，此时如果数据还没刷新到磁盘，那么内存中的数据就领先于磁盘，此时对应 page 就被称为 Dirty page。&lt;/p&gt;
&lt;p&gt;当前 Linux 下以两种方式实现文件一致性：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Write Through（写穿）：向用户层提供特定接口，应用程序可主动调用接口来保证文件一致性；&lt;/li&gt;
&lt;li&gt;Write back（写回）：系统中存在定期任务（表现形式为内核线程），周期性地同步文件系统中文件脏数据块，这是默认的 Linux 一致性方案；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;上述两种方式最终都依赖于系统调用，主要分为如下三种系统调用：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;方法&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;fsync(intfd)&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;fsync(fd)：将 fd 代表的文件的脏数据和脏元数据全部刷新至磁盘中。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;fdatasync (int fd)&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;fdatasync(fd)：将 fd 代表的文件的脏数据刷新至磁盘，同时对必要的元数据刷新至磁盘中，这里所说的必要的概念是指：对接下来访问文件有关键作用的信息，如文件大小，而文件修改时间等不属于必要信息&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;&lt;strong&gt;sync()&lt;/strong&gt;&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;sync()：则是对系统中所有的脏的文件数据元数据刷新至磁盘中&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;上述三种系统调用可以分别由用户进程与内核进程发起。下面我们研究一下内核线程的相关特性。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;创建的针对回写任务的内核线程数由系统中持久存储设备决定，为每个存储设备创建单独的刷新线程；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;关于多线程的架构问题，Linux 内核采取了 Lighthttp 的做法，即系统中存在一个管理线程和多个刷新线程（每个持久存储设备对应一个刷新线程）。管理线程监控设备上的脏页面情况，若设备一段时间内没有产生脏页面，就销毁设备上的刷新线程；若监测到设备上有脏页面需要回写且尚未为该设备创建刷新线程，那么创建刷新线程处理脏页面回写。而刷新线程的任务较为单调，只负责将设备中的脏页面回写至持久存储设备中。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;刷新线程刷新设备上脏页面大致设计如下：&lt;/p&gt;
&lt;p&gt;每个设备保存脏文件链表，保存的是该设备上存储的脏文件的 inode 节点。所谓的回写文件脏页面即回写该 inode 链表上的某些文件的脏页面；&lt;/p&gt;
&lt;p&gt;系统中存在多个回写时机，第一是应用程序主动调用回写接口（fsync，fdatasync 以及 sync 等），第二管理线程周期性地唤醒设备上的回写线程进行回写，第三是某些应用程序/内核任务发现内存不足时要回收部分缓存页面而事先进行脏页面回写，设计一个统一的框架来管理这些回写任务非常有必要。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Write Through 与 Write back 在持久化的可靠性上有所不同：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Write Through 以牺牲系统 I/O 吞吐量作为代价，向上层应用确保一旦写入，数据就已经落盘，不会丢失；&lt;/li&gt;
&lt;li&gt;Write back 在系统发生宕机的情况下无法确保数据已经落盘，因此存在数据丢失的问题。不过，在程序挂了，例如被 kill -9，Page Cache 中的数据操作系统还是会确保落盘；&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;3为什么使用-page-cache-与为什么不使用-page-cache&#34;&gt;3、为什么使用 Page Cache 与为什么不使用 Page Cache?&lt;/h2&gt;
&lt;h3 id=&#34;31-page-cache-的优势&#34;&gt;3.1 Page Cache 的优势&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;1.加快数据访问&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果数据能够在内存中进行缓存，那么下一次访问就不需要通过磁盘 I/O 了，直接命中内存缓存即可。&lt;/p&gt;
&lt;p&gt;由于内存访问比磁盘访问快很多，因此加快数据访问是 Page Cache 的一大优势。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2.减少 I/O 次数，提高系统磁盘 I/O 吞吐量&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;得益于 Page Cache 的缓存以及预读能力，而程序又往往符合局部性原理，因此通过一次 I/O 将多个 page 装入 Page Cache 能够减少磁盘 I/O 次数， 进而提高系统磁盘 I/O 吞吐量。&lt;/p&gt;
&lt;h3 id=&#34;32-page-cache-的劣势&#34;&gt;3.2 Page Cache 的劣势&lt;/h3&gt;
&lt;p&gt;page cache 也有其劣势，最直接的缺点是需要占用额外物理内存空间，物理内存在比较紧俏的时候可能会导致频繁的 swap 操作，最终导致系统的磁盘 I/O 负载的上升。&lt;/p&gt;
&lt;p&gt;Page Cache 的另一个缺陷是对于应用层并没有提供很好的管理 API，几乎是透明管理。应用层即使想优化 Page Cache 的使用策略也很难进行。因此一些应用选择在用户空间实现自己的 page 管理，例如 MySQL InnoDB 存储引擎以 16KB 的页进行管理。&lt;/p&gt;
&lt;p&gt;Page Cache 最后一个缺陷是在某些应用场景下比 Direct I/O 多一次磁盘读 I/O 以及磁盘写 I/O。&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>WAL</title>
      <link>https://weedge.github.io/post/wal/</link>
      <pubDate>Sun, 21 Nov 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/wal/</guid>
      
        <description>&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;p&gt;​	数据落地之前，如果出现持久化存储引擎实例重启，或者服务当机重启，如何进行故障恢复（Crash Recovery）呢？数据写操作增删改，这些操作状态数据，是如何保证事务中原子性和持久性的呢？ 这些问题数据大拿们提出了&lt;a href=&#34;https://en.wikipedia.org/wiki/Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics&#34;&gt;Algorithms for Recovery and Isolation Exploiting Semantics&lt;/a&gt; ，基于语义的恢复与隔离算法,现代数据库的基础理论；当前主流关系型数据在事务实现上都受到该理论的影响，其中有两种故障恢复的方法： 预写日志(write-ahead logging (WAL) ) 和shadow-page technique；shadow-page 方法简单介绍就是每次事务操作，以page为单位，写时复制的方式，分为Current和Shadow，类似主备的形式，如果commit成功，Current中的page合并到 Shadow中; 如果abort不成功丢弃Current的page; 如果Crash了，从Shadow中的page恢复，对所有未提交事务的回滚操作； 由于shadow-page技术的实现以page为单位，page内无法并发操作，commit/回滚时会有大量垃圾回收操作；本文主要介绍WAL，以及对应持久化存储引擎的实现机制介绍。&lt;/p&gt;
&lt;h2 id=&#34;wal&#34;&gt;WAL&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;预写日志&lt;/strong&gt;( &lt;strong&gt;WAL&lt;/strong&gt; ) 是一系列技术，用于在&lt;a href=&#34;https://en.wikipedia.org/wiki/Database_system&#34;&gt;数据库系统中&lt;/a&gt;提供&lt;a href=&#34;https://en.wikipedia.org/wiki/Atomicity_(database_systems)&#34;&gt;原子性&lt;/a&gt;和&lt;a href=&#34;https://en.wikipedia.org/wiki/Durability_(database_systems)&#34;&gt;持久性&lt;/a&gt;（两个&lt;a href=&#34;https://en.wikipedia.org/wiki/ACID&#34;&gt;ACID&lt;/a&gt;属性）。在将更改写入数据库之前，更改首先记录在日志中，日志必须写入&lt;a href=&#34;https://en.wikipedia.org/wiki/Stable_storage&#34;&gt;稳定存储&lt;/a&gt;（保证任何给定写入操作的原子性，并允许编写对某些硬件和电源故障具有&lt;a href=&#34;https://en.wikipedia.org/wiki/Robustness_(computer_science)&#34;&gt;鲁棒性的&lt;/a&gt;软件）。&lt;/p&gt;
&lt;p&gt;这样做的目的可以通过一个例子来说明。想象一下，当运行它的机器断电时，它正在执行某些操作。重新启动时，该程序可能需要知道它正在执行的操作是成功、部分成功还是失败。如果使用预写日志，程序可以检查此日志并将意外断电时应该执行的操作与实际执行的操作进行比较。在此比较的基础上，程序可以决定撤消已开始的内容、完成已开始的内容或保持原样。&lt;/p&gt;
&lt;p&gt;在使用 WAL 的系统中，所有修改在应用之前都会写入&lt;a href=&#34;https://en.wikipedia.org/wiki/Database_log&#34;&gt;日志&lt;/a&gt;。通常redo和undo信息都存储在日志中。&lt;/p&gt;
&lt;p&gt;注意：写不一定是顺序写，一般&lt;a href=&#34;https://en.wikipedia.org/wiki/Computer_data_storage&#34;&gt;计算机存储&lt;/a&gt; 非易失性的硬件结构对顺序写的性能高于随机写的性能，比如常用的磁盘HDD/SSD; 但是最近基于NVM技术(结合磁盘和内存的特性)的存储硬件PC-RAM(Phase Change Random Access Memory), STT-RAM( Spin Transfer Torque Random Access Memory),  R-RAM(Resistive Random Access Memory)，结合内存中随机访问，磁盘非易失性特性，随机写和顺序写没什么差别，&lt;a href=&#34;http://repository.bilkent.edu.tr/bitstream/handle/11693/37609/Implications%20of%20non-volatile%20memory%20as%20primary%20storage%20for%20database%20management%20systems.pdf&#34;&gt;Implications of Non-Volatile Memory as Primary Storage for Database Management Systems&lt;/a&gt; 这篇论文中提到Pg如果不部署内部的buffer cache，所有写直接写到NVM对应的存储硬件中，可以去掉redo日志，但是undo日志任然需要,在系统错误时复原; 一般学术方案要领先实际工程许多，真正落地在生产环境中，还是用躺过坑的成熟方案 （顺便想到现在一些k/v存储引擎考虑上云，支持云厂商的云盘，可以认为无限容量）。硬件结构决定上层软件存储引擎的设计的优化，以下都是以常用的磁盘HDD/SSD的硬件结构来介绍存储引擎实现WAL技术。&lt;/p&gt;
&lt;h2 id=&#34;mysql-innodb存储引擎&#34;&gt;mysql Innodb存储引擎&lt;/h2&gt;
&lt;p&gt;mysql Innodb存储引擎是通过 redo、undo 日志实现 WAL,主要用于crash 恢复和回滚，满足本地事务中的持久性和原子性，来保证数据一致性；当然innodb引擎为了提高并发读性能，undo log中加入了MVCC (多版本并发控制)相关信息； 另外，mysql server层执行器会写bin log，主要是用来恢复某个时间的点数据以及主从复制数据使用，bin log文件和存储引擎无关；分别简要介绍redo, undo, bin log 文件在mysql中的作用。&lt;/p&gt;
&lt;h3 id=&#34;redolog&#34;&gt;redolog&lt;/h3&gt;
&lt;h4 id=&#34;为什么需要redo-log&#34;&gt;为什么需要redo log？&lt;/h4&gt;
&lt;p&gt;我们都知道，事务的四大特性里面有一个是 &lt;strong&gt;持久性&lt;/strong&gt; ，具体来说就是&lt;strong&gt;只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态&lt;/strong&gt; 。那么mysql是如何保证一致性的呢？最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;因为 Innodb是以页为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！&lt;/li&gt;
&lt;li&gt;一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;因此 mysql设计了redolog ， &lt;strong&gt;具体来说就是只记录事务对数据页做了哪些修改&lt;/strong&gt;，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)。&lt;/p&gt;
&lt;h4 id=&#34;redo-log基本概念&#34;&gt;redo log基本概念&lt;/h4&gt;
&lt;p&gt;redo log包括两部分：一个是内存中的日志缓冲( redo log buffer )，另一个是磁盘上的日志文件(  redo log file )。 mysql 每执行一条 DML 修改写语句，操作的数据在内存中(如果没有会load到内存中)，首先会记修改操作的反操作逻辑数据记录写入undo log buffer中，然后会将修改哪个物理页面做了什么操作记录写入 redo log buffer ，后续某个时间点再一次性将多个操作记录写到 redo log file 和 undo log file。这种 &lt;strong&gt;先写日志，再写磁盘&lt;/strong&gt; 的技术就是 MySQL中的 WAL。&lt;/p&gt;
&lt;p&gt;在计算机操作系统中，用户空间( user space )下的缓冲区数据一般情况下是无法直接写入磁盘的，中间必须经过操作系统内核空间(kernel space )缓冲区( OS Buffer )。因此， redo/undo log buffer 写入 redo/undo log file; 实际上是先写入 OS Buffer ，然后再通过系统调用 fsync() 将其刷到 redo/undo log file 中，过程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://image-static.segmentfault.com/755/731/755731335-aec527828a1323b6_fix732&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;mysql 支持三种将 redo/undo log buffer 写入 redo/undo log file 的时机，可以通过 innodb_flush_log_at_trx_commit  参数配置，各参数值含义如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;参数值&lt;/th&gt;
&lt;th&gt;含义&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0（延迟写）&lt;/td&gt;
&lt;td&gt;事务提交时不会将 redo/undo log buffer 中日志写入到 os buffer ，而是每秒写入 os buffer 并调用 fsync() 写入到 redo/undo log file 中。也就是说设置为0时是(大约)每秒刷新写入到磁盘中的，当系统崩溃，会丢失1秒钟的数据。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1（实时写，实时刷）&lt;/td&gt;
&lt;td&gt;事务每次提交都会将 redo/undo log buffer 中的日志写入 os buffer 并调用 fsync() 刷到 redo/undo log file 中。这种方式即使系统崩溃也不会丢失任何数据，但是因为每次提交都写入磁盘，IO的性能较差。一般开启&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;2（实时写，延迟刷）&lt;/td&gt;
&lt;td&gt;每次提交都仅写入到 os buffer ，然后是每秒调用 fsync() 将 os buffer 中的日志写入到 redo/undo log file 。&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;&lt;img src=&#34;https://image-static.segmentfault.com/706/634/706634199-04894beff4e7b54f_fix732&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h4 id=&#34;redo-log记录形式&#34;&gt;redo log记录形式&lt;/h4&gt;
&lt;p&gt;前面说过， redo log 实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。通过&lt;code&gt;show variables like &#39;innodb_log%&#39;; &lt;/code&gt; 查看参数；记录文件形式如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://image-static.segmentfault.com/390/444/3904443652-cc3225d69e1d0476_fix732&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;在innodb存储引擎中，既有 redo log 需要刷盘，还有 数据页 也需要刷盘， redo log 存在的意义主要就是降低对数据页刷盘的要求 。在上图中， write pos 表示 redo log 当前记录的 LSN (逻辑序列号)位置， check point 表示数据页更改记录刷盘后对应 redo log 所处的 LSN (逻辑序列号)位置。 write pos 到 check point 之间的部分是 redo log 空着的部分，用于记录新的记录； check point 到 write pos 之间是 redo log 待落盘的数据页更改记录。当 write pos 追上 check point 时，会先推动 check point 向前移动，空出位置再记录新的日志。&lt;/p&gt;
&lt;p&gt;启动 innodb 的时候，不管上次是正常关闭还是异常关闭，总是会进行恢复操作。因为 redo log 记录的是数据页的物理变化，因此恢复的时候速度比逻辑日志(如 binlog )要快很多。 重启 innodb 时，首先会检查磁盘中数据页的 LSN ，如果数据页的 LSN 小于日志中的 LSN ，则会从 checkpoint 开始恢复。 还有一种情况，在宕机前正处于checkpoint 的刷盘过程，且数据页的刷盘进度超过了日志页的刷盘进度，此时会出现数据页中记录的 LSN 大于日志中的 LSN，这时超出日志进度的部分将不会重做，因为这本身就表示已经做过的事情，无需再重做。&lt;/p&gt;
&lt;p&gt;Mysql8.0 InnoDB存储引擎写操作，对redo log的写操作进行无锁全异步设计优化，增加；具体详细见官方文档：&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/optimizing-innodb-logging.html&#34;&gt;优化 InnoDB 重做日志&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&#34;undolog&#34;&gt;undolog&lt;/h3&gt;
&lt;p&gt;数据库事务四大特性中有一个是 &lt;strong&gt;原子性&lt;/strong&gt; ，具体来说就是 &lt;strong&gt;原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况&lt;/strong&gt;。实际上， &lt;strong&gt;原子性&lt;/strong&gt; 底层就是通过 undo log 实现的。 undo log 主要记录了数据的逻辑变化，比如一条  INSERT 语句，对应一条 DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的undo log ，这样在发生错误时，就能回滚到事务之前的数据状态。同时， undo log 也是 MVCC (多版本并发控制)实现的关键；通过 &lt;code&gt;show variables like &#39;%undo%&#39;; &lt;/code&gt;查看参数。&lt;/p&gt;
&lt;h3 id=&#34;binlog&#34;&gt;binlog&lt;/h3&gt;
&lt;p&gt;binlog 用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。 binlog 是 mysql的逻辑日志，并且由 Server 层进行记录，使用任何存储引擎的 mysql 数据库都会记录 binlog 日志（&lt;code&gt;log_bin&lt;/code&gt; 打开的情况下）。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;逻辑日志&lt;/strong&gt;： 可以简单理解为记录的就是sql语句 。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;物理日志&lt;/strong&gt;： mysql 数据最终是保存在数据页中的，物理日志记录的就是数据页变更 。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;binlog 是通过追加的方式进行写入的，可以通过 max_binlog_size 参数设置每个 binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。binlog相关参数通过&lt;code&gt;show variables like &amp;quot;%binlog%&amp;quot;;&lt;/code&gt; 查看；通过&lt;code&gt;show variables like &amp;quot;%log_bin%&amp;quot;;&lt;/code&gt;查看binlog是否开启,以及binlog日志目录，8.0版本默认时开启。&lt;/p&gt;
&lt;h4 id=&#34;binlog使用场景&#34;&gt;binlog使用场景&lt;/h4&gt;
&lt;p&gt;在实际应用中， binlog 的主要使用场景有两个，分别是 &lt;strong&gt;主从复制&lt;/strong&gt; 和 &lt;strong&gt;数据恢复&lt;/strong&gt; 。&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;主从复制&lt;/strong&gt; ：在 Master 端开启 binlog ，然后将 binlog 发送到各个 Slave 端， Slave 端重放 binlog 从而达到主从数据一致。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;数据恢复&lt;/strong&gt; ：通过使用 mysqlbinlog 工具来恢复数据。&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;binlog刷盘时机&#34;&gt;binlog刷盘时机&lt;/h4&gt;
&lt;p&gt;对于 InnoDB 存储引擎而言，只有在事务提交时才会记录 biglog ，此时记录还在内存中，那么 biglog是什么时候刷到磁盘中的呢？ mysql 通过 sync_binlog 参数控制 biglog 的刷盘时机，取值范围是 0-N：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;0：不去强制要求，由系统自行判断何时写入磁盘；&lt;/li&gt;
&lt;li&gt;1：每次 commit 的时候都要将 binlog 写入磁盘；一般开启&lt;/li&gt;
&lt;li&gt;N：每N个事务，才会将 binlog 写入磁盘。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;从上面可以看出， sync_binlog 最安全的是设置是 1 ，这也是 MySQL 5.7.7之后版本的默认值。但是设置一个大一些的值可以提升数据库性能，因此实际情况下也可以将值适当调大，牺牲一定的一致性来获取更好的性能。&lt;/p&gt;
&lt;h4 id=&#34;binlog日志格式&#34;&gt;binlog日志格式&lt;/h4&gt;
&lt;p&gt;binlog 日志有三种格式，分别为 STATMENT 、 ROW 和 MIXED 。在 MySQL 5.7.7 之前，默认的格式是 STATEMENT ， MySQL 5.7.7 之后，默认值是 ROW 。日志格式通过 binlog-format 指定; &lt;code&gt;show variables like &amp;quot;%binlog_format%&amp;quot;;&lt;/code&gt;查看&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;STATMENT ： 基于 SQL 语句的复制( statement-based replication, SBR )，每一条会修改数据的sql语句会记录到 binlog 中 。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点： 不需要记录每一行的变化，减少了 binlog  日志量，节约了  IO  , 从而提高了性能；&lt;/li&gt;
&lt;li&gt;缺点： 在某些情况下会导致主从数据不一致，比如执行本地时间操作； &lt;code&gt;SELECT NOW(),SYSDATE(),SLEEP(3),NOW(),SYSDATE();&lt;/code&gt;。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ROW ： 基于行的复制( row-based replication, RBR )，不记录每条sql语句的上下文信息，仅需记录哪条数据被修改了 。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;优点： 不会出现某些特定情况下的存储过程、或function、或trigger的调用和触发无法被正确复制的问题 ；&lt;/li&gt;
&lt;li&gt;缺点： 会产生大量的日志，尤其是 alter table 的时候会让日志暴涨；&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;MIXED ： 基于 STATMENT 和 ROW 两种模式的混合复制( mixed-based replication, MBR )，一般的复制使用 STATEMENT 模式保存 binlog ，对于 STATEMENT 模式无法复制的操作使用 ROW 模式保存 binlog；&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;binlog日志主要是用来主从同步复制数据以及数据恢复，是mysql server层执行器进行操作(主)写入和(从)读入(relaylog)；&lt;/p&gt;
&lt;p&gt;数据可以按天按周进行备份，顺序写入，没有大小限制(文件大小有限，但是整体没有限制，多个文件binlog.**可以通过binlog.index定位)；&lt;/p&gt;
&lt;h3 id=&#34;redo-log与binlog区别&#34;&gt;redo log与binlog区别&lt;/h3&gt;
&lt;p&gt;不同于redo log, 虽然两者都可以用来恢复数据，但是在mysql中innodb存储引擎的wal机制下生成的redolog有大小限制， redo log 实际上记录数据页的变更，而这种变更记录是没必要全部保存，因此 redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志；而binlog主要是用来数据恢复，如果备份时间长，用户在某段时间有误操作，需要回滚操作，就可以同binlog来恢复到某个时间点的日志状态；对于redo log是做不到的；而且binlog 不是存储引擎特有的，所以可以在不同的存储引擎公用来恢复数据场景；区别如下：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;/th&gt;
&lt;th&gt;redo log&lt;/th&gt;
&lt;th&gt;binlog&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;文件大小&lt;/td&gt;
&lt;td&gt;redo log 的大小是固定的。&lt;/td&gt;
&lt;td&gt;binlog 可通过配置参数 max_binlog_size 设置每个 binlog 文件的大小。&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;实现方式&lt;/td&gt;
&lt;td&gt;redo log 是 InnoDB 引擎层实现的，并不是所有引擎都有。&lt;/td&gt;
&lt;td&gt;binlog 是 Server 层实现的，MySQL 3.23.14 中引入的，所有引擎都可以使用 binlog 日志，服务器运行期间生成的服务器全局状态更改的跟踪日志&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;记录方式&lt;/td&gt;
&lt;td&gt;redo log 采用循环写的方式记录，当写到结尾时，会回到开头循环写日志。&lt;/td&gt;
&lt;td&gt;binlog通过追加的方式记录，当文件大小大于给定值后，后续的日志会记录到新的文件上&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;适用场景&lt;/td&gt;
&lt;td&gt;redo log 适用于崩溃恢复(crash-safe)，重启恢复的时候，通过check point和write pos 来恢复数据&lt;/td&gt;
&lt;td&gt;binlog 适用于主从复制和数据恢复，某个时间点的操作记录归档，可以按时间点进行恢复；以及主从之间的复制重放, 实现高可用的基础，以及订阅binlog进行不同分布式存储数据的同步&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;由 binlog 和 redo log 的区别可知：因为mysql 早期自带的MyISAM存储引擎设计用 binlog 日志只用于归档，进行数据恢复，只依靠 binlog 是没有 crash-safe 能力的。innodb存储引擎引入mysql之后，引入redo/undo log文件来支持事务持久性和原子性来保证写入数据的一致性；但只有 redo log 也不行，因为 redo log 是 InnoDB 特有的，循环写入，无法还原不在这个redo log中的记录，比如从服务启动或者记录数据落后很多；因此需要 binlog 和 redo log二者同时记录，才能保证当数据库发生误删或者宕机重启时，数据不会丢失。&lt;/p&gt;
&lt;h3 id=&#34;两阶段提交&#34;&gt;两阶段提交&lt;/h3&gt;
&lt;p&gt;为了保证写入两份日志redo log, binlog 最终恢复数据是一致的，采用两阶段提交的机制(XA,内部/全局事务 innodb提供一样的操作)，mysql server 执行器 在调用innodb存储引擎接口进行写操作的时候，起到一个事务协调者的作用,通过TC_LOG(Transaction Coordinator Log)基类定义了事务日志需要实现的接口: open, prepare, commit, rollback, close；实现这些接口的类：TC_LOG_DUMMY(disable the logging), TC_LOG_MMAP(mmap logging), MYSQL_BIN_LOG(binlog)；主要是是查看MYSQL_BIN_LOG类中&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L7881&#34;&gt;prepare&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L7934&#34;&gt;commit&lt;/a&gt; 的实现；prepare 和 commit最终会调用存储引擎初始化时指向的handlerton对象对应函数；（这种接口隔离的常用设计，将调用方和实现方进行解耦，根据参数配置来绑定实现方，运行时动态调用）&lt;/p&gt;
&lt;p&gt;mysql是以plugin的方式管理存储引擎，replication(主从副本同步)插件和其他插件（通过&lt;code&gt;SHOW PLUGINS;&lt;/code&gt;查看)；具体的插件代码在&lt;a href=&#34;https://github.com/mysql/mysql-server/tree/8.0/plugin&#34;&gt;plugin&lt;/a&gt;文件中，简单的插件示例&lt;a href=&#34;https://github.com/mysql/mysql-server/tree/8.0/plugin/rewrite_example&#34;&gt;rewrite_example&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;mysqld 启动时通过配置初始的存储引擎(默认innodb)，调用&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/mysqld.cc#L5815&#34;&gt;init_server_components&lt;/a&gt; 调用innodb存储引擎的接口进行初始化ha_handler, 在&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/handler/ha_innodb.cc#L4935&#34;&gt;innodb_init&lt;/a&gt;中进行初始化, 比如刷盘操作 innobase_hton-&amp;gt;flush_logs = innobase_flush_logs; 然后在sql/handler中定义的相关接口调用, 比如&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/handler.cc#L2459&#34;&gt;ha_flush_logs&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;安装replication插件时会注册插件中相应的方法加入observer 列表中，运行触发的时候以AOP的方式RUN_HOOK 扫描observer列表Observer_info-&amp;gt;observer调用对应插件函数；replication插件需要实现以下&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/replication.h&#34;&gt;replication文件中&lt;/a&gt;相关结构体的方法(接口) 才能加载：&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;struct Trans_observer /* Observes and extends transaction execution */
struct Server_state_observer /* Observer server state */
struct Binlog_transmit_observer /* Observe and extends the binlog dumping thread. */
struct Binlog_relay_IO_observer /* Observes and extends the service of slave IO thread. */
struct Binlog_storage_observer /* Observe binlog logging storage */
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这里会有各种日志的刷新机制，可以通过&lt;code&gt;show variables like &#39;%innodb%flush%&#39;; show variables like &#39;sync_binlog&#39;;&lt;/code&gt;获取对应的参数，可以去官网&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html&#34;&gt;Server Option, System Variable, and Status Variable Reference&lt;/a&gt; 查找对应的详情进行配置优化；&lt;/p&gt;
&lt;p&gt;当开启binlog时, MySQL默认使用该隐式XA模式，开启自动提交事务autocommit。事务的提交流程相对比较复杂，执行简单的update操作，简述如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;0. 执行器数据获取修改：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;执行器调用innodb存储引擎接口获取满足条件的数据，通过树索引查找/全表查找， 如果数据在buffer pool中查找到，返回数据；否则从磁盘表空间文件中读取数据page到buffer pool  clean page中，返回数据；无数据，流程终止返回；&lt;/li&gt;
&lt;li&gt;执行器修改找到的数据，将修改的数据 调用innodb存储引擎接口写入新数据，进行两阶段提交；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;事务的提交过程入口点位于 &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/handler.cc#L1592&#34;&gt;ha_commit_trans&lt;/a&gt;函数，以mysql binlog 为事务2pc协调者为例，事务提交的过程如下：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;1. mysql bin log 事务2pc协调者 处理 准备prepare阶段&lt;/strong&gt;：(tc_log-&amp;gt;prepare)&lt;/p&gt;
&lt;p&gt;MYSQL_BIN_LOG::prepare(THD *thd, bool all)  设置 thd-&amp;gt;durability_property = HA_IGNORE_DURABILITY; 用于在存储引擎准备阶段不刷新事务日志redo/undo log 到磁盘日志文件中；&lt;/p&gt;
&lt;p&gt;调用流程：ha_prepare_low → innobase_xa_prepare → trx_prepare_for_mysql →   &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/trx/trx0trx.cc#L2919&#34;&gt;static void trx_prepare(trx_t *trx)&lt;/a&gt;   → trx_prepare_low → trx_undo_set_state_at_prepare&lt;/p&gt;
&lt;ol start=&#34;3&#34;&gt;
&lt;li&gt;
&lt;p&gt;执行器调用innodb存储引擎接口进行修改操作，首先写入数据的旧值至undo log buffer中，更新InnoDB的undo回滚段，将其设置为Prepare状态（&lt;code&gt;TRX_UNDO_PREPARED&lt;/code&gt;）写入mlog中，返回 redo log 的LSN,&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更新buffer pool中的数据(如果插入需要从free(free list)变成clean page(lru list)，free list 不够时需要从flush ist或者lru list淘汰一定的page变成free page 加入free list); 修改的clean page(lru list)变成 dirty page(lru list)(更新的数据页在缓存中，还未刷盘)；dirty page写入flush list； 为了提高写性能异步线程刷盘(刷盘时机可以在commit之后；MySQL 5.7引入了page cleaner线程)&lt;/p&gt;
&lt;p&gt;Tips: 在flush list上的页面一定在lru List上，但是反之则不成立。一个数据页可能会在不同的时刻被修改多次，在数据页上记录了最老(也就是第一次)的一次修改的LSN，即oldest_modification。不同数据页有不同的oldest_modification，flush list中的节点按照oldest_modification排序，链表尾是最小的，也就是最早被修改的数据页，当需要从flush list中淘汰页面时候，从链表尾部开始淘汰。加入flush list，需要使用flush_list_mutex保护，所以能保证flush list中节点的顺序。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;同时将数据页的修改记录LSN写入redo log buffer中，准备提交事务，此时 redo log 处于 prepare 状态，如果thd-&amp;gt;durability_property = HA_IGNORE_DURABILITY, 将&lt;code&gt;LSN&lt;/code&gt; 写入redo log 磁盘文件中；原子化操作&lt;code&gt;trx_t&lt;/code&gt; 事务状态为 PREPARED (用于事务隔离操作)； 将&lt;code&gt;gtid_desc&lt;/code&gt;写入undolog 表空间中；然后告知执行器执行完成了，随时可以提交事务。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Tips: 这里会出现redo log file写满的情况，buffer 写入会hang住，MySQL就会停下手头的任务，先把脏页刷到磁盘里，才能继续干活，会导致MySQL的服务器的tps有明显的波动； 默认开启了innodb_adaptive_flushing 算法进行优化，在redo log file还没有满的时候，会根据redo log file生成的速度和刷新频率来将redo log file中的脏页刷入磁盘表空间文件中；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;2. mysql binlog 事务2pc协调者 处理 提交commit阶段：&lt;/strong&gt;(tc_log-&amp;gt;commit)&lt;/p&gt;
&lt;p&gt;调用流程：TC_LOG::enum_result MYSQL_BIN_LOG::commit(THD *thd, bool all) →&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L8717&#34;&gt;int MYSQL_BIN_LOG::ordered_commit(THD *thd, bool all, bool skip_commit)&lt;/a&gt;  , 如果没有开启log_bin，没有bin log文件，直接跳至commit阶段；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;组提交&lt;/strong&gt; (流程见代码中介绍 &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.h#L568-L641&#34;&gt;ordered_commit&lt;/a&gt; )：组提交第一眼看着有点懵逼，可以结合这片文章 &lt;a href=&#34;https://developer.aliyun.com/article/617776&#34;&gt;[图解MySQL]MySQL组提交(group commit)&lt;/a&gt; 了解；主要是为了提升事务吞吐量设计的方案(&lt;strong&gt;原则：尽量减少磁盘IO, 利用持久盘的特性顺序写&lt;/strong&gt;)；如同木桶效应一样，redo log 和 binlog 两者其中有一个没有组提交，都会降低事务吞吐量，所以最好的方式redo log 和 binlog 两者都组队提交; mysql设计者将组提交从flush阶段开始优化，将其分为几个阶段： flush 阶段、sync 阶段、(replication复制阶段) 、commit 阶段；其中replication复制阶段以HOOK的方式动态运行对于的replication复制策略，默认是异步复制。&lt;/p&gt;
&lt;p&gt;&lt;code&gt;binlog_order_commits&lt;/code&gt;参数控制innodb commit顺序和binlog写入顺序是否一致，默认启用保证顺序一致，方便备份和快速恢复；和binlog组提交配合使用，这个参数来自官网的介绍：&lt;/p&gt;
&lt;p&gt;当在复制源服务器上启用此变量时（这是默认设置），发送给存储引擎的事务提交指令在单个leader线程上被序列化，因此事务总是按照写入binlog的相同顺序提交。禁用此变量允许使用多个线程发出事务提交指令。与binlog组提交结合使用，这可以防止单个事务的提交率成为吞吐量的瓶颈，因此可能会产生性能改进。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Flush阶段：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;调用流程：TC_LOG::enum_result MYSQL_BIN_LOG::commit(THD *thd, bool all) →&lt;a href=&#34;&#34;&gt;int MYSQL_BIN_LOG::ordered_commit(THD *thd, bool all, bool skip_commit)&lt;/a&gt;  →  &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L8301&#34;&gt;int MYSQL_BIN_LOG::process_flush_stage_queue&lt;/a&gt; ;&lt;/p&gt;
&lt;p&gt;RUN_HOOK 去获取加载的插件，rpl handler Binlog_storage_delegate::after_flush FOREACH_OBSERVER宏 遍历observer列表Observer_info-&amp;gt;observer调用对应replication插件函数&lt;/p&gt;
&lt;p&gt;最终调用&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/os/os0file.cc#L2847&#34;&gt;os_file_fsync_posix&lt;/a&gt; flush redolog to disk ; 根据不同的操作系统来调用，unix操作系统调用fsync/fdatasync函数刷盘, fsync会确保OS cache中的数据直到写磁盘操作结束才会返回，并且写入元数据，而fdatasync不会; 如果想不走OS cache直接写磁盘，对打开/创建的文件句柄加上O_DIRECT属性，一般用于写系统表空间数据落盘；&lt;/p&gt;
&lt;p&gt;此时process_flush_stage_queue处理会形成一组队列，由组leader(一个组中最早开始的事务)依次为别的线程写binlog文件 在准备写binlog前，会先调用ha_flush_logs -&amp;gt; innobase_flush_logs接口，将存储的日志写到最新的LSN；然后再写binlog到文件; 这样做的目的是为了提升组提交的效率。&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;执行器 调用innodb存储引擎innobase_flush_logs-&amp;gt;log_flush_low-&amp;gt;redo_space_flush-&amp;gt;os_file_flush-&amp;gt;&lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/os/os0file.cc#L2847&#34;&gt;os_file_fsync_posix&lt;/a&gt; 接口 将 redo/undo log buffer中的数据写入redo/undo log file 磁盘中；&lt;/li&gt;
&lt;li&gt;执行器 调用 MYSQL_BIN_LOG::flush_thread_caches 将 thread caches binlog缓冲数据  写入 bin log(xid,GTID)中(还未刷盘),通过 &lt;code&gt;show variables like &#39;%binlog_cache%&#39;;&lt;/code&gt;查看缓冲大小； 并且设置好事务的写入位置m_trans_end_pos，当事务提交commit阶段的时候，直接获取位置提交；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Sync_binlog阶段：&lt;/strong&gt; &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/sql/binlog.cc#L8506&#34;&gt;std::pair&amp;lt;bool, bool&amp;gt; MYSQL_BIN_LOG::sync_binlog_file(bool force)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RUN_HOOK 去获取加载的插件，rpl handler Binlog_storage_delegate::after_sync FOREACH_OBSERVER宏遍历observer列表Observer_info-&amp;gt;observer调用对应replication插件函数；&lt;/p&gt;
&lt;p&gt;最终调用 &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/mysys/my_sync.cc#L84&#34;&gt;int my_sync(File fd, myf my_flags)&lt;/a&gt;  Sync binlog data in file to disk&lt;/p&gt;
&lt;p&gt;如果&lt;code&gt;sync_binlog&lt;/code&gt;计数超过配置值，则进行一次文件fsync，n&amp;gt;1 开启组提交，参数&lt;code&gt;sync_binlog&lt;/code&gt;的含义不是指的这么多个事务之后做一次fsync，而是多个事务一组之后做一次fsync，&lt;code&gt;binlog_group_commit_sync_delay&lt;/code&gt;,&lt;code&gt;binlog_group_commit_sync_no_delay_count&lt;/code&gt; 这些参数见官网文档；&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;开始生成这个时间点的逻辑操作日志格式，通过&lt;code&gt;sync_binlog&lt;/code&gt; flush策略异步将thead caches中的数据批量写入到磁盘binlog文件binlog.**/binlog.index中； 通过 &lt;code&gt;show binlog events;&lt;/code&gt;来查看binlog文件相关的信息，也可以对单个文件查看；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;Async/Semisync/Group 异步/半同步/组复制阶段：&lt;/strong&gt; (写操作都在主上)&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;异步复制&lt;/strong&gt;：主库在记录完binlog，执行完自己的事务之后就会直接返回，mysql主从模式默认是异步复制；异步复制流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/async-replication-diagram.png&#34; alt=&#34;async-replication-diagram&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;半同步复制&lt;/strong&gt;：主的事务需要等一台从同步binlog日志提交到Relay Log中(sync_relay=1)，返回ack，主库提交事务；半同步流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/semisync-replication-diagram.png&#34; alt=&#34;semisync-replication-diagram&#34;&gt;&lt;/p&gt;
&lt;p&gt;从MySQL5.5开始 以插件的形式支持半同步复制；如果需要支持，主从都需要安装半同步插件库；对应的代码在&lt;a href=&#34;https://github.com/mysql/mysql-server/tree/8.0/plugin/semisync&#34;&gt;plugin/semisync&lt;/a&gt;文件夹中。&lt;/p&gt;
&lt;p&gt;主 &lt;code&gt;install plugin rpl_semi_sync_master soname &#39;semisync_master.so&#39;;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;从 &lt;code&gt;install plugin rpl_semi_sync_slave soname &#39;semisync_slave.so&#39;;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;并且打开半同步复制，&lt;code&gt;set global rpl_semi_sync_master_enabled=1;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;其中通过参数&lt;code&gt;rpl_semi_sync_master_wait_point&lt;/code&gt;来决定什么时候提交事务：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;after_sync&lt;/strong&gt; 主库先不提交事务，等待某一个从库返回了结果之后，再提交事务，在返回结构通知客户端。这样一来，如果从库在没有任何返回的情况下宕机了，master这边也无法提交事务。主从仍然是一致的，mysql5.7之后默认值。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;after_commit&lt;/strong&gt; 主库先提交事务，等待从库返回结果再通知客户端。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;组复制&lt;/strong&gt;：基于原生复制及 paxos 协议，提供一致数据安全保证，一种可用于实现容错系统的技术；具体详情见官方文档：&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/group-replication.html&#34;&gt;MySQL8.0 Group Replication&lt;/a&gt;；组复制流程如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/gr-replication-diagram.png&#34; alt=&#34;gr-replication-diagram&#34;&gt;&lt;/p&gt;
&lt;p&gt;MySQL 5.7.17版本中引入MySQL 组复制，同样也是以插件的形式支持; 对应的代码在&lt;a href=&#34;https://github.com/mysql/mysql-server/tree/8.0/plugin/group_replication&#34;&gt;plugin/group_replication&lt;/a&gt;文件夹中。一组副本机器安装插件都是&lt;code&gt;INSTALL PLUGIN group_replication SONAME &#39;group_replication.so&#39;;&lt;/code&gt;&lt;/p&gt;
&lt;ol start=&#34;8&#34;&gt;
&lt;li&gt;如果开启的主从复制(默认异步)1:n，主库会等待从库I/O线程建立连接之后，创建binlog dump线程，通知slave有数据更新，当I/O线程请求日志内容时，会将此时的binlog名称和当前更新的位置pos同时传给slave的I/O线程, 把binlog event发送给从库I/O线程，从库I/O线程获取到binlog event之后将其写入到自己的Relay Log中，然后从库启动SQL线程，将Relay中的数据进行重放，完成从库的数据更新；为了保证不重复更新，binlog/relaylog 中记录了GTID（mysql5.6加入）, 全局唯一, 如果relaylog中已有GTID, 则执行GTID自动跳过，意味着在源上提交的事务只能在副本上应用一次，这有助于保证一致性;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;另外如果主从复制过程突然中断了，或者主从切换了，重启之后发现SQL线程实际执行到位置和数据库记录的不一致；mysql5.6之后将复制的进度放在系统的&lt;code&gt;mysql.slave_relay_log_info&lt;/code&gt;innodb表里，并且把更新进度、SQL线程执行用户事务绑定成一个事务执行。即使宕机了，可以通过MySQL内建的崩溃恢复机制来使实际执行的位置和数据库保存的进度恢复到一致。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Commit阶段:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;调用流程：int MYSQL_BIN_LOG::finish_commit(THD *thd) -&amp;gt; ha_commit_low -&amp;gt; innobase_commit -&amp;gt; &lt;a href=&#34;https://github.com/mysql/mysql-server/blob/8.0/storage/innobase/trx/trx0trx.cc#L2199&#34;&gt;void trx_commit(trx_t *trx)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RUN_HOOK 去获取加载的插件，rpl handler Trans_delegate::after_commit  FOREACH_OBSERVER宏遍历observer列表Observer_info-&amp;gt;observer调用对应replication插件函数；&lt;/p&gt;
&lt;ol start=&#34;9&#34;&gt;
&lt;li&gt;
&lt;p&gt;只有binlog写入磁盘成功之后，执行器才会调用innodb存储引擎接口，从队列中获取事务组依次进行innodb commit 提交释放事务，将redo log中已经prepare的事务提交写入commit标记，并且写入binlog位点；最后调用MYSQL_BIN_LOG::rotate 是否切换binlog文件(在切换文件期间，使用一个防止新的提交组执行刷新阶段的锁，并等待直到准备好的事务的计数器变为0，然后才创建新文件)，如果切成新文件， 调用MYSQL_BIN_LOG::purge()刷盘；结束ordered_commit 组提交流程,返回提交；&lt;/p&gt;
&lt;p&gt;Tips: Commit阶段不用刷盘，Flush阶段中的redo log刷盘已经足够保证数据库崩溃时的数据安全了; Commit阶段队列的作用是承接Sync阶段的事务，完成最后的引擎提交，使得Sync可以尽早的处理下一组事务，最大化组提交的效率。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;整体更新流程&#34;&gt;整体更新流程：&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/mysql-innodb-w.drawio.png&#34; alt=&#34;mysql-innodb-w&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;崩溃恢复&#34;&gt;崩溃恢复&lt;/h3&gt;
&lt;p&gt;更新流程中写入redo log的过程拆成了两个步骤prepare和commit 两个阶段；如果不使用两阶段提交，数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。在崩溃恢复中，&lt;!-- raw HTML omitted --&gt;是以 binlog 中的 xid 和 redolog 中的 xid 进行比较，xid 在 binlog 里存在则提交，不存在则回滚，以及判断redo log中是否有commit标识&lt;!-- raw HTML omitted --&gt;；崩溃恢复时具体的情况:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;binlog无记录，redolog无记录：在redolog写之前crash, 无prepare状态，无undo log 记录，恢复操作：无，无需关心；&lt;/li&gt;
&lt;li&gt;binlog无记录，redolog无记录：在redolog写之前crash, 无prepare状态，有undo log 记录，恢复操作：通过undo log回滚事务；&lt;/li&gt;
&lt;li&gt;binlog有记录，redolog有记录：redolog状态prepare， 则判断对应的事务是否存在完整的binlog，恢复操作：如果是, 则提交事务，否则, 通过undo log回滚事务;&lt;/li&gt;
&lt;li&gt;如果redo log里面的事务是完整的, 也就是有了commit标识, 恢复操作：直接提交事务；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;对于需要持久化的数据库系统，避免不了事务在处理过程中，突然中断的情况；WAL通过预写日志的方式在事务提交之前，需要把修改重放记录和撤销详细记录写入日志文件中，以便在故障后恢复数据；事务开始后，所有对数据库的修改在发送到缓冲池之前都被记录在内存中的WAL缓冲区中；事务提交之前，必须把WAL缓冲区刷新到磁盘。mysql innodb存储引擎引入redo/undo log文件来支持事务持久性和原子性，由于mysql binlog用来归档数据记录恢复和复制，为了保证写入两份日志redo log, binlog 最终恢复数据是一致的，采用两阶段提交机制，通过源码了解了些整体WAL的实现；以及崩溃时候需要用日志进行恢复。(其他持久化存储系统的WAL实现，待续)&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Write-ahead_logging&#34;&gt;Write-ahead_logging&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics&#34;&gt;ARIES:Algorithms_for_Recovery_and_Isolation_Exploiting_Semantics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cs.stanford.edu/people/chrismre/cs345/rl/aries.pdf&#34;&gt;aries.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/OceanBase-Partner/lectures-on-dbms-implementation/blob/main/lecture-6.md#642-%E7%BC%93%E5%86%B2%E6%B1%A0%E7%AE%A1%E7%90%86%E7%AD%96%E7%95%A5&#34;&gt;缓冲池管理策略&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mesl.ucsd.edu/pubs/SOSP2013-MARS.pdf&#34;&gt;From ARIES to MARS: Transaction Support for Next-Generation, Solid-State Drives.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://repository.bilkent.edu.tr/bitstream/handle/11693/37609/Implications%20of%20non-volatile%20memory%20as%20primary%20storage%20for%20database%20management%20systems.pdf&#34;&gt;Implications of Non-Volatile Memory as Primary Storage for Database Management Systems.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://infoscience.epfl.ch/record/170505/files/aether-smpfulltext.pdf&#34;&gt;Scalability of write-ahead logging on multicore and multisocket hardware.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.vldb.org/pvldb/vol10/p337-arulraj.pdf&#34;&gt;WBL.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=S9nctHdkggk&#34;&gt;ARIES Overview, Types of Log Records, ARIES Helper Structures&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4VGkRXVM5fk&#34;&gt;ARIES Database Recovery (CMU Databases Systems / Fall 2019)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/internals/en/binary-log.html&#34;&gt;mysql binary-log&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2021/10/01/&#34;&gt;MySQL · 引擎特性 · 庖丁解InnoDB之UNDO LOG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://catkang.github.io/2020/02/27/mysql-redo.html&#34;&gt;庖丁解InnoDB之REDO LOG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2020/05/09/&#34;&gt;MySQL · 引擎特性 · 基于GTID复制实现的工作原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2020/05/07/&#34;&gt;MySQL · 源码分析 · 内部 XA 和组提交&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.aliyun.com/article/617776&#34;&gt;[图解MySQL]MySQL组提交(group commit)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2018/07/01/&#34;&gt;MySQL · 引擎特性 · WAL那些事儿&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/372300181&#34;&gt;无处不在的 MySQL XA 事务&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html&#34;&gt;Server Option, System Variable, and Status Variable Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://icyfenix.cn/architect-perspective/general-architecture/transaction/local.html&#34;&gt;凤凰架构-本地事务&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>设计-配置平台</title>
      <link>https://weedge.github.io/post/conf/</link>
      <pubDate>Thu, 18 Nov 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/conf/</guid>
      
        <description>&lt;h3 id=&#34;介绍&#34;&gt;介绍&lt;/h3&gt;
&lt;p&gt;业务服务在启动时加载配置，配置分为静态配置和动态配置，静态配置如服务监听的端口，日志路径，访问依赖服务单元不同云(region / zone) 域名地址等；动态配置包括业务配置，流程管理配置，策略配置等；静态配置服务启动之后不会更改，而动态配置在服务启动运行时可以动态热加载；将配置的内容和版本进行分离，关注配置的管理而无需关注配置的内容，配置内容用户可以自定义配置内容，使用json-schema进行校验，提供自定义配置内容json给后台ui前端进行单个整体配置的交互，配置后台只需加载json-schema进行校验提交内容，json-schema由用户上传提供地址即可。&lt;/p&gt;
&lt;h3 id=&#34;目标&#34;&gt;目标&lt;/h3&gt;
&lt;p&gt;通过配置后台，业务服务流程可控，可配置，可视化，隔离已有业务场景配置，提高人效；&lt;/p&gt;
&lt;h3 id=&#34;功能&#34;&gt;功能&lt;/h3&gt;
&lt;h4 id=&#34;后台基础功能&#34;&gt;后台基础功能&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;后台管理发布生产环境的动态配置，包括新增，修改，审核，发布，回滚等功能；&lt;/li&gt;
&lt;li&gt;多人发布的时候，检查当前的版本是否已经发布，并进行版本diff;&lt;/li&gt;
&lt;li&gt;配置是服务接口维度进行操作管理， 以服务粒度进行整体发布；&lt;/li&gt;
&lt;li&gt;提供获取当前已发布的服务配置接口，用于订阅端拉取；&lt;/li&gt;
&lt;li&gt;提供RBAC权限管理;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;动态配置热加载功能&#34;&gt;动态配置热加载功能&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;业务服务配置获取方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;服务配置修改发布，通过发布/订阅模式(Pub-Sub Pattern)通知业务服务进行加载；可用组件为支持pub/sub命令的redis协议kv服务，或者通过get(mget)/set(mset) incr(seq)命令进行模拟实现；&lt;/li&gt;
&lt;li&gt;服务配置修改发布，通过观察者模式(Observer Pattern) watch机制通知业务服务进行实时加载；可以使用etcdv3的watch机制实现;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两种方案都可以，看是否有对应的高可用组件服务支持；如果都有，建议使用etcdv3(client 3.4+)的watch机制，通过长链接来通知变更事件。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;加载方式有两种实现方案：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;通过部署单独agent进程来获取配置进行解析写入指定配置路径文件中(重启时)和共享内存中(运行时)，先写文件，成功了，在写共享内存；然后由业务服务读取；&lt;/p&gt;
&lt;p&gt;优点：方便单独维护，无需业务方关心，只需关心加载配置的路径在后台维护，以及共享内存中的配置结构；&lt;/p&gt;
&lt;p&gt;缺点：多了一次进程之间的交互；业务方代码中需要有读取共享内存的逻辑考虑；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提供配置加载lib库，由业务方启动逻辑代码中调用；将获取配置进行解析写入指定配置路径文件中，加载到业务进程配置结构中使用即可；&lt;/p&gt;
&lt;p&gt;优点：业务方直接调用lib库中的方法，无需关心加载逻辑；&lt;/p&gt;
&lt;p&gt;缺点：假如业务方是不同的语言编写，需要提供不同语言版本的lib库方法；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;总体来说，2种方案都可行，如果统一技术栈，比如使用golang进行开发，可以选用第二种方案；&lt;/p&gt;
&lt;p&gt;但是这样就可以了么？还有业务集群配置一致性需要考虑到，比如业务集群某台机器突然抽风，未加载最新的配置，打到这台机器的请求和其他正常加载配置的机器的请求逻辑会有所不同，导致整体服务接口不是幂等的，会出现不一致的情况；可以借鉴一下 &lt;a href=&#34;https://github.com/XiaoMi/Gaea/blob/master/docs/config-reloading.md&#34;&gt;gaea配置热加载设计与实现&lt;/a&gt;；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;配置一致性方案：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;通过两阶段提交的方式，由业务服务侧提供prepare接口和commit接口；&lt;/p&gt;
&lt;p&gt;准备阶段：conf-dashboard模块发布的时候获取业务服务的ip列表并发调用每个业务服务ip的prepare接口，开始触发业务服务本地配置的更新流程，首先通过conf-dashboard模块获取最新版本和当前版本比较，如果相同就无需比较了，否则从获取配置接口获取配置进行更新；更新流程不是直接替换线上正在使用的文件，而是生成一个准备文件进行提交时替换；每个prepare接口同步调用返回结果都ok了，进入下一步提交阶段，如果其中一个返回失败，发布失败，展现失败详情；&lt;/p&gt;
&lt;p&gt;提交阶段：prepare成功后；conf-dashboard模块继续并发调用的commit接口，开始文件替换，加载至缓存配置结构中；这个操作比较快，都提交成功之后，发布成功，否则发布失败，展现失败详情；&lt;/p&gt;
&lt;p&gt;失败处理：如果某台机器发布失败，可以排查下具体原因之后(原因应尽量在prepare和commit接口中详细给出)，看是否跳过继续发布还是会滚，重复发布不影响，有md5和版本比较；&lt;/p&gt;
&lt;p&gt;tips: 如果发布机器很多，并发力度根据conf-dashboard模块部署机器接口负载，可以自适应调整降低；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;兜底检查更新方案：&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;配置发布成功后，调用业务服务机器的meta接口获取最新更新文件信息，进行兜底检查确认；&lt;/p&gt;
&lt;p&gt;业务服务开启兜底定时任务获取从conf-dashboard获取配置版本，配置信息进行兜底更新, 每隔10～30分钟执行一次；&lt;/p&gt;
&lt;p&gt;tips: 请求conf-dashboard获取配置信息的接口随机打散，防止并发流量对conf-dashboard模块的影响；&lt;/p&gt;
&lt;p&gt;定时任务流程图如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/confmg.drawio.png&#34; alt=&#34;cron-confmg&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;整体交互框架&#34;&gt;整体交互框架&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/config-arch.drawio.png&#34; alt=&#34;config-arch&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;数据库核心动态配置表设计&#34;&gt;数据库核心动态配置表设计&lt;/h3&gt;
&lt;p&gt;当前服务版本和当前conf版本是1对多的场景，而历史服务快照版本和历史conf快照版本是多对多的场景；&lt;/p&gt;
&lt;p&gt;如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/config-version.png&#34; alt=&#34;config-version&#34;&gt;&lt;/p&gt;
&lt;p&gt;服务类型枚举表 service_type&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;枚举值&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;配置类型枚举表 conf_type&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;枚举值&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;无&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;枚举值由配置平台统一分配收敛管理&lt;/p&gt;
&lt;p&gt;当前服务版本表 tb_service_cur_ver&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型 比如：0.无 1.liveme 2.livestation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cluster_name&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务集群名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cur_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;服务当前版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;最大版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;当前conf版本表 tb_conf_cur_ver&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cur_service_ver_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;当前服务版本 id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;conf类型，比如：&lt;!-- raw HTML omitted --&gt;0.无 &lt;!-- raw HTML omitted --&gt;1.livemeDSL &lt;!-- raw HTML omitted --&gt;101.livestationAggrDSL 102.livestationSceneDSL&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cur_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;conf当前版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;max_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;最大版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_name&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_target_path&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf生成的目标路径&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_val&lt;/td&gt;
&lt;td&gt;varchar(8192)&lt;/td&gt;
&lt;td&gt;conf当前内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;服务版本用户操作记录表 tb_service_op_record&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cluster_name&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务集群名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;check_status&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务配置审核状态: 0.待审核 1.审核不通过 2.审核通过&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;op_uid&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;操作者uid&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;conf版本用户操作记录 tb_conf_op_record&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_op_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;服务版本操作 id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;conf类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_name&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_target_path&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf生成的目标路径&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_val&lt;/td&gt;
&lt;td&gt;varchar(8192)&lt;/td&gt;
&lt;td&gt;conf当前内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;is_del&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;是否删除，0.可用，1.不可用&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;服务历史版本快照表 tb_service_ver_snapshot&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;cluster_name&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务集群名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;history_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;服务历史版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;conf历史版本快照表 tb_conf_version_snapshot&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_type&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;conf类型&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_name&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;history_ver&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;conf历史版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_target_path&lt;/td&gt;
&lt;td&gt;varchar(128)&lt;/td&gt;
&lt;td&gt;conf生成的目标路径&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_val&lt;/td&gt;
&lt;td&gt;varchar(8192)&lt;/td&gt;
&lt;td&gt;conf历史快照内容&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;pub_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;发布时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;服务conf历史版本关联表 tb_service_conf_ver_snapshot&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;主键&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;service_ver_snapshot_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;服务历史版本快照 id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;conf_ver_snapshot_id&lt;/td&gt;
&lt;td&gt;bigint&lt;/td&gt;
&lt;td&gt;conf历史版本快照 id&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;create_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;创建时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;update_time&lt;/td&gt;
&lt;td&gt;uint&lt;/td&gt;
&lt;td&gt;更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&#34;场景模拟&#34;&gt;场景模拟&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;新增版本保存更新删除&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;审核&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;发布&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;回滚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;获取当前服务conf版本配置&lt;/p&gt;
&lt;p&gt;服务粒度整体版本文件一次拉取下来，这里是接口形式提供， 后续可以提供将可用版本以服务粒度打个包提交；如果后续有多服务一起捆绑打包，需要考虑上线依赖顺序，暂时不提供&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;接口&#34;&gt;接口&lt;/h3&gt;
&lt;p&gt;线下内网域名访问需要配置router模块中的ngx proxy配置，新增一个location /confdashboard 进行路由跳转；或者指定ip端口访问路径；&lt;/p&gt;
&lt;p&gt;线上通过通过服务发现模块来获取confdashboard服务单元ip列表负载均衡进行访问；可以多机房部署，根据业务服务部署场景定；&lt;/p&gt;
&lt;h4 id=&#34;conf-dashboard-接口&#34;&gt;conf-dashboard 接口&lt;/h4&gt;
&lt;p&gt;提供给后台前端的CRUD接口不在这里描述，通过&lt;a href=&#34;https://github.com/smallnest/gen&#34;&gt;smallnest/gen&lt;/a&gt;生成RESTful接口提供给前端使用就行，修改操作，根据不同的conf_type加载不同的json_schema进行校验，以及审核，发布接口；主要是提供给业务服务调用的接口实现，如下：&lt;/p&gt;
&lt;p&gt;请求调用方式：http1.1 POST 或者 GRPC&lt;/p&gt;
&lt;p&gt;公共返回参数：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;字段&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;类型&lt;/th&gt;
&lt;th style=&#34;text-align:left&#34;&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;errNo&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;int&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;错误号，默认为0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;errStr&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;string&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;错误描述&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;data&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;json&lt;/td&gt;
&lt;td style=&#34;text-align:left&#34;&gt;返回响应数据&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;获取当前服务配置文件版本   /confdashboard/v1/getcurversion&lt;/p&gt;
&lt;p&gt;请求：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;参数是否必须&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;serviceType&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型:0.无 1.liveme 2.livestation&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;响应：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;curVer&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;当前版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;maxVer&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;最大版本&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;获取当前服务文件配置内容   /confdashboard/v1/getcurserverconf&lt;/p&gt;
&lt;p&gt;(服务粒度整体版本文件一次拉取下来，这里是接口形式给出对应配置数据，兜底定时轮训获取）&lt;/p&gt;
&lt;p&gt;请求：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th style=&#34;text-align:left&#34;&gt;字段&lt;/th&gt;
&lt;th&gt;参数是否必须&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;serviceType&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型:0.无 1.liveme 2.livestation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;confName&lt;/td&gt;
&lt;td&gt;可选&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务本地配置文件名称&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td style=&#34;text-align:left&#34;&gt;confTargetPath&lt;/td&gt;
&lt;td&gt;可选&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务本地配置路径&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;响应data：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;downloadUrl&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;服务配置整体打包地址&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;confData&lt;/td&gt;
&lt;td&gt;map&lt;!-- raw HTML omitted --&gt;confData&lt;!-- raw HTML omitted --&gt;(map&amp;lt;{confTargetPath}/{confName}&amp;gt;{confData})&lt;/td&gt;
&lt;td&gt;服务配置列表&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;confData&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;文件当前版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;data&lt;/td&gt;
&lt;td&gt;[]byte&lt;/td&gt;
&lt;td&gt;文件当前版本内容&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;业务服务配置更新结果报告 /confdashboard/v1/reportBizServConf&lt;/p&gt;
&lt;p&gt;请求：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;参数是否必须&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;serviceType&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;tinyint&lt;/td&gt;
&lt;td&gt;服务类型:0.无 1.liveme 2.livestation&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;reportInfos&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;map&lt;!-- raw HTML omitted --&gt;reportInfo&lt;/td&gt;
&lt;td&gt;业务服务配置更新结果报告列表&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;clusterName&lt;/td&gt;
&lt;td&gt;必须&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;集群名称&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;reportInfo&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;version&lt;/td&gt;
&lt;td&gt;int64&lt;/td&gt;
&lt;td&gt;版本&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;confFilePath&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;业务配置文件路径（绝对路径）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;md5sum&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;文件MD5值&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;confUpdateTime&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;业务配置文件更新时间&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;updateResultCode&lt;/td&gt;
&lt;td&gt;int&lt;/td&gt;
&lt;td&gt;0, 更新成功，1，更新失败&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;updateErrStr&lt;/td&gt;
&lt;td&gt;string&lt;/td&gt;
&lt;td&gt;更新失败原因&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;响应data：&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;字段&lt;/th&gt;
&lt;th&gt;类型&lt;/th&gt;
&lt;th&gt;描述&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;td&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;conf-agentlib-业务服务接口&#34;&gt;conf-agent/lib 业务服务接口&lt;/h4&gt;
&lt;p&gt;通过在业务服务机部署agent, 或者使用lib库封装函数的方式，最终都是需要提供获取配置的服务提供对应的接口，来保证整体服务配置的一致性，这里采用lib库封装函数提供给业务服务启动时调用这个函数的方式，是否启动单独启动端口是可选的，如果是在业务服务中启动，就用业务服务的端口，如果是单独agent方式启动，使用单独的端口；接口定义如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;获取配置开始准备替换工作 prepare接口 /{serviceType}/localconf/prepare&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;提交本地替换工作 commit接口 /{serviceType}/localconf/commit&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;获取本地配置文件元数据，比如md5,路径,版本等，meta接口 /{serviceType}/localconf/meta&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;施工&#34;&gt;施工&lt;/h3&gt;
&lt;p&gt;可以进行模块划分，按人力进行分工，可以用Project或者trello这些工具来管理整个项目需求，开发，测试，上线周期；也可以内部整合jira 和 wiki 等平台工具进行管理;&lt;/p&gt;
&lt;p&gt;这个有点像建筑施工队，有了设计稿，推演几遍，满足整体需求和目标；剩下的是去实施了，实施的话需要，整体系统架构设计的建筑工程师👷，懂这行工具的专工👷，以及领队包工头👷，大项目可能还有项目监工👷‍♀️，监控进度，以及交互后的质量把控工程师👷；一起配合把事干好，让用户和老板满意。&lt;/p&gt;
&lt;h3 id=&#34;总结&#34;&gt;总结&lt;/h3&gt;
&lt;p&gt;前期业务为了满足快速业务迭代，业务动态配置可能都是随着业务服务一起上线，或者通过单独的代码库进行管理分开单独上线；这个可能会因为代码上线了，但是配置忘记上线的情况；或者只需要修改配置上线，而不需要修改代码，也需要单独部署一次业务服务，如果涉及多个服务模块，不能及时响应了，不够KISS；为了满足业务集群配置化管理，配置平台需要管理业务动态配置来提高人效，保证业务集群上线配置的整体一致，通过后台页面来管理配置和历史配置，追踪配置的修改情况；需要注意的是，第一次上线的配置，可以先在测试环境配置平台上配置好，测试好之后，在到线上平台配置发布上线，然后在部署业务服务代码；发布配置也需要在线上未接入流量的机器上，测试之后才能上。&lt;/p&gt;
&lt;h3 id=&#34;qa&#34;&gt;Q&amp;amp;A&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;为什么不直接用etcd来管理配置呢？去掉mysql, 配置直接存etcd不行么？&lt;/p&gt;
&lt;p&gt;主要是因为mysql用来提供管理配置实体的关系，用于后台页面修改使用；如果是k8s中的场景，可以直接使用etcd来存放(100G以下的数据, 大厂多机房大集群会魔改etcd)；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;如果业务服务部署在Pod容器中, 怎么更新配置呢？&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;agent通过DaemonSet容器化部署,单独升级, agent与业务Pod之间通过共享内存进行通信更新配置；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;以SideCar Container方式将agent与业务Container部署在同一Pod中，利用Pod的共享IPC特性及Memory Medium EmptyDir Volume方式共享内存进行通信更新配置，随业务容器化部署上线；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;agent通过&lt;a href=&#34;https://github.com/openkruise/kruise&#34;&gt;OpenKruise&lt;/a&gt; SidecarSet部署在SideCar容器中；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;references&#34;&gt;references&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/Qihoo360/QConf/wiki&#34;&gt;QConf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.apolloconfig.com/#/zh/design/apollo-design&#34;&gt;apollo&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://icyfenix.cn/distribution/connect/service-discovery.html&#34;&gt;凤凰架构-service-discovery&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://time.geekbang.org/column/article/341060&#34;&gt;etcd-watch&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redisbook.readthedocs.io/en/latest/feature/pubsub.html&#34;&gt;redis-pub/sub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzU4NzU0MDIzOQ==&amp;amp;mid=2247490475&amp;amp;idx=2&amp;amp;sn=83e79449b409c363239de1b37b96f8c8&#34;&gt;Service Mesh 在超大规模场景下的落地挑战&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>共享内存与内存映射(mmap)「转载的哦」</title>
      <link>https://weedge.github.io/%E8%BD%AC%E8%BD%BD/mmap/</link>
      <pubDate>Tue, 16 Nov 2021 11:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/%E8%BD%AC%E8%BD%BD/mmap/</guid>
      
        <description>&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;from: &lt;a href=&#34;https://www.cnblogs.com/huangfuyuan/p/9476951.html&#34;&gt;https://www.cnblogs.com/huangfuyuan/p/9476951.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;首先关于共享内存的链接：&lt;a href=&#34;http://blog.csdn.net/qq_26768741/article/details/56014845&#34;&gt;共享内存&lt;/a&gt;。&lt;strong&gt;里面包含了创建共享内存区域的函数，以及两个进程怎么挂载共享内存通信，分离、释放共享内存&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;共享内存的好处就是效率高，不需要太多次的进行数据的copy。可以直接进行读写内存。所以，相对来说在IPC进程间通信三大主题（消息队列，信号量，共享内存）里面，共享内存要比消息队列使用多，而且消息队列只在有血缘关系的进程间通信；但是，共享内存不保证同步，可以使用信号量来保证共享内存同步。&lt;strong&gt;Linux中的两种共享内存&lt;/strong&gt;。一种是我们的IPC通信System V版本的共享内存，另外的一种就是我们今天提到的存储映射I/O（mmap函数），当然还有一种POSIX的共享内存，它是在mmap基础之上构建的。&lt;/p&gt;
&lt;h2 id=&#34;mmap&#34;&gt;mmap&lt;/h2&gt;
&lt;p&gt;mmap I/O的描述符间接说明内存映射是对文件操作。另外，mmap另外可以在无亲缘的进程之间提供共享内存区。这样，类似的两个进程之间就是可以进行了通信。&lt;/p&gt;
&lt;p&gt;Linux提供了内存映射函数mmap, 它把文件内容映射到一段内存上(准确说是&lt;strong&gt;虚拟内存&lt;/strong&gt;上，运行着进程), &lt;strong&gt;通过对这段内存的读取和修改, 实现对文件的读取和修改&lt;/strong&gt;。mmap()系统调用使得进程之间可以通过映射一个普通的文件实现共享内存。&lt;strong&gt;普通文件映射到进程地址空间后，进程可以像访问内存的方式对文件进行访问，不需要其他内核态的系统调用(read,write)去操作。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;这里是讲设备或者硬盘存储的一块空间映射到物理内存，然后操作这块物理内存就是在操作实际的硬盘空间，不需要经过内核态传递。比如你的硬盘上有一个文件，你可以使用linux系统提供的mmap接口，将这个文件映射到进程一块虚拟地址空间，这块空间会对应一块物理内存，当你读写这块物理空间的时候，就是在读取实际的磁盘文件，就是这么直接高效。&lt;strong&gt;通常诸如共享库的加载都是通过内存映射的方式加载到物理内存的&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;mmap系统调用并不完全是为了共享内存来设计的，它本身提供了不同于一般对&lt;strong&gt;普通文件&lt;/strong&gt;的访问的方式，进程可以像读写内存一样对普通文件进行操作（无需系统调用），IPC的共享内存是纯粹为了共享。&lt;/p&gt;
&lt;h3 id=&#34;mmap系统调用介绍&#34;&gt;mmap系统调用介绍&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;这就是mmap系统调用的接口，mmap函数成功返回指向内存区域的指针，失败返回MAP_FAILED。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;addr，某个特定的地址作为起始地址，当被设置为NULL，标识系统自动分配地址。实实在在的物理区域。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;length说的是内存段的长度。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;prot是用来设定内存段的访问权限。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;prot参数&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;PROT_READ&lt;/td&gt;
&lt;td&gt;内存段可读&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PROT_WRITE&lt;/td&gt;
&lt;td&gt;内存段可写&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PROT_EXEC&lt;/td&gt;
&lt;td&gt;内存段可执行&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;PROT_NONE&lt;/td&gt;
&lt;td&gt;内存段不能被访问&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;fd参数是用来被映射文件对应的文件描述符。通过open系统调用得到。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;flags参数&lt;/th&gt;
&lt;th&gt;说明&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;MAP_SHARED&lt;/td&gt;
&lt;td&gt;进程间共享内存，对该内存段修改反映到映射文件中。提供了POSIX共享内存&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAP_PRIVATE&lt;/td&gt;
&lt;td&gt;内存段为调用进程所私有。对该内存段的修改不会反映到映射文件&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAP_ANNOYMOUS&lt;/td&gt;
&lt;td&gt;这段内存不是从文件映射而来的。内容被初始化为全0&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAP_FIXED&lt;/td&gt;
&lt;td&gt;内存段必须位于start参数指定的地址处，start必须是页大小的整数倍（4K整数倍）&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;MAP_HUGETLB&lt;/td&gt;
&lt;td&gt;按照大内存页面来分配内存空间&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;offset设定从何处进行映射。&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;mmap用于共享内存的方式&#34;&gt;mmap用于共享内存的方式&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;我们可以使用普通文件进行提供内存映射，例如，open系统调用打开一个文件，然后进行mmap操作，得到共享内存，这种方式适用于任何进程之间。&lt;/li&gt;
&lt;li&gt;以使用特殊文件进行匿名内存映射，这个相对的是具有血缘关系的进程之间，当父进程调用mmap，然后进行fork，这样父进程创建的子进程会继承父进程匿名映射后的地址空间，这样，父子进程之间就可以进行通信了。相当于是mmap的返回地址此时是父子进程同时来维护。&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;另外&lt;a href=&#34;https://www.cnblogs.com/LubinLew/p/POSIX-shared_memory.html&#34;&gt;POSIX版本的共享内存&lt;/a&gt;底层也是使用了mmap。所以，共享内存在在posix上一定程度上就是指的内存映射了&lt;/strong&gt;。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;mmap和system-v共享内存的比较&#34;&gt;mmap和System V共享内存的比较&lt;/h2&gt;
&lt;h3 id=&#34;system-v版本的共享内存以下我们统称为shm&#34;&gt;System V版本的共享内存（以下我们统称为shm）&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://gitee.com/lienhui68/picStore/raw/master/null/20200917180539.png&#34; alt=&#34;https://gitee.com/lienhui68/picStore/raw/master/null/20200917180539.png&#34;&gt;&lt;/p&gt;
&lt;h3 id=&#34;mmap版本的共享内存&#34;&gt;mmap版本的共享内存&lt;/h3&gt;
&lt;p&gt;&lt;img src=&#34;https://gitee.com/lienhui68/picStore/raw/master/null/20200917180729.png&#34; alt=&#34;https://gitee.com/lienhui68/picStore/raw/master/null/20200917180729.png&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;mmap是在磁盘上&lt;strong&gt;建立一个文件&lt;/strong&gt;，每个进程地址空间中开辟出一块空间进行映射。而shm共享内存，每个进程最终会&lt;strong&gt;映射到同一块物理内存&lt;/strong&gt;。shm保存在物理内存，这样读写的速度肯定要比磁盘要快，但是存储量不是特别大。&lt;/li&gt;
&lt;li&gt;相对于shm来说，mmap更加简单，调用更加方便，所以这也是大家都喜欢用的原因。&lt;/li&gt;
&lt;li&gt;另外mmap有一个好处是当机器重启，因为mmap把文件保存在磁盘上，这个文件还保存了操作系统同步的映像，所以mmap不会丢失，但是shmget在内存里面就会丢失。&lt;/li&gt;
&lt;li&gt;总之，shm是在内存中创建空间，每个进程映射到此处。内存映射是创建一个文件，并且映射到每个进程开辟的空间中。&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>工具盒子-ping/traceroute</title>
      <link>https://weedge.github.io/post/ping/</link>
      <pubDate>Mon, 15 Nov 2021 14:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/ping/</guid>
      
        <description>&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;p&gt;在访问网络是否ok, 通常喜欢用ping 命令来访问&lt;code&gt;ping www.baidu.com&lt;/code&gt; 看是否出现超时；ping在不同的操作系统平台实现方式差不多，底层都是用ICMP协议，每次发ICMP ECHO_REQUEST packet (IP地址/Host, ttl，icmp_seq序列号，&lt;a href=&#34;https://en.wikipedia.org/wiki/Round-trip_delay&#34;&gt;RTD/RTT&lt;/a&gt;(往返延时)记录 ),  运行结束后统计每个RTT, 最大RTT, 最小RTT, 平均RTT, &lt;a href=&#34;https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford&#34;&gt;标准偏差&lt;/a&gt;RTT, 发送/接受packets总数，丢包率 等数据，ping工具在PING(8)中的定义如下：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The ping utility uses the ICMP protocol&amp;rsquo;s mandatory ECHO_REQUEST datagram to elicit an ICMP ECHO_RESPONSE from a host or gateway.  ECHO_REQUEST datagrams  (&amp;ldquo;pings&#39;&#39;) have an IP and ICMP header, followed by a &amp;ldquo;struct timeval&#39;&#39; and then an arbitrary number of &amp;ldquo;pad&amp;rdquo; bytes used to fill out the packet.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;icmphttpsenwikipediaorgwikiinternet_control_message_protocol&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol&#34;&gt;ICMP&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;互联网控制消息协议&lt;/strong&gt;（英语：&lt;strong&gt;I&lt;/strong&gt;nternet &lt;strong&gt;C&lt;/strong&gt;ontrol &lt;strong&gt;M&lt;/strong&gt;essage &lt;strong&gt;P&lt;/strong&gt;rotocol，缩写：&lt;strong&gt;ICMP&lt;/strong&gt;）是&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%92%E8%81%94%E7%BD%91&#34;&gt;互联网&lt;/a&gt;协议族的核心协议之一。它用于&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%BD%91%E9%99%85%E5%8D%8F%E8%AE%AE&#34;&gt;网际协议&lt;/a&gt;（IP）中发送控制消息，提供可能发生在通信环境中的各种问题反馈。通过这些信息，使管理者可以对所发生的问题作出诊断，然后采取适当的措施解决；使用在网络设备上，比如交换机，路由器&lt;/p&gt;
&lt;h3 id=&#34;为毛icmp设计在网络层呢&#34;&gt;为毛ICMP设计在网络层呢？&lt;/h3&gt;
&lt;p&gt;因为需要目的地址ip, 链路层无法通过ip socket编程，那为啥不用链路层的MAC地址呢？因为链路层的MAC地址只在局域网唯一，由交换机学习缓存策略决定(会缓存MAC地址，用于跳转)，如果广域网访问不同局域网，MAC地址可以不唯一(网络历史演变原因)，但是公网IP地址是全局唯一，相互转化通过NAT路由器(具体介绍看wiki: &lt;strong&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_address_translation&#34;&gt;Network address translation&lt;/a&gt;&lt;/strong&gt;)； 如图所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/lib/main/net/NAT.png&#34; alt=&#34;NAT&#34;&gt;&lt;/p&gt;
&lt;p&gt;如果在传输层的话，无需端口多了一次解包；ICMP与&lt;a href=&#34;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&#34;&gt;TCP&lt;/a&gt;、&lt;a href=&#34;https://en.wikipedia.org/wiki/User_Datagram_Protocol&#34;&gt;UDP&lt;/a&gt;等&lt;a href=&#34;https://en.wikipedia.org/wiki/Transport_protocol&#34;&gt;传输协议&lt;/a&gt;不同因为它通常不用于在系统之间交换数据，也不经常被最终用户网络应用程序使用（除了一些诊断工具，如&lt;a href=&#34;https://en.wikipedia.org/wiki/Ping_(networking_utility)&#34;&gt;ping&lt;/a&gt;和&lt;a href=&#34;https://en.wikipedia.org/wiki/Traceroute&#34;&gt;traceroute&lt;/a&gt;）。&lt;/p&gt;
&lt;p&gt;ICMP 依靠ip来完成它的任务，它是ip的主要部分。它与传输协议（如&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE&#34;&gt;TCP&lt;/a&gt;和&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE&#34;&gt;UDP&lt;/a&gt;）显著不同：它一般不用于在两点间传输数据。它通常不由网络程序直接使用，除了 &lt;a href=&#34;https://zh.wikipedia.org/wiki/Ping&#34;&gt;ping&lt;/a&gt; 和 &lt;a href=&#34;https://zh.wikipedia.org/wiki/Traceroute&#34;&gt;traceroute&lt;/a&gt; 这两个特别的例子。 &lt;a href=&#34;https://zh.wikipedia.org/wiki/IPv4&#34;&gt;IPv4&lt;/a&gt;中的ICMP被称作ICMPv4，&lt;a href=&#34;https://zh.wikipedia.org/wiki/IPv6&#34;&gt;IPv6&lt;/a&gt;中的ICMP则被称作&lt;a href=&#34;https://zh.wikipedia.org/wiki/ICMPv6&#34;&gt;ICMPv6&lt;/a&gt;。&lt;/p&gt;
&lt;h2 id=&#34;pinghttpsenwikipediaorgwikiping_networking_utility&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Ping_(networking_utility)&#34;&gt;ping&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Ping (Packet Internet Grope)，因特网包探索器，用于测试网络连接量的程序。Ping发送一个ICMP回声请求消息给目的地并报告是否收到所希望的ICMP回声应答；具体流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/lib/main/net/ping-icmp.png&#34; alt=&#34;ping-icmp&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;TTL&lt;/strong&gt;： 生存时间，指定&lt;!-- raw HTML omitted --&gt;数据包被路由器丢弃之前允许通过的网段数量&lt;!-- raw HTML omitted --&gt;；&lt;!-- raw HTML omitted --&gt;&lt;strong&gt;TTL 是由发送主机设置的，当其存活次数为0时，路由器便会取消数据包并发送一个ICMP TTL数据包给原数据包的发出者, 以防止数据包不断在 ip 互联网络上永不终止地循环, 而无法送达及耗尽网络资源&lt;/strong&gt;&lt;!-- raw HTML omitted --&gt;。转发 ip 数据包时，要求路由器至少将 TTL 减小 1；TTL 字段值不同操作系统类型对应的值不同，可以通过&lt;code&gt;ping 127.0.0.1&lt;/code&gt; 本地来查看初始值,或者&lt;code&gt;sysctl -a |grep ttl &lt;/code&gt;查看对应值(macOS Darwin下是net.inet.ip.ttl, linux下是net.ipv4.ip_default_ttl)；如果不修改这些值，linux系统一般是64，window系统一般是128。&lt;/p&gt;
&lt;h2 id=&#34;traceroutehttpsenwikipediaorgwikitraceroute&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Traceroute&#34;&gt;traceroute&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;traceroute是unix系统中，诊断&lt;a href=&#34;https://en.wikipedia.org/wiki/Computer_network&#34;&gt;计算机网络&lt;/a&gt;的命令程序(windos中对应tracert命令)；用于显示可能的路线（路径）和测量的传送延迟。路由的历史记录为从路由（路径）中每个连续主机（远程节点）接收到的数据包的往返次数；每&lt;a href=&#34;https://en.wikipedia.org/wiki/Hop_(networking)&#34;&gt;跳&lt;/a&gt;平均时间的总和是建立连接所花费的总时间的度量；如果所有（通常是三个）发送的数据包丢失两次以上，连接就会丢失并且无法评估路由，否则 Traceroute 会继续。&lt;/p&gt;
&lt;p&gt;主叫方首先发出 TTL=1 的数据包，第一个路由器将 TTL 减1得0后就不再继续转发此数据包，而是返回一个 ICMP 超时报文，主叫方从超时报文中即可提取出数据包所经过的第一个网关地址。然后又发出一个 TTL=2 的 ICMP 数据包，可获得第二个网关地址，依次递增 TTL 便获取了沿途所有网关地址。&lt;/p&gt;
&lt;p&gt;需要注意的是，并不是所有网关都会如实返回 ICMP 超时报文。出于安全性考虑，大多数防火墙以及启用了防火墙功能的路由器缺省配置为不返回各种 ICMP 报文，其余路由器或&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E4%BA%A4%E6%8D%A2%E6%9C%BA&#34;&gt;交换机&lt;/a&gt;也可被管理员主动修改配置变为不返回 ICMP 报文。因此 Traceroute 程序不一定能拿全所有的沿途网关地址。所以，当某个 TTL 值的数据包得不到响应时，并不能停止这一追踪过程，程序仍然会把 TTL 递增而发出下一个数据包。一直达到默认或用参数指定的追踪限制（maximum_hops）才结束追踪（没有到达目标ip, 所以收不到目标ip的ICMP报文）。&lt;/p&gt;
&lt;p&gt;而ping工具只计算从目的地点的最终往返时间。&lt;/p&gt;
&lt;p&gt;当然ping/traceroute，不一定用网络层的ICMP协议来实现，也可以用传输层的&lt;a href=&#34;https://en.wikipedia.org/wiki/User_Datagram_Protocol&#34;&gt;UDP协议&lt;/a&gt;来实现(发送udp协议报文),默认主目的主机端口是33434开始)，这个端口是有讲究的；利用了 UDP 数据包的 traceroute 程序在数据包到达真正的目的主机时，就可能因为该主机没有提供 &lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%94%A8%E6%88%B7%E6%95%B0%E6%8D%AE%E6%8A%A5%E5%8D%8F%E8%AE%AE&#34;&gt;UDP&lt;/a&gt; 服务而简单将数据包抛弃，并不返回任何信息。为了解决这个问题，traceroute 故意使用了一个大于 30000 的端口号(因 UDP 协议规定端口号必须小于 30000)，所以目标主机收到数据包后唯一能做的事就是返回一个“端口不可达(ICMP PORT_UNREACHABLE)”的 ICMP 报文，于是主叫方就将端口不可达报文当作跟踪结束的标志。&lt;/p&gt;
&lt;p&gt;甚至traceroute还用&lt;a href=&#34;https://en.wikipedia.org/wiki/Transmission_Control_Protocol&#34;&gt;TCP协议&lt;/a&gt;来实现(发送tcp协议报文)，这个需要看场景下，需要获取的测试监控数据是哪些，是否有必要建立可靠连接。比如一些traceroute 实现使用TCP 数据包，例如&lt;em&gt;tcptraceroute&lt;/em&gt;和&lt;a href=&#34;https://en.wikipedia.org/wiki/Layer_four_traceroute&#34;&gt;第四层traceroute&lt;/a&gt; (LFT)。&lt;/p&gt;
&lt;p&gt;具体使用可以参考&lt;code&gt;man traceroute&lt;/code&gt; 中的介绍，以上说的，在man文档里都有介绍到；&lt;/p&gt;
&lt;p&gt;可以通过&lt;code&gt;traceroute -P ICMP  www.baidu.com&lt;/code&gt; 使用ICMP协议来追踪每一跳的路由情况；支持ICMP, UDP(默认发送方式), TCP协议，具体见文档；&lt;/p&gt;
&lt;p&gt;如果想查看ICMP协议包的内容可以通过&lt;a href=&#34;https://gitlab.com/wireshark/wireshark/-/wikis/home&#34;&gt;Wireshark/TShark(命令)&lt;/a&gt;来抓包，主要是通过&lt;strong&gt;协议报文&lt;/strong&gt;，来分析网络问题；你会发现ping 命令程序只用到了IP/ICMP协议(send Type: 8 (Echo (ping) request)；recv Type: 0 (Echo (ping) reply) from dst ip)， 而traceroute 命令程序会用到IP/ICMP(send Type: 8 (Echo (ping) request)；recv Type: 11 (Time-to-live exceeded) code:0 from 每个路由，recv Type: 0 (Echo (ping) reply) from dst ip), IP/UDP协议(如果用UDP发送，send udp 数据报文, recv Type: 11 (Time-to-live exceeded) code:0 from  每个路由， recv Type: 3 (Destination unreachable) code:3 from dst ip)。&lt;/p&gt;
&lt;p&gt;可以分析出，ping 和 traceroute 都使用IP/ICMP协议时，traceroute 是接收了每一跳路由的响应进行处理，然后展现的每一跳累计的总耗时。流程如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/lib/main/net/traceroute-icmp.png&#34; alt=&#34;traceroute-icmp&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;轮子&#34;&gt;轮子&lt;/h2&gt;
&lt;p&gt;为啥要用golang重新写一个工具呢？ （已有开源的 &lt;a href=&#34;https://github.com/go-ping/ping.git&#34;&gt;go-ping&lt;/a&gt;, 支持icmp, udp (icmp.ListenPacket &lt;a href=&#34;https://godoc.org/golang.org/x/net/icmp&#34;&gt;x/net/icmp&lt;/a&gt;) 直接查看源码吧）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;平时虽然用，但是具体实现想了解下，主要是&lt;a href=&#34;https://en.wikipedia.org/w/index.php?title=Internet_Control_Message_Protocol&#34;&gt;ICMP协议&lt;/a&gt;中的控制信息(&lt;a href=&#34;https://en.wikipedia.org/w/index.php?title=Internet_Control_Message_Protocol#Control_messages&#34;&gt;Control messages&lt;/a&gt;), 以便在次协议上DIY网络需求；&lt;/li&gt;
&lt;li&gt;golang是跨系统平台编译语言，同一份代码编译运行在不同平台；&lt;/li&gt;
&lt;li&gt;可以做一些扩展，运用在K8S的编排容器中测试网络环境；因为icmp定义在网络层，只需ip，无需服务端口，利用icmp协议做一些扩展功能；比如机器是否挂了，目的ip是否不可到达了，以及做一些网络层监控等。&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;reference&#34;&gt;reference&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Ping_(networking_utility)&#34;&gt;PING&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Internet_Control_Message_Protocol&#34;&gt;ICMP&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.techtarget.com/searchnetworking/definition/time-to-live&#34;&gt;TTL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Network_address_translation&#34;&gt;NAT&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=IIicPE38O-s&#34;&gt;PING Command - Troubleshooting&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>缓存淘汰策略-LRU</title>
      <link>https://weedge.github.io/post/lru/</link>
      <pubDate>Mon, 08 Nov 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/lru/</guid>
      
        <description>&lt;h2 id=&#34;序言&#34;&gt;序言&lt;/h2&gt;
&lt;p&gt;​	在计算机硬件中缓/内存设计是用来机器启动的时候加载程序，分配运行空间数据，停机，缓/内存中的数据会丢失；磁盘用来持久化存储，提供数据加载到内存中，内存的读写速度比磁盘快很多，以下是&lt;a href=&#34;https://research.google/people/jeff/&#34;&gt;Jeff Dean&lt;/a&gt;  &amp;ldquo;&lt;a href=&#34;http://brenocon.com/dean_perf.html&#34;&gt;Numbers Everyone Should Know&lt;/a&gt;&amp;rdquo; 中提供的数据(虽然过去10多年了)， 读取1MB数据，从内存中读比从磁盘中读取快100+倍；但是缓/内存的空间比磁盘空间少，为了加快数据的访问，减少缓存/磁盘io，大概分为三种：1. 可以提前将数据从磁盘加载到内/缓存中(page)、2. 内/缓存miss从下层存储获取数据(cache,pool,page)、3. 无需加载，直接内/缓存evict；如果提供给进程的最大内/缓存资源到了最大限制，需要对存储资源进行evict操作，常用的evict策略可以从&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_replacement_policies&#34;&gt;Cache_replacement_policies&lt;/a&gt;中了解；有关特定于分页的详细算法，请参阅&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm&#34;&gt;页面替换算法&lt;/a&gt;；有关特定于 CPU 和 RAM 之间缓存的详细算法，请参阅&lt;a href=&#34;https://en.wikipedia.org/wiki/CPU_cache&#34;&gt;CPU 缓存&lt;/a&gt;。这里主要关注LRU evict相关策略。&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;OP(io)&lt;/th&gt;
&lt;th&gt;cost&lt;!-- raw HTML omitted --&gt;（1s= 10^9ns)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;L1 cache reference 读取CPU的一级缓存&lt;/td&gt;
&lt;td&gt;0.5 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Branch mispredict(转移、分支预测)&lt;/td&gt;
&lt;td&gt;5 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;L2 cache reference 读取CPU的二级缓存&lt;/td&gt;
&lt;td&gt;7 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Mutex lock/unlock 互斥锁\解锁&lt;/td&gt;
&lt;td&gt;100 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Main memory reference 读取内存数据&lt;/td&gt;
&lt;td&gt;100 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Compress 1K bytes with Zippy 1k字节压缩&lt;/td&gt;
&lt;td&gt;10,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Send 2K bytes over 1 Gbps network 在1Gbps的网络上发送2k字节&lt;/td&gt;
&lt;td&gt;20,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read 1 MB sequentially from memory 从内存顺序读取1MB&lt;/td&gt;
&lt;td&gt;250,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Round trip within same datacenter 从一个数据中心往返一次，ping一下&lt;/td&gt;
&lt;td&gt;500,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Disk seek  磁盘搜索&lt;/td&gt;
&lt;td&gt;10,000,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read 1 MB sequentially from network 从网络上顺序读取1兆的数据&lt;/td&gt;
&lt;td&gt;10,000,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Read 1 MB sequentially from disk 从磁盘里面读出1MB&lt;/td&gt;
&lt;td&gt;30,000,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;Send packet CA-&amp;gt;Netherlands-&amp;gt;CA 一个包的一次远程访问&lt;/td&gt;
&lt;td&gt;150,000,000 ns&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h2 id=&#34;lru算法&#34;&gt;LRU算法&lt;/h2&gt;
&lt;p&gt;​	LRU(least recently used)是一种缓存 evict 策略算法：在缓存有限的情况下，如果有新的数据需要加载进缓存，则需要将最不可能被继续访问的缓存剔除掉。这是一种提前预判假设的算法，因为缓存是否可能被访问到没法做预测的，所以假设 &lt;strong&gt;一个key经常被访问，那么该key的idle time应该是最小的。&lt;/strong&gt; (但这个假设也是基于概率，并不是充要条件,很明显,idle time最小的,甚至都不一定会被再次访问到)。&lt;/p&gt;
&lt;p&gt;​	LRU 的工作原理是一种时间局部性原理的假设，在过去的几条指令中使用最多的页面最有可能在接下来的几条指令中也被大量使用。&lt;/p&gt;
&lt;p&gt;​	实现方式可以采用wiki中的实现，每个缓存item中有序列号(每个新访问的增量为 1)，缓存满了将序列号最低的替换掉，这种实现需要找到最低的进行比较替换；还有种实现实现方式是通过hashMap+双向链表的方式实现，空间换时间的方式，&lt;a href=&#34;https://leetcode-cn.com/problems/lru-cache/&#34;&gt;leetcode上有这道题&lt;/a&gt;，一般面试会问到；&lt;/p&gt;
&lt;p&gt;实际工程实现中，由于实现成本，根据使用场景，考虑空间利用和时间的折中，使用的&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm#Variants_on_LRU&#34;&gt;LRU算法变体&lt;/a&gt;：(以下定义来自wiki)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm#cite_note-15&#34;&gt;LRU-K&lt;/a&gt; 驱逐过去第 K 次最近访问最远的页面。例如，LRU-1 只是 LRU，而 LRU-2 根据倒数第二次访问的时间驱逐页面。LRU-K 在时间上的局部性方面大大改进了 LRU。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm#cite_note-16&#34;&gt;ARC&lt;/a&gt; 算法通过保持最近驱逐页面的历史可LRU，并使用此选项可以更改的偏好近期或频繁访问。它对顺序扫描特别有抵抗力。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm#cite_note-17&#34;&gt;2Q&lt;/a&gt; 算法改进了 LRU 和 LRU/2 算法。通过具有两个队列，一个用于热路径项目，另一个用于慢路径项目，项目首先被放置在慢路径队列中，并且在第二次访问放置在热路径项目中的项目之后；由于对添加项的引用比 LRU 和 LRU/2 算法中的保留时间更长，因此它具有更好的热路径队列，从而提高了缓存的命中率。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_replacement_policies#Segmented_LRU_(SLRU)&#34;&gt;SLRU&lt;/a&gt; 缓存分为两个段，试用段和保护段。每个段中的行按从最近访问到最近最少访问的顺序排列。来自未命中的数据被添加到试用段最近访问的末端的缓存中。命中从它们当前所在的任何地方删除，并添加到受保护段的最近访问端。因此，受保护段中的行至少被访问了两次。&lt;/p&gt;
&lt;h2 id=&#34;本地缓存中的实现机制&#34;&gt;本地缓存中的实现机制&lt;/h2&gt;
&lt;p&gt;go语言实现的本地缓存策略中有开源方案&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/golang/groupcache&#34;&gt;https://github.com/golang/groupcache&lt;/a&gt;  (LRU)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://github.com/dgryski/go-s4lru&#34;&gt;http://github.com/dgryski/go-s4lru&lt;/a&gt; (S4LRU)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/dgryski/go-arc&#34;&gt;https://github.com/dgryski/go-arc&lt;/a&gt; (ARC)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/hashicorp/golang-lru&#34;&gt;https://github.com/hashicorp/golang-lru&lt;/a&gt; (LRU, ARC, TwoQueue)&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/vmihailenco/go-cache-benchmark&#34;&gt;https://github.com/vmihailenco/go-cache-benchmark&lt;/a&gt; 对不同的cache 淘汰策略的对比，引用结果：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;TinyLFU最适合少量的key(少于100k)。TinyLFU内存开销可以通过第二个参数进行调整。
Clock-pro有明显较小的内存使用大量的key(当key的数量超过 1m)。
分段LRU的内存使用量更小，但命中率不一致。
如果你需要它提供的额外功能，Ristretto仍然是一个不错的选择。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;存储组件中的实现机制&#34;&gt;存储组件中的实现机制&lt;/h2&gt;
&lt;h3 id=&#34;redis-dictsdsredisobject-lru-evict策略&#34;&gt;redis Dict(sds,redisObject) LRU evict策略&lt;/h3&gt;
&lt;p&gt;redis 是缓存数据库，缓存空间是有限的，可以指定最大内存使用空间；redis提供过期机制，给key制定过期时间，redis实现了删除这些过期key的删除策略（定期删除+惰性删除），但是还是存在问题，对于一些key没有设置过期时间，总会到最大内存使用空间，需要实现内存淘汰回收策略，其中策略就是LRU, 操作对象分为全部key (allkeys-lru) 和 过期key(volatile-lru)；这里整体介绍下redis缓存策略，然后单独介绍对应的redis LRU evict策略:&lt;/p&gt;
&lt;h4 id=&#34;最大内存配置选项&#34;&gt;最大内存配置选项&lt;/h4&gt;
&lt;p&gt;maxmemory 配置选项使用来配置 Redis 的存储数据所能使用的最大内存限制。可以通过在内置文件redis.conf中配置，也可在Redis运行时通过命令CONFIG SET来配置。例如，我们要配置内存上限是100M的Redis缓存，那么我们可以在 redis.conf 配置如下：maxmemory 100mb&lt;/p&gt;
&lt;p&gt;设置 maxmemory 为 0 表示没有内存限制。在 64-bit 系统中，默认是 0 无限制，但是在 32-bit 系统中默认是 3GB。当存储数据达到限制时，Redis 会根据情形选择不同策略，或者返回errors（这样会导致浪费更多的内存），或者清除一些旧数据回收内存来添加新数据。&lt;/p&gt;
&lt;h4 id=&#34;惰性释放的策略&#34;&gt;惰性释放的策略&lt;/h4&gt;
&lt;p&gt;应用这种策略的原因在于对于某些数据对象的释放需要消耗过多的系统资源，如果在&lt;em&gt;Redis&lt;/em&gt;的主线程中采用同步的方式去删除以及释放这样的&lt;em&gt;key-value&lt;/em&gt;数据，那么会导致系统长时间的阻塞在释放数据操作上，而无法处理其他的业务逻辑。对于这种情况，我们以惰性释放的策略，使用一个后台线程，通过异步的方式来对数据对象进行释放，无疑是一种较为合适的选择，可配置三种情况：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;redisServer.lazyfree_lazy_eviction： 是否在淘汰某个&lt;em&gt;key&lt;/em&gt;时，使用惰性释放策略；这个在内存淘汰策略异步释放会用到；&lt;/li&gt;
&lt;li&gt;redisServer.lazyfree_lazy_expire：是否在过期某个&lt;em&gt;key&lt;/em&gt;时，使用惰性释放策略;&lt;/li&gt;
&lt;li&gt;redisServer.lazyfree_lazy_server_del: 服务器端删除某个&lt;em&gt;key&lt;/em&gt;时，是否使用惰性释放策略;&lt;/li&gt;
&lt;/ol&gt;
&lt;h4 id=&#34;过期删除缓存策略&#34;&gt;过期删除缓存策略&lt;/h4&gt;
&lt;p&gt;分为定期删除，惰性删除, 两种策略配合使用：&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;定期删除&lt;/strong&gt; 指的是Redis默认会每隔一定时间（默认100ms）就会&lt;!-- raw HTML omitted --&gt;抽取一批设置了过期时间的key&lt;!-- raw HTML omitted --&gt;来检测是否过期，过期就删除。&lt;/p&gt;
&lt;p&gt;在Redis2.6版本中，规定每秒运行10次，大概100ms运行一次。在Redis2.8版本后，可以通过修改配置文件redis.conf 的 &lt;strong&gt;hz&lt;/strong&gt; 选项来调整每秒次数(一般用默认值， 过高会的cpu造成一定压力)。由redis.c/activeExpireCycle 函数实现。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;惰性删除&lt;/strong&gt; 在获取某个Key时Redis会先检测一下，这个key是否设置了过期时间？如果设置了过期时间那么是否过期？过期就删除。由 db.c/expireIfNeeded 函数实现。&lt;/p&gt;
&lt;p&gt;如果定期抽取一批过期key删除, 以及没有对过期key访问了，这样会存在大量过期key未删除回收的情况，会导致内存使用率大大降低；所以redis内部提供了不同的内存淘汰回收策略。&lt;/p&gt;
&lt;h4 id=&#34;内存淘汰回收策略&#34;&gt;内存淘汰回收策略&lt;/h4&gt;
&lt;p&gt;当内存达到限制时，Redis 具体的回收策略是通过 maxmemory-policy 配置项配置的。&lt;/p&gt;
&lt;p&gt;以下的策略都是可用的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;noenviction：不清除数据，只是返回错误，这样会导致浪费掉更多的内存，对大多数写命令（DEL 命令和其他的少数命令例外）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allkeys-lru：从所有的数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰，以供新数据使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;volatile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰，以供新数据使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allkeys-random：从所有数据集（server.db[i].dict）中任意选择数据淘汰，以供新数据使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰，以供新数据使用&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰，以供新数据使用&lt;/p&gt;
&lt;p&gt;从 Redis 4.0 版开始，引入了新的 LFU（最近最不常用）策略。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;volatile-lfu：从已设置过期时间的数据集（server.db[i].expires）中挑选近似 LFU 数据淘汰。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;allkeys-lfu：从所有的数据集（server.db[i].dict）中挑选近似 LFU 数据淘汰。&lt;/p&gt;
&lt;p&gt;LFU 类似于 LRU：它使用一个概率计数器，称为&lt;a href=&#34;https://en.wikipedia.org/wiki/Approximate_counting_algorithm&#34;&gt;莫里斯计数器&lt;/a&gt;，以便仅使用每个对象的几位来估计对象访问频率，并结合衰减周期，以便计数器随着时间的推移而减少：在某些时候，我们不再希望将key视为经常访问的key，即使它们过去是这样，以便算法可以适应访问的转变。LFU具有可调参数:  （见：&lt;a href=&#34;http://antirez.com/news/109&#34;&gt;Random notes on improving the Redis LRU algorithm&lt;/a&gt; Least Frequently Used)&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;lfu-log-factor 10 //在大约一百万个请求时使计数器饱和因子，计数器对数因子会改变需要多少次命中才能使频率计数器饱和，这恰好在 0-255 的范围内。系数越高，需要越多的访问以达到最大值。系数越低，低访问计数器的分辨率越好，见redis示例redis.conf文件
lfu-decay-time 1 //每一分钟衰减一次计数器。
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当 cache 中没有符合清除条件的 key 时，回收策略 volatile-lru, volatile-random 和volatile-ttl 将会和 策略 noeviction 一样返回错误。选择正确的回收策略是很重要的，取决于你的应用程序的访问模式。但是，你可以在程序运行时重新配置策略，使用 INFO 输出来监控缓存命中和错过的次数，以调优你的设置。&lt;/p&gt;
&lt;p&gt;普适经验规则：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;如果期望用户请求呈现幂律分布(power-law distribution)，也就是，期望一部分子集元素被访问得远比其他元素多时，可以使用allkeys-lru策略。在你不确定时这是一个好的选择。&lt;/li&gt;
&lt;li&gt;如果期望是循环周期的访问，所有的键被连续扫描，或者期望请求符合平均分布(每个元素以相同的概率被访问)，可以使用allkeys-random策略。&lt;/li&gt;
&lt;li&gt;如果你期望能让 Redis 通过使用你创建缓存对象的时候设置的TTL值，确定哪些对象应该是较好的清除候选项，可以使用volatile-ttl策略。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;当你想使用单个Redis实例来实现缓存和持久化一些键，allkeys-lru和volatile-random策略会很有用。但是，通常最好是运行两个Redis实例来解决这个问题。&lt;/p&gt;
&lt;p&gt;另外值得注意的是，为键设置过期时间需要消耗内存，所以使用像allkeys-lru这样的策略会更高效，因为在内存压力下没有必要为键的回收设置过期时间。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;回收过程&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;理解回收过程是运作流程非常的重要，回收过程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;一个客户端运行一个新命令，添加了新数据。&lt;/li&gt;
&lt;li&gt;Redis检查内存使用情况，如果大于maxmemory限制，根据策略来回收键。&lt;/li&gt;
&lt;li&gt;一个新的命令被执行，如此等等。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;我们添加数据时通过检查，然后回收键以返回到限制以下，来连续不断的穿越内存限制的边界。如果一个命令导致大量的内存被占用(比如一个很大的集合保存到一个新的键)，那么内存限制很快就会被这个明显的内存量所超越。&lt;/p&gt;
&lt;h4 id=&#34;近似lru算法&#34;&gt;近似LRU算法&lt;/h4&gt;
&lt;p&gt;Redis整体上是一个大的dict，如果实现一个双向链表需要在每个key上首先增加两个指针，需要16个字节，并且额外需要一个list结构体去存储该双向链表的头尾节点信息。Redis作者认为这样实现不仅内存占用太大，而且可能导致性能降低。具体详见作者博客文章：&lt;a href=&#34;http://antirez.com/news/109&#34;&gt;Random notes on improving the Redis LRU algorithm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;  &lt;strong&gt;Redis为什么不使用原生LRU算法？&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;原生LRU算法需要 双向链表 来管理数据，需要&lt;strong&gt;额外内存&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;数据访问时涉及&lt;strong&gt;数据移动，有性能损耗&lt;/strong&gt;；&lt;/li&gt;
&lt;li&gt;Redis现有&lt;strong&gt;数据结构需要改造&lt;/strong&gt;，dictEntry, key指向sds, val指向redisObject，dictEntry 是个单向链表；&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Redis的LRU算法不是一个严格的LRU实现。这意味着Redis不能选择最佳候选键来回收，也就是最久未被访问的那些键。相反，Redis 会尝试执行一个近似的LRU算法，通过采样一小部分键，然后在采样键中回收最适合(拥有最久访问时间)的那个。然而，从Redis3.0开始，算法被改进为维护一个回收候选键池。这改善了算法的性能，使得更接近于真实的LRU算法的行为。Redis的LRU算法有一点很重要，你可以调整算法的精度，通过改变每次回收时检查的采样数量。这个参数可以通过如下配置指令：&lt;code&gt;maxmemory-samples 5&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Redis没有使用真实的LRU实现的原因，是因为这会消耗更多的内存。然而，近似值对使用Redis的应用来说基本上也是等价的。文章&lt;a href=&#34;https://redis.io/topics/lru-cache&#34;&gt;Using Redis as an LRU cache&lt;/a&gt;为Redis使用的LRU近似值和真实LRU之间的比较。&lt;/p&gt;
&lt;p&gt; 触发时机是在redis server执行新的写命令时, 当 mem_used &amp;gt; maxmemory 的时候，通过 &lt;a href=&#34;https://github.com/redis/redis/blob/c1718f9d862267bc44b2a326cdc8cb1ca5b81a39/src/evict.c#L531:5&#34;&gt;performEvictions&lt;/a&gt; 方法完成数据淘汰(所看的Redis6.2.6源码)。LRU策略淘汰核心逻辑在 &lt;a href=&#34;https://github.com/redis/redis/blob/c1718f9d862267bc44b2a326cdc8cb1ca5b81a39/src/evict.c#L145:6&#34;&gt;evictionPoolPopulate&lt;/a&gt;（淘汰数据集合填充） 方法。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Redis6.2.6 淘汰策略整体逻辑&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/lib/blob/main/client/redis/redis-lru.png?raw=true&#34; alt=&#34;redis-lru&#34;&gt;&lt;/p&gt;
&lt;p&gt;key访问变更策略值(用于计算idle)：&lt;/p&gt;
&lt;p&gt;在Redis的dict中每次按key获取一个值的时候，都会调用&lt;code&gt;lookupKey&lt;/code&gt;函数，前提是没有fork出来的saving子进程(会触发copy on write)
如果配置使用了LRU模式,该函数&lt;code&gt;LRU_CLOCK&lt;/code&gt;会更新val-&amp;gt;redisObject中的lru字段为当前秒级别的时间戳, 在估算idle time的时候，&lt;code&gt;estimateObjectIdleTime&lt;/code&gt;会再次调用&lt;code&gt;LRU_CLOCK&lt;/code&gt;获取时间戳和最近一次val-&amp;gt;redisObject中的lru相减获取idle；
为后面的样本池中获取bestKey来淘汰删除。&lt;/p&gt;
&lt;p&gt;采样方法：&lt;/p&gt;
&lt;p&gt;遍历数据库，根据淘汰策略从dict(没有过期时间的key)还是expires(有过期时间的key)中获取随机&lt;code&gt;maxmemory_samples&lt;/code&gt;个样本，放入&lt;code&gt;static struct evictionPoolEntry *EvictionPoolLRU&lt;/code&gt; pool样本池中。样本池中的样本idle值从低到高插入排序，数据淘汰策略每次选择idle最高数据进行淘汰释放(根据配置是否开启惰性淘汰策略释放异步释放还是同步释放)；样本池大小是&lt;code&gt;EVPOOL_SIZE 16&lt;/code&gt;，所以采集样本要根据自己的idle值大小或池中是否有空位来确定是否成功插入样本池中，如果池中没有空位，或者被插入样本的idle值都小于池子中的数据，那插入将会失败；这样样本池中一致存放idle最大，最大几率被淘汰的key(sds)样本(通过key找到dictEntry中的val-&amp;gt;redisObject 去释放)。&lt;/p&gt;
&lt;p&gt;Idle获取：&lt;/p&gt;
&lt;p&gt;如果是LRU策略：estimateObjectIdleTime(o)  获取redisObject 的 idle 时间，一个key经常被访问，那么该key的idle time应该是最小；
如果是LFU策略：255-LFUDecrAndReturn(o) 最大使用频率255减去redisObject的使用频率，所以最小使用频率，idle越大；
如果是已过期中淘汰策略： ULLONG_MAX - (long)dictGetVal(de);  过期越早越好；
pool中按idle从小到大插入排序，便于获取bestKey,用于删除。&lt;/p&gt;
&lt;p&gt;淘汰删除策略：&lt;/p&gt;
&lt;p&gt;如果开启惰性淘汰策略，则使用dbAsyncDelete 异步回收只释放key, 不会对主线程造成过大的负担，否则使用dbSyncDelete同步回收；
异步回收如果释放对象数目&amp;gt;64, 将对象创建job加入lazy free list；通知&lt;code&gt;signal type: bio_lazy_free&lt;/code&gt;回收处理线程进行回收；
这两种操作都是会将key从数据库的键空间中移除，唯一的区别就在于，对value数据的释放，是同步操作还是异步操作。&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/redis/redis/blob/79ac57561f268814babe212c9216efe45cfdf937/src/server.c#L5330&#34;&gt;触发代码在server.c中&lt;/a&gt;：activeExpireCycle performEvictions 函数 在 &lt;a href=&#34;https://github.com/redis/redis/blob/b71c5849e3e5c040b029c6e25cec2069d70760c1/README.md#serverc&#34;&gt;server.c&lt;/a&gt; readme中有介绍什么时候触发。&lt;/p&gt;
&lt;h3 id=&#34;mysql80-innodb-page-buffer-pool-lru-evict策略&#34;&gt;Mysql8.0 InnoDB page buffer pool LRU evict策略&lt;/h3&gt;
&lt;h4 id=&#34;页page&#34;&gt;页Page&lt;/h4&gt;
&lt;p&gt;数据库的数据是放在磁盘空间以表空间存放的，加载的时候以页page为单位进行加载，页是InnoDB存储引擎磁盘管理的最小单位，每个页默认16KB；可以通过参数innodb_page_size设置(一个页内必须存储2行记录，否则就不是B+tree，而是链表了)，页面类型：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;数据页（B-tree Node）&lt;/p&gt;
&lt;p&gt;undo页（undo Log Page）&lt;/p&gt;
&lt;p&gt;系统页（System Page）&lt;/p&gt;
&lt;p&gt;事务数据页（Transaction system Page）&lt;/p&gt;
&lt;p&gt;插入缓冲位图页（Insert Buffer Page）&lt;/p&gt;
&lt;p&gt;插入缓冲空闲列表页（Insert Buffer Free List）&lt;/p&gt;
&lt;p&gt;未压缩的二进制大对象页（Uncompressd BLOB Page）&lt;/p&gt;
&lt;p&gt;压缩的二进制大对象页（Compressd BLOB Page）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://blogstatic.haohtml.com/uploads/2019/08/innodb_engine_struct.png&#34; alt=&#34;innodb_engine_struct&#34;&gt;&lt;/p&gt;
&lt;p&gt;从InnoDB存储引擎的逻辑结构看，所有数据都被逻辑地存放在一个空间内，称为表空间(tablespace)，而表空间由段（sengment）、区（extent）、页（page）组成。 在一些文档中extend又称块（block）。这里有几个概念简单介绍下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;表空间（Tablespace）&lt;/strong&gt; 是一个逻辑容器，表空间存储的对象是段，在一个表空间中可以有一个或多个段，但是一个段只能属于一个表空间。数据库由一个或多个表空间组成，表空间从管理上可以划分为&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-system-tablespace.html&#34;&gt;系统表空间&lt;/a&gt;、&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-file-per-table-tablespaces.html&#34;&gt;File-per-table 表空间&lt;/a&gt;、&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/general-tablespaces.html&#34;&gt;通用表空间&lt;/a&gt;、&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-undo-tablespaces.html&#34;&gt;撤销表空间&lt;/a&gt;、&lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-temporary-tablespace.html&#34;&gt;临时表空间&lt;/a&gt;。(表空间文件可以通过xxd进行分析)&lt;/p&gt;
&lt;p&gt;在 InnoDB 中存在两种表空间的类型：共享表空间(例如系统表空间或通用表空间)和独立表空间(File-per-table 表空间)。如果是共享表空间就意味着多张表共用一个表空间。如果是独立表空间，就意味着每张表有一个独立的表空间，也就是数据和索引信息都会保存在自己的表空间中。独立的表空间可以在不同的数据库之间进行迁移。禁用&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-parameters.html#sysvar_innodb_file_per_table&#34;&gt;&lt;code&gt;innodb_file_per_table&lt;/code&gt;&lt;/a&gt; 会在系统表空间中创建表。&lt;/p&gt;
&lt;p&gt;mysql8.0 InnoDB存储引擎对磁盘结构中的表空间操作有些改变：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;8.0版本中，系统表空间只是更改缓冲区的存储区域；以前版本是InnoDB数据字典、双写缓冲区、更改缓冲区和撤消日志的存储区域 。(如果表是在系统表空间中创建的，而不是在每个表文件或通用表空间中创建，则它还可能包含表和索引数据)&lt;/li&gt;
&lt;li&gt;在8.0以前的 MySQL 版本中，系统表空间包含InnoDB数据字典mysql.* 。在 MySQL 8.0 中InnoDB将元数据存储在 MySQL 数据字典表空间中，表结构等数据字典元数据都是通过InnoDB来管理(mysql.ibd或者独立表空间*.ibd文件中）。&lt;/li&gt;
&lt;li&gt;在 MySQL 8.0.20 之前，doublewrite 缓冲区存储区位于InnoDB系统表空间中；从 MySQL 8.0.20 开始，双写缓冲区存储区域位于双写文件中。附上官方mysql8.0 InnoDB存储引擎架构图(对比 &lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html&#34;&gt;5.7版本架构&lt;/a&gt;)：&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/innodb-architecture.png&#34; alt=&#34;innodb-architecture&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;段（Segment）&lt;/strong&gt; 由一个或多个区组成，区在文件系统是一个连续分配的空间（在 InnoDB 中是连续的 64 个页），不过在段中不要求区与区之间是相邻的。段是数据库中的分配单位，不同类型的数据库对象以不同的段形式存在。当我们创建数据表、索引的时候，就会相应创建对应的段，比如创建一张表时会创建一个表段，创建一个索引时会创建一个索引段。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;区（extent）&lt;/strong&gt; 在 InnoDB 存储引擎中，一个区会分配 64 个连续的页。因为 InnoDB 中的页大小默认是 16KB，所以一个区的大小是 64*16KB=1MB。在任何情况下每个区大小都为1MB，为了保证页的连续性，InnoDB存储引擎每次从磁盘一次申请4-5个区。默认情况下，InnoDB存储引擎的页大小为16KB，即一个区中有64个连续的页。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;页（page）&lt;/strong&gt; 是InnoDB存储引擎磁盘管理的最小单位，每个页默认16KB，页结构如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blogstatic.haohtml.com/uploads/2019/08/1d49c975639e53fe92466f0b1ebe2b2a99672e8b-1024x828.jpeg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;Page directory 页目录用来存储每组最后一条记录的地址偏移量，这些地址偏移量会按照先后顺序存储起来，每组的地址偏移量也被称之为槽（slot），每个槽相当于指针指向了不同组的最后一个记录，这样方便二分查找快速定位到记录；&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://blogstatic.haohtml.com/uploads/2019/08/innodb-page-dir-1024x959.jpg&#34; alt=&#34;page-slot&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;行（row）&lt;/strong&gt; InnoDB存储引擎是按行进行存放的，每个页存放的行记录也是有硬性定义的，最多允许存放16KB/2-200，即7992行记录。&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-row-format.html&#34;&gt;InnoDB 行格式&lt;/a&gt;支持四名的格式：REDUNDANT，COMPACT， DYNAMIC，和COMPRESSED，默认DYNAMIC&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;B+ 树是如何进行记录检索的？&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如果通过 B+ 树的索引查询行记录，首先是从 B+ 树的根开始，逐层检索，直到找到&lt;strong&gt;叶子节点&lt;/strong&gt;，也就是找到对应的&lt;strong&gt;数据页&lt;/strong&gt;为止，如果数据页没在缓冲池中，将数据页加载到内存 &lt;strong&gt;缓冲池(buffer pool)&lt;/strong&gt; 中，页目录中的 &lt;strong&gt;槽(slot)&lt;/strong&gt; 采用二分查找的方式先找到一个粗略的&lt;strong&gt;记录分组&lt;/strong&gt;，然后再在分组中通过链表遍历的方式查找&lt;strong&gt;记录&lt;/strong&gt;。&lt;/p&gt;
&lt;h4 id=&#34;缓冲池buffer-pool--lruunzip_lru-链表&#34;&gt;缓冲池(buffer pool)  LRU/unzip_LRU 链表&lt;/h4&gt;
&lt;p&gt;&lt;strong&gt;缓冲池(buffer pool)&lt;/strong&gt; 是主内存中的一个区域，用于在 &lt;code&gt;InnoDB&lt;/code&gt;访问时缓存表和索引数据。缓冲池允许直接从内存访问经常使用的数据，从而加快处理速度。在专用服务器上，多达 80% 的物理内存通常分配给缓冲池。&lt;/p&gt;
&lt;p&gt;这里有个问题，比如有如下 场景，一个直播间id为1的观看人数上百万，假如运营后台需要查找全部数据，（这里假设没有通过CQRS模式将数据放入ES中，ES查询缓存也用到了LRU, 可以参考这篇&lt;a href=&#34;https://www.easyice.cn/archives/367&#34;&gt;Elasticsearch 的查询缓存&lt;/a&gt;）&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;select * from room_student_history where room_id=1  and id&amp;gt;=(select id from room_student_history where order by id limit 1000000,1) order by id limit 1000&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;如果room_student_history中有大量长尾用户数据并且读取之后不会继续使用,则LRU头部会被大量的room_student_history中的数据占据。这样会造成热点数据被逐出缓存从而导致大量的磁盘io ;&lt;/p&gt;
&lt;p&gt;mysql innodb的buffer pool使用了一种改进的LRU算法，大意是将LRU链表分成两部分，一部分为newlist,一部分为oldlist,newlist是头部热点数据，oldlist是非热点数据,oldlist默认占整个list长度的3/8.当初次加载一个page的时候，会首先放入oldlist的头部，只有满足一定条件后，才被移到new list上，主要是为了防止预读的数据页和全表扫描污染buffer pool。详细介绍见&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html&#34;&gt;官方文档&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://dev.mysql.com/doc/refman/8.0/en/images/innodb-buffer-pool-list.png&#34; alt=&#34;innodb-buffer-pool&#34;&gt;&lt;/p&gt;
&lt;p&gt;附mac下把玩操作：（单机实例，通过brew切换版本服务挺方便的；生产环境优化配置: 高可用，性能优化稳定等配置）&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;brew install &lt;a href=&#34;mailto:mysql@5.7&#34;&gt;mysql@5.7&lt;/a&gt; //安装5.7版本&lt;/li&gt;
&lt;li&gt;brew services start &lt;a href=&#34;mailto:mysql@5.7&#34;&gt;mysql@5.7&lt;/a&gt; //启动5.7版本mysqld,mysqld_safe&lt;/li&gt;
&lt;li&gt;建表，查看/usr/local/var/mysql 目录下的数据文件，可以对照 &lt;a href=&#34;https://dev.mysql.com/doc/refman/5.7/en/innodb-architecture.html&#34;&gt;5.7版本架构&lt;/a&gt; 查看表空间文件；&lt;/li&gt;
&lt;li&gt;写些数据，查看相关数据文件的数据变化， 通过 xxd/hexdump 以十六进制的方式查看表空间二进制文件*.ibd等&lt;/li&gt;
&lt;li&gt;brew install mysql //安装最新版本8.0&lt;/li&gt;
&lt;li&gt;brew services stop &lt;a href=&#34;mailto:mysql@5.7&#34;&gt;mysql@5.7&lt;/a&gt;  //停止mysql@5.7服务&lt;/li&gt;
&lt;li&gt;brew services start mysql //启动8.0版本mysqld,mysqld_safe&lt;/li&gt;
&lt;li&gt;查看/usr/local/var/mysql 目录下的数据文件, 对比5.7版本的文件变化，新增了哪些文件分开管理, 以及对数据字典的变化&lt;/li&gt;
&lt;li&gt;/usr/local/opt/mysql/bin/ibd2sdi (utilities/ibd2sdi.cc文件)  查看ibd文件中的字典序列化信息,mysqlbinlog binlog.* 打印binlo g信息&lt;/li&gt;
&lt;li&gt;客户端命令执行show VARIABLES like &amp;ldquo;%Innodb%&amp;quot;; show status like &amp;ldquo;%Innodb%&amp;quot;; 查看Innodb参数和状态统计；&lt;/li&gt;
&lt;li&gt;客户端命令执行  SHOW ENGINE INNODB STATUS; 查看整体运行状态监控数据(io,thread, buffer pool memory, SEMAPHORES, TRANSACTIONS,INSERT BUFFER AND ADAPTIVE HASH INDEX,LOG,ROW OPERATIONS)&lt;/li&gt;
&lt;li&gt;客户端执行命令，通过dtruss -p  查看mysqld进程对应的系统调用&lt;/li&gt;
&lt;li&gt;相关的参数可以从官网查看介绍&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html&#34;&gt;Server Option, System Variable, and Status Variable Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;下载源码 &lt;a href=&#34;https://github.com/mysql/mysql-server&#34;&gt;https://github.com/mysql/mysql-server&lt;/a&gt; 8.0 版本分支，download zip文件，解压，编译，运行，gdb debug&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;​	缓/内存io比磁盘io快许多，但是缓/内存空间有限，且无法持久化，所以需要提供缓/内存淘汰机制来保证缓/内存使用命中率，本文介绍常用的LRU算法；golang实现的开源方案，可以结合业务场景，进行使用，redis 为了节省空间，通过抽样将淘汰的数据放入待淘汰数据池(evictionPoolEntry) 进行淘汰，在 Redis 3.0 中使用 10 个样本大小，该近似值非常接近 Redis 3.0 的原始LRU理论性能。mysql 需要充分利用缓存池资源，减少磁盘io, 因为加载单元是page, 如果第一次加载放入LRU链表头，可能这些数据使用频率不高，导致缓存池命中率低，将LRU链表按3/8分成old list 和new list , 第一次加载放入oldList头，再次访问时才会移动到newlist。根据淘汰的结构，根据数据使用场景，将LRU算法优化, redis和mysql 都用到了pool, 但是是两种场景，redis是为了淘汰释放使用样本pool, 样本池中放入的是idle值，根据不同策略算出的值，用来淘汰最大的idle, 方便扩展优化算法； mysql 中的pool是buffer pool 缓冲池，主要是为了存放page, page 是innodb磁盘管理的最小单位，为了减少磁盘io, 尽量减少缓存miss, 增加hit率，提高读写操作方案。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Cache_replacement_policies#Least_recently_used_(LRU)&#34;&gt;Cache_replacement_policies#Least_recently_used_(LRU)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Adaptive_replacement_cache&#34;&gt;Adaptive_replacement_cache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Page_replacement_algorithm&#34;&gt;Page_replacement_algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://antirez.com/news/109&#34;&gt;Random notes on improving the Redis LRU algorithm&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://redis.io/topics/lru-cache&#34;&gt;Using Redis as an LRU cache&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://brenocon.com/dean_perf.html&#34;&gt;Numbers Everyone Should Know&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://videolectures.net/wsdm09_dean_cblirs/&#34;&gt;Challenges in Building Large-Scale Information Retrieval Systems&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/innodb-buffer-pool.html&#34;&gt;mysql8.0 innodb-buffer-pool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/dev/mysql-server/latest/buf0lru_8cc.html&#34;&gt;mysql8.0 source code buf0lru.cc File Reference&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2017/11/05/&#34;&gt;MySQL · 源码分析 · InnoDB LRU List刷脏改进之路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2017/05/01/&#34;&gt;MySQL · 引擎特性 · InnoDB Buffer Pool&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://mysql.taobao.org/monthly/2021/01/06/&#34;&gt;MySQL · 源码阅读 · Innodb内存管理解析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/internals/en/&#34;&gt;MySQL Internals Manual&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dev.mysql.com/doc/refman/8.0/en/server-option-variable-reference.html&#34;&gt;Server Option, System Variable, and Status Variable Reference&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>服务改造简述</title>
      <link>https://weedge.github.io/post/servicetransformation/</link>
      <pubDate>Tue, 26 Oct 2021 22:04:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/servicetransformation/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;随着前期业务迭代不断增多，会留下一些技术债务；用户不断累计增加，整体DAU,MAU,PV/UV的不断上升，为了符合根据组织结构和业务需求更加稳定健康的发展，需要对业务服务进行改造/重构；采用团队适合的语言开发，将服务进行分层，抽象底层模型，分离出不变/易变业务逻辑；业务改造和基础建设服务升级（整体系统认知的改变）&lt;/p&gt;
&lt;h2 id=&#34;过程&#34;&gt;过程&lt;/h2&gt;
&lt;p&gt;整体服务分为4个阶段进行简述：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;快速上线，需求多，迭代快，开发团队整体使用熟悉开发框架（效益：前期起步使用rd熟悉的开发脚本语言，支持需求快速迭代）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;后面功能复用， 建设业务中台， 直播中台，互动中台的建设，中台的请求大，采用golang进行开发，（效益：整体机器资源消耗减少, 高峰期机器负载降低)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;根据直播业务场景，抽象中台底层数据模型，（效益：减少人力，提高复用，增加整体研发效能）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;开发语言迁移， 服务模型从多进程脚本弱类型语言切到多协程强类型语言，需要适配接口&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;需要梳理核心服务接口和非核心服务接口，&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务上线，迁移老接口， 需要做流量的切分，新老接口的diff , 有两种方案：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;在业务层面加上灰度策略，通过策略配置，对不同的业务id进行异步分流，一份请求数据，2份响应数据，只返回老的响应数据，新老响应数据进行diff处理；优点：业务改造方自己把控；缺点：对业务代码有侵入，如果改造灰度策略多的话，会降低业务代码逻辑稳定性；&lt;/li&gt;
&lt;li&gt;在新老服务之上加一层接口代理层，接口适配，灰度策略流量切分，新老接口diff功能 移至 接口代理层做，相当于提供一层网关服务来处理；优点： 对接口灰度进行统一管理，不会对业务代码有浸入操作；缺点：多了一层代理层，接口响应时间会有所增加，需要保证代理层的稳定性；&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;两种方案都可以，需要结合组织结构来考虑开发技术成本， 方案一：不需要额外的人力来支持维护代理层；方案二：需要单独的团队或者开发人员来维护代理层； 如果看整体收益的话，偏向于第二种方案，前者就是战术编程，后者就是战略编程，应该侧重战略编程。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课中直播是流量突发的场景，对于服务优化改造，服务压力测试必不可少：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;接口压测，关注qps，接口响应时间，服务监控，负载等情况；&lt;/li&gt;
&lt;li&gt;全链路压侧，关注tps，整体链路调用接口响应时间耗时，总响应时间耗时，各服务监控，负载等情况；并且输出测试报表；为了不污染线上数据，需要对基础存储组件 单独部署一套影子系统，服务链路上需要加上压侧标签参数；可参考：&lt;a href=&#34;https://help.aliyun.com/document_detail/29337.html&#34;&gt;性能测试 PTS&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;保证切流过程中服务比较稳定，进行周期性引流，切流观察：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;旁路引流diff，覆盖到业务全场景的情况，diff在可接受范围内，进行下一步 流量切流&lt;/li&gt;
&lt;li&gt;为了保证服务稳定性，不出现p0,p1,p2事故，流量切换的周期一般比较长，按覆盖到的业务场景和整体服务监控情况而定，按1%、2%、10%、20%，40%，80%放量；查看客户端是否有异常以及用户的反馈工单，切流放量阶段diff还是正常进行，返回是否有问题，存放数据是否一致；没有问题，进入下一步  线上观察&lt;/li&gt;
&lt;li&gt;线上观察一段时间，会以月为单位，观察阶段主要服务流量是新改造的服务，如果发现有异动，还可以切回原来的服务；如果观察阶段没有问题，可以下掉原来的服务了；&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;服务改造过程中，会有新的业务需求进来，如果是大的需求，开发周期比较长的项目，如果是紧急项目，只能在原有服务上进行开发，后续在迁移至新系统中；对于非紧急需求，可以暂缓压压，可以等新服务上线稳定之后，在使用新服务框架开发，上线部署，主要看需求中是否需要修改老接口，还是直接提供新接口就可以满足；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;容器化改造，上云（效益：整体测试，线上环节保持一致，节约开发测试时间；线上服务治理通过K8S+Istio,进行网格化治理, 以前部署在物理机或者虚拟机上，混部的情况，资源分配和隔离不合理，迁移后，可以充分合理利用宿主物理机/虚拟机资源，隔离，弹性扩缩容，部署上线前提条件是需要保证K8S可用性）&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对不同语言服务进行容器化改造，有不同业务部门推进(主要是项目构建打包成镜像，docker的话需要编写Dockerfile)，基础的资源管理由devops提供CI(gitlab ci)/CD平台整合上线(可以部署物理机/虚拟机/部署(kubectl/istioctl)容器上云)&lt;/li&gt;
&lt;li&gt;在迁移至容器云(Kubernetes 集群中的应用)的过程中，会涉及到一部分服务容器化部署上线，一部分还是部署在物理机/虚拟机上，服务之间相互访问，容器云-&amp;gt;容器云，容器云-&amp;gt;物理机/虚拟机， 物理机/虚拟机-&amp;gt;容器云，需要业务梳理出服务之间的调用关系，然后对3种服务调用情况进行改造，其中可以使用sidecar模式进行流量输入输出&lt;/li&gt;
&lt;li&gt;通过K8S来编排服务，会出现服务治理的问题，需要可视化，监控，追查定位问题等相关平台来整合，对应的规范和开源工具整合进来，log: 采集日志，存储日志(热/冷)，查找日志；metric: 监控数据采集，监控指标，监控看板/大盘；trace: 服务请求访问链路追踪，服务调用响应时间，整体响应时间；以及k8s本身调度节点中pod资源监控&lt;/li&gt;
&lt;li&gt;部署至容器云后的整体测试，接口压侧，整体链路压侧&lt;/li&gt;
&lt;li&gt;上线后的切流方案&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;整体流程&#34;&gt;整体流程&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/cicd.png&#34; alt=&#34;cicd&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;随着业务的发展，服务不断迭代改造，涉及到业务层面抽象改造，以及基础平台服务的升级；最终目的都是为了满足日益增长的需求，缩短需求发布到上线的周期，复用，减少迭代对服务整体稳定性的影响。&lt;/p&gt;
&lt;h4 id=&#34;references&#34;&gt;References&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://jimmysong.io/kubernetes-handbook/practice/service-discovery-and-loadbalancing.html&#34;&gt;k8s-service-discovery-and-loadbalancing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/practice/integration-registry.html&#34;&gt;istio集成服务注册中心&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.servicemesher.com/istio-handbook/concepts/sidecar-injection.html&#34;&gt;Sidecar 模式&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhaohuabing.com/post/2019-10-21-pilot-discovery-code-analysis/&#34;&gt;Istio Pilot 组件介绍&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>工程师六大意识</title>
      <link>https://weedge.github.io/post/rd/</link>
      <pubDate>Sat, 02 Oct 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/rd/</guid>
      
        <description>&lt;h2 id=&#34;1时间意识&#34;&gt;&lt;strong&gt;1.时间意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    时间意识的终极目标是按时保质的完成工作。时间是一种宝贵的资源，由于每天工作时间的有限的而需要处理事情是复杂多变性的，为了按时保质的完成工作，我们首先需要有极强的时间意识，使用科学的时间管理策略。总的来说，时间管理就是让我们更有计划的知道需要做什么，什么时候做什么，而时间管理的难点为：事情具有突发性、完成时间难以预算性、执行力和预期不符合。&lt;/p&gt;
&lt;h3 id=&#34;11做明确计划&#34;&gt;1.1做明确计划&lt;/h3&gt;
&lt;p&gt;​    花一定的时间专门做计划，精确到小时，磨刀不误砍材工。为了做出精确的计划，提高时间的利用率，我们可以把个人时间和任务安排分块化，让同性质的任务部门分配同一段时间来处理，让零碎的时间处理细碎的问题，高效率的时间做大块重要困难的问题。&lt;/p&gt;
&lt;h3 id=&#34;12能尽快完成就尽快完成给以突发事情一定预算余地&#34;&gt;1.2能尽快完成就尽快完成，给以突发事情一定预算余地&lt;/h3&gt;
&lt;p&gt;​    即使每天计划的清清楚楚的工作安排，还是很大可能出现突发事情打乱计划，因为我们的工作性质就是这样的，需要随时待命解决突发的问题，并且很多事情是难以准确预算完成时间的，所以我们应该尽快的完成任务而不是拖到最后甚至拖到明天，这样才能最大限度的留给未知可能的处理空间。&lt;/p&gt;
&lt;p&gt;​    现在的社会处于互联网产业高速发展时期，到处充满着机遇，但是不管对企业还对个人来说又都面领着极大的竞争挑战。想要在这样的环境下生存并且前进，需要我们具有争分夺秒的意识，今天落后一步，就需要无数天的加速才能追上别人，更重要的是，身为团队的一员，很可能因为自己的一点懈怠而拖慢团队的脚步。&lt;/p&gt;
&lt;h3 id=&#34;13总结提高锻炼坚毅的性格提高执行力度&#34;&gt;1.3总结提高，锻炼坚毅的性格，提高执行力度&lt;/h3&gt;
&lt;p&gt;​    除了事情本身的多变性和竞争的激烈性，还有一点就是我们通常会高估自己的执行力，这需要我们我们进行自我管理自我约束，培养坚毅的性格，具有很强的责任心，高效率的执行力，主动的向别人汇报进度，树立起一个让自己和别人都信得过的形象。我们还需要不断的总结提高计划的准确性，看清自己，看清问题，将自己和问题准确的在时间维度上来对应起来。&lt;/p&gt;
&lt;h2 id=&#34;2质量意识&#34;&gt;&lt;strong&gt;2.质量意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    时间是宝贵的资源，但是不能为了节省时间而降低质量，时间是用来使用的，真正的节省时间就是合理高效的使用时间。欲速则不达，在复杂庞大的网络环境中，每一个小小的质量问题，都可能导致巨大的灾难，比如有可能这个灾难只是因为某一个进制转换精度损失引起的。如何保证质量，需要个人的责任心、需要团队的正确文化氛围、需要科学的质量保证流程。&lt;/p&gt;
&lt;p&gt;​    首先需要我们拥有一个保证质量的责任心，每一个人都要对质量负责，要有居安思危的意识，不能默认没问题，而是要反复核对自己的工作，不要等着别人来发现自己的问题，不要依赖流程，比如开发不能依赖测试，测试只是最后的质量检查而已，而不是保证，而且局限性小，即使测试出问题，修改也是费时费力。&lt;/p&gt;
&lt;p&gt;​    然后就是有一套科学的质量保证流程，比如需求的审核、开发的测试、上线过程评审等，质量保证工作存在于每一个环节，早发现早解决，因为越到后面挽救的代价越大。&lt;/p&gt;
&lt;h2 id=&#34;3沟通意识&#34;&gt;&lt;strong&gt;3.沟通意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    沟通的本质就是，了解他人的需要，表达自己的需要，沟通是项目成功的重要技巧之一。沟通无处不在，包括：文档、邮件、合同，更直接点的就是电话、口头。对于开发而言，代码本身就是用于沟通，所以我们要严格要求代码规范，要意识到代码是要用于沟通的，让人一看就懂的才是好代码。&lt;/p&gt;
&lt;h3 id=&#34;31沟通的态度&#34;&gt;3.1沟通的态度&lt;/h3&gt;
&lt;p&gt;​    沟通中的双发是代表各自角色的沟通，而不是个人间的沟通，也是通常我们说的 对事不对人 。因此，我们在沟通中不要忘记自己的职业角色，也不要忽视对方的职业角色。在沟通中我们要公开和坦诚地表达自己的意见，同时要有尊重别人的权利的态度，多用描述性语句，少用判断性语句，要有积极的态度。&lt;/p&gt;
&lt;h3 id=&#34;32主动沟通&#34;&gt;3.2主动沟通&lt;/h3&gt;
&lt;p&gt;​    看问题的角度不同，看法和观点会不一致，我们无法寄希望于对方主动来找我们沟通，所以为了得到好的结果，我们需要主动去沟通。所以要做好以下几点：&lt;/p&gt;
&lt;p&gt;（1）做好沟通前的准备，想好要表述的问题和想知道的问题&lt;/p&gt;
&lt;p&gt;（2）把握沟通时机，要在适当的时间、地点，同时考虑好沟通对象的状态。&lt;/p&gt;
&lt;p&gt;（3）选择好沟通方式，根据沟通紧急程度，具体问题的不同，选择合适的沟通方式，如：面谈、电话、书面（含即时通讯工具）等&lt;/p&gt;
&lt;h2 id=&#34;4团队意识&#34;&gt;&lt;strong&gt;4.团队意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    要实现目标，最重要的就是团队，我们让自己变得优秀的本质也是为了能够为团队做更大的贡献，通过团队实现个人，也通过个人贡献团队。听说这样一句话，一个中国人是一条龙，一群中国人是一群虫，这就是我们在国外人眼中缺少团队的意识。对于团队我们要有以下意识：&lt;/p&gt;
&lt;h3 id=&#34;41集体荣誉感&#34;&gt;4.1集体荣誉感&lt;/h3&gt;
&lt;p&gt;​    要有集体荣誉感，凡事看大局，每个人都是团队的一份子，不能有打酱油的心态。&lt;/p&gt;
&lt;h3 id=&#34;42建立完善的规则&#34;&gt;4.2建立完善的规则&lt;/h3&gt;
&lt;p&gt;​    没有规矩，不以成方圆，没有没有纪律的军队，不可能打胜仗。对于研发团队，统一的规则可以有效的减低沟通成本，集合整个团队的智慧，降低错误的可能性，规则要不断总结，不断优化。&lt;/p&gt;
&lt;h3 id=&#34;43团结互进&#34;&gt;4.3团结互进&lt;/h3&gt;
&lt;p&gt;​    团队之间要互相信任，乐于为别人提供帮助，乐于和善于从其他同事那里获得帮助，互相学习共同进步。开诚布公、相互尊重、相互理解，多站在对方的立场上考虑，对事不对人。团队意识不等于哥们义气、拉帮结派，也不等于好好先生，建立优秀的团队氛围。&lt;/p&gt;
&lt;h3 id=&#34;44建立强沟通&#34;&gt;4.4建立强沟通&lt;/h3&gt;
&lt;p&gt;​    团队要强调沟通意识，以各种方式建立起成员之间的联系。&lt;/p&gt;
&lt;h2 id=&#34;5进取意识&#34;&gt;&lt;strong&gt;5.进取意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    要有理想，有进取心，不断的追求更高的目标。在激烈竞争的环境，要有忧患意识，不断进步，否则迟早要淘汰。而进取意识最终要的是客服自己的心态，“破山中贼易，破心中贼难”，&lt;strong&gt;对自己的要求比别人对自己的要求更严格&lt;/strong&gt; ，客服自己的内心，加强计划性和执行力，这是见于所有能快速成长的优秀工程师所共有特质，而恰恰是那些不适应一个高速成长的团队而被淘汰掉的工程师身上所最缺乏的东西。&lt;/p&gt;
&lt;p&gt;​    要未雨绸缪，也要容忍失败。进取是为了未雨绸缪，但是进取不代表不会失败，而是指能在失败面前勇于剖析、勇于承担责任，又能自我总结经验教训、保持自己的进取心。 ¡&lt;/p&gt;
&lt;h2 id=&#34;6求实意识&#34;&gt;&lt;strong&gt;6.求实意识&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;​    实事求是，是《毛泽东思想》的精髓之一，也正是实事求是，不搞虚的，才能有高速发展的中国的今天。在实际项目中要注重事实，反对弄虚作假，大胆的假设小心地求证，一切以数据说话，用准确的数字和事实来论证，不能只有臆测的结论。&lt;/p&gt;
&lt;p&gt;​    以量化指标作为判断的依据，实际数据为王，没有量化，就没有绩效，通过这些指标衡量自己的成长和进步，通过这些指标知道工作的方向和重点。&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;p&gt;工程师，是从复杂的需求中，&lt;strong&gt;定义问题&lt;/strong&gt;，解决问题，给出具体方案而生的工种，不能单兵作战，需要通过高效的工具进行武装，对复杂重复通用的场景进行沉淀下移，方便其他工程师使用，所谓开源；在不断挖坑填坑中，解决特定任务，锻炼出皮实耐操的难得品格，需求虐我千百遍，我对需求如初恋；没有需求何来架构落地呢，何来量化指标，升值加薪呢～&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>组织引擎</title>
      <link>https://weedge.github.io/post/zborg/</link>
      <pubDate>Sun, 05 Sep 2021 21:04:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/zborg/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景：&lt;/h2&gt;
&lt;p&gt;教学直播间场景多样性，按年龄段区分辅导后台角色，构成整个教学课中直播和互动的多样性，为了快速支持业务发展，导致后端服务接口过多，不易维护，统一管理。&lt;/p&gt;
&lt;p&gt;主要分为如下场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;对接辅导侧后台的场景：&lt;/strong&gt; 辅导侧不同的辅导运营后台，比如：低幼辅导，班主任(班课)，督学服务，0转化督学服务等，后续可能还有小鹿编程，大师素养课对应的辅导侧；辅导侧会分班去带学生，不同的辅导侧会有单独的课中业务服务来对接辅导后台的接口，课中理解不同的业务组织形态，代码逻辑和存放数据冗余，不方便维护；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;业务前台对接直播接口场景&lt;/strong&gt;：直播业务服务多样；按照课程类型分为专题课，班课，短训班，素养课，编程课等；直播服务：班主任出镜（课前，课中，课后），小班，小组，大班，自习室等；服务的多样性，导致业务接口繁琐，前期快速开发上线，针对每个直播服务业务场景单独提供接口， 带来的问题不方便统一管理维护；&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;课中互动中台互动聊天场景：&lt;/strong&gt; 大班，小班，小组直播间场景依赖售卖和辅导侧的组织结构进行聊天，答题，鼓励，PK，发红包等互动；导致课前需要对这些组织结构按照不同直播场景+不同辅导侧数据进行提前预热处理，逻辑重复；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;设计目标&#34;&gt;设计目标：&lt;/h2&gt;
&lt;p&gt;需要一个承上启下的模块来连接辅导侧支撑课中直播/回放互动场景：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;对不同业务直播场景进行收敛，减少重复开发；&lt;/li&gt;
&lt;li&gt;隔离底层业务后台辅导侧，售卖侧数据，统一接入辅导/售卖侧全量数据，以及异动，减少数据冗余；&lt;/li&gt;
&lt;li&gt;隔离底层业务数据，抽象直播中台数据模型，中台面向这个数据模型进行编程，提供原子化接口；&lt;/li&gt;
&lt;li&gt;当天上课课前预热数据需要在0-6点尽量全部预热完成；预热加速，预热后的数据检查；&lt;/li&gt;
&lt;li&gt;复用中台数据模型已支持的直播场景能力，提供saas化服务，前台使用中台定义的dsl，根据业务场景进行组装，提高开发效率；&lt;/li&gt;
&lt;li&gt;提供可配置后台，管理服务接口；&lt;/li&gt;
&lt;li&gt;将读写io最小化，提高原子化接口响应时间RT&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;原则： 高内聚低耦合、空间换时间&lt;/p&gt;
&lt;h2 id=&#34;数据模型&#34;&gt;数据模型：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;一个章节会有多个直播间，比如辅导老师出镜(课前，课中，课后)，最多3n+1个直播间，n为课程章节下的辅导老师数目，liveRoom&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不同直播间，对应不同的直播间业务流程:  bizType&lt;/p&gt;
&lt;p&gt;三分屏直播间，进入教室→签到→直播/互动→离开(切直播间)&lt;/p&gt;
&lt;p&gt;小组直播间，进入教室→课件下载→分组→签到→直播/互动→离开(切直播间)&lt;/p&gt;
&lt;p&gt;小班直播间，进入直播间→ 课件下载→ 分班→ 直播/互动→离开(切直播间)&lt;/p&gt;
&lt;p&gt;自习室直播间，进入直播间→ 签到→直播&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不同直播间，对应不同的流媒体推拉流方案：streamPolicy&lt;/p&gt;
&lt;p&gt;三分屏直播间，rtmp + 长链接&lt;/p&gt;
&lt;p&gt;小组直播间，rtc + 长链接&lt;/p&gt;
&lt;p&gt;小班直播间，rtc + 长链接&lt;/p&gt;
&lt;p&gt;自习室直播间，rtmp + 长链接&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;不同组织关系对应聊天互动广播统计维度，抽象组织结构：orgPolicy, orgTree(node)&lt;/p&gt;
&lt;p&gt;一课三分屏：/课程章节,  无班主任，全员互动；课中自动生成；&lt;/p&gt;
&lt;p&gt;小英小数小语文小组直播间，/课程章节/辅导老师/{队/小组}，  辅导老师： 低幼辅导，班主任(班课)，督学服务，0转化督学服务等， 队/小组由课中学生选组自动生成；低幼辅导，班主任，督学服务，0转化督学服务提供数据；&lt;/p&gt;
&lt;p&gt;班主任小班直播间，/课程章节/辅导老师/小班，辅导老师： 低幼辅导，班主任(班课)，小班由辅导侧课前排灌班生成；低幼辅导，班主任服务提供数据；&lt;/p&gt;
&lt;p&gt;短训班，/课程章节/督学LPC/微信群，微信群有督学老师课前排灌班生产，督学服务提供数据；&lt;/p&gt;
&lt;p&gt;0转化服务，/课程章节/督学LPC , 0转化督学服务提供数据；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;lessonPolicy: (bizType,streamPolicy,orgPolicy)&lt;/p&gt;
&lt;p&gt;原则：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;直播中台解耦业务属性，支持抽象业务场景，作为底层直播能力输出；&lt;/li&gt;
&lt;li&gt;可复用，直播功能，性能，稳定性的复用；比如三分屏，班课，小组，伪直播等不同维度业务属性解耦前置到预热阶段；&lt;/li&gt;
&lt;li&gt;可扩展，直播数据模型属性如有新增，不会影响原有属性；&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;数据量&#34;&gt;数据量：&lt;/h2&gt;
&lt;p&gt;1天最高峰2w节课，总报名学生数量600w+， 在线学生100w+ ， 课中进入上课页面qps 120w+&lt;/p&gt;
&lt;p&gt;处理数据量：按一个课程章节来计算，最大的报名学生数目3w+  实际测试用60w+ 的报名学生，预热大概45多分钟&lt;/p&gt;
&lt;p&gt;3w 的报名学生， 小组直播间，班主任出镜，一个班主任最多带500学生，预热大概 1分钟30多秒&lt;/p&gt;
&lt;p&gt;策略数据： 一个章节对应一个策略，一个策略可以给多个章节使用，&lt;/p&gt;
&lt;p&gt;policy (id,conf,desc,name)&lt;/p&gt;
&lt;p&gt;lessonPolicy (keyId,keyType,bizType,partition,policyId)&lt;/p&gt;
&lt;p&gt;直播间数量： 3n+1 (n是班主任数目，出镜场景） 最多181个直播间 180*8*5(id,roomId,virturalRoomId,rootId,bizId,roomType,teacherUid,startTime,endTime,status) = 7.2KB&lt;/p&gt;
&lt;p&gt;组织节点数量：3w/6=5000个小组节点，5000/6 = 800多个队节点，60个辅导老师节点，总共6000个组织节点， 6000*8*7(id, nodeId,parentId,rootId,virturalNodeId,sourceId,path) =328KB&lt;/p&gt;
&lt;p&gt;用户数量： 3w+  每个班主任最多带500个学生，  3w/500 = 60  个班主任，最多 181 个直播间， 180*500 + 3w =12w条直播间用户数据， 按直播间维度协程任务分批处理; 12w*8*4(id,uid,nodeId,roomId) =3.7MB&lt;/p&gt;
&lt;p&gt;一天大概总共 2w * 4M =  78GB数据可能需要课前预热 （以一天最大2w节课程章节，每个章节报名人数3w计算, 报名学生2w*3w =6亿）&lt;/p&gt;
&lt;h2 id=&#34;依赖中间件基础服务&#34;&gt;依赖中间件基础服务&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;redis (stored k/v存储）  前期是哨兵模式架构， 后期采用proxy模式架构&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;DB(mysql ) 主从架构，未使用proxy数据库中间件&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MQ(NMQ, RocketMQ) 消息队列&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;前期用的NMQ  消息以push的方式发送的消费方，通过groupKey来保证有序，以及消息积压报警，无限重试，消费方来保证幂等&lt;/p&gt;
&lt;p&gt;RMQ是为了兼容NMQ , 对rocketMQ进行来封装， 消息生成侧提供proxy, 兼容nmqproxy；消费侧rocketMQ是pull长轮训方式，为了兼容NMQ的push方式，提供pusher模块；数据存放用rocketMQ的broker&lt;/p&gt;
&lt;p&gt;rocketMQ : &lt;a href=&#34;https://github.com/apache/rocketmq/tree/master/docs/cn&#34;&gt;https://github.com/apache/rocketmq/tree/master/docs/cn&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;kafka : &lt;a href=&#34;https://kafka.apachecn.org/intro.html&#34;&gt;https://kafka.apachecn.org/intro.html&lt;/a&gt; 长链接心跳打点数据 → kafka → 计算引擎&lt;/p&gt;
&lt;h2 id=&#34;流程&#34;&gt;流程&lt;/h2&gt;
&lt;h3 id=&#34;数据对接方&#34;&gt;&lt;strong&gt;数据对接方&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;预热模块接入辅导侧三方数据：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;班主任侧（小班，辅导老师：班主任）&lt;/li&gt;
&lt;li&gt;督学服务侧（微信服务，辅导老师：督学）&lt;/li&gt;
&lt;li&gt;0转化督学服务侧（拉新转化，辅导老师：0转化督学）&lt;/li&gt;
&lt;li&gt;低幼服务侧（小班，辅导老师：班主任）&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;场景直播间维度&#34;&gt;&lt;strong&gt;场景（直播间维度）&lt;/strong&gt;&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;一个章节里一个主直播间一个组织树 （非出境）&lt;/li&gt;
&lt;li&gt;一个章节里多个主直播间一个组织树 （出境）&lt;/li&gt;
&lt;li&gt;一个章节里多个主直播间对应多个从直播间多个组织树 （旁听+出境）&lt;/li&gt;
&lt;li&gt;多个章节情况都转化成一个章节下的直播间情况 （共享）&lt;/li&gt;
&lt;li&gt;跟课场景：一个章节可能给不同的辅导侧在使用，辅导平台的数据源不同，一个组织树对应多个业务组织，一个直播间主讲推流，多个辅导侧后台拉流监控&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;流程-1&#34;&gt;流程&lt;/h3&gt;
&lt;p&gt;定义规范辅导侧数据接入 → 上课课程章节绑定对应策略(如不满足，新增支持）→ 分发任务前置预热 → 生成中台理解的属性 (liveRoom,lessonPolicy,orgTree 等)  →直播中台面向这些属性编程，提供原子化读写接口&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/%E7%9B%B4%E6%92%AD%E4%B8%AD%E5%8F%B0-%E7%BB%84%E7%BB%87%E5%BC%95%E6%93%8E%E6%B5%81%E7%A8%8B%E6%A1%86%E6%A1%86%E6%96%BD%E5%B7%A5%E5%9B%BE.jpg&#34; alt=&#34;直播中台-组织引擎流程框框施工图.jpg&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;策略规则平台policy&#34;&gt;策略规则平台policy：&lt;/h2&gt;
&lt;p&gt;用于不同的业务直播间类型绑定组织策略，开发提供给运营产品团队使用&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;推拉流策略（rtc(udp),rtmp(tcp)+CDN 延迟较高，价格低； 学生，老师小组直播间互动场景用的rtc, 一课(三分屏)直播间用的rtmp; 辅导跟课后台，监控后台用的rtmp）；&lt;/li&gt;
&lt;li&gt;直播间策略(班主任课前/课中/课后出镜直播间，主讲直播间)；&lt;/li&gt;
&lt;li&gt;互动组织策略（基于组织树，学生，班主任，老师 通过长链接的聊天广播模式）;&lt;/li&gt;
&lt;li&gt;预热策略（极简，简单，全部预热）;&lt;/li&gt;
&lt;li&gt;预热时间计算预热时长(根据直播间数，组织节点数，用户数，计算预热时长）；用于分层时间轮来监控预热任务超时报警&lt;/li&gt;
&lt;li&gt;缓存设计中直播间的学生集合和在线学生集合 zset 分片策略（根据课程报名人数和商品库存数调权相加获取）；&lt;/li&gt;
&lt;li&gt;数据源定义（辅导侧数据：低幼，0转化督学，督学，班主任等，售卖侧数据）；&lt;/li&gt;
&lt;li&gt;异动数据通知定义 (学生更换班主任/小班，老师更换，课程章节上课时间更改，课程章节重开）&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;组织数据生成引擎core&#34;&gt;组织数据生成引擎core：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;缓存设计：&lt;/p&gt;
&lt;p&gt;策略缓存/本地缓存，组织树缓存，直播间缓存，学生缓存，预热任务缓存&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;数据库数据设计：&lt;/p&gt;
&lt;p&gt;业务策略表，组织节点表，直播间表，学生表&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;直播中台组织引擎课中数据接口设计：&lt;/p&gt;
&lt;p&gt;直接从缓存中取，交互的数据通过write-behind 模式写入&lt;/p&gt;
&lt;p&gt;获取组织树节点信息，节点原始节点信息，子节点信息，学生所在直播间节点，选组/位置&lt;/p&gt;
&lt;p&gt;获取业务课程章节业务id的直播间信息&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;直播中台组织引擎回放数据接口设计：&lt;/p&gt;
&lt;p&gt;接口数据缓存，cache-aside 模式读取，课后回放数据都是读的场景&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;消息队列topic 消息体设计 ：异步落库，为了同步db,  同步db逻辑幂等，降低db的写压力&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;直播间，组织节点，学生数据&lt;/p&gt;
&lt;p&gt;内部优化设计：（原则：尽量减少读写io, 达到最优解）&lt;/p&gt;
&lt;ol start=&#34;2&#34;&gt;
&lt;li&gt;异步缓冲buffer数据批量发送队列入库，减少网络io，降低db的写压力&lt;/li&gt;
&lt;li&gt;课中老师的课件信令记录，zset存缓存，学生高并发场景获取直播间信令记录，通过本地缓存来减少对zset 大key数据读取压力&lt;/li&gt;
&lt;li&gt;任务池化，并发批量处理任务，提高吞吐相应速度&lt;/li&gt;
&lt;li&gt;临时对象池化，高并发吞吐减少gc&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;配置平台conf-dashboard&#34;&gt;配置平台conf-dashboard：&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;预热流程 DSL pipeline 配置,&lt;/li&gt;
&lt;li&gt;依赖缓存和数据配置 ，&lt;/li&gt;
&lt;li&gt;业务配置，&lt;/li&gt;
&lt;li&gt;预热报警通知配置,&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;预热数据监控平台monitor-dashboard&#34;&gt;预热数据监控平台monitor-dashboard:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;提供手动触发预热和预热数据检查；&lt;/li&gt;
&lt;li&gt;查看预热好的直播间，组织树，学生所在直播间的组织节点信息，以及课中直播间开始结束时间，直播间状态，学生在线状态，聊天状态（禁言/可聊天), 分组信息，到课时间&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;开发工具&#34;&gt;开发工具&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;线上/线下预热通知群&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预热报警通知群&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;预热回归diff检查工具&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/%E9%A2%84%E7%83%AD%E6%A3%80%E6%9F%A5.jpg&#34; alt=&#34;预热检查&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/preload-diff.png&#34; alt=&#34;preload-diff&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;容错处理&#34;&gt;容错处理&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;分布式任务处理，如果一个机器挂了不影响任务处理，failover机制&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;任务执行失败会右报警机制，可以手动处理重新预热，还有自动轮训检查预热是否成功机制，如果预热失败，会在下个轮训周期出发预热， 轮训周期可调，默认是10分钟&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;技术难点和收益&#34;&gt;技术难点和收益&lt;/h2&gt;
&lt;h3 id=&#34;组织引擎&#34;&gt;组织引擎：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;业务数据源梳理，设计通用的模型，通过策略配置将不属于课中直播中台的业务属性进行隔离&lt;/strong&gt;，&lt;/p&gt;
&lt;p&gt;比如售卖平台和辅导侧运营平台 售卖的课程产品，分班排管班策略，以及课程中每一节大纲章节业务属性，都通过课前预热的时候进行解耦，生成课中理解的内聚模型，直播间，组织树；主讲，辅导老师和学生在直播间上课，通过组织树进行互动；课中学生老师进入教室获取课前绑定的策略，初始化直播间和组织树属性。这样能够服用已有沉淀下来的稳定功能；而且在支持新业务直播场景下，节省开发人力，加速产品迭代，将业务属性隔离，也有助于服务稳定运行&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;组织树在分布式缓存和数据库中的设计；&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;如何在k/v存储中表示一颗组织树，以及在db数据库表中表示一颗组织树和学生，老师之间的关系；&lt;/p&gt;
&lt;p&gt;数据库需要考虑每天的数据容量，以及未来3年的数据容量(按一天2w节课，一节课3w+报名，估算78GB数据量)；&lt;/p&gt;
&lt;p&gt;为了方便课后问题排查，缓存数据过期时间7天（可调整），课中接口是直接和缓存交互，改变的数据状态通过Write behind模式异步刷盘写入db中，后台的接口数据通过Cache aside 课前预读提前加载至缓存中(延迟双删)。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;半夜0点～6点这段时间需要保证当天预热数据的高效性，准确性，以及可视化监控报警&lt;/strong&gt;:&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	1. &lt;strong&gt;预热框架的设计&lt;/strong&gt; ，业务数据和课中直播组织模型 策略绑定平台，生产预热任务，负载均衡分发至预热worker节点，记录预热，任务监控(预热和检查)，预热失败的容错，failover，报警；&lt;/p&gt;
&lt;p&gt;​	将业务属性和直播属性通过策略进行绑定，生成任务发送给消息队列，通过消息队列pusher到 预热模块, 利用内部的nmq工具属性，进行任务的负载均衡发布到每台worker协程来预热，考虑到可能会同时发多个相同的任务在不同的worker上执行，需要加锁；预热记录在预热记录表中，进行监控；&lt;/p&gt;
&lt;p&gt;​	每个预热worker会统计本机处理的章节，直播间，组织节点/树，学生数目，预热完之后，通过丁丁通知预热结果，也会同时触发数据检查流程；&lt;/p&gt;
&lt;p&gt;​	为了支持不同的预热场景，加入了极速预热，快速预热策略，满足新建一个课直接上课的场景(这些场景在内部老师的测试课会使用到), 秒级内完成；&lt;/p&gt;
&lt;p&gt;​&lt;/p&gt;
&lt;p&gt;​	2. &lt;strong&gt;预热数据检查&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​	检查预热数据的完整性，通过和数据源的对比，检查绑定的策略属性是否是好的；缓存和db中的直播间，组织数据，以及学生所在组织树，老师所在的直播间等数据的检查&lt;/p&gt;
&lt;p&gt;​	批量数据检查不能影响线上的稳定性，主要是读取线上缓存和db中的数据，也会像预热那样分发到集群机器上去并行处理；如果是业务高峰期进行检查，需要对检查流量进行限流，&lt;/p&gt;
&lt;p&gt;限流方案：对单机进行限流，对整体检查集群进行限流，都是以当前运行的检查任务数进行计数限流控制(redis hincr)；每个检查worker进程会统计当前正在运行的任务数，如果到了单机最大任务数，新的检查请求会直接返回检查容量已超限制错误，pusher会重试到另外一台机器上，&lt;/p&gt;
&lt;p&gt;​	3. &lt;strong&gt;预热数据监控&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;​	课前 预热任务和检查任务的监控；&lt;/p&gt;
&lt;p&gt;​	课前 业务数据和课中直播组织模型 绑定策略， 老师直播间，组织树，学生等数据，在缓存，db中的监控；&lt;/p&gt;
&lt;p&gt;​	课中 直播间状态，所在组织树下的学生数据状态的监控；&lt;/p&gt;
&lt;ol start=&#34;4&#34;&gt;
&lt;li&gt;&lt;strong&gt;需要考虑课前，课中的异动场景&lt;/strong&gt;，比如&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	课前，辅导侧给分好班的学生重新分班，需要订阅辅导测的异动，如果是同一时间批量修改，课中直播中台预热好的组织树需要考虑 并发异动修改学生所在的节点；&lt;/p&gt;
&lt;p&gt;​	课中，并发场景动态扩容，比如学生进入教室之前需要选组，如果初始小组节点不够，到了阈值，发送扩容任务，通过异步动态扩容协程进行扩容；&lt;/p&gt;
&lt;ol start=&#34;5&#34;&gt;
&lt;li&gt;&lt;strong&gt;课中获取缓存数据的接口优化，分布式缓存中的大key和热key的优化&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;​	大key优化 通过分片处理，直播间的在线学生集合 和 报名学生集合，对key 进行partition分片，每个partition 5000个学生， partition的值是在课前预热的时候通过报名人数和课程的库存数量进行加权和预估的值；&lt;/p&gt;
&lt;p&gt;​	热key优化 通过加本地缓存，通过LRU进行evict，比如 一个老师上课时产生的信令列表(直播间维度，按时间顺序)，存放在zset中，提供学生进入教室时拉取，以及数据滞后时候的拉取，如果是一个热门直播间，会同时上万个学生获取这个老师产生的信令列表，会对分布式缓存中的slot带了压力，为了解决这个问题，将以获取的信令列表数据缓存到本地的有序列表中(sortedlist -&amp;gt; skiplist), 这些有序列表通过直播间维度hash分桶， 本地的有序列表数据只需维护 新增的数据，而不需要整段去获取缓存，减少获取热key的网络io； 这里会打点记录每个key的hit命中/miss未命中的数据量，数据日志采集接入基础监控平台，实时查看；&lt;/p&gt;
&lt;ol start=&#34;6&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;新业务接入，对新策略的增加，以及对老策略的修改，如何保证系统稳定性&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;进行预热逻辑升级之后，上线之前都会在线下进行一轮未改策略的预热数据自动化diff，是拉取不同的版本，还未合入master的线上版本和修改了的版本，分布部署在两个容器中；根据不同的直播场景，从线上获取数据，预热写入线下缓存实例k/v和数据库实例表中，然后分别读取两份数据进行对比，比较为修改的策略是否有影响，有数据diff, 并报告diff的数据点，进行线下修复，再次进行自动化diff, 无diff之后，才能合并到master上线分支，上线；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&#34;建设组织引擎课前预热整体收益&#34;&gt;建设组织引擎课前预热整体收益：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;节约了人力，加速产品开发迭代周期；以前如果接入新的业务辅导侧数据，以及提供相关的课中接口，从开发，测试上线，大概3～4个人力，需要2～3周的时间， 改造之后，开发，测试上线，大概1-2个人，需要1周的开发时间，节约了一半的成本；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;复用现有直播场景功能，将底层业务和直播属性进行隔离， 直播只关注直播属性，无需关注业务属性；保证直播服务的稳定性，将业务数据提供规范化接入后，可以将业务依赖进行反正，为后续saas化提供保障；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;直播接口性能有所提高，以前是有不同的业务方去把控，现在收敛整体把控，降低资源消耗（cpu, 内存，磁盘空间，网络io)，有些业务当时还是用php开发，php是多进程的方式处理业务请求逻辑，相对于go协程，占用资源更多；&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;系统更加稳定，引入自动化工具检查预热数据，监控报警机制，修改策略线下检查机制，能保障系统稳定升级，减少线上出错率；&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;qa&#34;&gt;Q&amp;amp;A&lt;/h2&gt;
&lt;p&gt;Q：课前预热直播间数据为什么选择先写缓存，然后在通过mq异步落db呢？&lt;/p&gt;
&lt;p&gt;A： 因为预热的过程是异步多台机器单机进程并行预热，进程中通过协程并发处理流程预热，为了预热提速；&lt;/p&gt;
&lt;p&gt;如果直接写db, 然后在更新缓存，因为mysql是主从架构，预热是写多读多场景， 写多是因为预热数据初始写入数据库，读多是因为数据入库之后，会通知接口缓存模块去请求读db接口缓存数据(接口数据为空，不会存储，都为insert操作成功之后，才通知接口缓存模块，不会出现不一致的情况)；读请求可以通过多个从来分担，但是写的话都是在主上，分库分表都是在单实例上, 单机抗大量写请求会成为整体预热的瓶颈；&lt;/p&gt;
&lt;p&gt;如果直接写入缓存，然后mq异步落db 的形式可以充分利用缓存比磁盘读写io速度快的优势，缓存的实例部署是以proxy的形式分布式部署，可以对slot分片进行读写 扩容，分散读写压力；不会成为预热的瓶颈；（以前是无中心化的形式通过业务使用方一致性hash 来访问分布式缓存slot分片, 后面改成proxy中心化的方式，统一管理方便运维，业务使用方直接通过redis协议请求，无需关心分片操作）&lt;/p&gt;
&lt;p&gt;通过mq异步落db，mq是通过push的方式直接发给后端接口入库的，降低mq的push的并发窗口，可以减少push频率，降低后端接口的请求量，但是会消费变慢，为了加快操作，对发送给mq的数据进行buffer 处理，批量发送，通过后端接口批量写入数据库，减少网络i/o, 提高写入吞吐量；&lt;/p&gt;
&lt;p&gt;Q: 预热过程中，如果有上线，预热中断了，怎么处理呢？&lt;/p&gt;
&lt;p&gt;A： 在预热的时候会上报预热的启动状态， 旁路脚本每半小时会检查一次预热的启动状态，如果一直处于运行中，则报警，根据阈值判断(比如报名人数估算处预热时间，报警次数) 触发自动预热重新预热上；预热监控后台也提供了手动触发预热；&lt;/p&gt;
&lt;p&gt;这里没有像数据库那样使用WAL机制（进程crash后，缓存中的数据没有了，可以通过WAL日志找回），业务场景可以回溯数据，按章节或者直播间重新预热&lt;/p&gt;
&lt;p&gt;Q: 组织树的作用是什么呢？&lt;/p&gt;
&lt;p&gt;A： 将业务组织关系进行解偶，如果接入其他业务组织关系，只需要提供原始数据，就可以服务用课中的组织关系能力，提供课中组织关系下的直播互动；课中组织树是可以动态扩展的，满足课中报名人数突增的情况；&lt;/p&gt;
&lt;p&gt;Q: 后续会提供用户维度的组织树操作接口吗？&lt;/p&gt;
&lt;p&gt;A： 现在是通过采集其他平台的组织数据进行一份转化生成提供给课中直播互动使用的组织树，后续提供相关的基础读写接口来初始/更改预热数据，使用方只需要在构造业务组织结构的时候调用写入缓存&lt;/p&gt;
&lt;p&gt;Q: 现在业务数据量有多大？&lt;/p&gt;
&lt;p&gt;A: 系统是按照最大量估算的，一天大概总共 2w * 4M =  78GB数据可能需要课前预热 （报名学生2w*3w =6亿）&lt;/p&gt;
&lt;p&gt;Q: 是否考虑用工作流任务调度的方式处理呢？&lt;/p&gt;
&lt;p&gt;A: 正在考虑中，现在方式是后台绑定好预热策略，把策略发到消息队列里，然后通过消息队列负载均衡推送给预热任务执行；&lt;/p&gt;
&lt;p&gt;后面会优化成工作流任务调度的方式，将整个预热流程拆分成可单独执行的任务，然后生成一个DAG工作流，通过任务调度模块，分发到预热执行机器上执行，入度为0的任务开始启动执行&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>网络模型</title>
      <link>https://weedge.github.io/post/poller/</link>
      <pubDate>Thu, 02 Sep 2021 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/poller/</guid>
      
        <description>&lt;p&gt;看了一些开源的网络I/O模型框架库，尝试着按照理解简单实现一个相对简单的网络I/O模型框架，类似netty的reactor模型。&lt;/p&gt;
&lt;p&gt;Netty的NIO模型是Reactor反应堆模型（Reactor相当于有分发功能的多路复用器Selector）。每一个连接对应一个Channel（多路指多个Channel，复用指多个连接复用了一个线程或少量线程，在Netty指EventLoop），一个Channel对应唯一的ChannelPipeline，多个Handler串行的加入到Pipeline中，每个Handler关联唯一的ChannelHandlerContext。&lt;/p&gt;
&lt;p&gt;Reactor 模式的基本工作流程如下：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Server 端完成在 &lt;code&gt;bind&amp;amp;listen&lt;/code&gt; 之后，将 listenfd 注册到 epollfd 中，最后进入 event-loop 事件循环。循环过程中会调用 &lt;code&gt;select/poll/epoll_wait&lt;/code&gt; 阻塞等待，若有在 listenfd 上的新连接事件则解除阻塞返回，并调用 &lt;code&gt;socket.accept&lt;/code&gt; 接收新连接 connfd，并将 connfd 加入到 epollfd 的 I/O 复用（监听）队列。&lt;/li&gt;
&lt;li&gt;当 connfd 上发生可读/可写事件也会解除 &lt;code&gt;select/poll/epoll_wait&lt;/code&gt; 的阻塞等待，然后进行 I/O 读写操作，这里读写 I/O 都是非阻塞 I/O，这样才不会阻塞 event-loop 的下一个循环。然而，这样容易割裂业务逻辑，不易理解和维护。&lt;/li&gt;
&lt;li&gt;调用 &lt;code&gt;read&lt;/code&gt; 读取数据之后进行解码并放入队列中，等待工作线程处理。&lt;/li&gt;
&lt;li&gt;工作线程处理完数据之后，返回到 event-loop 线程，由这个线程负责调用 &lt;code&gt;write&lt;/code&gt; 把数据写回 client。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;参考这些网络模型，采用golang封装的底层epoll/kqueue系统调用方法，支持tcp协议，实现一个相对简单的网络模型，框架如下：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/im/main/go-epoll.png&#34; alt=&#34;go-epoll.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;代码实现：&lt;a href=&#34;https://github.com/weedge/lib/tree/main/poller&#34;&gt;https://github.com/weedge/lib/tree/main/poller&lt;/a&gt;  (对一个开源库进行的改造，codec编解码器待完善)&lt;/p&gt;
&lt;h4 id=&#34;参考&#34;&gt;参考：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/panjf2000/gnet&#34;&gt;gnet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/cloudwego/netpoll&#34;&gt;netpoll&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/tidwall/evio&#34;&gt;evio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/AlexStocks/getty&#34;&gt;getty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/netty/netty&#34;&gt;netty&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/xinali/articles/issues/57&#34;&gt;Linux网络编程模型&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>教学直播概括</title>
      <link>https://weedge.github.io/post/jxzb/</link>
      <pubDate>Wed, 01 Sep 2021 22:04:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/jxzb/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景：&lt;/h2&gt;
&lt;p&gt;不同于常规的主播互动直播；教学直播，面向k12人群，&lt;/p&gt;
&lt;p&gt;前期会有课前的准备工作比如课程创建，学生购买数据，老师课件，试卷题目的准备；&lt;/p&gt;
&lt;p&gt;双师模式：学生会分配给不同的辅导老师，辅导老师会对学生进行分班处理，课中也会有学生选组上课互动的场景，辅导老师也可以给学生上课，也会在后台进行跟课，监督学生上课；&lt;/p&gt;
&lt;p&gt;相对于常规的主播互动，会模拟线下上课的场景到线上课中直播，形成一套线上教学直播间场景模式&lt;/p&gt;
&lt;h2 id=&#34;业务发展&#34;&gt;业务发展：&lt;/h2&gt;
&lt;p&gt;课中直播是按章节维度进行直播交互的，一个章节一个直播间；&lt;/p&gt;
&lt;p&gt;随着业务发展，出现了一个章节多个不同直播间的场景（出镜），多个章节共享一个章节直播间的场景(共享直播间）； 一个章节有2个相同课中主讲直播间的场景（旁听）; 后面根据业务需求衍生出其他组合玩法；&lt;/p&gt;
&lt;h2 id=&#34;上课业务流程介绍&#34;&gt;上课业务流程介绍：&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;售卖侧建课&lt;/strong&gt;：售卖老师在售卖后台新建课程章节，定义课程章节的属性，形成售卖商品上架；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;学生侧购买报名&lt;/strong&gt;：学生在售卖页面可以购买课程章节上课，或者0元课扫二维码直接购买报名上课；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;辅导侧&lt;/strong&gt;： 根据上课用户的年龄段进行分类：低幼，班主任，督学，0转化督学；对报名的用户课前排灌班，以大班/小班/小组的组织形式上课；&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;教学直播课前预热：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;将当天课前准备的课件，试卷题目，课程章节老师辅导相关的等非状态非易变接口数据在上课之前预热至缓存中；因为课中上课是突发流量场景，减少对后台接口db的并发压力； 对课中不会变的接口数据可以加上本地缓存，提高相应吞吐效率；(读多写少场景接口，cache-aside模式）&lt;/li&gt;
&lt;li&gt;课前对课中异动易变数据需要直播间缓存，业务组织缓存等初始化缓存数据；提供给课中互动场景使用；后面通过业务策略绑定，把业务组织数据抽象一个课中理解的数据模型，直播间缓存， 组织树节点缓存，学生所在直播间节点缓存等初始数据；（基于这个课中缓存数据模型，进行编码，隔离业务属性）&lt;/li&gt;
&lt;li&gt;对于异动状态易变更新频繁的接口直接课中缓存交互，异步落盘，降低相应延迟减少对后台接口的读写压力；（写多频繁场景接口，write-behind模式）&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;教学直播课中互动：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;不同用户角色直播链路
&lt;ol&gt;
&lt;li&gt;老师端：初始化直播间(配置加载，不同的互动ui, 互动功能是否可用，流媒体appid/token)→ 加载课件(cocos资源) →进入直播间 → 通过流媒体推流拉流/连麦/通过长链接发送聊天消息和信令→互动（发题目/答案/红包/奖励）→ 切换直播间(辅导出镜)/结束直播&lt;/li&gt;
&lt;li&gt;学生端：初始化直播间(配置加载，流媒体appid/token, 流程配置)→加载资源(cocos互动资源包/ai模型资源包)→签到/分组→进入直播间→通过流媒体拉流推流/连麦/通过长链接发送聊天消息→互动（发题目/答案/红包/奖励/pk）→ 退出直播间&lt;/li&gt;
&lt;li&gt;辅导跟课后台：进入跟课后台→ 进入直播间→通过流媒体拉流/通过长链接发送聊天消息→处理报警/遮盖/鉴黄/标记→直播结束获取计算好的学生到课时长，作答率，出勤率，完课率等&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;互动依赖长链接，答题，pk等场景，都有开始到结束的过程，对每个互动场景用互动id来管理生命周期，涉及金额的互动，需要考虑黑产的影响，需要对答案加密，以及金额的提前计算预热和防止多发少发，互动读写接口尽量细化，防止读写io多在同一个接口中；尽量把计算放在用户端来处理， 比如 答题是否成功，pk是否赢了等，分散服务端流量压力；(原则：统一管理互动类型，可配置化，细化io, 计算前置,分流)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;strong&gt;教学直播课后回放：&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;建课后直接根据绑定的策略直接生成直播间，提供回放数据，比如素养课，伪直播&lt;/li&gt;
&lt;li&gt;课中的回放数据，会有直播间和用户互动最终状态数据落库&lt;/li&gt;
&lt;li&gt;回放数据是不会更改，读多写非常少的场景，缓存直接通过cache-aside的模式缓存db后台接口数据&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;教学整体概括架构&#34;&gt;教学整体概括架构&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/zyb-jx.png&#34; alt=&#34;jxzb&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;总结思考&#34;&gt;总结思考&lt;/h2&gt;
&lt;p&gt;​	底层的基础建设比较重要(&lt;strong&gt;高效能&lt;/strong&gt;)；上层业务的发展离不开基础组件的稳定性(&lt;strong&gt;高可用&lt;/strong&gt;)；以及服务多了之后，如何高效快速迭代，上线之后保证整体服务性能的稳定性(&lt;strong&gt;高并发/低延迟/可监控/可配置&lt;/strong&gt;)； 以及服务模块之间的划分合理，细化出功能组件，异动业务代码的可维护性（&lt;strong&gt;低耦合高内聚&lt;/strong&gt;）；这些都需要理论知识加以指导(比如服务划分抽象原则DDD, 业务抽象设计原则SOLID)，以及实践场景中去平衡折中改进；没有永恒的银弹(内卷)，尚需不断迭代提高。一个字 &amp;ldquo;稳&amp;rdquo;。&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;references&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/theme/119&#34;&gt;作业帮云原生探索和实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/9jn0qfcx2xq7h6xltwa9&#34;&gt;学而思网校直播课堂的架构演进之路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://insights.thoughtworks.cn/tag/domain-driven-design/&#34;&gt;Thoughtworks洞见-领域驱动设计&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.meituan.com/2020/03/19/design-pattern-practice-in-marketing.html&#34;&gt;设计模式在美团外卖营销业务中的实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.meituan.com/2017/12/22/ddd-in-practice.html&#34;&gt;领域驱动设计在互联网业务开发中的实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://read.douban.com/ebook/169386436/&#34;&gt;架构整洁之道&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://sre.google/books/&#34;&gt;google-sre-book&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://2012.33degree.org/pdf/JamesLewisMicroServices.pdf&#34;&gt;JamesLewisMicroServices.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://icyfenix.cn/&#34;&gt;凤凰架构&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/6dlQZisMiXK3hzLIwEET&#34;&gt;微服务架构设计中的设计模式、原则及最佳实践&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/mojOSgEUaHWGU3H3j7WjlQ&#34;&gt;微服务拆分之道&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://book.douban.com/subject/26938710/&#34;&gt;系统架构-复杂系统的产品设计与开发&lt;/a&gt;: 理论知识，多读多思考多实践，&amp;lsquo;&amp;lsquo;虚实&#39;&amp;lsquo;结合&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzIzNjUxMzk2NQ==&amp;amp;mid=2247497722&amp;amp;idx=1&amp;amp;sn=33df39c492c508b2086a704612edf186&#34;&gt;架构指导原则&lt;/a&gt;&lt;/strong&gt;: 值得反复推敲，内化，回顾以往做过的项目，总结出底层原理&lt;/li&gt;
&lt;/ol&gt;</description>
      
    </item>
    
    <item>
      <title>直播系列之消息模块演进</title>
      <link>https://weedge.github.io/post/jxzbim/</link>
      <pubDate>Mon, 02 Nov 2020 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/jxzbim/</guid>
      
        <description>&lt;h4 id=&#34;整体服务框架&#34;&gt;整体服务框架&lt;/h4&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/im/blob/main/zbim.png?raw=true&#34; alt=&#34;zbim&#34;&gt;&lt;/p&gt;
</description>
      
    </item>
    
    <item>
      <title>policy worker</title>
      <link>https://weedge.github.io/todo/policyworker/</link>
      <pubDate>Wed, 10 Jun 2020 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/todo/policyworker/</guid>
      
        <description>&lt;h4 id=&#34;策略模型&#34;&gt;策略模型&lt;/h4&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4&#34;&gt;&lt;code class=&#34;language-go&#34; data-lang=&#34;go&#34;&gt;&lt;span style=&#34;color:#00a&#34;&gt;package&lt;/span&gt; main

&lt;span style=&#34;color:#00a&#34;&gt;import&lt;/span&gt; (
  &lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;sync/atomic&amp;#34;&lt;/span&gt;
  &lt;span style=&#34;color:#a50&#34;&gt;&amp;#34;time&amp;#34;&lt;/span&gt;
)

&lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#0a0&#34;&gt;loadConfig&lt;/span&gt;() &lt;span style=&#34;color:#00a&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt; {
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 从数据库或者文件系统中读取配置信息，然后以map的形式存放在内存里
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#00a&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;make&lt;/span&gt;(&lt;span style=&#34;color:#00a&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;)
}

&lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#0a0&#34;&gt;requests&lt;/span&gt;() &lt;span style=&#34;color:#00a&#34;&gt;chan&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;int&lt;/span&gt; {
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 将从外界中接受到的请求放入到channel里
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#00a&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;make&lt;/span&gt;(&lt;span style=&#34;color:#00a&#34;&gt;chan&lt;/span&gt; &lt;span style=&#34;color:#0aa&#34;&gt;int&lt;/span&gt;)
}

&lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt; &lt;span style=&#34;color:#0a0&#34;&gt;main&lt;/span&gt;() {
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// config变量用来存放该服务的配置信息
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#00a&#34;&gt;var&lt;/span&gt; config atomic.Value
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 初始化时从别的地方加载配置文件，并存到config变量里
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  config.&lt;span style=&#34;color:#0a0&#34;&gt;Store&lt;/span&gt;(&lt;span style=&#34;color:#0a0&#34;&gt;loadConfig&lt;/span&gt;())
  &lt;span style=&#34;color:#00a&#34;&gt;go&lt;/span&gt; &lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt;() {
    &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 每10秒钟定时的拉取最新的配置信息，并且更新到config变量里
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#00a&#34;&gt;for&lt;/span&gt; {
      time.&lt;span style=&#34;color:#0a0&#34;&gt;Sleep&lt;/span&gt;(&lt;span style=&#34;color:#099&#34;&gt;10&lt;/span&gt; * time.Second)
      &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 对应于赋值操作 config = loadConfig()
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;      config.&lt;span style=&#34;color:#0a0&#34;&gt;Store&lt;/span&gt;(&lt;span style=&#34;color:#0a0&#34;&gt;loadConfig&lt;/span&gt;())
    }
  }()
  &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 创建工作线程，每个工作线程都会根据它所读取到的最新的配置信息来处理请求
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;  &lt;span style=&#34;color:#00a&#34;&gt;for&lt;/span&gt; i := &lt;span style=&#34;color:#099&#34;&gt;0&lt;/span&gt;; i &amp;lt; &lt;span style=&#34;color:#099&#34;&gt;10&lt;/span&gt;; i++ {
    &lt;span style=&#34;color:#00a&#34;&gt;go&lt;/span&gt; &lt;span style=&#34;color:#00a&#34;&gt;func&lt;/span&gt;() {
      &lt;span style=&#34;color:#00a&#34;&gt;for&lt;/span&gt; r := &lt;span style=&#34;color:#00a&#34;&gt;range&lt;/span&gt; &lt;span style=&#34;color:#0a0&#34;&gt;requests&lt;/span&gt;() {
        &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 对应于取值操作 c := config
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;        &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 由于Load()返回的是一个interface{}类型，所以我们要先强制转换一下
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;        c := config.&lt;span style=&#34;color:#0a0&#34;&gt;Load&lt;/span&gt;().(&lt;span style=&#34;color:#00a&#34;&gt;map&lt;/span&gt;[&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;]&lt;span style=&#34;color:#0aa&#34;&gt;string&lt;/span&gt;)
        &lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;// 这里是根据配置信息处理请求的逻辑...
&lt;/span&gt;&lt;span style=&#34;color:#aaa;font-style:italic&#34;&gt;&lt;/span&gt;        _, _ = r, c
      }
    }()
  }
}

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h4 id=&#34;参考&#34;&gt;参考：&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.betacat.io/post/golang-atomic-value-exploration/&#34;&gt;https://blog.betacat.io/post/golang-atomic-value-exploration/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
      
    </item>
    
    <item>
      <title>2019 TODO</title>
      <link>https://weedge.github.io/post/2019todo/</link>
      <pubDate>Sat, 26 Jan 2019 01:16:30 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/2019todo/</guid>
      
        <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt; 2018年感觉过的好快，时间荏苒，有些事和人，感觉在2018变化很大；人都是有欲望的，在欲望的驱使下，去实现自己的目标，其中有失败，有成功，还有一直在路上前行的；每年给自己定的目标要么期望太高，要么随遇而安，到头来给自己的感觉是不太务实，有点好高骛远了和缺乏动力；但是如果没有梦想和目标，和咸鱼有什么分别呢？所以把2019年的新年目标任务写下来，给自己立个flag，实施准则：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;低头看书学习做事，抬头思考总结做人~&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;书&#34;&gt;书&lt;/h2&gt;
&lt;p&gt;现在大部分时间看书都是利用手机，在上班下班的时间，碎片化阅读；双休日和假期的时候，找一个天上午下午来深度阅读；不过感觉后面给书的时间越来越少了，时间的管理是越发的重要。&lt;/p&gt;
&lt;h3 id=&#34;非技术类&#34;&gt;非技术类&lt;/h3&gt;
&lt;p&gt;读书不分先后顺序， 按一年12个月算，暂时定每个月看完一到两本书，这里大部分心理学和经济学方面的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/1012611/&#34;&gt;乌合之众&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/10785583/&#34;&gt;思考，快与慢&lt;/a&gt; (书比较难啃)&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/10785583/&#34;&gt;原则&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/11445548/&#34;&gt;自私的基因&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/30259720/&#34;&gt;今日简史&lt;/a&gt; &lt;a href=&#34;https://book.douban.com/subject/26945094/&#34;&gt;未来简史&lt;/a&gt; &lt;a href=&#34;https://book.douban.com/subject/25985021/&#34;&gt;人类简史&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/30186119/&#34;&gt;硅谷增长黑客实战笔记&lt;/a&gt; (适合ab策略数据分析)&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/27167992/&#34;&gt;见识&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/26704143/&#34;&gt;把时间当作朋友&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/27662713/&#34;&gt;舆论&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/26412113/&#34;&gt;机器人叛乱&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/6811366/&#34;&gt;禅与摩托车维修艺术&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;技术类&#34;&gt;技术类&lt;/h3&gt;
&lt;p&gt;技术类的主要是最近工作可能会用到的，作为参考书籍，具体还需要到工作中实践转化成自己，就如一本武功秘籍，还需要日积月累的修炼，大侠不是一招一式就能混迹江湖的；技术迭代越来越快，学习是一个长期的过期，新技术层出不穷(新技术的学习离不开开源社区github，代码是最好的文档)，但是计算机基础的东西是不变的，技术的迭代都是在原有的基础技术上发展，所以修炼内功心法还是很重要的：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/26337939/&#34;&gt;七周七并发模型&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/26586598/&#34;&gt;性能之巅&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/26586598/&#34;&gt;Linux高性能服务器编程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;input disabled=&#34;&#34; type=&#34;checkbox&#34;&gt; &lt;a href=&#34;https://book.douban.com/subject/10590856/&#34;&gt;统计学习方法&lt;/a&gt; &lt;a href=&#34;https://book.douban.com/subject/26708119/&#34;&gt;机器学习&lt;/a&gt; &lt;a href=&#34;https://book.douban.com/subject/27087503/&#34;&gt;深度学习&lt;/a&gt; (这个学起来有些枯燥，需要网上找点代码case来结合实际应用场景)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;其他语言类的，网络编程类的，数据库操作优化类的数据都可以在越到问题的时候，通过技术专有的关键字可以google/百度一下, 去解决实际越到问题，要比直接看书要印象深刻的多，知其然而知所以然。&lt;/p&gt;
&lt;h2 id=&#34;事&#34;&gt;事&lt;/h2&gt;
&lt;p&gt;2018的事还是比较简单的。&lt;/p&gt;
&lt;p&gt;工作上大部分时间是解决业务需求，偶尔也会写出一些bug, 做事缺乏全面的考虑，有些事情不是自己愿意去做的，有时候缺乏积极性；作为一个在职场混迹六年的人来说，范这些错误，难免会有点尴尬，所以在后面的职场工作中，不管是喜欢和重复厌倦的事情，都要认真负责的去对待，工作是给公司解决问题，不能带着情绪化处理；还有工作上需要协调把控好效率和产出质量。&lt;/p&gt;
&lt;p&gt;感情上通过相亲认识了投缘的另一半，虽然两人外形上可能有些不搭调~，但是最后异地恋走在一起挺不容易的；年底总数把买房子的事情给结尾，装修的事情两人商量着慢慢来，彼此相信会有一个温馨的家🏠&lt;/p&gt;
&lt;p&gt;2019的规划：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;主要是自己工作上有突破，不管是技能还是处理事情&lt;/li&gt;
&lt;li&gt;帮助她找到一份还算满意的工作&lt;/li&gt;
&lt;li&gt;弄完房子准备结婚🎎&lt;/li&gt;
&lt;li&gt;接父母过来玩&lt;/li&gt;
&lt;li&gt;用golang 重构一下小机器人&lt;/li&gt;
&lt;li&gt;完成网关weegate&lt;/li&gt;
&lt;li&gt;more&amp;hellip;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;思&#34;&gt;思&lt;/h2&gt;
&lt;p&gt;年复一年，岁月催人老，30+的程序猿看着00后都已经开始上大学，开始进入社会实习了，突然危机感油然而生，是否就一定会被社会淘汰呢，是否就到了35+岁, 就不能编程了呢，给公司创造的价值就打折了呢？也许这些问题和社会上的鸭梨一直会存在，并激励着资历老猿们去反思，去复盘总结；经验是有的，斗志在，就怕不学习，俗话说的好：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;活到老，学到老，干到老！（为即将或者已成老猿 代言，笔芯~）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;最后&#34;&gt;最后&lt;/h2&gt;
&lt;p&gt;借用我最喜欢的乔布斯语录，作为本文的结尾（虽然有点鸡血的感觉）：&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;人这一辈子没法做太多的事情，所以每一件都要做得精彩绝伦。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;你的时间有限，所以不要为别人而活。不要被教条所限，不要活在别人的观念里。不要让别人的意见左右自己内心的声音。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;最重要的是，勇敢的去追随自己的心灵和直觉，只有自己的心灵和直觉才知道你自己的真实想法，其他一切都是次要。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id=&#34;链接&#34;&gt;链接&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MjM5MDE0Mjc4MA==&amp;amp;mid=2651011968&amp;amp;idx=1&amp;amp;sn=3d500660f7dd47c9fa4033bd9fa69c2f&#34;&gt;解读2018：我们处在一个什么样的技术浪潮当中？&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://www.zhihu.com/question/22937279&#34;&gt;程序员工作只能做到 35 岁吗？&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s?__biz=MzI2MDI5NDQwMg==&amp;amp;mid=2247483959&amp;amp;idx=1&amp;amp;sn=bcb5fb9eb2aca5810d87ad3b63c4612b&amp;amp;chksm=ea6a905add1d194c57468ac88b611b9005290d1d922154a7b6fe9fec3fdd710c27de41282608&amp;amp;mpshare=1&amp;amp;scene=1&amp;amp;srcid=0327cbNpv&#34;&gt;35岁以后的大龄程序员，正处于怎样一种状态?&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>屏蔽macbook内置键盘</title>
      <link>https://weedge.github.io/post/mackeyboard-hhkb/</link>
      <pubDate>Sat, 19 Jan 2019 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/mackeyboard-hhkb/</guid>
      
        <description>&lt;!-- raw HTML omitted --&gt;
&lt;p&gt;  昨天晚上和女友争吵，不小心把水洒在macbook的键盘上了，当时没有及时关机烘干，直接就把本给关上了，导致今天早上起来发现键盘按z左边的shift键失灵，有时候一直重复z键，过了一段时间z键失灵，还有其他几个键也失灵了，网上搜了一下，有可能是排线的原因，找官网修理一下, 估计也得300到1000不等；想想这些维修费用都可以买个键盘了。&lt;/p&gt;
&lt;p&gt;  生日的时候女友给我买了一个有线静容无刻版的hhkb（答应用这个努力赚钱的），当时用了一段时间，无刻版的数字键不是很好按，后面觉得上班每天背着它有点沉，就搁浅了；现在好了，内置键盘已坏，以后就靠这个键盘了，一直用也不换了;&lt;/p&gt;
&lt;p&gt;但是有个问题，把键盘放在macbook的内置键盘上有可能会触发上面的按键， 需要禁用掉内置键盘；网上找了一个挺好用的软件&lt;a href=&#34;https://pqrs.org/osx/karabiner/&#34;&gt;Karabiner&lt;/a&gt;，也可以设置物理键映射，具体操作帮助文档可以见&lt;a href=&#34;https://pqrs.org/osx/karabiner/document.html&#34;&gt;官网文档&lt;/a&gt;；下载安装后，设置如下图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/weedge.github.io/master/image/kar.png&#34; alt=&#34;karabiner&#34;&gt;&lt;/p&gt;</description>
      
    </item>
    
    <item>
      <title>abtest</title>
      <link>https://weedge.github.io/todo/abtest/</link>
      <pubDate>Sat, 23 Dec 2017 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/todo/abtest/</guid>
      
        <description></description>
      
    </item>
    
    <item>
      <title>id生成</title>
      <link>https://weedge.github.io/post/idgen/</link>
      <pubDate>Tue, 12 Dec 2017 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/idgen/</guid>
      
        <description>&lt;h2 id=&#34;背景&#34;&gt;背景&lt;/h2&gt;
&lt;p&gt;  用户业务数据增长过快，比如文章评论系统，feed流系统，订单系统；数据的存放模型需要从主从的单机单库 演变成 分布式集群数据库； 分库分表的数据查询需用到全局唯一标识的id来查询业务，比如莫个feed的评论数据、推送消息、购物订单、活动优惠劵等等都需要进行唯一ID标识；以便分布式存储(mysql,nosql,newsql)索引(b+tree, LSMtree,inverted index)快速查询；至于数据一致性通过约定规范协议保证(强：类Paxos算法/raft算法，弱: mq) 。&lt;/p&gt;
&lt;h2 id=&#34;特征&#34;&gt;特征&lt;/h2&gt;
&lt;p&gt;根据不同的需求场景进行总体归纳全局id生成服务的特征：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;全局唯一：最基本要求，不能出现重复的id；&lt;/li&gt;
&lt;li&gt;趋势递增：业务中如果大量使用mysql innodb来存放数据，而innodb使用聚集索引(cluster index)，使用b+tree来存放索引数据，所以在主键的选择存放上应该尽量使用整数型有序的主键，来保证数据的写入性能(顺序io)&lt;/li&gt;
&lt;li&gt;单调递增：IM增量消息，排序序列号&lt;/li&gt;
&lt;li&gt;可解码：比如统计分析id的生成情况，尽量是服务分布均匀，需要查看业务id(appID),生成时间(time ms), 以及id服务节点号(nodeID)&lt;/li&gt;
&lt;li&gt;信息安全：生成id的规律不能过于简单，比如单调递增，信息详情展示页会有规律的爬取，这样直接可以估算出一些指标数据(天订单量，天feed产生流量等)；所以需要id无规律生成(可以内部获取有规律的id后，进行加盐编码处理)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这些特征有些是互斥的，不能同时满足，需要根据业务场景具体分析(可能有些场景特征还未考虑到，后续加入），选择对应特征方案来满足。&lt;/p&gt;
&lt;p&gt;id生成服务的评价指标：（由于在分布式系统中，id生成服务依赖度非常高，需要高可用和高性能）&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;平均响应时间和所有请求中的千分之999的最低相应时间(TP999)尽可能的低；&lt;/li&gt;
&lt;li&gt;SLA(可用性)5个9(全年低于5分钟的不可用时间)&lt;/li&gt;
&lt;li&gt;QPS(每秒请求量)尽可能的高&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;方案&#34;&gt;方案&lt;/h2&gt;
&lt;h3 id=&#34;uuid&#34;&gt;uuid&lt;/h3&gt;
&lt;p&gt;标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的36个字符，无序，不适合用来做为数据库(B+Tree)中的主键。&lt;/p&gt;
&lt;h3 id=&#34;snowflake&#34;&gt;snowflake&lt;/h3&gt;
&lt;p&gt;twitter中的feed数据从mysql迁移至Cassandra中存放，cassandra没有顺序id生成机制，提出的一种解决方案；不依赖其他组件服务，直接程序算法实现；&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;41位的时间序列（精确到毫秒，41位的长度可以使用69年）&lt;/li&gt;
&lt;li&gt;10位的机器标识（10位的长度最多支持部署1024个节点），根据业务服务类型和部署还可进行细分，比如idc,机器,业务id(appid)&lt;/li&gt;
&lt;li&gt;12位的计数顺序号（12位的计数顺序号支持每个节点每毫秒产生4096个ID序号）&lt;/li&gt;
&lt;li&gt;最高位是符号位，始终为0&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/weedge.github.io/master/image/snowflake-64bit.jpg&#34; alt=&#34;snowflake&#34;&gt;&lt;/p&gt;
&lt;p&gt;64位bigint类型ID, 最大2^63-1  19位10进制数&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;缺点: 多机部署时，必须保证时间是同步的，否则如果存在时间回溯，出现重复id。&lt;/li&gt;
&lt;li&gt;解决方案：可以加上多台机器时间同步检测恢复机制&lt;a href=&#34;https://zh.wikipedia.org/wiki/%E7%B6%B2%E8%B7%AF%E6%99%82%E9%96%93%E5%8D%94%E5%AE%9A&#34;&gt;NTP网络时间协议&lt;/a&gt;，可以尽量避免&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;redis生成id&#34;&gt;redis生成id:&lt;/h3&gt;
&lt;p&gt;利用redis的单线程机制，以及原子递增操作INCR和INCRBY来实现；多台部署：采用按起始值分N台机器数间隔递增(等差数列)，格式：时间戳+单日增长号；(单点故障，由于等差值N机器数是事先定义好的，水平扩容不方便，不便于运维)&lt;/p&gt;
&lt;h3 id=&#34;mysql生成id64位&#34;&gt;mysql生成id(64位):&lt;/h3&gt;
&lt;p&gt;利用mysql的auto_increment自助机制 + replace into table操作(table定义两个字段，一个是64位的主键自增字段，一个是属性唯一字段) +InnoDB/MyISAM引擎 来实现，多台主从部署：采用按起始值分N台机器数间隔递增(等差数列)，需要设置mysql自增参数：set auto_increment_increment=N.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;存在问题：&lt;br&gt;
主跪了，切从，主从数据同步存在延时的话，id会出现重复的情况，以及每次生成id，都要访问一次数据库replace操作，性能会降低很多；&lt;/li&gt;
&lt;li&gt;解决方案：&lt;br&gt;
通过“号段”segment批量获取的方式，从mysql中获取ID,然后扩大倍数M,设定范围[ID*M,(ID+1)*M]，然后从内存中的这个范围里生成一个自增序列号，如果到了范围的最大值，则阻塞其他请求，由最早的线程去db获取id，设定范围，或者在号码到达最大范围的10~75%的时候提前去db获取id，这样就不会阻塞的情况；然后继续以述过程。这个方案有个小缺陷就是服务重启，以往内存中的id范围段就会浪费掉，但是64位还是挺多的，性能提高了，浪费点也就无所谓啦~ 当然如果你是处女座，最求极致可以旁路监控记录已经分配出去的id，启动的时候在捞回来放入内存中继续分配生成id）。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;这个方案比较常用，稳定，依赖mysql，需要与dba配合操作,和redis生成id一样不便于水平扩展，运维维护，改进方案类似于美团的Leaf-segment设计，采用元数据(tag,max_id,step,desc,create_time,update_time)管理，对业务tag进行分库扩容，减低运维维护成本&lt;/p&gt;
&lt;h2 id=&#34;总结&#34;&gt;总结&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;性能上当然snowflake性能最好，全局唯一，趋势递增，可解码，不依赖其他组件，唯一缺陷是时间不同步的问题，如果回退的时间比较大，服务可能就跪了，解决方案：服务启动时就进行校验时间是否与启动的服务节点一致，依赖于zk或者etcd来记录监控各个genId service服务节点的时间信息，验证相同则ok，否则启动失败，报警。应用场景feed流&lt;/li&gt;
&lt;li&gt;稳定上mysql生成id方案比较好，全局唯一，单个mysql实例可以保证单调递增，扩容多实例变成趋势递增(proxy wrr负载均衡w=1)，性能和主从同步延迟导致id重复问题，这些问题可以通过内存中的ID范围段segment来计算生成自增序列id解决。应用场景订单号，消息id&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;参考阅读&#34;&gt;参考阅读&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://mp.weixin.qq.com/s/F7WTNeC3OUr76sZARtqRjw&#34;&gt;分布式架构系统生成全局唯一序列号的一个思路&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://tech.meituan.com/MT_Leaf.html&#34;&gt;美团点评id生成器系统-Leaf&lt;/a&gt;  (HA，性能，便于扩容,通过管理元数据(tag,max_id,step,desc,create_time,update_time)，对业务tag进行分库扩容；通过zk来同步每个启动的Leaf节点时间，新的服务启动是通过时间校验机制来规避时间戳不同步，回拨问题上的监控)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://yuerblog.cc/2017/11/21/golang-id-alloc/&#34;&gt;golang分布式id生成服务&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://thesecretlivesofdata.com/raft/&#34;&gt;raft&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
      
    </item>
    
    <item>
      <title>消息队列</title>
      <link>https://weedge.github.io/todo/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</link>
      <pubDate>Sun, 12 Nov 2017 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/todo/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/</guid>
      
        <description>&lt;h2 id=&#34;消息队列介绍what&#34;&gt;消息队列介绍what&lt;/h2&gt;
&lt;h3 id=&#34;协议&#34;&gt;协议：&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;MQTT&lt;/strong&gt;(Message Queuing Telemetry Transport，消息队列遥测传输，基于二进制消息的发布/订阅编程模式的消息协议):&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;http://docs.emqtt.cn/zh_CN/latest/mqtt.html&#34;&gt;http://docs.emqtt.cn/zh_CN/latest/mqtt.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/20888181&#34;&gt;https://zhuanlan.zhihu.com/p/20888181&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;简单的协议:&lt;a href=&#34;http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html&#34;&gt;http://docs.oasis-open.org/mqtt/mqtt/v3.1.1/os/mqtt-v3.1.1-os.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;由于规范协议很简单，非常适合需要低功耗和网络带宽有限的IoT场景。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;AMQP&lt;/strong&gt;(Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议，是应用层协议的一个开发标准，为面向消息的中间件设计)：&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;XMPP&lt;/strong&gt;(可扩展消息处理现场协议，Extensible Messaging and Presence Protocol）是基于可扩展标记语言的协议，多用于即时消息)：&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;消息队列原理why&#34;&gt;&lt;strong&gt;消息&lt;/strong&gt;队列原理why&lt;/h2&gt;
&lt;h2 id=&#34;消息队列使用场景where&#34;&gt;消息队列使用场景where&lt;/h2&gt;
&lt;h2 id=&#34;如何设计消息队列how&#34;&gt;如何设计消息队列how&lt;/h2&gt;
&lt;h2 id=&#34;开源消息队列&#34;&gt;开源消息队列&lt;/h2&gt;
&lt;h3 id=&#34;kafka&#34;&gt;kafka&lt;/h3&gt;
&lt;h3 id=&#34;nsq&#34;&gt;NSQ&lt;/h3&gt;
&lt;h2 id=&#34;参考&#34;&gt;参考&lt;/h2&gt;
</description>
      
    </item>
    
  </channel>
</rss>

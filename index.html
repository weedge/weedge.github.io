<!DOCTYPE html>
<html lang="zh-cn" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>时间飘过</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="weedge" />
  <meta name="description" content="记录工作和生活" />
  <meta name="keywords" content="工作, 技术, 生活" />






<meta name="generator" content="Hugo 0.91.0" />


<link rel="canonical" href="https://weedge.github.io/" />
<link href="/index.xml" rel="alternate" type="application/rss+xml" title="时间飘过" />




<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css" integrity="sha256-&#43;ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media="screen" crossorigin="anonymous">




<link rel="stylesheet" href="/css/copy-to-clipboard.css">


<meta property="og:title" content="时间飘过" />
<meta property="og:description" content="记录工作和生活" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://weedge.github.io/" />

<meta itemprop="name" content="时间飘过">
<meta itemprop="description" content="记录工作和生活"><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="时间飘过"/>
<meta name="twitter:description" content="记录工作和生活"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->







</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">时间飘过</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/tags/">标签</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/categories/">分类</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/about/">About</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/perf-book-cn/zh/" rel="noopener" target="_blank">
              《现代CPU性能分析与优化》
              
              <i class="iconfont">
                <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92 0 0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"></path>
  <path d="M841.152 457.152c-30.528 0-54.784 24.512-54.784 54.656l0 274.752L237.696 786.56 237.696 237.696l206.016 0c6.656 0 10.752 0 13.248 0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128L183.04 128C153.216 128 128 152.576 128 182.848c0 3.136 0.256 6.272 0.768 9.28C128.256 195.136 128 198.272 128 201.408l0 639.488c0 0.064 0 0.192 0 0.256 0 0.128 0 0.192 0 0.32 0 30.528 24.512 54.784 54.784 54.784l646.976 0c6.592 0 9.728 0 11.712 0 28.736 0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344l0-20.352L896 561.408 896 512.128C896 481.792 871.424 457.152 841.152 457.152z"></path>
</svg>

              </i>
            </a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.us.kg/" rel="noopener" target="_blank">
              Podcast AI
              
              <i class="iconfont">
                <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92 0 0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"></path>
  <path d="M841.152 457.152c-30.528 0-54.784 24.512-54.784 54.656l0 274.752L237.696 786.56 237.696 237.696l206.016 0c6.656 0 10.752 0 13.248 0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128L183.04 128C153.216 128 128 152.576 128 182.848c0 3.136 0.256 6.272 0.768 9.28C128.256 195.136 128 198.272 128 201.408l0 639.488c0 0.064 0 0.192 0 0.256 0 0.128 0 0.192 0 0.32 0 30.528 24.512 54.784 54.784 54.784l646.976 0c6.592 0 9.728 0 11.712 0 28.736 0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344l0-20.352L896 561.408 896 512.128C896 481.792 871.424 457.152 841.152 457.152z"></path>
</svg>

              </i>
            </a>
          
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/" class="logo">
    
      时间飘过
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/tags/">标签</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/categories/">分类</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/about/">About</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/perf-book-cn/zh/" rel="noopener" target="_blank">
              《现代CPU性能分析与优化》
              
              <i class="iconfont">
                <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92 0 0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"></path>
  <path d="M841.152 457.152c-30.528 0-54.784 24.512-54.784 54.656l0 274.752L237.696 786.56 237.696 237.696l206.016 0c6.656 0 10.752 0 13.248 0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128L183.04 128C153.216 128 128 152.576 128 182.848c0 3.136 0.256 6.272 0.768 9.28C128.256 195.136 128 198.272 128 201.408l0 639.488c0 0.064 0 0.192 0 0.256 0 0.128 0 0.192 0 0.32 0 30.528 24.512 54.784 54.784 54.784l646.976 0c6.592 0 9.728 0 11.712 0 28.736 0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344l0-20.352L896 561.408 896 512.128C896 481.792 871.424 457.152 841.152 457.152z"></path>
</svg>

              </i>
            </a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.us.kg/" rel="noopener" target="_blank">
              Podcast AI
              
              <i class="iconfont">
                <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92 0 0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"></path>
  <path d="M841.152 457.152c-30.528 0-54.784 24.512-54.784 54.656l0 274.752L237.696 786.56 237.696 237.696l206.016 0c6.656 0 10.752 0 13.248 0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128L183.04 128C153.216 128 128 152.576 128 182.848c0 3.136 0.256 6.272 0.768 9.28C128.256 195.136 128 198.272 128 201.408l0 639.488c0 0.064 0 0.192 0 0.256 0 0.128 0 0.192 0 0.32 0 30.528 24.512 54.784 54.784 54.784l646.976 0c6.592 0 9.728 0 11.712 0 28.736 0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344l0-20.352L896 561.408 896 512.128C896 481.792 871.424 457.152 841.152 457.152z"></path>
</svg>

              </i>
            </a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          
<section id="posts" class="posts">
  
  
    
  
  
  
    <article class="post bg-white">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/post/multimoding/voices/cosyvoice/">论文解读：CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</a>
    </h1>
    
    <div class="post-meta">
      <time datetime="2025-01-15" class="post-time">
        2025-01-15
      </time>
      <div class="post-category">
          <a href="https://weedge.github.io/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
          <a href="https://weedge.github.io/categories/tts/"> TTS </a>
          
        </div>
      
      
      
    </div>
  </header>
  
  <div class="post-content">
    
    <div class="post-summary">
      <h2 id="cosyvoice">CosyVoice</h2>
<ul>
<li><a href="https://arxiv.org/abs/2407.04051">2024.7 FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs</a> （主要介绍ASR SenseVoice 和 TTS CosyVoice,其中 SenseVoice 没有单独论文，相关CosyVoice 和单独论文是重复的, SenseVoice Large的工作可以用于 CosyVoice 在多语言上， Supervised speech tokenizer 模块的训练和推理）</li>
<li><a href="https://arxiv.org/abs/2407.05407">2024.7 <strong>CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</strong></a></li>
<li><a href="https://arxiv.org/abs/2412.10117">2024.12 CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models</a> （流式合成）</li>
<li><a href="https://github.com/FunAudioLLM/CosyVoice">paper code</a>: 没有pre-trainning过程；公开推理和权重，以及微调。</li>
</ul>
<p>创新点：</p>
<ul>
<li>将监督语音token集成到TTS 模型，增强了零样本语音克隆中的内容一致性和说话者相似性。</li>
<li>一种可扩展的零样本 TTS 合成系统，它将用于文本到token生成的 LLM 与用于token到语音合成的条件流匹配模型(conditional flow matching model(CFM))相结合，不依赖于音素持续时间预测(Duration predictor)，不需要使用补充音素器(phonemizers)和强制对齐器aligners (比如：Glow-TTS中 Monotonic Alignment Search(MAS))。</li>
<li>为了进一步细化生成语音的质量，将 x-vector 合并到 LLM 中，将语音建模分为语义、说话者和韵律(semantic, speaker, and prosody)组件。 LLM 对语义(semantic)内容和韵律(prosody)进行建模，而条件流匹配模型(CFM)则捕获音色(timbre)和环境信息。我们使用<strong>Classifier-Free Guidance</strong>(<a href="https://arxiv.org/abs/2207.12598">2022. <strong>Classifier-free diffusion guidance</strong></a>)、余弦调度器(<a href="https://d2l.ai/chapter_optimization/lr-scheduler.html#cosine-scheduler">cosine scheduler</a>)和屏蔽条件(masked conditions)等技术来优化流匹配过程。</li>
</ul>
<p><img src="https://github.com/user-attachments/assets/3e8c1132-e146-4b73-8d0c-f3972bf7c8bd" alt=""></p>
<p>CosyVoice由四个组件组成，即文本编码器(text encoder)、语音分词器(speech tokenizer)、大语言模型(large language model)和条件流匹配模型(conditional flow matching model)</p>
<ul>
<li>文本编码器(text encoder)用于对齐文本和语音token的语义空间;</li>
<li>语音标记器(speech tokenizer)用于提取语义token;</li>
<li>LLM(GLM)学习文本编码和语音标记的整个序列，将 TTS 重新表述为以文本作为提示的自回归序列生成问题;</li>
<li>利用条件流匹配模型(conditional flow matching model), 通过最优路径上的去噪处理,将语音标记转换为梅尔谱图(Mel spectrogram); 通过<strong>Classifier-Free Guidance</strong>（Classifier-free diffusion guidance CFG）提高扩散概率模型的生成质量, 将CFG适应到条件流匹配模型中;</li>
<li>获得人类耳朵可感知的声音信号，声码器(vocoder)使用 Hifi-GAN Generator 用于将生成的梅尔频谱图作为输入来合成波形(waveform)。</li>
</ul>
<p>其中：</p>
<ul>
<li>conditional flow matching model (OT-CFM) 来自 <a href="https://arxiv.org/abs/2309.03199">2023.9 <strong>Matcha-TTS: A fast TTS architecture with conditional flow matching</strong></a>(CFM的改进版本OT-CFM)</li>
<li>Classifier-free diffusion guidance (CFG) 来自 <a href="https://arxiv.org/abs/2207.12598">2022. <strong>Classifier-free diffusion guidance</strong></a></li>
<li>vocoder 来自 <a href="https://arxiv.org/abs/2010.05646">2020. <strong>HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</strong></a> Generator。</li>
</ul>
<p>附：</p>
<ul>
<li>achatbot 接入 CosyVoice:
<ul>
<li><a href="https://github.com/ai-bot-pro/achatbot/pull/21">https://github.com/ai-bot-pro/achatbot/pull/21</a></li>
<li><a href="https://github.com/ai-bot-pro/achatbot/pull/23">https://github.com/ai-bot-pro/achatbot/pull/23</a></li>
</ul>
</li>
</ul>
    </div>
    <div class="read-more">
      <a href="/post/multimoding/voices/cosyvoice/" class="read-more-link">阅读全文</a>
    </div>
    
  </div>
</article>

  
    <article class="post bg-white">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/post/multimoding/voices/matcha-tts/">论文解读 Matcha-TTS: A fast TTS architecture with conditional flow matching</a>
    </h1>
    
    <div class="post-meta">
      <time datetime="2025-01-14" class="post-time">
        2025-01-14
      </time>
      <div class="post-category">
          <a href="https://weedge.github.io/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
          <a href="https://weedge.github.io/categories/tts/"> TTS </a>
          
        </div>
      
      
      
    </div>
  </header>
  
  <div class="post-content">
    
    <div class="post-summary">
      <h1 id="-matcha-tts">🍵 matcha-tts</h1>
<ul>
<li><a href="https://arxiv.org/abs/2309.03199">2023.9 <strong>Matcha-TTS: A fast TTS architecture with conditional flow matching</strong></a> | <a href="https://github.com/shivammehta25/Matcha-TTS">paper code</a></li>
</ul>
<h1 id="摘要">摘要：</h1>
<p>一种用于快速 TTS 声学建模的新编码器-解码器架构，使用最佳传输条件流匹配 (OT-CFM) 进行训练。与使用分数匹配训练的模型相比，这产生了基于 ODE 的解码器，能够以更少的合成步骤实现高输出质量。仔细的设计选择还确保每个合成步骤都能快速运行。该方法是概率性的、非自回归的，并且无需外部对齐即可从头开始学习说话。与强大的预训练基线模型相比，Matcha-TTS 系统具有最小的内存占用，可以与长语音上最快的模型相媲美，并在听力测试中获得最高的平均意见得分。</p>
<p>一种非自回归神经 TTS 的新方法，它使用条件流匹配(CFM from <a href="https://arxiv.org/abs/2210.02747">2022.10 <strong>Flow Matching for Generative Modeling</strong></a>)（类似于校正流(Rectified Flow <a href="https://arxiv.org/abs/2209.03003">2022.9 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow</a>）来加速基于 ODE 的语音合成。</p>
<ul>
<li>Is probabilistic  是概率性的</li>
<li>Has compact memory footprint 具有紧凑的内存占用</li>
<li>Sounds highly natural  听起来非常自然</li>
<li>Is very fast to synthesise from 合成速度非常快</li>
</ul>
<p>简洁的结构，训练推理快，使用更少额内存空间，</p>
<p>一种基于连续归一化流的概率性、非自回归、快速采样的 TTS 声学模型。主要有两个创新点：</p>
<ol>
<li>提出了一种改进的编码器-解码器 TTS 结构，该结构在解码器中结合使用 1D CNN 和 Transformer。这减少了内存消耗并且可以快速评估，从而提高综合速度。</li>
<li>使用最优传输条件流匹配 optimal-transport conditional flow matching(OT-CFM) 来训练这些模型，这是一种学习从数据分布中采样的 ODE 的新方法。与传统的 连续时间归一化流 CNF（continuous-time normalising flows ） 和分数匹配概率流 ODE （probability flow ODE） 相比，OT-CFM 定义了从源到目标的更简单的路径，从而能够以比 DPM（Diffusion probabilistic model） 更少的步骤进行准确合成。</li>
</ol>
<p>实验结果表明，这两种创新都加速了合成，减少了速度和合成质量之间的权衡。尽管速度快且轻量级，Matcha-TTS能够在不需要外部对齐器的情况下学习说话和对齐。与强大的预训练基线模型相比，Matcha-TTS实现了快速合成，并获得了更好的自然度评分。</p>
<hr>
<p><strong>附</strong>：</p>
<ul>
<li>
<p>使用LJ Speech数据集训练202 epochs, 在1xGPU 上训练了 79,372 step 的ckpt(论文中是2x3080GPU 50K step)：</p>
<p><a href="https://huggingface.co/weege007/matchaTTS/tree/main">https://huggingface.co/weege007/matchaTTS/tree/main</a></p>
</li>
<li>
<p>笔记地址： <a href="https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb">https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb</a></p>
<p><img src="https://github.com/user-attachments/assets/95bccbf2-b164-484f-a6c9-8ab7e235c018" alt="loss"></p>
</li>
</ul>
    </div>
    <div class="read-more">
      <a href="/post/multimoding/voices/matcha-tts/" class="read-more-link">阅读全文</a>
    </div>
    
  </div>
</article>

  
    <article class="post bg-white">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/post/multimoding/voices/vall-e-x/">论文解读： VALL-E 系列</a>
    </h1>
    
    <div class="post-meta">
      <time datetime="2025-01-13" class="post-time">
        2025-01-13
      </time>
      <div class="post-category">
          <a href="https://weedge.github.io/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
          <a href="https://weedge.github.io/categories/tts/"> TTS </a>
          
        </div>
      
      
      
    </div>
  </header>
  
  <div class="post-content">
    
    <div class="post-summary">
      <p>前文讲到VITS，采用的端到端的NAR模型，这篇文章记录下微软提出的VALL-E系列，从 AR+NAR 到 AR 模型的转变，以及后面MELLE引入的VAE和Mel-Spectorgram，将neural codec text speech LM (AR+NAR Transformer Decoder) 转变为  autoregressive  mel-spectrogram text speech LM  (AR Transformer Decoder) ；由于LM生成的是mel-spectrogram 需要通过vocoder 转换成 waveform； 生成的内容采样模块：从top-p random sampling 变成 Latent Sampling潜在采样模块（思想源自VAE, 从预测的高斯分布中采样潜在嵌入，然后将其投影回频谱图空间）</p>
<h2 id="vall-e-系列">VALL-E 系列</h2>
<p><a href="https://www.microsoft.com/en-us/research/project/vall-e-x/">https://www.microsoft.com/en-us/research/project/vall-e-x/</a></p>
<p>Vall-E: <a href="https://ar5iv.labs.arxiv.org/html/2301.02111">https://ar5iv.labs.arxiv.org/html/2301.02111</a></p>
<p>具体来说，我们使用从现成的神经音频编解码器模型派生的离散代码来训练<em><strong>神经编解码器语言模型（neural codec language model）</strong></em>（称为VALL-E ），并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 在预训练阶段，我们将 TTS 训练数据扩展到 60K 小时的英语语音，比现有系统大数百倍。 VALL-E具有情境学习功能，可用于合成高质量的个性化语音，只需对看不见的说话者进行 3 秒的注册录音作为声音提示。实验结果表明， VALL-E在语音自然度和说话人相似度方面显着优于最先进的零样本 TTS 系统。此外，我们发现VALL-E可以在合成时保留说话者的情感和声音提示的声学环境。</p>
<p>与之前的管道不同（例如，音素 → 梅尔谱图 → 波形）， VALL-E的管线是音素 → 离散码 → 波形。</p>
<p>VALL-E根据音素和声学代码提示生成与目标内容和说话者的声音相对应的离散音频编解码器代码。 VALL-E直接支持各种语音合成应用，例如零样本 TTS、语音编辑以及与 GPT-3 等其他生成式 AI 模型相结合的内容创建。</p>
<p>VALL-E系列：2023年的1月份开始 - 2024年的7月份</p>
<ul>
<li>VALL-E 使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型，并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 VALL-E 具有情境学习功能，可用于合成高质量的个性化语音，只需录制未见过的讲话者的 3 秒注册录音作为提示。在语音自然度和说话人相似度方面，VALL-E 显着优于最先进的零样本 TTS 系统。此外，VALL-E可以在合成时保留说话者的情绪和声音提示的声学环境。</li>
<li>VALL-E X 扩展其能力，适应多语言场景，促进跨语言零样本 TTS。</li>
<li>VALL-E R 引入了音素单调对齐策略，增强了语音生成的鲁棒性。</li>
<li>VALL-E 2 通过集成重复感知采样和分组代码建模技术， 实现了一个突破性的里程碑：在 LibriSpeech 和 VCTK 数据集上的零样本 TTS 性能与人类相当。这标志着此类成就的首次实例，为该领域树立了新标准。</li>
<li>MELLE 是一种新颖的基于连续值标记的语言建模方法，用于文本到语音合成 (TTS)。 MELLE 直接从文本条件自回归生成连续的梅尔频谱图帧，绕过了矢量量化的需要，矢量量化最初是为音频压缩而设计的，与梅尔频谱图相比，牺牲了保真度。</li>
</ul>
    </div>
    <div class="read-more">
      <a href="/post/multimoding/voices/vall-e-x/" class="read-more-link">阅读全文</a>
    </div>
    
  </div>
</article>

  
    <article class="post bg-white">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/post/multimoding/voices/vits/">论文解读 VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</a>
    </h1>
    
    <div class="post-meta">
      <time datetime="2025-01-11" class="post-time">
        2025-01-11
      </time>
      <div class="post-category">
          <a href="https://weedge.github.io/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
          <a href="https://weedge.github.io/categories/tts/"> TTS </a>
          
        </div>
      
      
      
    </div>
  </header>
  
  <div class="post-content">
    
    <div class="post-summary">
      <p>前文讲到OpenVoicev2，补充下细节，然后梳理使用的基础模型VITS：</p>
<blockquote>
<p>📓</p>
<p>melo-tts 生成原始音频：</p>
<ul>
<li>OpenVoice 版本1不依赖melo-tts, 升级后的V2版本依赖melo-tts, 主要是生成原始音频质量加强了(由melo-tts生成);</li>
<li>默认配置使用了TransformerCouplingBlock list作为flow 和 reverse flow, 而第一版的OpenVoice 模型使用的 ResidualCouplingBlock ;</li>
<li>melo-tts的模型权重支持多语言，更具语言区分，比如 ZH: <a href="https://huggingface.co/myshell-ai/MeloTTS-Chinese">myshell-ai/MeloTTS-Chinese</a>, EN_NEWEST: <a href="https://huggingface.co/myshell-ai/MeloTTS-English-v3">myshell-ai/MeloTTS-English-v3</a>;</li>
</ul>
<p>音色转换生成目标音频：</p>
<ul>
<li>通过训练好的<strong>音色抽取器</strong>抽取目标说话者的音色 (<a href="https://huggingface.co/myshell-ai/OpenVoiceV2/tree/main/base_speakers/ses">myshell-ai/OpenVoiceV2/converter</a>)；</li>
<li>生成的原始音频信息通过 训练抽取好的基础说话者的音色(<a href="https://huggingface.co/myshell-ai/OpenVoiceV2/tree/main/converter">myshell-ai/OpenVoiceV2/base_speakers/ses</a>)，将原始音频中的音色去除 （flow）；</li>
<li>将去除原始音色的音频 和 抽取好的目标说话者的音色 合并 （reverse flow）； 最终通过 vocoder(也是论文中的Decoder,使用的 HiFi-Gan模型)合成目标音频。</li>
</ul>
<p>额外注意的是，由melo-tts生成原始音频sample rate是 44100， 而通过音色提取器 提取 并且 生成目标音频sample rate是 22050</p>
</blockquote>
<p>前提知识这里简单概括如下：</p>
<p>AE(Autoencoder): 自编码器是<a href="https://www.ibm.com/cn-zh/topics/self-supervised-learning">自监督</a>系统，其训练目标是通过降维来压缩（或<em>编码</em>）输入数据，然后使用该压缩后的表示准确重建（或<em>解码</em>）其原始输入。无泛化生成能力，但是可以执行特定任务：常用于数据压缩、图像去噪、异常检测和面部识别等任务。</p>
<p><strong>VAE(Variational Autoencoder)</strong> :与其他自编码器(Autoencoder(AE)的区别在于它们对潜在空间进行编码的独特方式，以及可以应用其概率编码的不同用例，即随机生成训练数据的变体。具有泛化生成能力。</p>
<p><strong>CVAE(Conditional Variational Autoencoder)</strong>: 条件变分自编码器 可以以特定输入为条件进行输出，而不仅仅是随机生成训练数据的变体。这是通过将监督学习（或半监督学习）的元素与常规自编码器的传统无监督训练目标相结合来实现的。具有指定特征的泛化能力。</p>
<ul>
<li>
<p>VAE 与 GAN的区别：</p>
<p>VAE 经常与生成式对抗网络 (GAN) 进行比较，GAN 是另一种模型架构，用于生成类似于训练数据的样本，尤其是图像。</p>
<p>与 VAE 类似，GAN 是结合两种神经网络的联合架构：一个生成器网络，负责输出与训练数据集中的图像相似的图像样本，另一个判别器网络，负责确定特定图像是训练数据中的“真实”图像还是来自生成器网络的“虚假”图像。</p>
<p>这两个网络在零和博弈中进行对抗性训练：来自判别器的反馈用于改进生成器的输出，直到判别器不再能够区分真假样本。</p>
<p>就图像合成而言，两者各有优劣：</p>
<ul>
<li>GAN 可以生成更清晰的图像，但由于两种复合模型之间的对抗性权衡，在训练中并不稳定。</li>
<li>VAE 更容易训练，但由于其根据训练数据的“平均”特征生成图像的性质，往往会生成比较模糊的图像。</li>
</ul>
</li>
<li>
<p>VAE-GAN 两者结合
顾名思义，VAE-GAN 是变分自编码器 (VAE) 和生成式对抗网络 (GAN) 的混合体。通过用判别器网络替换 VAE 模型的重建损失项，来降低 VAE 生成图像的模糊性，提高生成质量。</p>
</li>
</ul>
<p>VITS 使用了 条件变分自编码器 (Conditional Variational Autoencoder (CVAE)) 和生成式对抗网络 (<a href="https://en.wikipedia.org/wiki/Generative_adversarial_network">Generative adversarial network</a>(GAN)) 两个模型架构。 至于VAE和GAN的细节可以关注下baby-llm这个学习项目中的对应模块PR学习资料:</p>
<ul>
<li>VAE: <a href="https://github.com/ai-bot-pro/baby-llm/tree/main/modules/VAE">https://github.com/ai-bot-pro/baby-llm/tree/main/modules/VAE</a> | PR:  <a href="https://github.com/ai-bot-pro/baby-llm/pull/13">https://github.com/ai-bot-pro/baby-llm/pull/13</a></li>
<li>GAN: <a href="https://github.com/ai-bot-pro/baby-llm/tree/main/modules/GAN">https://github.com/ai-bot-pro/baby-llm/tree/main/modules/GAN</a> | PR: <a href="https://github.com/ai-bot-pro/baby-llm/pull/12">https://github.com/ai-bot-pro/baby-llm/pull/12</a></li>
</ul>
<p>这篇文章是讲解VITS，是现在工业上TTS常用的基础方案(NAR模型，成本相对AR模型低， 推理快，生成质量尽可能追平或超越SOTA AR模型)。作者来自韩国现代汽车公司的 AIR 实验室（人工智能研究实验室），论文结合了以前的研究成果：</p>
<ul>
<li><a href="https://arxiv.org/abs/1811.02155">2018. <strong>FloWaveNet : A Generative Flow for Raw Audio</strong></a></li>
<li><a href="https://arxiv.org/abs/2005.11129">2020. <strong>Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search</strong></a></li>
<li><a href="https://arxiv.org/abs/2010.05646">2020. <strong>HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis</strong></a></li>
</ul>
<p>后续作者还研究了加入扩散模型来生成语音，不需要使用分类器指导的目标说话者的任何转录。</p>
<ul>
<li><a href="https://arxiv.org/abs/2111.11755">2022. Guided-TTS: A Diffusion Model for Text-to-Speech via Classifier Guidance</a></li>
</ul>
<p>Guided-TTS 将无条件扩散概率模型(unconditional Diffusion Model)与单独训练的音素分类器(phoneme classifier )相结合，用于分类器指导。无条件扩散模型学习在没有任何上下文的情况下从未转录的语音数据中生成语音。对于 TTS 合成，使用在大规模语音识别数据集上训练的音素分类器来指导扩散模型的生成过程。</p>
<h1 id="vits">VITS</h1>
<ul>
<li><a href="https://arxiv.org/abs/2106.06103">2021. <strong>Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</strong></a>  | <a href="https://github.com/jaywalnut310/vits">paper coder</a></li>
</ul>
<p>主要贡献：</p>
<ul>
<li>提出了一种并行的端到端 TTS 方法，它可以生成比当前两阶段模型更自然的音频；</li>
<li>采用通过归一化流程和对抗性训练过程增强的变分推理，提高了生成模型的表达能力；</li>
<li>一个随机持续时间预测器（stochastic duration predictor）来从输入文本中合成具有不同节奏的语音；</li>
<li>通过对潜在变量的不确定性建模和随机持续时间预测器，表达了自然的一对多关系，其中文本输入可以以不同的音调（pitches）和节奏（rhythms）以多种方式说出。</li>
</ul>
<p>通过利用条件变分自编码器 CVAE，模型特点：</p>
<ol>
<li>学习直接从文本合成原始波形，而不需要额外的输入条件；</li>
<li>使用动态编程方法 MAS 来搜索最佳对齐方式，而不是与计算损失相比,不需要任何外部对齐器；</li>
<li>并行生成样本；</li>
<li>高效的端到端训练方法, 并且生成质量优于最好的公开可用的两阶段模型。附两阶段的数据处理过程(在后续的研究论文中称之为级联方法(cascaded)，见<a href="https://www.microsoft.com/en-us/research/project/vall-e-x/">VALL-E</a>系列论文研究)：
<ul>
<li>第一阶段是从预处理的文本中生成中间语音表示，例如梅尔谱图(mel-spectrograms)或语言特征(linguistic features)</li>
<li>第二阶段是生成以中间表示为条件的原始波形。</li>
<li>两阶段的相关模型大都是独立开发的。</li>
</ul>
</li>
</ol>
<p>结构：</p>
<p><img src="https://github.com/user-attachments/assets/3ddec975-a9fd-460c-91fa-894b8ebd8c8c" alt="VITS"></p>
<p>PS： <a href="https://github.com/ai-bot-pro/achatbot">achatbot</a> 集成了OpenVoiceV2 with meloTTS(meloTTS代码大部分来自VITS，Flow 采用 Transformer Encoder 结构来自 <a href="https://arxiv.org/abs/2307.16430">VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design</a> | <a href="https://github.com/daniilrobnikov/vits2">paper code</a></p>
<p>PR地址： <a href="https://github.com/ai-bot-pro/achatbot/pull/103">https://github.com/ai-bot-pro/achatbot/pull/103</a></p>
    </div>
    <div class="read-more">
      <a href="/post/multimoding/voices/vits/" class="read-more-link">阅读全文</a>
    </div>
    
  </div>
</article>

  
    <article class="post bg-white">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/post/multimoding/voices/open_voice_extra_se_and_convert/">论文解读 OpenVoice: Versatile Instant Voice Cloning</a>
    </h1>
    
    <div class="post-meta">
      <time datetime="2024-05-11" class="post-time">
        2024-05-11
      </time>
      <div class="post-category">
          <a href="https://weedge.github.io/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
          <a href="https://weedge.github.io/categories/tts/"> TTS </a>
          
        </div>
      
      
      
    </div>
  </header>
  
  <div class="post-content">
    
    <div class="post-summary">
      <p>使用meloTTS 本文生成的音频</p>



<figure >
  <audio controls class="player" preload="">
    <source src="https://media.githubusercontent.com/media/weedge/paper-speaker/main/multimoding/voices/open_voice_inference/zh-tts.wav" type="audio/mpeg">
  </audio>
  
  
</figure>

<p>使用openVoice clone 自己的声音 阅读本文内容 


<figure >
  <audio controls class="player" preload="">
    <source src="https://media.githubusercontent.com/media/weedge/paper-speaker/main/multimoding/voices/open_voice_inference/clone-me-zh-tts.wav" type="audio/mpeg">
  </audio>
  
  
</figure>
</p>
<blockquote>
<p>文件直接上传在github中, 暂未走cdn, 缓存比较慢，可下载播放， 下载地址： <a href="http://github.com/weedge/paper-speaker/tree/main/multimoding/voices/open_voice_inference">http://github.com/weedge/paper-speaker/tree/main/multimoding/voices/open_voice_inference</a></p>
</blockquote>
<hr>
<p>openVoiceV2 tone color clone: base TTS + extra tone color + convert</p>
<p>Base TTS: use meloTTS , 支持TTS模型训练，以及load Pre-Trained ckpt 进行TTS,  在 <a href="https://github.com/jaywalnut310/vits">VITS</a>基础上支持多种语言；</p>
<p>论文地址：<a href="https://arxiv.org/abs/2312.01479">OpenVoice: Versatile Instant Voice Cloning</a></p>
<p>论文主作者：Zengyi Qin (同时是JetMoE的作者，站在巨人的肩膀上创新)</p>
<p>公开的权重：</p>
<ul>
<li>OpenVoice: <a href="https://huggingface.co/myshell-ai/OpenVoice">https://huggingface.co/myshell-ai/OpenVoice</a></li>
<li>OpenVoiceV2: <a href="https://huggingface.co/myshell-ai/OpenVoiceV2">https://huggingface.co/myshell-ai/OpenVoiceV2</a></li>
</ul>
<p>源码：</p>
<ul>
<li><a href="https://github.com/myshell-ai/OpenVoice">https://github.com/myshell-ai/OpenVoice</a></li>
<li><a href="https://github.com/myshell-ai/MeloTTS">https://github.com/myshell-ai/MeloTTS</a></li>
</ul>
<p>训练： MSML dataset 和 训练过程 未公开</p>
<p><strong>附操作笔记</strong>： <a href="https://github.com/weedge/doraemon-nb/blob/main/myshell_ai_OpenVoiceV2.ipynb">https://github.com/weedge/doraemon-nb/blob/main/myshell_ai_OpenVoiceV2.ipynb</a></p>
    </div>
    <div class="read-more">
      <a href="/post/multimoding/voices/open_voice_extra_se_and_convert/" class="read-more-link">阅读全文</a>
    </div>
    
  </div>
</article>

  
    <article class="post bg-white">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/post/paper/transformer/delight/">论文解读 DeLighT: Very Deep and Light-weight Transformers</a>
    </h1>
    
    <div class="post-meta">
      <time datetime="2024-04-28" class="post-time">
        2024-04-28
      </time>
      <div class="post-category">
          <a href="https://weedge.github.io/categories/%E5%AD%A6%E6%9C%AF/"> 学术 </a>
          <a href="https://weedge.github.io/categories/paper/"> paper </a>
          
        </div>
      
      
      
    </div>
  </header>
  
  <div class="post-content">
    
    <div class="post-summary">
      <p>在看apple 最近发布的OpenELM 模型，其论文中提到 block-wise scaling 模型结构优化方法，（论文见： <a href="https://machinelearning.apple.com/research/openelm"><strong>OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework</strong></a>），这里记录下DeLighT论文中的 block-wise scaling，翻译整理下以便对照代码实现，了解背景和原理。DeLighT论文中的实验任务主要是在两个标准的序列建模任务上评估了DeLighT的性能：机器翻译（machine translation）任务 encoder-decoder architecture 和 语言建模（ language modeling）decoder architecture，论文中机器翻译任务未对En-Zh(英文译中文)进行实验，可以作为一个复现练习，根据源码实操一下论文中的实验；而语言建模可以作为openELM的来源延伸~ 结合cornet进行复现(也有mxl示例，mxl针对Apple Silicon 硬件进行的优化深度学习框架)。</p>
<p>论文主作者：<a href="https://sacmehta.github.io/">Sachin Mehta </a></p>
<p>论文地址：https://arxiv.org/pdf/2008.00623</p>
<p>论文代码： <a href="https://github.com/sacmehta/delight">https://github.com/sacmehta/delight</a> （基于当时facebook的 <a href="https://github.com/facebookresearch/fairseq">fairseq</a> seq2seq工具库开发）</p>
<p>该论文研究是在作者以前的DeFINE: DEep Factorized INput Token Embeddings for Neural Sequence Modeling 进行改进，模型结构引入更多的GLTs，来学习更宽的权重，并且减少了参数数量。</p>
<h2 id="摘要"><strong>摘要</strong></h2>
<p>我们介绍了一种深度且轻量级的Transformer，名为DeLighT，它在参数数量显著减少的情况下，提供了与标准基于Transformer的模型相似或更好的性能。DeLighT更有效地在每个Transformer块内部（通过DeLighT变换）以及跨块（通过块级缩放）分配参数，允许输入端使用较浅较窄的DeLighT块，输出端使用较宽较深的DeLighT块。总体而言，DeLighT网络比标准Transformer模型深2.5到4倍，但参数和运算量更少。在基准机器翻译和语言建模任务上的实验表明，DeLighT在平均参数数量减少2到3倍的情况下，达到或提高了基线Transformer的性能。</p>
    </div>
    <div class="read-more">
      <a href="/post/paper/transformer/delight/" class="read-more-link">阅读全文</a>
    </div>
    
  </div>
</article>

  
    <article class="post bg-white">
  <header class="post-header">
    <h1 class="post-title">
      
      <a class="post-link" href="/post/paper/transformer/infini_attention/">解读论文：Leave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</a>
    </h1>
    
    <div class="post-meta">
      <time datetime="2024-04-12" class="post-time">
        2024-04-12
      </time>
      <div class="post-category">
          <a href="https://weedge.github.io/categories/%E5%AD%A6%E6%9C%AF/"> 学术 </a>
          <a href="https://weedge.github.io/categories/paper/"> paper </a>
          
        </div>
      
      
      
    </div>
  </header>
  
  <div class="post-content">
    
    <div class="post-summary">
      <p><img src="https://aiptcomics.com/ezoimgfmt/i0.wp.com/aiptcomics.com/wp-content/uploads/2024/04/transformers-7.jpg?w=1500&amp;ssl=1&amp;ezimgfmt=ngcb4/notWebP" alt=""></p>
<p>图片来源： <a href="https://aiptcomics.com/2024/04/10/transformers-7-2024-review/">https://aiptcomics.com/2024/04/10/transformers-7-2024-review/</a></p>
<p><strong>摘要</strong>： 本文介绍了一种有效的方法，将基于Transformer的大型语言模型（LLMs）扩展到无限长的输入，同时受到内存和计算的限制。我们提出的方法的关键组成部分是一种新的注意力技术，称为Infini-attention。Infini-attention将一种压缩内存集成到了传统的注意力机制中，并在单个Transformer块中构建了掩码局部注意力和长期线性注意力机制。我们通过在长上下文语言建模基准、1M序列长度的口令(keypass)上下文块检索和500K长度的书籍摘要任务中使用1B和8B LLMs，展示了我们方法的有效性。我们的方法引入了最小的有界内存参数，并实现了LLMs的快速流式推理。</p>
<p><strong>注</strong>：为解决大模型（LLMs）在处理超长输入序列时遇到的内存限制问题，本文作者提出了一种新型架构：Infini-Transformer，它可以在有限内存条件下，让基于Transformer的大语言模型（LLMs）高效处理无限长的输入序列。实验结果表明：Infini-Transformer在长上下文语言建模任务上超越了基线模型，内存最高可节约114倍。</p>
<p>感觉有种外挂存储库(类似向量数据库)嵌入到模型结构中。比如： <a href="https://arxiv.org/abs/2203.08913">Memorizing Transformers</a> + <a href="https://github.com/lucidrains/memorizing-transformers-pytorch">code</a></p>
<p>在论文《Memorizing Transformers》中，作者提出了一种新的注意力机制，称为kNN-augmented attention layer，它结合了局部上下文的密集自注意力和对外部记忆的近似k-最近邻（kNN）搜索。这个机制的关键部分之一是使用了一个门控机制（gating mechanism）来结合局部注意力和外部记忆的注意力。</p>
    </div>
    <div class="read-more">
      <a href="/post/paper/transformer/infini_attention/" class="read-more-link">阅读全文</a>
    </div>
    
  </div>
</article>

  
</section>






  
  
  

  
  

  
  

  
  

  
  
  <nav class="pagination">
    <ul>
      
      <li  class="active" >
        <a href="/">1</a>
      </li>
      
      <li >
        <a href="/page/2/">2</a>
      </li>
      
      <li >
        <a href="/page/3/">3</a>
      </li>
      
      <li >
        <a href="/page/4/">4</a>
      </li>
      
      <li >
        <a href="/page/5/">5</a>
      </li>
      
      <li >
        <a href="/page/6/">6</a>
      </li>
      
      <li >
        <a href="/page/7/">7</a>
      </li>
      
      <li >
        <a href="/page/8/">8</a>
      </li>
      
      <li >
        <a href="/page/9/">9</a>
      </li>
      
      <li >
        <a href="/page/10/">10</a>
      </li>
      
      <li >
        <a href="/page/11/">11</a>
      </li>
      
      <li >
        <a href="/page/12/">12</a>
      </li>
      
    </ul>
  </nav>

  
  





        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:weege007@gmail.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/weedge" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://weibo.com/weedge" rel="me noopener" class="iconfont"
      title="weibo"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M385.714286 733.714286q12-19.428571 6.285714-39.428571t-25.714286-28.571429q-19.428571-8-41.714286-0.571429t-34.285714 26.285714q-12.571429 19.428571-7.428571 39.142857t24.571429 28.857143 42.571429 1.428571 35.714286-27.142857zm53.714286-69.142857q4.571429-7.428571 2-15.142857t-10-10.571429q-8-2.857143-16.285714 2.857143t-12.285714 10.571429q-9.714286 17.714286 7.428571 25.714286 8 2.857143 16.571429 2.857143t12.571429-10.571429zm99.428571 61.142857q-25.714286 58.285714-90.285714 85.714286t-128 6.857143q-61.142857-19.428571-84.285714-72.285714t3.714286-107.142857q26.857143-53.142857 86.571429-79.428571t120.285714-10.857143q63.428571 16.571429 90.571429 68.285714t1.428571 108.857143zm178.285714-91.428571q-5.142857-54.857143-50.857143-97.142857t-119.142857-62.285714-156.857143-12q-127.428571 13.142857-211.142857 80.857143t-75.714286 151.142857q5.142857 54.857143 50.857143 97.142857t119.142857 62.285714 156.857143 12q127.428571-13.142857 211.142857-80.857143t75.714286-151.142857zm176 2.285714q0 38.857143-21.142857 79.714286t-62.285714 78.285714-96.285714 67.142857-129.142857 47.428571-154.571429 17.714286-157.142857-19.142857-137.428571-53.142857-98-86.285714-37.142857-114q0-65.714286 39.714286-140t112.857143-147.428571q96.571429-96.571429 195.142857-134.857143t140.857143 4q37.142857 36.571429 11.428571 119.428571-2.285714 8-0.571429 11.428571t5.714286 4 8.285714 2.857143 7.714286-2l3.428571-1.142857q79.428571-33.714286 140.571429-33.714286t87.428571 34.857143q25.714286 36 0 101.714286-1.142857 7.428571-2.571429 11.428571t2.571429 7.142857 6.857143 4.285714 9.714286 3.428571q32.571429 10.285714 58.857143 26.857143t45.714286 46.571429 19.428571 66.571429zm-42.285714-356.571429q24 26.857143 31.142857 62t-3.714286 67.142857q-4.571429 13.142857-16.857143 19.428571t-25.428571 2.285714q-13.142857-4.571429-19.428571-16.857143t-2.285714-25.428571q11.428571-36-13.714286-63.428571t-61.142857-20q-13.714286 2.857143-25.714286-4.571429t-14.285714-21.142857q-2.857143-13.714286 4.571429-25.428571t21.142857-14.571429q34.285714-7.428571 68 3.142857t57.714286 37.428571zm103.428571-93.142857q49.714286 54.857143 64.285714 127.142857t-7.714286 138q-5.142857 15.428571-19.428571 22.857143t-29.714286 2.285714-22.857143-19.428571-2.857143-29.714286q16-46.857143 5.714286-98.285714t-45.714286-90.285714q-35.428571-39.428571-84.571429-54.571429t-98.857143-4.857143q-16 3.428571-29.714286-5.428571t-17.142857-24.857143 5.428571-29.428571 24.857143-16.857143q70.285714-14.857143 139.428571 6.571429t118.857143 76.857143z"></path>
</svg>

    </a>


<a href="https://weedge.github.io/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
   
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2013 -
    2025
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        weedge
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  









  <script id="dsq-count-scr" src="//weedge.disqus.com/count.js" async></script>






  <script src="/js/copy-to-clipboard.js"></script>


</body>
</html>

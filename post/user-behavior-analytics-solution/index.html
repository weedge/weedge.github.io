<!DOCTYPE html>
<html lang="zh-cn" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>用户行为分析方案设计 - 时间飘过</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="weedge" />
  <meta name="description" content="背景 用户在手机和pc端使用客户业务产品，比如浏览网页，购买商品，查看文档，观看视频，直播，IOT场景；会产生大量的用户行为数据，主要包括：
 非结构化数据：日志(前端事件埋点日志，服务端处理事件日志)，还有些非结构化的图片，音视频数据等等，主要存放在文件存储系统中； 结构化和半结构化数据： 用户操作产品写入的结构化数据存放于数据库表中，将文档型半结构化的数据放入文档数据库中；  需要分析用户的行为数据，进行决策；分为实时流式处理和离线批处理：
 实时流处理，主要用于实时展现客户端看板，后台BI实时分析，实时风控/推荐，异常报警等场景； 离线批处理，分析用户历史数据，进行推荐算法等机器学习算法模型训练使用，数据仓库中根据不同维度对数据过滤聚合，进行上卷下钻分析，比如计算DAU,WAU,MAU，转化率(购买率，注册率)分析等，通常对数据建设投入多的话， 会把用户产生的结构化非结构化的数据都存下，放在一个大的池子里待使用时进行分析，即所谓的数据湖，围湖而建挖掘数据价值；而数仓相对精细化的分析，前置建模建表分析；  对此进行方案分析，本文将介绍一种实时离线处理分析用户行为数据方案，即能帮助企业低成本地使用海量数据，又能更快速地响应业务需求，同时借助亚马逊云科技的托管服务，能够快速实施和轻松运维。
" />

  <meta name="keywords" content="工作, 技术, 生活" />






<meta name="generator" content="Hugo 0.88.1" />


<link rel="canonical" href="https://weedge.github.io/post/user-behavior-analytics-solution/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css" integrity="sha256-&#43;ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media="screen" crossorigin="anonymous">





<meta property="og:title" content="用户行为分析方案设计" />
<meta property="og:description" content="背景
用户在手机和pc端使用客户业务产品，比如浏览网页，购买商品，查看文档，观看视频，直播，IOT场景；会产生大量的用户行为数据，主要包括：

非结构化数据：日志(前端事件埋点日志，服务端处理事件日志)，还有些非结构化的图片，音视频数据等等，主要存放在文件存储系统中；
结构化和半结构化数据： 用户操作产品写入的结构化数据存放于数据库表中，将文档型半结构化的数据放入文档数据库中；

需要分析用户的行为数据，进行决策；分为实时流式处理和离线批处理：

实时流处理，主要用于实时展现客户端看板，后台BI实时分析，实时风控/推荐，异常报警等场景；
离线批处理，分析用户历史数据，进行推荐算法等机器学习算法模型训练使用，数据仓库中根据不同维度对数据过滤聚合，进行上卷下钻分析，比如计算DAU,WAU,MAU，转化率(购买率，注册率)分析等，通常对数据建设投入多的话， 会把用户产生的结构化非结构化的数据都存下，放在一个大的池子里待使用时进行分析，即所谓的数据湖，围湖而建挖掘数据价值；而数仓相对精细化的分析，前置建模建表分析；

对此进行方案分析，本文将介绍一种实时离线处理分析用户行为数据方案，即能帮助企业低成本地使用海量数据，又能更快速地响应业务需求，同时借助亚马逊云科技的托管服务，能够快速实施和轻松运维。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://weedge.github.io/post/user-behavior-analytics-solution/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2022-11-02T10:26:23+08:00" />
<meta property="article:modified_time" content="2022-11-02T10:26:23+08:00" />

<meta itemprop="name" content="用户行为分析方案设计">
<meta itemprop="description" content="背景
用户在手机和pc端使用客户业务产品，比如浏览网页，购买商品，查看文档，观看视频，直播，IOT场景；会产生大量的用户行为数据，主要包括：

非结构化数据：日志(前端事件埋点日志，服务端处理事件日志)，还有些非结构化的图片，音视频数据等等，主要存放在文件存储系统中；
结构化和半结构化数据： 用户操作产品写入的结构化数据存放于数据库表中，将文档型半结构化的数据放入文档数据库中；

需要分析用户的行为数据，进行决策；分为实时流式处理和离线批处理：

实时流处理，主要用于实时展现客户端看板，后台BI实时分析，实时风控/推荐，异常报警等场景；
离线批处理，分析用户历史数据，进行推荐算法等机器学习算法模型训练使用，数据仓库中根据不同维度对数据过滤聚合，进行上卷下钻分析，比如计算DAU,WAU,MAU，转化率(购买率，注册率)分析等，通常对数据建设投入多的话， 会把用户产生的结构化非结构化的数据都存下，放在一个大的池子里待使用时进行分析，即所谓的数据湖，围湖而建挖掘数据价值；而数仓相对精细化的分析，前置建模建表分析；

对此进行方案分析，本文将介绍一种实时离线处理分析用户行为数据方案，即能帮助企业低成本地使用海量数据，又能更快速地响应业务需求，同时借助亚马逊云科技的托管服务，能够快速实施和轻松运维。"><meta itemprop="datePublished" content="2022-11-02T10:26:23+08:00" />
<meta itemprop="dateModified" content="2022-11-02T10:26:23+08:00" />
<meta itemprop="wordCount" content="7612">
<meta itemprop="keywords" content="aws,方案,全栈," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="用户行为分析方案设计"/>
<meta name="twitter:description" content="背景
用户在手机和pc端使用客户业务产品，比如浏览网页，购买商品，查看文档，观看视频，直播，IOT场景；会产生大量的用户行为数据，主要包括：

非结构化数据：日志(前端事件埋点日志，服务端处理事件日志)，还有些非结构化的图片，音视频数据等等，主要存放在文件存储系统中；
结构化和半结构化数据： 用户操作产品写入的结构化数据存放于数据库表中，将文档型半结构化的数据放入文档数据库中；

需要分析用户的行为数据，进行决策；分为实时流式处理和离线批处理：

实时流处理，主要用于实时展现客户端看板，后台BI实时分析，实时风控/推荐，异常报警等场景；
离线批处理，分析用户历史数据，进行推荐算法等机器学习算法模型训练使用，数据仓库中根据不同维度对数据过滤聚合，进行上卷下钻分析，比如计算DAU,WAU,MAU，转化率(购买率，注册率)分析等，通常对数据建设投入多的话， 会把用户产生的结构化非结构化的数据都存下，放在一个大的池子里待使用时进行分析，即所谓的数据湖，围湖而建挖掘数据价值；而数仓相对精细化的分析，前置建模建表分析；

对此进行方案分析，本文将介绍一种实时离线处理分析用户行为数据方案，即能帮助企业低成本地使用海量数据，又能更快速地响应业务需求，同时借助亚马逊云科技的托管服务，能够快速实施和轻松运维。"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->




</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">时间飘过</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/tags/">标签</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/categories/">分类</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/about/">About</a>
          
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/" class="logo">
    
      时间飘过
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/tags/">标签</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/categories/">分类</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/about/">About</a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">用户行为分析方案设计</h1>
      
      <div class="post-meta">
        <time datetime="2022-11-02" class="post-time">
          2022-11-02
        </time>
        <div class="post-category">
            <a href="https://weedge.github.io/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
            
          </div>
        

        
        

        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#背景">背景</a>
      <ul>
        <li><a href="#操作概括">操作概括</a></li>
      </ul>
    </li>
    <li><a href="#解决方案">解决方案</a>
      <ul>
        <li><a href="#数据源采集">数据源采集</a></li>
        <li><a href="#数据处理存储">数据处理存储</a></li>
        <li><a href="#数据分析">数据分析</a></li>
        <li><a href="#组织用户角色权限管理">组织用户角色权限管理</a></li>
      </ul>
    </li>
    <li><a href="#场景">场景</a>
      <ul>
        <li><a href="#case-实时异常事件报警展现">CASE 实时异常事件报警展现</a></li>
      </ul>
    </li>
    <li><a href="#服务构建">服务构建</a>
      <ul>
        <li><a href="#构建">构建</a></li>
        <li><a href="#代码结构">代码结构</a></li>
      </ul>
    </li>
    <li><a href="#参考">参考</a></li>
  </ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <h2 id="背景">背景</h2>
<p>用户在手机和pc端使用客户业务产品，比如浏览网页，购买商品，查看文档，观看视频，直播，IOT场景；会产生大量的用户行为数据，主要包括：</p>
<ol>
<li>非结构化数据：日志(前端事件埋点日志，服务端处理事件日志)，还有些非结构化的图片，音视频数据等等，主要存放在文件存储系统中；</li>
<li>结构化和半结构化数据： 用户操作产品写入的结构化数据存放于数据库表中，将文档型半结构化的数据放入文档数据库中；</li>
</ol>
<p>需要分析用户的行为数据，进行决策；分为实时流式处理和离线批处理：</p>
<ol>
<li>实时流处理，主要用于实时展现客户端看板，后台BI实时分析，实时风控/推荐，异常报警等场景；</li>
<li>离线批处理，分析用户历史数据，进行推荐算法等机器学习算法模型训练使用，数据仓库中根据不同维度对数据过滤聚合，进行上卷下钻分析，比如计算DAU,WAU,MAU，转化率(购买率，注册率)分析等，通常对数据建设投入多的话， 会把用户产生的结构化非结构化的数据都存下，放在一个大的池子里待使用时进行分析，即所谓的数据湖，围湖而建挖掘数据价值；而数仓相对精细化的分析，前置建模建表分析；</li>
</ol>
<p>对此进行方案分析，本文将介绍一种实时离线处理分析用户行为数据方案，即能帮助企业低成本地使用海量数据，又能更快速地响应业务需求，同时借助亚马逊云科技的托管服务，能够快速实施和轻松运维。</p>
<h3 id="操作概括">操作概括</h3>
<ol>
<li>权限设置：根据公司业务组织，分配对应服务资源权限，比如系统管理员OP, 开发人员DEV, 还有业务管理员OP；组织架构权限建设；</li>
<li>服务基础架构：首先需要搭好基础服务框架，结合云厂商服务，进行可水平垂直自动扩展，高容错性，低成本，可观测监控，易于维护，持续集成发布的稳定性架构建设；</li>
<li>业务迭代数据建设开发：架子搭好之后，需要对特定的业务场景进行数据建模，AI模型训练，挖掘出数据的价值，进行决策；服务代码质量，框架建设；</li>
</ol>
<h2 id="解决方案">解决方案</h2>
<p>使用aws 现有产品服务组件进行搭建，主要分为三个阶段，数据采集，数据处理存储，数据分析，整体架构如下：</p>
<p><img src="https://github.com/weedge/user-behavior-analytics-cdk/blob/master/docs/aws-user-behavior-analytics.drawio.png?raw=true" alt=""></p>
<h3 id="数据源采集">数据源采集</h3>
<ol>
<li>访问日志和请求事件：用户在手机端通访CloudFront 内容分发服务, 会生成用户行为<a href="https://docs.aws.amazon.com/zh_cn/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html">访问日志</a>，这些<a href="https://docs.aws.amazon.com/zh_cn/AmazonCloudFront/latest/DeveloperGuide/real-time-logs.html">实时日志</a>中会有产品中定义的行为分析埋点记录事件，存放在S3中，通过Lambda无服务函数写入kinesis data streams中；如果需要实时处理，需要开启<a href="https://docs.aws.amazon.com/zh_cn/AmazonCloudFront/latest/DeveloperGuide/real-time-logs.html">CloudFront实时日志功能</a>，将数据写入Kinesis Data Streams中，会有几秒的处理延时；还有一种方式是服务端在线实时通过使用aws SDK方式直接写入记录事件数据，可通过无服务部署的lambda函数写入或者API gateway配置写入(参考:<a href="https://docs.aws.amazon.com/zh_cn/apigateway/latest/developerguide/integrating-api-with-aws-services-kinesis.html">在 API Gateway 中创建 REST API 作为 Amazon Kinesis 代理</a>)，常用于实时异常报警和统计；</li>
<li>数据库数据： 存放在数据库中的数据，需要将数据同步存放在数仓和数据湖中，进行离线分析; 数据库的数据可以通过<a href="https://docs.aws.amazon.com/zh_cn/dms/latest/userguide/CHAP_Introduction.html">aws DMS</a>服务来支持存量增量数据同步至Kinesis Data Streams中，具体方案可以参考**<a href="https://aws.amazon.com/cn/blogs/big-data/stream-change-data-to-amazon-kinesis-data-streams-with-aws-dms/">使用 AWS DMS 将更改数据流式传输到 Amazon Kinesis Data Streams</a>**；也可以使用<a href="https://ververica.github.io/flink-cdc-connectors/master/">flink CDC connector</a>  <a href="https://docs.aws.amazon.com/zh_cn/emr/latest/ReleaseGuide/emr-flink.html">on aws EMR</a>支持同步(需要理解反压机制，以便触发时看是否增大下游消费能力提高吞吐), 可参考<a href="https://aws.amazon.com/cn/blogs/china/best-practice-of-using-amazon-emr-cdc-to-enter-the-lake-in-real-time-in-a-multi-database-multi-table-scenario/">多库多表场景下使用Amazon EMR CDC实时入湖最佳实践</a>，注意数据库表中的数据字段需要规范，需要一个更新时间字段方便数据顺序同步，比如mysql <code>update_time timestamp DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP</code>；</li>
</ol>
<p>您可以参阅 AWS 白皮书<a href="https://d1.awsstatic.com/whitepapers/aws-cloud-data-ingestion-patterns-practices.pdf">AWS Cloud Data Ingestion Patterns and Practices</a>，了解有关数据采集模式的更多详细信息；</p>
<p>将数据采集写入消息队列中主要是方便多个消费方来处理流，以及服务之间的整体解耦，可作为数据流缓存层，数据流量突增时，增加分片数，提高吞吐，当然整体吞吐量也取决于下游数据的消费能力，引入消息队列，以pull方式进行消费(主动消费)，不至于将下游服务打挂，而且方便下游异常消费重启时，继续在未消费点开始消费；这里提供两种方案，一种将数据写入Kinesis Data Streams中，一种将数据写入<a href="https://docs.aws.amazon.com/zh_cn/msk">MSK</a>(aws 托管的kafka集群服务，如果直接自己搭建维护，成本比较高，对接其他aws服务相对复杂些) 中；</p>
<ol>
<li>数据写入Kinesis Data Streams中主要是方便多个消费方来处理流，以及服务之间的整体解耦，数据流缓存层，更重要的是方便使用aws Kinesis方案，减少运维成本，对接也丰富，主要是方便对接内部Kinesis相关服务组件;</li>
<li>数据写入MSK中，使用的开源解决方案对接；下游对接kinesis Data Analytics 服务需要通过flink 计算引擎加载对应kafka connector包，从kafka中获取数据源进行分析；如果下游对接其他服务，比如：Kinesis Data Firehose，将数据传输转化写入数据湖S3中存储，写入Redshift数仓中分析；使用SNS 进行报警等； 需要引入无服务框架lambda函数，通过使用<a href="https://docs.confluent.io/platform/current/clients/index.html">kafka client SDK库</a>来进行生产/消费处理；</li>
</ol>
<p>具体使用结合公司实际场景而定，如果想想通过kafka对接更多的开源大数据服务框架， 可以选择MSK方案，额外需要开发维护lambda函数服务；使用Kinesis Data streams 很方便接入aws相关服务，减少额外的开发维护成本，不过如果对接其他开源大数据服务框架，同样需要引入lambda函数服务；本文采用将数据写入Kinesis Data streams 服务，提供给下游对接。</p>
<h3 id="数据处理存储">数据处理存储</h3>
<p>数据处理分析，分为实时处理的<a href="https://aws.amazon.com/cn/streaming-data/">流数据</a>和离线处理批数据处理存放；</p>
<p>实时处理使用AWS Kinesisi Data Analytics(KDA)进行分析，支持三种分析方式：</p>
<ol>
<li>使用老的方式<a href="https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/dev/what-is.html">SQL 应用程序</a>进行分析处理，不能使用编程语言python/Scala来调用api来进行精细化操作(需要定义UDF包提供使用),以及即席查询；</li>
<li>使用基于 <a href="https://flink.apache.org/">Apache Flink</a> 的开源库在 Kinesis Data Analytics 中构建 Java ,Scala 和Python 应用程序,Apache Flink 是处理数据流的常用框架和引擎，Kinesis Data Analytics现使用flink支持最高版本是<a href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/learn-flink/overview/">1.13</a>；在开发应用时，需要打印日志，以便使用CloudWatch 日志监控应用程序的性能和错误状况；如果应用程序出现bug或者服务异常中断可以使用检查点(<a href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/ops/state/checkpoints/">CheckPoints</a>)和保存点(<a href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/ops/state/savepoints/">SavePoints</a> 生成<a href="https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/java/how-fault-snapshot.html">快照</a>)在 Kinesis Data Analytics 应用程序中实现容错功能; 同时Kinesis Data Analytics <a href="https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/java/how-scaling.html"><strong>可弹性扩缩</strong></a>应用程序的并行度，以适应大多数场景下的源数据吞吐量和操作复杂性，Kinesis Data Analytics 监控应用程序的资源 (CPU) 使用情况，并相应地弹性地向上或向下扩展应用程序的并行度; 使用算子(<a href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/dev/datastream/operators/overview/#operators">operators</a>)进行数据流拓扑计算；同时通过<a href="https://nightlies.apache.org/flink/flink-docs-release-1.13/docs/connectors/datastream/overview/">connector</a>可直接引入jar包接入数据源或者sink到下游服务，可以在mvn库中找到，比如<a href="https://mvnrepository.com/artifact/org.apache.flink/flink-sql-connector-kinesis">kinesis stream connector</a>;</li>
<li>在基于 <a href="https://flink.apache.org/">Apache Flink</a> 的开源库构建应用程序的基础上，结合<a href="https://docs.aws.amazon.com/zh_cn/glue/latest/dg/how-it-works.html">Glue</a>定义数据库表存放数据catalog元数据，通过<a href="https://zeppelin.apache.org/">zeppelin</a>增加了可视化即席查询, 直接可以在notebook上编写flink 流/批**<a href="https://nightlies.apache.org/flink/flink-docs-master/docs/dev/table/sql/overview/">SQL</a>**(notice: *flinkSQL和KDA SQL有所不同，特别是在window上有些区别*), 以及编写调用flink API的Scala,Python程序, 具体见<a href="https://zeppelin.apache.org/docs/0.9.0/interpreter/flink.html">zeppelin flink解释器</a>; 这种方式是相对于第二种方式，在方便运维管理的基础上更加容易上手，直接在notebook上就可以进行即席查询, 查询会话还可以保留或存放本地，还可以作为测试开发调试的平台，构建好处理程序，可直接转化成<a href="https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/java/how-notebook-durable.html">持久化的应用程序部署</a>；当然这部分费用相比前面的分析方式相对多些，启动的studio notebook 费用，Kinesis 处理单元(KPU)将按小时收费；可参考<a href="https://docs.aws.amazon.com/kinesisanalytics/latest/java/how-zeppelin-examples.html">实例教程</a>，<a href="https://aws.amazon.com/cn/blogs/big-data/query-your-data-streams-interactively-using-kinesis-data-analytics-studio-and-python/">使用 Kinesis Data Analytics Studio 和 Python 以交互方式查询数据流</a></li>
</ol>
<p>整体来说： <a href="https://aws.amazon.com/kinesis/data-analytics/">Amazon Kinesis Data Analytics</a> 可以轻松地实时分析流数据，并使用标准 SQL、Python 和 Scala 构建由 Apache Flink 提供支持的流处理应用程序。特别是notebook功能只需在AWS 管理控制台中单击几下，写下分析SQL，就可以启动无服务器笔记本来查询数据流并在几秒钟内获得结果。Kinesis Data Analytics 降低了构建和管理 Apache Flink 应用程序的复杂性。</p>
<p>离线处理的数据主要是通过<a href="">AWS Kinesis Data Firehose</a> 传输流写入下游服务存储，将数据写入湖仓系统中, 用于后续的数据分析，以及前期规划好的数据分析；选用firehose的原因是有原始备份机制存放于S3中，即使数据传输错误时，数据传输中不会丢失数据，同时内置lambd函数在传输之前将数据转化处理，同时也支持用Glue定义表来转换大数据相关的记录格式;</p>
<p>原始分析数据直接存放于<a href="https://docs.aws.amazon.com/zh_cn/AmazonS3/latest/userguide/Welcome.html">S3</a>中，11个9的保障可以非常可靠保证数据不丢失，通过<a href="https://aws.amazon.com/cn/s3/storage-classes/glacier/">Glacier</a>持久冷热存放，降低成本，方便后面追查数据，以及通过Athena查询引擎结合Glue来定义表从S3中挖掘出更有价值的数据；数据存放下来之后，结合大数据相关平台，<a href="https://docs.aws.amazon.com/zh_cn/emr/latest/ManagementGuide/emr-what-is-emr.html">EMR</a>进行海量数据处理(PB级别)；同时结合<a href="https://docs.aws.amazon.com/zh_cn/glue/latest/dg/what-is-glue.html">Glue</a> 进行ETL 数据处理，集成编排成DAG工作流，可视化管理这些ETL任务作业，也可以迁移调度平台比如Azkaban的工作流迁移至Glue ETL工作流,参考<a href="https://aws.amazon.com/cn/blogs/china/preliminary-study-on-selection-of-aws-glue-scheduling-tool/">Amazon Glue ETL作业调度工具选型初探</a>；</p>
<p>提前业务场景数据分析建模，使用<a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/gsg/concepts-diagrams.html">Redshift</a>来存放不同维度(DIM)的表，分层(ODS-&gt;<strong>DWD-&gt;DWM-&gt;DWS</strong>)建设数据仓库； 选用redshift性价比比较高，开箱即用，存放结构化，半结构化数据，数据列式存储，分片存放，计算和存储分离，很方便无服务化，在数秒内轻松运行和扩展分析，而无需调配和管理数据仓库; 和数据湖打通，可以使用 <a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/gsg/data-lake.html">Redshift Spectrum</a> 在 Amazon S3 文件中查询数据，而不必将数据加载到 Amazon Redshift 表中，提高关联查询；还可以对接机器学习<a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/dg/machine_learning.html">ML</a>，通过CREATE MODEL DDL语句下推到Amazon <a href="https://docs.aws.amazon.com/zh_cn/sagemaker/latest/dg/whatis.html">SageMaker</a>，从S3中加载数据进行训练；</p>
<h3 id="数据分析">数据分析</h3>
<p>主要是通过分析引擎从数据存储获取数据，根据维度展现看板，进行实时数据查看，离线分析，以及可视化即席分析：</p>
<ol>
<li>实时结果数据查看：通过<a href="https://docs.aws.amazon.com/zh_cn/amazondynamodb/latest/developerguide/Introduction.html">DynamoDB</a>获取实时结果数据，主要是Key/Value数据，同时查询速度很快，利用<a href="https://docs.aws.amazon.com/zh_cn/amazondynamodb/latest/developerguide/DAX.html">DAX</a>实现内存中加速；通过<a href="https://docs.aws.amazon.com/zh_cn/lambda/latest/dg/welcome.html">lambda</a>对接<a href="https://docs.aws.amazon.com/zh_cn/apigateway/latest/developerguide/welcome.html">API Gateway</a>提供数据接口，方便业务场景实时展现，比如监控查看异常数据，访问计数等结果展现；这些结果数据可以直接通过<a href="https://docs.aws.amazon.com/zh_cn/sns/latest/dg/welcome.html">SNS</a>发送邮件或者短信进行通知；</li>
<li>通过<a href="https://docs.aws.amazon.com/zh_cn/opensearch-service/latest/developerguide/what-is.html">OpenSearch</a>提供实时搜索服务，比如日志搜索实时定位追查问题，通过KDA实时分析写入；在线检索商品，这些数据主要来源于数据库，异构成OpenSearch索引数据进行检索，可通过<a href="https://ververica.github.io/flink-cdc-connectors/master/">flink CDC</a> on <a href="https://docs.aws.amazon.com/zh_cn/emr/latest/ReleaseGuide/emr-flink.html">EMR</a>来同步数据到OpenSearch中；</li>
<li>S3中的数据通过<a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/what-is.html">Athena</a>在Glue/Hive上建表元数据，使用<a href="https://docs.aws.amazon.com/zh_cn/athena/latest/ug/ddl-sql-reference.html">SQL</a>查询，几分钟内可以查询到结果;</li>
<li>存放在<a href="https://docs.aws.amazon.com/zh_cn/redshift/latest/gsg/concepts-diagrams.html">Redshift</a>数据仓库中的数据，通过Amazon <a href="https://docs.aws.amazon.com/zh_cn/quicksight/latest/user/welcome.html">QuickSight</a>接入进行BI分析，响应时间在秒级别，只需要在界面上选择图表组合成一个仪表盘展现即可，方便快速决策；<a href="https://docs.aws.amazon.com/zh_cn/quicksight/latest/user/regions.html">支持AWS区域接入IP范围</a>;</li>
</ol>
<h3 id="组织用户角色权限管理">组织用户角色权限管理</h3>
<p>以上这些谈到的服务需要进行安全访问，通过<a href="https://docs.aws.amazon.com/zh_cn/iam/">IAM</a>定义策略角色分配权限进行<a href="https://docs.aws.amazon.com/zh_cn/service-authorization/latest/reference/reference.html">服务授权</a>，来进行安全访问，有两种情况：</p>
<ol>
<li>
<p>服务资源之间的访问，需要分配读写权限，需要把这些策略赋予莫个角色，然后资源通过这个赋予资源权限的角色来访问对应资源；</p>
</li>
<li>
<p>还有就是操作者访问服务资源，需要分配不同资源的读写权限，可以根据公司组织架构来管理每个员工的权限使用范围，非常方便；</p>
<p>角色权限设置规则如下：<a href="https://docs.aws.amazon.com/zh_cn/IAM/latest/UserGuide/id.html">IAM身份</a>设置用户组 dev, op, biz user，后续 细分在按组织部门进行建组；</p>
<ol>
<li>op: 理论上构建完一组资源可以分配对应权限策略角色Role，给予服务资源的运维管理操作；</li>
<li>dev: 只有使用开发资源权限，比如lambda编辑发布权限，数据库读写权限，而非管理删除权限策略Role；</li>
<li>bizUser: 业务操作者，大部分只有读权限策略Role，没有写操作权限；</li>
<li>admin: 管理员，Administrator权限，可以访问任何资源</li>
</ol>
</li>
</ol>
<p>还有是创建的应用是给外部服务用户使用，比如Web,移动端用户，通过Amazon <a href="https://docs.aws.amazon.com/zh_cn/cognito/">Cognito</a>来注册登录管理用户，也可以通过第三方登录进行身份验证；两个主要组件是用户池和身份池：用户池是为应用程序提供注册和登录选项的用户目录，身份池授予用户访问其他 AWS 服务的权限。请参考<a href="https://docs.aws.amazon.com/zh_cn/cognito/latest/developerguide/cognito-scenarios.html">Amazon Cognito常见场景</a>。</p>
<h2 id="场景">场景</h2>
<h3 id="case-实时异常事件报警展现">CASE 实时异常事件报警展现</h3>
<p>打点事件数据：（实体数据，通过同步实体表数据流进行关联jion操作）</p>
<table>
<thead>
<tr>
<th>field</th>
<th>type</th>
<th>desc</th>
</tr>
</thead>
<tbody>
<tr>
<td>eventId</td>
<td>string</td>
<td>用户行为事件id</td>
</tr>
<tr>
<td>action</td>
<td>string</td>
<td>统一定义的事件动作，比如 浏览文档：viewDoc</td>
</tr>
<tr>
<td>userId</td>
<td>string</td>
<td>触发事件的用户id</td>
</tr>
<tr>
<td>createdAt</td>
<td>string</td>
<td>触发事件时间</td>
</tr>
<tr>
<td>objectId</td>
<td>string</td>
<td>操作对象id, 比如文档id</td>
</tr>
<tr>
<td>bizId</td>
<td>string</td>
<td>所属业务id</td>
</tr>
<tr>
<td>errorMsg</td>
<td>string</td>
<td>错误信息</td>
</tr>
</tbody>
</table>
<p>实时过滤出异常事件SQL</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql"><span style="color:#aaa;font-style:italic">-- ** Continuous Filter ** 
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">-- Performs a continuous filter based on a WHERE condition.
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">--          .----------.   .----------.   .----------.              
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">--          |  SOURCE  |   |  INSERT  |   |  DESTIN. |              
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">-- Source--&gt;|  STREAM  |--&gt;| &amp; SELECT |--&gt;|  STREAM  |--&gt;Destination
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">--          |          |   |  (PUMP)  |   |          |              
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">--          &#39;----------&#39;   &#39;----------&#39;   &#39;----------&#39;               
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">-- STREAM (in-application): a continuously updated entity that you can SELECT from and INSERT into like a TABLE
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">-- PUMP: an entity used to continuously &#39;SELECT ... FROM&#39; a source STREAM, and INSERT SQL results into an output STREAM
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#aaa;font-style:italic">-- Create output stream, which can be used to send to a destination
</span><span style="color:#aaa;font-style:italic">-- reference: 
</span><span style="color:#aaa;font-style:italic">-- https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/sqlref/analytics-sql-reference.html
</span><span style="color:#aaa;font-style:italic">-- https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/dev/streaming-sql-concepts.html
</span><span style="color:#aaa;font-style:italic">-- https://docs.aws.amazon.com/zh_cn/kinesisanalytics/latest/sqlref/kinesis-analytics-sqlref.pdf
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#aaa;font-style:italic">-- abnormality event stream
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#00a">CREATE</span><span style="color:#bbb"> </span><span style="color:#00a">OR</span><span style="color:#bbb"> </span><span style="color:#00a">REPLACE</span><span style="color:#bbb"> </span>STREAM<span style="color:#bbb"> </span><span style="color:#a50">&#34;DESTINATION_SQL_STREAM&#34;</span><span style="color:#bbb"> 
</span><span style="color:#bbb"></span>(<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;eventId&#34;</span><span style="color:#bbb">       </span><span style="color:#0aa">varchar</span>(<span style="color:#099">64</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;action&#34;</span><span style="color:#bbb">        </span><span style="color:#0aa">varchar</span>(<span style="color:#099">256</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;userId&#34;</span><span style="color:#bbb">        </span><span style="color:#0aa">varchar</span>(<span style="color:#099">64</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;objectId&#34;</span><span style="color:#bbb">      </span><span style="color:#0aa">varchar</span>(<span style="color:#099">64</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;bizId&#34;</span><span style="color:#bbb">         </span><span style="color:#0aa">varchar</span>(<span style="color:#099">64</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;errorMsg&#34;</span><span style="color:#bbb">      </span><span style="color:#0aa">varchar</span>(<span style="color:#099">1024</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;createdAt&#34;</span><span style="color:#bbb">      </span><span style="color:#0aa">varchar</span>(<span style="color:#099">32</span>)<span style="color:#bbb">
</span><span style="color:#bbb"></span>);<span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#aaa;font-style:italic">-- Filter errorMsg like panic/error pump
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#00a">CREATE</span><span style="color:#bbb"> </span><span style="color:#00a">OR</span><span style="color:#bbb"> </span><span style="color:#00a">REPLACE</span><span style="color:#bbb"> </span>PUMP<span style="color:#bbb"> </span><span style="color:#a50">&#34;ERROR_PANIC_STREAM_PUMP&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">AS</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">INSERT</span><span style="color:#bbb"> </span><span style="color:#00a">INTO</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;DESTINATION_SQL_STREAM&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">SELECT</span><span style="color:#bbb"> </span>STREAM<span style="color:#bbb"> </span><span style="color:#a50">&#34;eventId&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;action&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;userId&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;objectId&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;bizId&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;errorMsg&#34;</span>,<span style="color:#a50">&#34;createdAt&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">FROM</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;SOURCE_SQL_STREAM_001&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">WHERE</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;errorMsg&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">LIKE</span><span style="color:#bbb"> </span><span style="color:#a50">&#39;%[PANIC]%&#39;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#00a">or</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;errorMsg&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">LIKE</span><span style="color:#bbb"> </span><span style="color:#a50">&#39;%[panic]%&#39;</span><span style="color:#bbb"> 
</span><span style="color:#bbb">        </span><span style="color:#00a">or</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;errorMsg&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">LIKE</span><span style="color:#bbb"> </span><span style="color:#a50">&#39;%[ERROR]%&#39;</span><span style="color:#bbb"> 
</span><span style="color:#bbb">        </span><span style="color:#00a">or</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;errorMsg&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">LIKE</span><span style="color:#bbb"> </span><span style="color:#a50">&#39;%[error]%&#39;</span>;<span style="color:#bbb">
</span></code></pre></div><p>每1分钟warn数目超过10次的SQL(滚动窗口)</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-sql" data-lang="sql"><span style="color:#00a">CREATE</span><span style="color:#bbb"> </span><span style="color:#00a">OR</span><span style="color:#bbb"> </span><span style="color:#00a">REPLACE</span><span style="color:#bbb"> </span>STREAM<span style="color:#bbb"> </span><span style="color:#a50">&#34;DESTINATION_SQL_STREAM&#34;</span><span style="color:#bbb"> 
</span><span style="color:#bbb"></span>(<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;eventId&#34;</span><span style="color:#bbb">       </span><span style="color:#0aa">varchar</span>(<span style="color:#099">64</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;action&#34;</span><span style="color:#bbb">        </span><span style="color:#0aa">varchar</span>(<span style="color:#099">256</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;userId&#34;</span><span style="color:#bbb">        </span><span style="color:#0aa">varchar</span>(<span style="color:#099">64</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;objectId&#34;</span><span style="color:#bbb">      </span><span style="color:#0aa">varchar</span>(<span style="color:#099">64</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;bizId&#34;</span><span style="color:#bbb">         </span><span style="color:#0aa">varchar</span>(<span style="color:#099">64</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;errorMsg&#34;</span><span style="color:#bbb">      </span><span style="color:#0aa">varchar</span>(<span style="color:#099">1024</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;createAt&#34;</span><span style="color:#bbb">      </span><span style="color:#0aa">varchar</span>(<span style="color:#099">32</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;INGREST_ROW_TIME&#34;</span><span style="color:#bbb">      </span><span style="color:#0aa">varchar</span>(<span style="color:#099">32</span>),<span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#a50">&#34;APPROXIMATE_ARRIVAL_TIME&#34;</span><span style="color:#bbb">      </span><span style="color:#0aa">varchar</span>(<span style="color:#099">32</span>)<span style="color:#bbb">
</span><span style="color:#bbb"></span>);<span style="color:#bbb">
</span><span style="color:#bbb">
</span><span style="color:#bbb"></span><span style="color:#aaa;font-style:italic">-- Filter errorMsg like warning pump
</span><span style="color:#aaa;font-style:italic">-- Aggregation with time window(u can use stagger windows,tumbling windows, sliding windows)
</span><span style="color:#aaa;font-style:italic">-- use tumbling windows for this case
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#00a">CREATE</span><span style="color:#bbb"> </span><span style="color:#00a">OR</span><span style="color:#bbb"> </span><span style="color:#00a">REPLACE</span><span style="color:#bbb"> </span>PUMP<span style="color:#bbb"> </span><span style="color:#a50">&#34;STREAM_PUMP&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">AS</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">INSERT</span><span style="color:#bbb"> </span><span style="color:#00a">INTO</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;DESTINATION_SQL_STREAM&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">SELECT</span><span style="color:#bbb"> </span>STREAM<span style="color:#bbb"> </span><span style="color:#a50">&#34;eventId&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;userId&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;objectId&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;bizId&#34;</span>,<span style="color:#bbb"> </span><span style="color:#a50">&#34;createAt&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#a50">&#34;errorMsg&#34;</span>,<span style="color:#a50">&#34;action&#34;</span>,<span style="color:#bbb">
</span><span style="color:#bbb">        </span>STEP(<span style="color:#a50">&#34;SOURCE_SQL_STREAM_001&#34;</span>.ROWTIME<span style="color:#bbb"> </span><span style="color:#00a">BY</span><span style="color:#bbb"> </span><span style="color:#0aa">INTERVAL</span><span style="color:#bbb"> </span><span style="color:#a50">&#39;60&#39;</span><span style="color:#bbb"> </span><span style="color:#00a">SECOND</span>)<span style="color:#bbb"> </span><span style="color:#00a">AS</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;INGREST_ROW_TIME&#34;</span>,<span style="color:#bbb">
</span><span style="color:#bbb">        </span>STEP(<span style="color:#a50">&#34;SOURCE_SQL_STREAM_001&#34;</span>.APPROXIMATE_ARRIVAL_TIME<span style="color:#bbb"> </span><span style="color:#00a">BY</span><span style="color:#bbb"> </span><span style="color:#0aa">INTERVAL</span><span style="color:#bbb"> </span><span style="color:#a50">&#39;60&#39;</span><span style="color:#bbb"> </span><span style="color:#00a">SECOND</span>)<span style="color:#bbb"> </span><span style="color:#00a">AS</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;APPROXIMATE_ARRIVAL_TIME&#34;</span>,<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#aaa;font-style:italic">-- STEP(&#34;SOURCE_SQL_STREAM_001&#34;.EVENT_TIME BY INTERVAL &#39;60&#39; SECOND) AS &#34;EVENT_TIME&#34;,
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">        </span><span style="color:#00a">COUNT</span>(*)<span style="color:#bbb"> </span><span style="color:#00a">AS</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;action_warn_count&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">FROM</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;SOURCE_SQL_STREAM_001&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">WHERE</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;errorMsg&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">LIKE</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;% WARNNING %&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">or</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;errorMsg&#34;</span><span style="color:#bbb"> </span><span style="color:#00a">LIKE</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;% warnning %&#34;</span><span style="color:#bbb">
</span><span style="color:#bbb">    </span><span style="color:#00a">GROUP</span><span style="color:#bbb"> </span><span style="color:#00a">BY</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;action&#34;</span>,<span style="color:#bbb">
</span><span style="color:#bbb">        </span>STEP(<span style="color:#a50">&#34;SOURCE_SQL_STREAM_001&#34;</span>.ROWTIME<span style="color:#bbb"> </span><span style="color:#00a">BY</span><span style="color:#bbb"> </span><span style="color:#0aa">INTERVAL</span><span style="color:#bbb"> </span><span style="color:#a50">&#39;60&#39;</span><span style="color:#bbb"> </span><span style="color:#00a">SECOND</span>),<span style="color:#bbb">
</span><span style="color:#bbb">        </span>STEP(<span style="color:#a50">&#34;SOURCE_SQL_STREAM_001&#34;</span>.APPROXIMATE_ARRIVAL_TIME<span style="color:#bbb"> </span><span style="color:#00a">BY</span><span style="color:#bbb"> </span><span style="color:#0aa">INTERVAL</span><span style="color:#bbb"> </span><span style="color:#a50">&#39;60&#39;</span><span style="color:#bbb"> </span><span style="color:#00a">SECOND</span>)<span style="color:#bbb">
</span><span style="color:#bbb">        </span><span style="color:#aaa;font-style:italic">-- STEP(&#34;SOURCE_SQL_STREAM_001&#34;.EVENT_TIME BY INTERVAL &#39;60&#39; SECOND) 
</span><span style="color:#aaa;font-style:italic"></span><span style="color:#bbb">    </span><span style="color:#00a">Having</span><span style="color:#bbb"> </span><span style="color:#a50">&#34;action_warn_count&#34;</span><span style="color:#bbb"> </span>&gt;=<span style="color:#bbb"> </span><span style="color:#099">10</span>;<span style="color:#bbb">
</span></code></pre></div><h2 id="服务构建">服务构建</h2>
<p>基于以上服务搭建，需要用户去aws云平台上点击，配置使用， 特别是构建表，以及数据传输，属性和安全访问权限角色的管理，随着业务复杂度变高，基础服务也随之增多，可配置化的东西越来越多，会带来灾难性的后果，最终变得不可控，人力管理运维成本增加；aws平台提供了AWS CloudFormation 允许您通过将基础设施视为代码来建模、预置和管理 AWS 和第三方资源。即IaC，也是Devops经常所做的事情，可以使用相关IaC工具来自动化构建一个系统，常用的场景是CI/CD支持快速变化的业务需求开发；AWS一直提供基础服务的配置API，有相关的SDK可供使用，也有<code>aws</code> 工具来操作这些基础服务资源； 后面提供了一种开源软件开发框架AWS Cloud Development Kit (AWS <a href="https://docs.aws.amazon.com/zh_cn/cdk/v2/guide/home.html">CDK</a>)，可使用熟悉的编程语言来定义云应用程序资源；将云上硬件资源可编程化，可以很方便的实现自动化运维管理，充分利用云上的资源来组装construct成一个模块栈stack, 各个模块栈最终合成一个落地解决方案，方便开箱即用(安装软件一样)，降低云构建的复杂性；cdk construct分3个层次的封装，L1是最低级别初始封装，直接对应CloudFormation配置模版文件映射，称之为CFN 资源，必须配置每一项属性，需要深入了解资源模型的详细信息；L2是是对了L1的组合封装，使用资源属性默认值，比如new VPC；L3则是一种模式(pattern)，通过多种资源组合成一个常见资源架构，比如 new Fargate无服务化容器集群；具体参考见：<a href="https://docs.aws.amazon.com/zh_cn/cdk/v2/guide/constructs.html">constructs</a></p>
<p>通过<a href="https://cdkworkshop.com">cdk workshop</a> 大概花半天时间学习这里的demo就可以试着搭建相关的服务， 也有更多的<a href="https://awesome-aws-workshops.com/">awesome workshop</a>可供参考和学习的，并且 <a href="https://aws.amazon.com/blogs">aws blog</a>  <a href="https://aws.amazon.com/cn/builders-library">builders' lib</a>也会有很多相关的解决方案提供学习；当然需要很好的架构aws服务，需要多落地实践，深入服务细节(查看帮助文档<a href="https://docs.aws.amazon.com/">docs</a>)，结合需求，才能构建一个相对完美的解决方案；当然前期生产落地需要使用CDK来进行架构推理。</p>
<p>这里结合上述需求，使用CDK来搭建一些stack, 方便数据流分析管道的组装，后续也方便与其他contstucts进行组装；主要是分为以下stack:</p>
<ol>
<li>
<p><strong>CDK-Workshop-Lambda-KDS-stack</strong>：</p>
<p>APIGateway-&gt;lambda(put KDS record &amp; hit counter in dynamodb)-&gt;lambda(hello)  dynamotableviewer</p>
</li>
<li>
<p>DMS-KDS-stack</p>
</li>
<li>
<p><strong>KDS-KDA-sql-Lambda-Dynamodb-stack</strong>: KDS-&gt;KDA-&gt;lambda-&gt;dynamodb dynamotableviewer</p>
</li>
<li>
<p><strong>KDS-KDF-S3-stack</strong>: KDS-&gt;KDF-&gt;S3</p>
</li>
<li>
<p>KDS-KDA-flink-OpenSearch-stack</p>
</li>
<li>
<p>KDS-KDA-flink-KDS-stack: eg: for near-realtime-warehouse, make a pipeline (ODS-&gt;<strong>DWD-&gt;DWM-&gt;DWS</strong>) sink to Redshift; like this <a href="https://cloud.tencent.com/developer/article/1919594">tencent news Pipeline pattern</a></p>
</li>
<li>
<p>KDS-KDF-Redshift-stack:</p>
</li>
<li>
<p>Redshift-QuickSight-stack</p>
</li>
<li>
<p>S3-Glue-Athena-stack</p>
</li>
</ol>
<p>这里主要部署CDK-Workshop-Lambda-KDS-stack, KDS-KDA-sql-Lambda-Dynamodb-stack 和KDS-KDF-S3-stack 搭建SQL流式处理用户行为数据,具体见<a href="https://github.com/weedge/user-behavior-analytics-cdk">代码</a>；其他stack可以后续进行扩展进行构建，推理整体基础设施架构。</p>
<h3 id="构建">构建</h3>
<p>首先需要安装CDK, 具体查看<a href="https://aws.amazon.com/cn/getting-started/guides/setup-cdk/">入门教程</a>，执行如下命令：</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#aaa;font-style:italic"># download code to start</span>
git clone https://github.com/weedge/user-behavior-analytics-cdk.git &amp;&amp; <span style="color:#0aa">cd</span> user-behavior-analytics-cdk
<span style="color:#aaa;font-style:italic"># tips: cdk load cdk.json + cdk.context.json to run by js on node</span>
<span style="color:#aaa;font-style:italic"># list stacks</span>
cdk ls
<span style="color:#aaa;font-style:italic"># deploy KDS-KDA-sql-Lambda-DynamoDB-stack with KDS-KDF-S3-stack(need created kinesis data stream)</span>
cdk deploy KDS-KDA-sql-Lambda-DynamoDB-stack
<span style="color:#aaa;font-style:italic"># deploy CDK-Workshop-Lambda-KDS-stack for hit event stream; lambda func put record to KDS, dependcy KDS</span>
cdk deploy CDK-Workshop-Lambda-KDS-stack
</code></pre></div><p>部署完之后，会输出kinesis数据流的名称以及用于查看数据结果地址；</p>
<p>开始写入测试数据，需要使用python3, 使用pip3 安装依赖包</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#aaa;font-style:italic"># init python virtural env</span>
python3 -m venv .venv &amp;&amp; <span style="color:#0aa">source</span> .venv/bin/activate 
<span style="color:#aaa;font-style:italic"># install boto3  faker</span>
pip3 install boto3 faker
<span style="color:#aaa;font-style:italic"># run test script, wait KDA run, put record to KDS</span>
python3 src/scripts/producer-kds-test.py
</code></pre></div><p>运行测试脚本，输入region地域名称,比如us-east-1, 等待启动后，输入数据流名称，开始发送数据；</p>
<p>每1秒发一次数据写入KDS中，发了10次含有错误事件，发了10次随机事件，总共20条；</p>
<p>也可以使用aws提供KDS数据生成器：https://github.com/awslabs/amazon-kinesis-data-generator</p>
<p>从刚才部署输出结果地址查看含有错误的数据已经有10条展现出来(数据获取式前端每隔几秒轮训获取api数据，实时展现可通过<a href="https://docs.aws.amazon.com/zh_cn/apigateway/latest/developerguide/apigateway-websocket-api.html">API Gateway WebSocket</a> 来支持)；历史数据可以在KDF配置的S3目标中点击查看，原始数据可以下载gz包进行解压查看;</p>
<p>通过使用提供给前端访问的事件api(api地址在部署CDK-Workshop-Lambda-KDS-stack后输出的访问地址)来写入异常<code>[error]</code> 数据</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell">curl -XPOST -iv https://{APIGateway}.execute-api.{region}.amazonaws.com/prod/event -d <span style="color:#a50">&#39;{&#34;eventId&#34;:&#34;1-1-1&#34;,&#34;bizId&#34;:&#34;123123&#34;,&#34;objectId&#34;:&#34;123&#34;,&#34;action&#34;:&#34;test&#34;,&#34;errorMsg&#34;:&#34;[error]&#34;,&#34;userId&#34;:&#34;1231321&#34;}&#39;</span>
</code></pre></div><p>通过刚才部署KDS-KDA-sql-Lambda-DynamoDB-stack的结果地址可以 查看异常数据已经实时写入。</p>
<p>最后将部署资源清除，依赖删除(和卸载软件一样)。</p>
<div class="highlight"><pre tabindex="0" style="background-color:#fff;-moz-tab-size:4;-o-tab-size:4;tab-size:4"><code class="language-shell" data-lang="shell"><span style="color:#aaa;font-style:italic"># destroy resources with dependent resources</span>
cdk destroy KDS-KDF-S3-stack
cdk destroy KDS-KDA-sql-Lambda-DynamoDB-stack
cdk destroy CDK-Workshop-Lambda-KDS-stack
<span style="color:#aaa;font-style:italic"># or cdk destroy --all</span>
cdk destroy --all
</code></pre></div><h3 id="代码结构">代码结构</h3>
<pre tabindex="0"><code>├── cmd                              -- golang cmd bin dir
├── docs                             -- help doc
├── infra                            -- infrastructures stack
│   └── lib                          -- cdk constuct in stack
├── src                              -- source code to run
│   ├── kinesis-analytics-pyflink    -- KDA python scripts use flink python api 
│   ├── kinesis-analytics-sql        -- KDA sql
│   ├── lambda                       -- js,python,golang lambda func 
│   ├── redshift-sql                 -- redshift sql 
│   └── scripts                      -- local run test code by use aws sdk
├── test                             -- test cdk logic
</code></pre><h2 id="参考">参考</h2>
<p>sam cli <a href="https://docs.aws.amazon.com/zh_cn/serverless-application-model/latest/developerguide/serverless-sam-cli-using-invoke.html">local debug lambda</a></p>
<p>streaming cdk: <a href="https://github.com/aws-samples/streaming-solution-aws-cdk">https://github.com/aws-samples/streaming-solution-aws-cdk</a></p>
<p>kds and msk cdk: <a href="https://github.com/aws-solutions/streaming-data-solution-for-amazon-kinesis-and-amazon-msk">https://github.com/aws-solutions/streaming-data-solution-for-amazon-kinesis-and-amazon-msk</a></p>
<p>Redshift cdk : <a href="https://github.com/miztiik/redshift-demo">https://github.com/miztiik/redshift-demo</a></p>
<p>Glue cdk: <a href="https://github.com/aws-samples/glue-workflow-aws-cdk">https://github.com/aws-samples/glue-workflow-aws-cdk</a></p>
<p>opensearch cdk: <a href="https://www.luminis.eu/blog/cloud-en/deploying-a-secure-aws-elasticsearch-cluster-using-cdk/">https://www.luminis.eu/blog/cloud-en/deploying-a-secure-aws-elasticsearch-cluster-using-cdk/</a></p>
<p>mysql cdk: <a href="https://aws.amazon.com/cn/blogs/infrastructure-and-automation/use-aws-cdk-to-initialize-amazon-rds-instances/">https://aws.amazon.com/cn/blogs/infrastructure-and-automation/use-aws-cdk-to-initialize-amazon-rds-instances/</a></p>
<p>mysql dms cdk: <a href="https://aws.amazon.com/cn/blogs/database/accelerate-data-migration-using-aws-dms-and-aws-cdk/">https://aws.amazon.com/cn/blogs/database/accelerate-data-migration-using-aws-dms-and-aws-cdk/</a></p>
<p>aurora mysql dms kds opensearch cdk: <a href="https://github.com/aws-samples/aws-dms-cdc-data-pipeline.git">https://github.com/aws-samples/aws-dms-cdc-data-pipeline.git</a></p>
<p>kda-flink-py: <a href="https://aws.amazon.com/cn/blogs/china/python-stream-data-processing-and-analysis-using-pyflink-in-amazon-kinesis-data-analytics/">https://aws.amazon.com/cn/blogs/china/python-stream-data-processing-and-analysis-using-pyflink-in-amazon-kinesis-data-analytics/</a></p>
<p>kda-zeppelin-flink-py: <a href="https://aws.amazon.com/cn/blogs/big-data/query-your-data-streams-interactively-using-kinesis-data-analytics-studio-and-python/">https://aws.amazon.com/cn/blogs/big-data/query-your-data-streams-interactively-using-kinesis-data-analytics-studio-and-python/</a></p>
<p><strong><a href="https://docs.aws.amazon.com/pdfs/whitepapers/latest/microservices-on-aws/microservices-on-aws.pdf">Implementing Microservices on AWS</a></strong></p>
<p><strong><a href="https://d1.awsstatic.com/whitepapers/aws-cloud-data-ingestion-patterns-practices.pdf">AWS Cloud Data Ingestion Patterns and Practices</a></strong></p>
<p><a href="https://catalog.us-east-1.prod.workshops.aws/workshops/c342c6d1-2baf-4827-ba42-52ef9eb173f6/en-US/flink-on-kda">Flink-on-KDS Workshop</a></p>
<p><a href="https://catalog.us-east-1.prod.workshops.aws/workshops/2300137e-f2ac-4eb9-a4ac-3d25026b235f/en-US">Real time streaming with kinesis Workshop</a></p>
    </div>

    
    
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">weedge</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
      2022-11-02
      
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>


    
    

    <footer class="post-footer">
      <div class="post-tags">
          <a href="https://weedge.github.io/tags/aws/">aws</a>
          <a href="https://weedge.github.io/tags/%E6%96%B9%E6%A1%88/">方案</a>
          <a href="https://weedge.github.io/tags/%E5%85%A8%E6%A0%88/">全栈</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/let-ml-go/">
            
            <i class="iconfont">
              <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

            </i>
            <span class="prev-text nav-default">让ML跑起来</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        
          <a class="next" href="/post/shop/">
            <span class="next-text nav-default">全栈开发</span>
            <span class="prev-text nav-mobile">下一篇</span>
            
            <i class="iconfont">
              <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

            </i>
          </a>
      </nav>
    </footer>
  </article>

  
  

  
  

  

  
  

  

  

  

    

  

        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:weege007@gmail.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/weedge" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://weibo.com/weedge" rel="me noopener" class="iconfont"
      title="weibo"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M385.714286 733.714286q12-19.428571 6.285714-39.428571t-25.714286-28.571429q-19.428571-8-41.714286-0.571429t-34.285714 26.285714q-12.571429 19.428571-7.428571 39.142857t24.571429 28.857143 42.571429 1.428571 35.714286-27.142857zm53.714286-69.142857q4.571429-7.428571 2-15.142857t-10-10.571429q-8-2.857143-16.285714 2.857143t-12.285714 10.571429q-9.714286 17.714286 7.428571 25.714286 8 2.857143 16.571429 2.857143t12.571429-10.571429zm99.428571 61.142857q-25.714286 58.285714-90.285714 85.714286t-128 6.857143q-61.142857-19.428571-84.285714-72.285714t3.714286-107.142857q26.857143-53.142857 86.571429-79.428571t120.285714-10.857143q63.428571 16.571429 90.571429 68.285714t1.428571 108.857143zm178.285714-91.428571q-5.142857-54.857143-50.857143-97.142857t-119.142857-62.285714-156.857143-12q-127.428571 13.142857-211.142857 80.857143t-75.714286 151.142857q5.142857 54.857143 50.857143 97.142857t119.142857 62.285714 156.857143 12q127.428571-13.142857 211.142857-80.857143t75.714286-151.142857zm176 2.285714q0 38.857143-21.142857 79.714286t-62.285714 78.285714-96.285714 67.142857-129.142857 47.428571-154.571429 17.714286-157.142857-19.142857-137.428571-53.142857-98-86.285714-37.142857-114q0-65.714286 39.714286-140t112.857143-147.428571q96.571429-96.571429 195.142857-134.857143t140.857143 4q37.142857 36.571429 11.428571 119.428571-2.285714 8-0.571429 11.428571t5.714286 4 8.285714 2.857143 7.714286-2l3.428571-1.142857q79.428571-33.714286 140.571429-33.714286t87.428571 34.857143q25.714286 36 0 101.714286-1.142857 7.428571-2.571429 11.428571t2.571429 7.142857 6.857143 4.285714 9.714286 3.428571q32.571429 10.285714 58.857143 26.857143t45.714286 46.571429 19.428571 66.571429zm-42.285714-356.571429q24 26.857143 31.142857 62t-3.714286 67.142857q-4.571429 13.142857-16.857143 19.428571t-25.428571 2.285714q-13.142857-4.571429-19.428571-16.857143t-2.285714-25.428571q11.428571-36-13.714286-63.428571t-61.142857-20q-13.714286 2.857143-25.714286-4.571429t-14.285714-21.142857q-2.857143-13.714286 4.571429-25.428571t21.142857-14.571429q34.285714-7.428571 68 3.142857t57.714286 37.428571zm103.428571-93.142857q49.714286 54.857143 64.285714 127.142857t-7.714286 138q-5.142857 15.428571-19.428571 22.857143t-29.714286 2.285714-22.857143-19.428571-2.857143-29.714286q16-46.857143 5.714286-98.285714t-45.714286-90.285714q-35.428571-39.428571-84.571429-54.571429t-98.857143-4.857143q-16 3.428571-29.714286-5.428571t-17.142857-24.857143 5.428571-29.428571 24.857143-16.857143q70.285714-14.857143 139.428571 6.571429t118.857143 76.857143z"></path>
</svg>

    </a>


<a href="https://weedge.github.io/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
   
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2013 -
    2022
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        weedge
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  















</body>
</html>

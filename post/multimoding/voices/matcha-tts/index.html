<!DOCTYPE html>
<html lang="zh-cn" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>论文解读 Matcha-TTS: A fast TTS architecture with conditional flow matching - 时间飘过</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="weedge" />
  <meta name="description" content="🍵 matcha-tts  2024.1 Matcha-TTS: A fast TTS architecture with conditional flow matching | paper code  摘要： 一种用于快速 TTS 声学建模的新编码器-解码器架构，使用最佳传输条件流匹配 (OT-CFM) 进行训练。与使用分数匹配训练的模型相比，这产生了基于 ODE 的解码器，能够以更少的合成步骤实现高输出质量。仔细的设计选择还确保每个合成步骤都能快速运行。该方法是概率性的、非自回归的，并且无需外部对齐即可从头开始学习说话。与强大的预训练基线模型相比，Matcha-TTS 系统具有最小的内存占用，可以与长语音上最快的模型相媲美，并在听力测试中获得最高的平均意见得分。
一种非自回归神经 TTS 的新方法，它使用条件流匹配(CFM from 2022.10 Flow Matching for Generative Modeling)（类似于校正流(Rectified Flow 2022.9 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow）来加速基于 ODE 的语音合成。
 Is probabilistic 是概率性的 Has compact memory footprint 具有紧凑的内存占用 Sounds highly natural 听起来非常自然 Is very fast to synthesise from 合成速度非常快  简洁的结构，训练推理快，使用更少额内存空间，
一种基于连续归一化流的概率性、非自回归、快速采样的 TTS 声学模型。主要有两个创新点：
 提出了一种改进的编码器-解码器 TTS 结构，该结构在解码器中结合使用 1D CNN 和 Transformer。这减少了内存消耗并且可以快速评估，从而提高综合速度。 使用最优传输条件流匹配 optimal-transport conditional flow matching(OT-CFM) 来训练这些模型，这是一种学习从数据分布中采样的 ODE 的新方法。与传统的 连续时间归一化流 CNF（continuous-time normalising flows ） 和分数匹配概率流 ODE （probability flow ODE） 相比，OT-CFM 定义了从源到目标的更简单的路径，从而能够以比 DPM（Diffusion probabilistic model） 更少的步骤进行准确合成。  实验结果表明，这两种创新都加速了合成，减少了速度和合成质量之间的权衡。尽管速度快且轻量级，Matcha-TTS能够在不需要外部对齐器的情况下学习说话和对齐。与强大的预训练基线模型相比，Matcha-TTS实现了快速合成，并获得了更好的自然度评分。
 附：
 使用LJ Speech数据集训练202 epochs 的ckpt: https://huggingface.co/weege007/matchaTTS/tree/main 笔记地址：https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb " />

  <meta name="keywords" content="工作, 技术, 生活" />






<meta name="generator" content="Hugo 0.91.0" />


<link rel="canonical" href="https://weedge.github.io/post/multimoding/voices/matcha-tts/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css" integrity="sha256-&#43;ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media="screen" crossorigin="anonymous">




<link rel="stylesheet" href="/css/copy-to-clipboard.css">


<meta property="og:title" content="论文解读 Matcha-TTS: A fast TTS architecture with conditional flow matching" />
<meta property="og:description" content="🍵 matcha-tts

2024.1 Matcha-TTS: A fast TTS architecture with conditional flow matching | paper code

摘要：
一种用于快速 TTS 声学建模的新编码器-解码器架构，使用最佳传输条件流匹配 (OT-CFM) 进行训练。与使用分数匹配训练的模型相比，这产生了基于 ODE 的解码器，能够以更少的合成步骤实现高输出质量。仔细的设计选择还确保每个合成步骤都能快速运行。该方法是概率性的、非自回归的，并且无需外部对齐即可从头开始学习说话。与强大的预训练基线模型相比，Matcha-TTS 系统具有最小的内存占用，可以与长语音上最快的模型相媲美，并在听力测试中获得最高的平均意见得分。
一种非自回归神经 TTS 的新方法，它使用条件流匹配(CFM from 2022.10 Flow Matching for Generative Modeling)（类似于校正流(Rectified Flow 2022.9 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow）来加速基于 ODE 的语音合成。

Is probabilistic  是概率性的
Has compact memory footprint 具有紧凑的内存占用
Sounds highly natural  听起来非常自然
Is very fast to synthesise from 合成速度非常快

简洁的结构，训练推理快，使用更少额内存空间，
一种基于连续归一化流的概率性、非自回归、快速采样的 TTS 声学模型。主要有两个创新点：

提出了一种改进的编码器-解码器 TTS 结构，该结构在解码器中结合使用 1D CNN 和 Transformer。这减少了内存消耗并且可以快速评估，从而提高综合速度。
使用最优传输条件流匹配 optimal-transport conditional flow matching(OT-CFM) 来训练这些模型，这是一种学习从数据分布中采样的 ODE 的新方法。与传统的 连续时间归一化流 CNF（continuous-time normalising flows ） 和分数匹配概率流 ODE （probability flow ODE） 相比，OT-CFM 定义了从源到目标的更简单的路径，从而能够以比 DPM（Diffusion probabilistic model） 更少的步骤进行准确合成。

实验结果表明，这两种创新都加速了合成，减少了速度和合成质量之间的权衡。尽管速度快且轻量级，Matcha-TTS能够在不需要外部对齐器的情况下学习说话和对齐。与强大的预训练基线模型相比，Matcha-TTS实现了快速合成，并获得了更好的自然度评分。

附：

使用LJ Speech数据集训练202 epochs 的ckpt: https://huggingface.co/weege007/matchaTTS/tree/main
笔记地址：https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://weedge.github.io/post/multimoding/voices/matcha-tts/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2025-01-14T10:26:23+08:00" />
<meta property="article:modified_time" content="2025-01-14T10:26:23+08:00" />

<meta itemprop="name" content="论文解读 Matcha-TTS: A fast TTS architecture with conditional flow matching">
<meta itemprop="description" content="🍵 matcha-tts

2024.1 Matcha-TTS: A fast TTS architecture with conditional flow matching | paper code

摘要：
一种用于快速 TTS 声学建模的新编码器-解码器架构，使用最佳传输条件流匹配 (OT-CFM) 进行训练。与使用分数匹配训练的模型相比，这产生了基于 ODE 的解码器，能够以更少的合成步骤实现高输出质量。仔细的设计选择还确保每个合成步骤都能快速运行。该方法是概率性的、非自回归的，并且无需外部对齐即可从头开始学习说话。与强大的预训练基线模型相比，Matcha-TTS 系统具有最小的内存占用，可以与长语音上最快的模型相媲美，并在听力测试中获得最高的平均意见得分。
一种非自回归神经 TTS 的新方法，它使用条件流匹配(CFM from 2022.10 Flow Matching for Generative Modeling)（类似于校正流(Rectified Flow 2022.9 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow）来加速基于 ODE 的语音合成。

Is probabilistic  是概率性的
Has compact memory footprint 具有紧凑的内存占用
Sounds highly natural  听起来非常自然
Is very fast to synthesise from 合成速度非常快

简洁的结构，训练推理快，使用更少额内存空间，
一种基于连续归一化流的概率性、非自回归、快速采样的 TTS 声学模型。主要有两个创新点：

提出了一种改进的编码器-解码器 TTS 结构，该结构在解码器中结合使用 1D CNN 和 Transformer。这减少了内存消耗并且可以快速评估，从而提高综合速度。
使用最优传输条件流匹配 optimal-transport conditional flow matching(OT-CFM) 来训练这些模型，这是一种学习从数据分布中采样的 ODE 的新方法。与传统的 连续时间归一化流 CNF（continuous-time normalising flows ） 和分数匹配概率流 ODE （probability flow ODE） 相比，OT-CFM 定义了从源到目标的更简单的路径，从而能够以比 DPM（Diffusion probabilistic model） 更少的步骤进行准确合成。

实验结果表明，这两种创新都加速了合成，减少了速度和合成质量之间的权衡。尽管速度快且轻量级，Matcha-TTS能够在不需要外部对齐器的情况下学习说话和对齐。与强大的预训练基线模型相比，Matcha-TTS实现了快速合成，并获得了更好的自然度评分。

附：

使用LJ Speech数据集训练202 epochs 的ckpt: https://huggingface.co/weege007/matchaTTS/tree/main
笔记地址：https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb
"><meta itemprop="datePublished" content="2025-01-14T10:26:23+08:00" />
<meta itemprop="dateModified" content="2025-01-14T10:26:23+08:00" />
<meta itemprop="wordCount" content="3465">
<meta itemprop="keywords" content="diffusion,flow,NAR,mel-spectrogram," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="论文解读 Matcha-TTS: A fast TTS architecture with conditional flow matching"/>
<meta name="twitter:description" content="🍵 matcha-tts

2024.1 Matcha-TTS: A fast TTS architecture with conditional flow matching | paper code

摘要：
一种用于快速 TTS 声学建模的新编码器-解码器架构，使用最佳传输条件流匹配 (OT-CFM) 进行训练。与使用分数匹配训练的模型相比，这产生了基于 ODE 的解码器，能够以更少的合成步骤实现高输出质量。仔细的设计选择还确保每个合成步骤都能快速运行。该方法是概率性的、非自回归的，并且无需外部对齐即可从头开始学习说话。与强大的预训练基线模型相比，Matcha-TTS 系统具有最小的内存占用，可以与长语音上最快的模型相媲美，并在听力测试中获得最高的平均意见得分。
一种非自回归神经 TTS 的新方法，它使用条件流匹配(CFM from 2022.10 Flow Matching for Generative Modeling)（类似于校正流(Rectified Flow 2022.9 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow）来加速基于 ODE 的语音合成。

Is probabilistic  是概率性的
Has compact memory footprint 具有紧凑的内存占用
Sounds highly natural  听起来非常自然
Is very fast to synthesise from 合成速度非常快

简洁的结构，训练推理快，使用更少额内存空间，
一种基于连续归一化流的概率性、非自回归、快速采样的 TTS 声学模型。主要有两个创新点：

提出了一种改进的编码器-解码器 TTS 结构，该结构在解码器中结合使用 1D CNN 和 Transformer。这减少了内存消耗并且可以快速评估，从而提高综合速度。
使用最优传输条件流匹配 optimal-transport conditional flow matching(OT-CFM) 来训练这些模型，这是一种学习从数据分布中采样的 ODE 的新方法。与传统的 连续时间归一化流 CNF（continuous-time normalising flows ） 和分数匹配概率流 ODE （probability flow ODE） 相比，OT-CFM 定义了从源到目标的更简单的路径，从而能够以比 DPM（Diffusion probabilistic model） 更少的步骤进行准确合成。

实验结果表明，这两种创新都加速了合成，减少了速度和合成质量之间的权衡。尽管速度快且轻量级，Matcha-TTS能够在不需要外部对齐器的情况下学习说话和对齐。与强大的预训练基线模型相比，Matcha-TTS实现了快速合成，并获得了更好的自然度评分。

附：

使用LJ Speech数据集训练202 epochs 的ckpt: https://huggingface.co/weege007/matchaTTS/tree/main
笔记地址：https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb
"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->



<script>
  MathJax = {
    tex: {
      inlineMath: [["$", "$"]],
    },
    displayMath: [
      ["$$", "$$"],
      ["\[\[", "\]\]"],
    ],
    svg: {
      fontCache: "global",
    },
  };
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
></script>





</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">时间飘过</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/tags/">标签</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/categories/">分类</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/about/">About</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/perf-book-cn/zh/" rel="noopener" target="_blank">
              《现代CPU性能分析与优化》
              
              <i class="iconfont">
                <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92 0 0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"></path>
  <path d="M841.152 457.152c-30.528 0-54.784 24.512-54.784 54.656l0 274.752L237.696 786.56 237.696 237.696l206.016 0c6.656 0 10.752 0 13.248 0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128L183.04 128C153.216 128 128 152.576 128 182.848c0 3.136 0.256 6.272 0.768 9.28C128.256 195.136 128 198.272 128 201.408l0 639.488c0 0.064 0 0.192 0 0.256 0 0.128 0 0.192 0 0.32 0 30.528 24.512 54.784 54.784 54.784l646.976 0c6.592 0 9.728 0 11.712 0 28.736 0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344l0-20.352L896 561.408 896 512.128C896 481.792 871.424 457.152 841.152 457.152z"></path>
</svg>

              </i>
            </a>
          
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/" class="logo">
    
      时间飘过
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/tags/">标签</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/categories/">分类</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/about/">About</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/perf-book-cn/zh/" rel="noopener" target="_blank">
              《现代CPU性能分析与优化》
              
              <i class="iconfont">
                <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92 0 0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"></path>
  <path d="M841.152 457.152c-30.528 0-54.784 24.512-54.784 54.656l0 274.752L237.696 786.56 237.696 237.696l206.016 0c6.656 0 10.752 0 13.248 0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128L183.04 128C153.216 128 128 152.576 128 182.848c0 3.136 0.256 6.272 0.768 9.28C128.256 195.136 128 198.272 128 201.408l0 639.488c0 0.064 0 0.192 0 0.256 0 0.128 0 0.192 0 0.32 0 30.528 24.512 54.784 54.784 54.784l646.976 0c6.592 0 9.728 0 11.712 0 28.736 0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344l0-20.352L896 561.408 896 512.128C896 481.792 871.424 457.152 841.152 457.152z"></path>
</svg>

              </i>
            </a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">论文解读 Matcha-TTS: A fast TTS architecture with conditional flow matching</h1>
      
      <div class="post-meta">
        <time datetime="2025-01-14" class="post-time">
          2025-01-14
        </time>
        <div class="post-category">
            <a href="https://weedge.github.io/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
            <a href="https://weedge.github.io/categories/tts/"> TTS </a>
            
          </div>
        

        
        

        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#text-encoder-文本编码器">Text encoder 文本编码器</a></li>
    <li><a href="#duration-predictor-持续时间预测器">Duration predictor 持续时间预测器</a></li>
    <li><a href="#decoder-the-flow-prediction-network-流预测网络">Decoder (the Flow-prediction network 流预测网络)</a></li>
    <li><a href="#optimal-transport-conditional-flow-matching-最优传输条件流匹配">Optimal-transport conditional flow matching 最优传输条件流匹配</a></li>
  </ul>

  <ul>
    <li><a href="#训练数据集">训练数据集：</a></li>
    <li><a href="#对比开源模型">对比开源模型</a></li>
    <li><a href="#对比评估">对比评估</a></li>
  </ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <h1 id="-matcha-tts">🍵 matcha-tts</h1>
<ul>
<li><a href="https://arxiv.org/abs/2309.03199">2024.1 <strong>Matcha-TTS: A fast TTS architecture with conditional flow matching</strong></a> | <a href="https://github.com/shivammehta25/Matcha-TTS">paper code</a></li>
</ul>
<h1 id="摘要">摘要：</h1>
<p>一种用于快速 TTS 声学建模的新编码器-解码器架构，使用最佳传输条件流匹配 (OT-CFM) 进行训练。与使用分数匹配训练的模型相比，这产生了基于 ODE 的解码器，能够以更少的合成步骤实现高输出质量。仔细的设计选择还确保每个合成步骤都能快速运行。该方法是概率性的、非自回归的，并且无需外部对齐即可从头开始学习说话。与强大的预训练基线模型相比，Matcha-TTS 系统具有最小的内存占用，可以与长语音上最快的模型相媲美，并在听力测试中获得最高的平均意见得分。</p>
<p>一种非自回归神经 TTS 的新方法，它使用条件流匹配(CFM from <a href="https://arxiv.org/abs/2210.02747">2022.10 <strong>Flow Matching for Generative Modeling</strong></a>)（类似于校正流(Rectified Flow <a href="https://arxiv.org/abs/2209.03003">2022.9 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow</a>）来加速基于 ODE 的语音合成。</p>
<ul>
<li>Is probabilistic  是概率性的</li>
<li>Has compact memory footprint 具有紧凑的内存占用</li>
<li>Sounds highly natural  听起来非常自然</li>
<li>Is very fast to synthesise from 合成速度非常快</li>
</ul>
<p>简洁的结构，训练推理快，使用更少额内存空间，</p>
<p>一种基于连续归一化流的概率性、非自回归、快速采样的 TTS 声学模型。主要有两个创新点：</p>
<ol>
<li>提出了一种改进的编码器-解码器 TTS 结构，该结构在解码器中结合使用 1D CNN 和 Transformer。这减少了内存消耗并且可以快速评估，从而提高综合速度。</li>
<li>使用最优传输条件流匹配 optimal-transport conditional flow matching(OT-CFM) 来训练这些模型，这是一种学习从数据分布中采样的 ODE 的新方法。与传统的 连续时间归一化流 CNF（continuous-time normalising flows ） 和分数匹配概率流 ODE （probability flow ODE） 相比，OT-CFM 定义了从源到目标的更简单的路径，从而能够以比 DPM（Diffusion probabilistic model） 更少的步骤进行准确合成。</li>
</ol>
<p>实验结果表明，这两种创新都加速了合成，减少了速度和合成质量之间的权衡。尽管速度快且轻量级，Matcha-TTS能够在不需要外部对齐器的情况下学习说话和对齐。与强大的预训练基线模型相比，Matcha-TTS实现了快速合成，并获得了更好的自然度评分。</p>
<hr>
<p><strong>附</strong>：</p>
<ul>
<li>使用LJ Speech数据集训练202 epochs 的ckpt: <a href="https://huggingface.co/weege007/matchaTTS/tree/main">https://huggingface.co/weege007/matchaTTS/tree/main</a></li>
<li>笔记地址：https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb</li>
</ul>
<h1 id="结构">结构：</h1>
<p>Matcha-TTS 是一种非自回归的神经文本到语音（TTS）编码器-解码器结构。其结构的概述在图1中提供。文本编码器和时长预测器结构和Grad-TTS一致，但Text encoder使用旋转位置嵌入而不是相对位置嵌入。对齐和时长模型训练遵循MAS和先验损失  $\mathcal{L}_{enc}$ ，如Grad-TTS中所述。预测的时长，经过向上取整后，用于上采样（复制）编码器输出的向量，以获得 $\mu$ ，即在给定文本和所选时长的情况下预测的平均声学特征（例如，梅尔频谱图）。这个平均值用于条件化解码器，解码器预测用于合成的向量场 $v_{t}\left(\phi_{t}^{OT}\left(x_{0}\right)\mid\mu;\theta\right)$，但它并不用作初始噪声样本 $x_0$ 的均值（与Grad-TTS不同）。最终通过vocoder(HiFi-GAN Generator)生成waveform</p>
<p><img src="https://github.com/user-attachments/assets/50e1e3ad-7181-41a5-8cc2-6d6c62473065" alt="image"></p>
<h2 id="text-encoder-文本编码器">Text encoder 文本编码器</h2>
<p>位置编码使用 RoPE embedding 而不是相对位置 relative embedding, 和Grad-TTS中Text encoder 相同的超参数</p>
<ul>
<li>来自 <a href="https://arxiv.org/abs/2005.11129">2020. <strong>Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search</strong></a></li>
<li>来自 <a href="https://arxiv.org/abs/2105.06337">2021. <strong>Grad-TTS: A diffusion probabilistic model for text-to-speech</strong></a></li>
</ul>
<h2 id="duration-predictor-持续时间预测器">Duration predictor 持续时间预测器</h2>
<p>和Grad-TTS中Duration predictor 相同的超参数</p>
<ul>
<li>来自 <a href="https://arxiv.org/abs/2005.11129">2020. <strong>Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search</strong></a></li>
<li>来自 <a href="https://arxiv.org/abs/2105.06337">2021. <strong>Grad-TTS: A diffusion probabilistic model for text-to-speech</strong></a></li>
</ul>
<h2 id="decoder-the-flow-prediction-network-流预测网络">Decoder (the Flow-prediction network 流预测网络)</h2>
<p>使用两个下采样块，然后是两个中采样块和两个上采样块，如图 2 所示。每个块都有一个 Transformer 层，隐藏维度为 256、2 个头、注意力维度为 64，并且使用snake 激活函数。</p>
<p><img src="https://github.com/user-attachments/assets/5c50f129-e7bf-427e-aa75-cfd01f6b089b" alt="image"></p>
<ul>
<li>
<p>受LDM <a href="https://arxiv.org/abs/2112.10752">2021. High-resolution image synthesis with latent diffusion models</a>的启发,一个包含 1D 卷积残差块的 U-Net，用于对输入进行下采样和上采样，并具有流匹配步骤 t∈[0,1] 嵌入, 每个残差块后面都有一个 Transformer块，其前馈网络使用 snake 激活函数，这些 Transformer 不使用任何位置嵌入，因为音素(phone)之间的位置信息已经由编码器嵌入，并且卷积和下采样操作用于在同一音素内的帧之间，插入这些信息并区分它们彼此的相对位置。与 Grad-TTS 使用的仅 2D 卷积 U-Net 相比，该解码器网络的评估速度明显更快，并且消耗的内存更少。</p>
</li>
<li>
<p>激活函数： snake active function 来自 <a href="https://arxiv.org/abs/2006.08195">2020. Neural networks fail to learn periodic functions and how to fix it</a> 和 <a href="https://arxiv.org/abs/2206.04658">2022. BigVGAN: A universal neural vocoder with large-scale training</a> 一样的使用方法</p>
</li>
<li>
<p>结构来自 <a href="https://arxiv.org/abs/2105.06337">2021. <strong>Grad-TTS: A diffusion probabilistic model for text-to-speech</strong></a></p>
</li>
</ul>
<h2 id="optimal-transport-conditional-flow-matching-最优传输条件流匹配">Optimal-transport conditional flow matching 最优传输条件流匹配</h2>
<p>在这一部分，首先介绍由向量场生成的概率密度路径，然后引入提出的方法中使用的最优传输条件流匹配（OT-CFM）目标。
设 $\mathbf{x}$ 表示数据空间 $\mathbb{R}^d$中的一个观测值，它从复杂且未知的数据分布 $q(\mathbf{x}) q(x)$ 中采样得到。一个概率密度路径是一个随时间变化的概率密度函数， $p_t: [0,1] \times \mathbb{R}^d \rightarrow \mathbb{R}^{&gt;0} pt:[0,1]×Rd→R&gt;0 $，其中 $t \in [0,1] t∈[0,1]$ ，
$p_0(\mathbf{x}) = \mathcal{N}(\mathbf{x}; \mathbf{0}, \mathbf{I})$ 是一个先验分布，使得 $p_1(\mathbf{x})$ 近似于数据分布 $q(\mathbf{x})$ 。
例如，连续时间归一化流（CNFs）首先定义一个向量场 $\mathbf{v}_t: [0,1] \times \mathbb{R}^d \rightarrow \mathbb{R}^d$ ，它通过下面的常微分方程（ODE）生成流 $\phi_t: [0,1] \times \mathbb{R}^d \rightarrow \mathbb{R}^d$ ：</p>
<p>$$
\frac{d}{dt} \phi_t(\mathbf{x}) = \mathbf{v}_t(\phi_t(\mathbf{x})) \quad ; \quad \phi_0(\mathbf{x}) = \mathbf{x}.
$$
这生成了路径 $p_t$ ，作为数据点的边际概率分布。我们可以通过解决方程（1）中的初值问题，从近似的数据分布 $p_1$ 中采样。 假设存在一个已知的向量场 $\mathbf{u}_t$ ，它从 $p_0$ 到 $p_1 \approx q$ 生成概率路径 $p_t$ 。流匹配损失定义为：</p>
<p>$$
\mathcal{L}_{\mathrm{FM}}(\theta) = \mathbb{E}_{t,p_t(\mathbf{x})} \left| \mathbf{u}_t(\mathbf{x}) - \mathbf{v}_t(\mathbf{x}; \theta) \right|^2,
$$
其中 $t \sim \mathbb{U}[0,1]$ 并且 $\mathbf{v}_t(\mathbf{x}; \theta)$ 是一个具有参数 $\theta$ 的神经网络。然而，流匹配在实践中是不可行的，因为获取向量场 $\mathbf{u}_t$ 和目标概率 $p_t$ 并非易事。因此，条件流匹配考虑的是：</p>
<p>$$
\mathcal{L}_{\mathrm{CFM}}(\theta) = \mathbb{E}_{t,q(\mathbf{x}_1),p_t(\mathbf{x} \mid \mathbf{x}_1)} \left| \mathbf{u}_t(\mathbf{x} \mid \mathbf{x}_1) - \mathbf{v}_t(\mathbf{x}; \theta) \right|^2.
$$</p>
<p>这替换了难以处理的边际概率密度和向量场，转而考虑条件概率密度和条件向量场。关键是，这些通常是可行的，并且有封闭形式的解决方案，而且可以证明 $\mathcal{L}_{\mathrm{CFM}}(\theta)$ 和 $\mathcal{L}_{\mathrm{FM}}(\theta)$ 在 $\theta$ 方面具有相同的梯度。</p>
<p>Matcha-TTS 使用最优传输条件流匹配（OT-CFM）进行训练，这是一种具有特别简单梯度的 CFM 变体。OT-CFM 损失函数可以写成：
$$
L(\theta)=\mathbb{E}_{t, q(x_{1}), p_{0}(x_{0})}\left|u_{t}^{OT}\left(\phi_{t}^{OT}(x)\mid x_{1}\right)-v_{t}\left(\phi_{t}^{OT}(x)\mid\mu;\theta\right)\right|^{2}, \quad
$$</p>
<p>定义 $\phi_{t}^{OT}(x)=(1-(1-\sigma_{\min}) t) x_{0}+t x_{1}$ 为从 $x_{0}$ 到 $x_{1}$ 的流，其中每个数据 $x_{1}$ 与一个随机样本 $x_{0}\sim\mathcal{N}(0, I)$ 匹配，其梯度向量场(其期望值是学习的目标) 则是 $u_{t}^{OT}\left(\phi_{t}^{OT}\left(x_{0}\right)\mid x_{1}\right)=x_{1}-(1-\sigma_{\min}) x_{0}$，它是线性的、时间不变的，并且只依赖于 $x_{0}$ 和 $x_{1}$ 。这些属性使得训练更简单、更快，生成更快，并且与 DPMs 相比性能更好。</p>
<p>在Matcha-TTS的情况下，$\mathbf{x}_1$ 是声学帧，而 $\boldsymbol{\mu}$ 是从文本预测的这些帧的条件均值，使用下一部分描述的架构。 $\sigma_{\min}$ 是一个具有很小值（在我们的实验中为1e-4）的超参数。</p>
<ul>
<li>来自 <a href="https://arxiv.org/abs/2210.02747">2022.10 Flow Matching for Generative Modeling</a></li>
</ul>
<h1 id="训练">训练</h1>
<p>常规数据集，论文中使用单人数据（LJ Speech），额外也用多人数据（VCTK）来训练；可以使用lhotse工具下载, 进行切分数据预处理，然后通过带有 espeak-ng 后端的phonemizer: <a href="https://github.com/bootphon/phonemizer">https://github.com/bootphon/phonemizer</a> 用于将输入字素（graphemes）转换为 IPA 音素（IPA phones），在 2 个 GPU 上训练了 500k 更新，批量大小为 32，学习率为 1e-4。</p>
<h2 id="训练数据集">训练数据集：</h2>
<ul>
<li><a href="https://keithito.com/LJ-Speech-Dataset/">LJ Speech</a></li>
<li><a href="https://datashare.ed.ac.uk/handle/10283/2651">VCTK</a></li>
</ul>
<h2 id="对比开源模型">对比开源模型</h2>
<ul>
<li><a href="https://arxiv.org/abs/2006.04558">2020. FastSpeech 2: Fast and High-Quality End-to-End Text to Speech</a> 一种快速非-概率声学模型 | <a href="https://github.com/ming024/FastSpeech2">非官方 code</a>， Matcha-TTS的论文中提到用，改为使用 Meta 的 <a href="https://github.com/facebookresearch/fairseq">https://github.com/facebookresearch/fairseq</a> 中的检查点（ckpt）?；</li>
<li><a href="https://arxiv.org/abs/2106.06103">2021.6 <strong>VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</strong></a> 一个具有离散时间归一化流的强大概率端对端 TTS 系统 | <a href="https://github.com/jaywalnut310/vits">paper code</a></li>
<li><a href="https://arxiv.org/abs/2105.06337">2021.5 Grad-TTS: A Diffusion Probabilistic Model for Text-to-Speech</a> 一种基于 DPM 的强大声学模型 | <a href="https://github.com/huawei-noah/Speech-Backbones/tree/main/Grad-TTS">paper code</a></li>
</ul>
<h2 id="对比评估">对比评估</h2>
<p>从内存使用量(模型参数)，推理速度，以及生成语音质量三个方面评估：</p>
<ul>
<li>所有系统训练期间（批量大小为 32 和 fp16）的参数数量和最大内存使用情况，使用内存小;</li>
<li>在训练系统之后，我们通过计算在测试集上合成时的实时因子（RTF）的平均值和标准差，以及将Whisper medium ASR系统应用于结果时的单词错误率（WER），来评估不同条件的合成速度和可理解性；</li>
<li>平均意见得分（MOS）听力测试(众包人工测试)，这个比较意义不大；</li>
<li>评估了不同模型的合成速度如何随着语句长度的增加而变化，通过使用GPT-2模型生成不同长度的180个句子，评估合成时间，对长句子合成更快；</li>
</ul>
<hr>
<p>结合作者以前的研究成果，都是在3090上进行训练，构造精简小而美的结构，满足基本要求(正常文本到语音)</p>
<ul>
<li><a href="https://arxiv.org/abs/2108.13320">2021.8 Neural HMMs are all you need (for high-quality attention-free TTS)</a> | <a href="https://github.com/shivammehta25/Neural-HMM">paper code</a></li>
<li><a href="https://arxiv.org/abs/2211.06892">2022.11 OverFlow: Putting flows on top of neural transducers for better TTS</a> | <a href="https://github.com/shivammehta25/OverFlow">paper code</a></li>
</ul>
<h1 id="总结">总结：</h1>
<p>论文实现的代码结构清晰，提炼的网络结构参数少，所需硬件成本不高，挺适合快速上手训练一个tts，然后根据需求和所要解决的实际问题，加入其他网络结构，再去推进升级。比如 VALL-E, Seed-TTS(非纯DiT结构)，CosyVoice 基于大语言模型（LLM）的文本转语音（TTS）成为主流，生成更加泛化(涌现),但是所需训练数据和模型网络参数大(scaling)，训练推理成本高(虽然有大量的推理优化工作)。 <a href="https://arxiv.org/abs/2407.05407">2024.7 CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</a> | <a href="https://arxiv.org/abs/2412.10117">2024.12 CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models</a> | <a href="https://github.com/FunAudioLLM/CosyVoice">paper code</a></p>
    </div>

    
    
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">weedge</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
      2025-01-14
      
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>


    
    

    <footer class="post-footer">
      <div class="post-tags">
          <a href="https://weedge.github.io/tags/diffusion/">diffusion</a>
          <a href="https://weedge.github.io/tags/flow/">flow</a>
          <a href="https://weedge.github.io/tags/nar/">NAR</a>
          <a href="https://weedge.github.io/tags/mel-spectrogram/">mel-spectrogram</a>
          
        </div>

      
      <nav class="post-nav">
        
        
          <a class="next" href="/post/multimoding/voices/vall-e-x/">
            <span class="next-text nav-default">论文解读： VALL-E 系列</span>
            <span class="prev-text nav-mobile">下一篇</span>
            
            <i class="iconfont">
              <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

            </i>
          </a>
      </nav>
    </footer>
  </article>

  
  

  
  

  

  
  

  

  

  <div class="disqus-comment">
  <div class="disqus-button" id="load_disqus" onclick="load_disqus()">
    显示 Disqus 评论
  </div>
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_config = function () {
      this.page.url = "https://weedge.github.io/post/multimoding/voices/matcha-tts/";
    };
    function load_disqus() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'weedge';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);

      $('#load_disqus').remove();
    };
  </script>
  <noscript>Please enable JavaScript to view the
    <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
  
  </div>

    

  

        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:weege007@gmail.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/weedge" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://weibo.com/weedge" rel="me noopener" class="iconfont"
      title="weibo"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M385.714286 733.714286q12-19.428571 6.285714-39.428571t-25.714286-28.571429q-19.428571-8-41.714286-0.571429t-34.285714 26.285714q-12.571429 19.428571-7.428571 39.142857t24.571429 28.857143 42.571429 1.428571 35.714286-27.142857zm53.714286-69.142857q4.571429-7.428571 2-15.142857t-10-10.571429q-8-2.857143-16.285714 2.857143t-12.285714 10.571429q-9.714286 17.714286 7.428571 25.714286 8 2.857143 16.571429 2.857143t12.571429-10.571429zm99.428571 61.142857q-25.714286 58.285714-90.285714 85.714286t-128 6.857143q-61.142857-19.428571-84.285714-72.285714t3.714286-107.142857q26.857143-53.142857 86.571429-79.428571t120.285714-10.857143q63.428571 16.571429 90.571429 68.285714t1.428571 108.857143zm178.285714-91.428571q-5.142857-54.857143-50.857143-97.142857t-119.142857-62.285714-156.857143-12q-127.428571 13.142857-211.142857 80.857143t-75.714286 151.142857q5.142857 54.857143 50.857143 97.142857t119.142857 62.285714 156.857143 12q127.428571-13.142857 211.142857-80.857143t75.714286-151.142857zm176 2.285714q0 38.857143-21.142857 79.714286t-62.285714 78.285714-96.285714 67.142857-129.142857 47.428571-154.571429 17.714286-157.142857-19.142857-137.428571-53.142857-98-86.285714-37.142857-114q0-65.714286 39.714286-140t112.857143-147.428571q96.571429-96.571429 195.142857-134.857143t140.857143 4q37.142857 36.571429 11.428571 119.428571-2.285714 8-0.571429 11.428571t5.714286 4 8.285714 2.857143 7.714286-2l3.428571-1.142857q79.428571-33.714286 140.571429-33.714286t87.428571 34.857143q25.714286 36 0 101.714286-1.142857 7.428571-2.571429 11.428571t2.571429 7.142857 6.857143 4.285714 9.714286 3.428571q32.571429 10.285714 58.857143 26.857143t45.714286 46.571429 19.428571 66.571429zm-42.285714-356.571429q24 26.857143 31.142857 62t-3.714286 67.142857q-4.571429 13.142857-16.857143 19.428571t-25.428571 2.285714q-13.142857-4.571429-19.428571-16.857143t-2.285714-25.428571q11.428571-36-13.714286-63.428571t-61.142857-20q-13.714286 2.857143-25.714286-4.571429t-14.285714-21.142857q-2.857143-13.714286 4.571429-25.428571t21.142857-14.571429q34.285714-7.428571 68 3.142857t57.714286 37.428571zm103.428571-93.142857q49.714286 54.857143 64.285714 127.142857t-7.714286 138q-5.142857 15.428571-19.428571 22.857143t-29.714286 2.285714-22.857143-19.428571-2.857143-29.714286q16-46.857143 5.714286-98.285714t-45.714286-90.285714q-35.428571-39.428571-84.571429-54.571429t-98.857143-4.857143q-16 3.428571-29.714286-5.428571t-17.142857-24.857143 5.428571-29.428571 24.857143-16.857143q70.285714-14.857143 139.428571 6.571429t118.857143 76.857143z"></path>
</svg>

    </a>


<a href="https://weedge.github.io/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
   
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2013 -
    2025
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        weedge
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  









  <script id="dsq-count-scr" src="//weedge.disqus.com/count.js" async></script>






  <script src="/js/copy-to-clipboard.js"></script>


</body>
</html>

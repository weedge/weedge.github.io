<!DOCTYPE html>
<html lang="zh-cn" itemscope itemtype="http://schema.org/WebPage">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>论文解读： VALL-E 系列 - 时间飘过</title>
  

<meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=yes"/>

<meta name="MobileOptimized" content="width"/>
<meta name="HandheldFriendly" content="true"/>


<meta name="applicable-device" content="pc,mobile">

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">

<meta name="mobile-web-app-capable" content="yes">

<meta name="author" content="weedge" />
  <meta name="description" content="前文讲到VITS，采用的端到端的NAR模型，这篇文章记录下微软提出的VALL-E系列，从 AR&#43;NAR 到 AR 模型的转变，以及后面MELLE引入的VAE和Mel-Spectorgram，将neural codec text speech LM (AR&#43;NAR Transformer Decoder) 转变为 autoregressive mel-spectrogram text speech LM (AR Transformer Decoder) ；由于LM生成的是mel-spectrogram 需要通过vocoder 转换成 waveform； 生成的内容采样模块：从top-p random sampling 变成 Latent Sampling潜在采样模块（思想源自VAE, 从预测的高斯分布中采样潜在嵌入，然后将其投影回频谱图空间）
VALL-E 系列 https://www.microsoft.com/en-us/research/project/vall-e-x/
Vall-E: https://ar5iv.labs.arxiv.org/html/2301.02111
具体来说，我们使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型（neural codec language model）（称为VALL-E ），并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 在预训练阶段，我们将 TTS 训练数据扩展到 60K 小时的英语语音，比现有系统大数百倍。 VALL-E具有情境学习功能，可用于合成高质量的个性化语音，只需对看不见的说话者进行 3 秒的注册录音作为声音提示。实验结果表明， VALL-E在语音自然度和说话人相似度方面显着优于最先进的零样本 TTS 系统。此外，我们发现VALL-E可以在合成时保留说话者的情感和声音提示的声学环境。
与之前的管道不同（例如，音素 → 梅尔谱图 → 波形）， VALL-E的管线是音素 → 离散码 → 波形。
VALL-E根据音素和声学代码提示生成与目标内容和说话者的声音相对应的离散音频编解码器代码。 VALL-E直接支持各种语音合成应用，例如零样本 TTS、语音编辑以及与 GPT-3 等其他生成式 AI 模型相结合的内容创建。
VALL-E系列：2023年的1月份开始 - 2024年的7月份
 VALL-E 使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型，并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 VALL-E 具有情境学习功能，可用于合成高质量的个性化语音，只需录制未见过的讲话者的 3 秒注册录音作为提示。在语音自然度和说话人相似度方面，VALL-E 显着优于最先进的零样本 TTS 系统。此外，VALL-E可以在合成时保留说话者的情绪和声音提示的声学环境。 VALL-E X 扩展其能力，适应多语言场景，促进跨语言零样本 TTS。 VALL-E R 引入了音素单调对齐策略，增强了语音生成的鲁棒性。 VALL-E 2 通过集成重复感知采样和分组代码建模技术， 实现了一个突破性的里程碑：在 LibriSpeech 和 VCTK 数据集上的零样本 TTS 性能与人类相当。这标志着此类成就的首次实例，为该领域树立了新标准。 MELLE 是一种新颖的基于连续值标记的语言建模方法，用于文本到语音合成 (TTS)。 MELLE 直接从文本条件自回归生成连续的梅尔频谱图帧，绕过了矢量量化的需要，矢量量化最初是为音频压缩而设计的，与梅尔频谱图相比，牺牲了保真度。 " />

  <meta name="keywords" content="工作, 技术, 生活" />






<meta name="generator" content="Hugo 0.91.0" />


<link rel="canonical" href="https://weedge.github.io/post/multimoding/voices/vall-e-x/" />





<link rel="icon" href="/favicon.ico" />











<link rel="stylesheet" href="/sass/jane.min.fa4b2b9f31b5c6d0b683db81157a9226e17b06e61911791ab547242a4a0556f2.css" integrity="sha256-&#43;ksrnzG1xtC2g9uBFXqSJuF7BuYZEXkatUckKkoFVvI=" media="screen" crossorigin="anonymous">




<link rel="stylesheet" href="/css/copy-to-clipboard.css">


<meta property="og:title" content="论文解读： VALL-E 系列" />
<meta property="og:description" content="前文讲到VITS，采用的端到端的NAR模型，这篇文章记录下微软提出的VALL-E系列，从 AR&#43;NAR 到 AR 模型的转变，以及后面MELLE引入的VAE和Mel-Spectorgram，将neural codec text speech LM (AR&#43;NAR Transformer Decoder) 转变为  autoregressive  mel-spectrogram text speech LM  (AR Transformer Decoder) ；由于LM生成的是mel-spectrogram 需要通过vocoder 转换成 waveform； 生成的内容采样模块：从top-p random sampling 变成 Latent Sampling潜在采样模块（思想源自VAE, 从预测的高斯分布中采样潜在嵌入，然后将其投影回频谱图空间）
VALL-E 系列
https://www.microsoft.com/en-us/research/project/vall-e-x/
Vall-E: https://ar5iv.labs.arxiv.org/html/2301.02111
具体来说，我们使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型（neural codec language model）（称为VALL-E ），并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 在预训练阶段，我们将 TTS 训练数据扩展到 60K 小时的英语语音，比现有系统大数百倍。 VALL-E具有情境学习功能，可用于合成高质量的个性化语音，只需对看不见的说话者进行 3 秒的注册录音作为声音提示。实验结果表明， VALL-E在语音自然度和说话人相似度方面显着优于最先进的零样本 TTS 系统。此外，我们发现VALL-E可以在合成时保留说话者的情感和声音提示的声学环境。
与之前的管道不同（例如，音素 → 梅尔谱图 → 波形）， VALL-E的管线是音素 → 离散码 → 波形。
VALL-E根据音素和声学代码提示生成与目标内容和说话者的声音相对应的离散音频编解码器代码。 VALL-E直接支持各种语音合成应用，例如零样本 TTS、语音编辑以及与 GPT-3 等其他生成式 AI 模型相结合的内容创建。
VALL-E系列：2023年的1月份开始 - 2024年的7月份

VALL-E 使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型，并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 VALL-E 具有情境学习功能，可用于合成高质量的个性化语音，只需录制未见过的讲话者的 3 秒注册录音作为提示。在语音自然度和说话人相似度方面，VALL-E 显着优于最先进的零样本 TTS 系统。此外，VALL-E可以在合成时保留说话者的情绪和声音提示的声学环境。
VALL-E X 扩展其能力，适应多语言场景，促进跨语言零样本 TTS。
VALL-E R 引入了音素单调对齐策略，增强了语音生成的鲁棒性。
VALL-E 2 通过集成重复感知采样和分组代码建模技术， 实现了一个突破性的里程碑：在 LibriSpeech 和 VCTK 数据集上的零样本 TTS 性能与人类相当。这标志着此类成就的首次实例，为该领域树立了新标准。
MELLE 是一种新颖的基于连续值标记的语言建模方法，用于文本到语音合成 (TTS)。 MELLE 直接从文本条件自回归生成连续的梅尔频谱图帧，绕过了矢量量化的需要，矢量量化最初是为音频压缩而设计的，与梅尔频谱图相比，牺牲了保真度。
" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://weedge.github.io/post/multimoding/voices/vall-e-x/" /><meta property="article:section" content="post" />
<meta property="article:published_time" content="2025-01-13T10:26:23+08:00" />
<meta property="article:modified_time" content="2025-01-13T10:26:23+08:00" />

<meta itemprop="name" content="论文解读： VALL-E 系列">
<meta itemprop="description" content="前文讲到VITS，采用的端到端的NAR模型，这篇文章记录下微软提出的VALL-E系列，从 AR&#43;NAR 到 AR 模型的转变，以及后面MELLE引入的VAE和Mel-Spectorgram，将neural codec text speech LM (AR&#43;NAR Transformer Decoder) 转变为  autoregressive  mel-spectrogram text speech LM  (AR Transformer Decoder) ；由于LM生成的是mel-spectrogram 需要通过vocoder 转换成 waveform； 生成的内容采样模块：从top-p random sampling 变成 Latent Sampling潜在采样模块（思想源自VAE, 从预测的高斯分布中采样潜在嵌入，然后将其投影回频谱图空间）
VALL-E 系列
https://www.microsoft.com/en-us/research/project/vall-e-x/
Vall-E: https://ar5iv.labs.arxiv.org/html/2301.02111
具体来说，我们使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型（neural codec language model）（称为VALL-E ），并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 在预训练阶段，我们将 TTS 训练数据扩展到 60K 小时的英语语音，比现有系统大数百倍。 VALL-E具有情境学习功能，可用于合成高质量的个性化语音，只需对看不见的说话者进行 3 秒的注册录音作为声音提示。实验结果表明， VALL-E在语音自然度和说话人相似度方面显着优于最先进的零样本 TTS 系统。此外，我们发现VALL-E可以在合成时保留说话者的情感和声音提示的声学环境。
与之前的管道不同（例如，音素 → 梅尔谱图 → 波形）， VALL-E的管线是音素 → 离散码 → 波形。
VALL-E根据音素和声学代码提示生成与目标内容和说话者的声音相对应的离散音频编解码器代码。 VALL-E直接支持各种语音合成应用，例如零样本 TTS、语音编辑以及与 GPT-3 等其他生成式 AI 模型相结合的内容创建。
VALL-E系列：2023年的1月份开始 - 2024年的7月份

VALL-E 使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型，并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 VALL-E 具有情境学习功能，可用于合成高质量的个性化语音，只需录制未见过的讲话者的 3 秒注册录音作为提示。在语音自然度和说话人相似度方面，VALL-E 显着优于最先进的零样本 TTS 系统。此外，VALL-E可以在合成时保留说话者的情绪和声音提示的声学环境。
VALL-E X 扩展其能力，适应多语言场景，促进跨语言零样本 TTS。
VALL-E R 引入了音素单调对齐策略，增强了语音生成的鲁棒性。
VALL-E 2 通过集成重复感知采样和分组代码建模技术， 实现了一个突破性的里程碑：在 LibriSpeech 和 VCTK 数据集上的零样本 TTS 性能与人类相当。这标志着此类成就的首次实例，为该领域树立了新标准。
MELLE 是一种新颖的基于连续值标记的语言建模方法，用于文本到语音合成 (TTS)。 MELLE 直接从文本条件自回归生成连续的梅尔频谱图帧，绕过了矢量量化的需要，矢量量化最初是为音频压缩而设计的，与梅尔频谱图相比，牺牲了保真度。
"><meta itemprop="datePublished" content="2025-01-13T10:26:23+08:00" />
<meta itemprop="dateModified" content="2025-01-13T10:26:23+08:00" />
<meta itemprop="wordCount" content="2510">
<meta itemprop="keywords" content="encodec,AR,NAR,VALL-E,mel-spectrogram," /><meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="论文解读： VALL-E 系列"/>
<meta name="twitter:description" content="前文讲到VITS，采用的端到端的NAR模型，这篇文章记录下微软提出的VALL-E系列，从 AR&#43;NAR 到 AR 模型的转变，以及后面MELLE引入的VAE和Mel-Spectorgram，将neural codec text speech LM (AR&#43;NAR Transformer Decoder) 转变为  autoregressive  mel-spectrogram text speech LM  (AR Transformer Decoder) ；由于LM生成的是mel-spectrogram 需要通过vocoder 转换成 waveform； 生成的内容采样模块：从top-p random sampling 变成 Latent Sampling潜在采样模块（思想源自VAE, 从预测的高斯分布中采样潜在嵌入，然后将其投影回频谱图空间）
VALL-E 系列
https://www.microsoft.com/en-us/research/project/vall-e-x/
Vall-E: https://ar5iv.labs.arxiv.org/html/2301.02111
具体来说，我们使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型（neural codec language model）（称为VALL-E ），并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 在预训练阶段，我们将 TTS 训练数据扩展到 60K 小时的英语语音，比现有系统大数百倍。 VALL-E具有情境学习功能，可用于合成高质量的个性化语音，只需对看不见的说话者进行 3 秒的注册录音作为声音提示。实验结果表明， VALL-E在语音自然度和说话人相似度方面显着优于最先进的零样本 TTS 系统。此外，我们发现VALL-E可以在合成时保留说话者的情感和声音提示的声学环境。
与之前的管道不同（例如，音素 → 梅尔谱图 → 波形）， VALL-E的管线是音素 → 离散码 → 波形。
VALL-E根据音素和声学代码提示生成与目标内容和说话者的声音相对应的离散音频编解码器代码。 VALL-E直接支持各种语音合成应用，例如零样本 TTS、语音编辑以及与 GPT-3 等其他生成式 AI 模型相结合的内容创建。
VALL-E系列：2023年的1月份开始 - 2024年的7月份

VALL-E 使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型，并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 VALL-E 具有情境学习功能，可用于合成高质量的个性化语音，只需录制未见过的讲话者的 3 秒注册录音作为提示。在语音自然度和说话人相似度方面，VALL-E 显着优于最先进的零样本 TTS 系统。此外，VALL-E可以在合成时保留说话者的情绪和声音提示的声学环境。
VALL-E X 扩展其能力，适应多语言场景，促进跨语言零样本 TTS。
VALL-E R 引入了音素单调对齐策略，增强了语音生成的鲁棒性。
VALL-E 2 通过集成重复感知采样和分组代码建模技术， 实现了一个突破性的里程碑：在 LibriSpeech 和 VCTK 数据集上的零样本 TTS 性能与人类相当。这标志着此类成就的首次实例，为该领域树立了新标准。
MELLE 是一种新颖的基于连续值标记的语言建模方法，用于文本到语音合成 (TTS)。 MELLE 直接从文本条件自回归生成连续的梅尔频谱图帧，绕过了矢量量化的需要，矢量量化最初是为音频压缩而设计的，与梅尔频谱图相比，牺牲了保真度。
"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->



<script>
  MathJax = {
    tex: {
      inlineMath: [["$", "$"]],
    },
    displayMath: [
      ["$$", "$$"],
      ["\[\[", "\]\]"],
    ],
    svg: {
      fontCache: "global",
    },
  };
</script>
<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script
  id="MathJax-script"
  async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"
></script>





</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="/" class="logo">时间飘过</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/">主页</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/post/">归档</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/tags/">标签</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/categories/">分类</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/about/">About</a>
          
        
      </li><li class="mobile-menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/perf-book-cn/zh/" rel="noopener" target="_blank">
              《现代CPU性能分析与优化》
              
              <i class="iconfont">
                <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92 0 0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"></path>
  <path d="M841.152 457.152c-30.528 0-54.784 24.512-54.784 54.656l0 274.752L237.696 786.56 237.696 237.696l206.016 0c6.656 0 10.752 0 13.248 0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128L183.04 128C153.216 128 128 152.576 128 182.848c0 3.136 0.256 6.272 0.768 9.28C128.256 195.136 128 198.272 128 201.408l0 639.488c0 0.064 0 0.192 0 0.256 0 0.128 0 0.192 0 0.32 0 30.528 24.512 54.784 54.784 54.784l646.976 0c6.592 0 9.728 0 11.712 0 28.736 0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344l0-20.352L896 561.408 896 512.128C896 481.792 871.424 457.152 841.152 457.152z"></path>
</svg>

              </i>
            </a>
          
        
      </li>
    

    
  </ul>
</nav>


  
    






  <link rel="stylesheet" href="/lib/photoswipe/photoswipe.min.css" />
  <link rel="stylesheet" href="/lib/photoswipe/default-skin/default-skin.min.css" />




<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>

  

  

  

  <header id="header" class="header container">
    <div class="logo-wrapper">
  <a href="/" class="logo">
    
      时间飘过
    
  </a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/">主页</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/post/">归档</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/tags/">标签</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/categories/">分类</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/about/">About</a>
          

        

      </li>
    
        <li class="menu-item">
        
          
          
            <a class="menu-item-link" href="https://weedge.github.io/perf-book-cn/zh/" rel="noopener" target="_blank">
              《现代CPU性能分析与优化》
              
              <i class="iconfont">
                <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6C496.064 467.648 528.64 500.224 528.64 500.224 534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92 0 0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"></path>
  <path d="M841.152 457.152c-30.528 0-54.784 24.512-54.784 54.656l0 274.752L237.696 786.56 237.696 237.696l206.016 0c6.656 0 10.752 0 13.248 0C487.68 237.696 512 213.184 512 182.848 512 152.32 487.36 128 456.96 128L183.04 128C153.216 128 128 152.576 128 182.848c0 3.136 0.256 6.272 0.768 9.28C128.256 195.136 128 198.272 128 201.408l0 639.488c0 0.064 0 0.192 0 0.256 0 0.128 0 0.192 0 0.32 0 30.528 24.512 54.784 54.784 54.784l646.976 0c6.592 0 9.728 0 11.712 0 28.736 0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344l0-20.352L896 561.408 896 512.128C896 481.792 871.424 457.152 841.152 457.152z"></path>
</svg>

              </i>
            </a>
          

        

      </li>
    

    
    

    
  </ul>
</nav>

  </header>

  <div id="mobile-panel">
    <main id="main" class="main bg-llight">
      <div class="content-wrapper">
        <div id="content" class="content container">
          <article class="post bg-white">
    
    <header class="post-header">
      <h1 class="post-title">论文解读： VALL-E 系列</h1>
      
      <div class="post-meta">
        <time datetime="2025-01-13" class="post-time">
          2025-01-13
        </time>
        <div class="post-category">
            <a href="https://weedge.github.io/categories/%E6%8A%80%E6%9C%AF/"> 技术 </a>
            <a href="https://weedge.github.io/categories/tts/"> TTS </a>
            
          </div>
        

        
        

        
        
      </div>
    </header>

    
    
<div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">文章目录</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#vall-e-系列">VALL-E 系列</a></li>
    <li><a href="#melle">MELLE</a></li>
  </ul>
</nav>
  </div>
</div>

    
    <div class="post-content">
      <p>前文讲到VITS，采用的端到端的NAR模型，这篇文章记录下微软提出的VALL-E系列，从 AR+NAR 到 AR 模型的转变，以及后面MELLE引入的VAE和Mel-Spectorgram，将neural codec text speech LM (AR+NAR Transformer Decoder) 转变为  autoregressive  mel-spectrogram text speech LM  (AR Transformer Decoder) ；由于LM生成的是mel-spectrogram 需要通过vocoder 转换成 waveform； 生成的内容采样模块：从top-p random sampling 变成 Latent Sampling潜在采样模块（思想源自VAE, 从预测的高斯分布中采样潜在嵌入，然后将其投影回频谱图空间）</p>
<h2 id="vall-e-系列">VALL-E 系列</h2>
<p><a href="https://www.microsoft.com/en-us/research/project/vall-e-x/">https://www.microsoft.com/en-us/research/project/vall-e-x/</a></p>
<p>Vall-E: <a href="https://ar5iv.labs.arxiv.org/html/2301.02111">https://ar5iv.labs.arxiv.org/html/2301.02111</a></p>
<p>具体来说，我们使用从现成的神经音频编解码器模型派生的离散代码来训练<em><strong>神经编解码器语言模型（neural codec language model）</strong></em>（称为VALL-E ），并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 在预训练阶段，我们将 TTS 训练数据扩展到 60K 小时的英语语音，比现有系统大数百倍。 VALL-E具有情境学习功能，可用于合成高质量的个性化语音，只需对看不见的说话者进行 3 秒的注册录音作为声音提示。实验结果表明， VALL-E在语音自然度和说话人相似度方面显着优于最先进的零样本 TTS 系统。此外，我们发现VALL-E可以在合成时保留说话者的情感和声音提示的声学环境。</p>
<p>与之前的管道不同（例如，音素 → 梅尔谱图 → 波形）， VALL-E的管线是音素 → 离散码 → 波形。</p>
<p>VALL-E根据音素和声学代码提示生成与目标内容和说话者的声音相对应的离散音频编解码器代码。 VALL-E直接支持各种语音合成应用，例如零样本 TTS、语音编辑以及与 GPT-3 等其他生成式 AI 模型相结合的内容创建。</p>
<p>VALL-E系列：2023年的1月份开始 - 2024年的7月份</p>
<ul>
<li>VALL-E 使用从现成的神经音频编解码器模型派生的离散代码来训练神经编解码器语言模型，并将 TTS 视为条件语言建模任务，而不是像之前的工作那样将 TTS 视为连续信号回归。 VALL-E 具有情境学习功能，可用于合成高质量的个性化语音，只需录制未见过的讲话者的 3 秒注册录音作为提示。在语音自然度和说话人相似度方面，VALL-E 显着优于最先进的零样本 TTS 系统。此外，VALL-E可以在合成时保留说话者的情绪和声音提示的声学环境。</li>
<li>VALL-E X 扩展其能力，适应多语言场景，促进跨语言零样本 TTS。</li>
<li>VALL-E R 引入了音素单调对齐策略，增强了语音生成的鲁棒性。</li>
<li>VALL-E 2 通过集成重复感知采样和分组代码建模技术， 实现了一个突破性的里程碑：在 LibriSpeech 和 VCTK 数据集上的零样本 TTS 性能与人类相当。这标志着此类成就的首次实例，为该领域树立了新标准。</li>
<li>MELLE 是一种新颖的基于连续值标记的语言建模方法，用于文本到语音合成 (TTS)。 MELLE 直接从文本条件自回归生成连续的梅尔频谱图帧，绕过了矢量量化的需要，矢量量化最初是为音频压缩而设计的，与梅尔频谱图相比，牺牲了保真度。</li>
</ul>
<p><img src="https://github.com/user-attachments/assets/9551079c-03b9-4b7e-8b94-fce8e3e5a408" alt="image"></p>
<p>字节的seed-tts 借鉴了Vall-E模型(用扩散模型替换了 VALL-E 中的 NAR 模型，该模型根据 AR 阶段生成的语音标记生成连续的语音表示)</p>
<h2 id="melle">MELLE</h2>
<p>最新研究到2024年的7月份， MELLE： 一种新颖的基于连续值标记的语言建模方法，用于文本到语音合成 (TTS)。 MELLE 直接从文本条件自回归生成连续的梅尔频谱图帧，绕过了矢量量化的需要，矢量量化最初是为音频压缩而设计的，与梅尔频谱图相比，牺牲了保真度。具体来说，（i）不是使用交叉熵损失，而是应用回归损失和所提出的频谱图通量损失函数来对连续值标记的概率分布进行建模。 (ii) 将变分推理纳入 MELLE 中以促进采样机制，从而增强输出多样性和模型鲁棒性。
没有采用audio encodec, 而是采用 梅尔频谱图 Mel-Spectrogram 抽取器，通过 Mel-Spectrogram LM生成 Mel-Spectrogram， 然后将Mel-Spectrogram 通过 vocoder 生成 waveform
MELLE包括以下主要组件：</p>
<ul>
<li>pre-nets：
<ul>
<li>text tokenizer: 分别将文本转换为子词标记(BPE),</li>
<li>mel-spectrogram extractor: 从语音中提取梅尔频谱图，</li>
<li>然后将它们投影到模型维度；</li>
</ul>
</li>
<li>autoregressive (AR) Transformer decoder： 充当语言模型的自回归 (AR) Transformer 解码器；</li>
<li>latent sampling module： 从预测的高斯分布中采样潜在嵌入，然后将其投影回频谱图空间；</li>
<li>stop prediction layer： 确定语音结尾的停止预测层；</li>
<li>post-net：频谱图细化的卷积后网络。</li>
<li>vocoder：最后，使用声码器从生成的梅尔频谱图中恢复语音。</li>
</ul>
<p>其中引入VAE和Mel-Spectorgram 借鉴了<a href="https://arxiv.org/abs/2404.02781">2024. CLaM-TTS: Improving Neural Codec Language Modeling for Zero-shot Text-to-Speech</a></p>
<p><img src="https://github.com/user-attachments/assets/baf84eb2-379c-4240-93af-4c2ab3d10552" alt=""></p>
<p>不像VALL-E系列模型，由于梅尔谱图的完整性，不需要额外的非自回归（NAR）模型。这种简化显着提高了计算和存储效率。此外，通过调整缩减因子， MELLE可以一步生成多个梅尔谱图帧，进一步提高效率，同时仍保持卓越的性能。</p>
<p>总体来说：
主要目的是将 <strong>文本和声学嵌入的串联作为输入来对语义和声学信息之间的依赖关系进行建模</strong>，生成的隐藏层进行采样，通过audio codec decoder 直接生成 waveform 或者 生成 Mel-Spectrogram 然后生成 waveform</p>
<ul>
<li>VALL-E 系列：text-speech LM 是 AR 和 NAR 的组合模型；text tokenizer使用 phonemizer/pypinyin（中文）, audio tokenizer 使用 audio codec encode/decode ； 生成的内容采样模块：top-p random sampling</li>
<li>MELLE ： tex-speech LM 是 AR 模型； text tokenizer使用 BPE, audio tokenizer 使用  mel-spectrograms extractor; 由于LM生成的是mel-spectrogram 需要通过vocoder 转换成 waveform； 生成的内容采样模块：Latent Sampling潜在采样模块（思想源自VAE, 从预测的高斯分布中采样潜在嵌入，然后将其投影回频谱图空间）</li>
</ul>
<p>PS: 还有一种采样模块： 基于Flow matching 流匹配的方式，从更简单的分布采样中恢复语音表示。比如: meta的 <a href="https://arxiv.org/abs/2306.15687">2023. Voicebox: Text-Guided Multilingual Universal Speech Generation at Scale</a></p>
<p>这里主要是学习在TTS中引入GLM，如何训练。</p>
<p>官方没有给出源码和训练好的权重， 这里只是为例学习AR（生成式语言模型GLM）和NAR的结合，</p>
<p>非官方实现： <a href="https://github.com/lifeiteng/vall-e">https://github.com/lifeiteng/vall-e</a> (只实现了第一版vall-e, 其实类似训练文本LLM一样的步骤，增加了文本转音素，加上语音的tokenizer, 采用的Transform decoder， AR模型需要掩码self-Attention， NAR则不需要掩码操作，文本到音素采用 <a href="https://github.com/bootphon/phonemizer">https://github.com/bootphon/phonemizer</a> , audio codece 使用 <a href="https://github.com/facebookresearch/encodec">https://github.com/facebookresearch/encodec</a>)</p>
<p>数据集处理工具使用 <a href="https://github.com/lhotse-speech/lhotse">https://github.com/lhotse-speech/lhotse</a>；主要是数据处理比较耗时。可以先小数据验证训练逻辑，然后在scaling。</p>
<p>PS: 后续可以改进下，尽量复现下MELLE, 需要花点钱 :(</p>
    </div>

    
    
<div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">文章作者</span>
    <span class="item-content">weedge</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">上次更新</span>
    <span class="item-content">
      2025-01-13
      
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">许可协议</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>


    
    

    <footer class="post-footer">
      <div class="post-tags">
          <a href="https://weedge.github.io/tags/encodec/">encodec</a>
          <a href="https://weedge.github.io/tags/ar/">AR</a>
          <a href="https://weedge.github.io/tags/nar/">NAR</a>
          <a href="https://weedge.github.io/tags/vall-e/">VALL-E</a>
          <a href="https://weedge.github.io/tags/mel-spectrogram/">mel-spectrogram</a>
          
        </div>

      
      <nav class="post-nav">
        
          <a class="prev" href="/post/multimoding/voices/matcha-tts/">
            
            <i class="iconfont">
              <svg  class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417 757.434875 204.940602c11.338233-12.190647 11.035334-32.285311-0.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-0.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891 0.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"></path>
</svg>

            </i>
            <span class="prev-text nav-default">论文解读 Matcha-TTS: A fast TTS architecture with conditional flow matching</span>
            <span class="prev-text nav-mobile">上一篇</span>
          </a>
        
          <a class="next" href="/post/multimoding/voices/vits/">
            <span class="next-text nav-default">论文解读 VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</span>
            <span class="prev-text nav-mobile">下一篇</span>
            
            <i class="iconfont">
              <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="18" height="18">
  <path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311 0.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889 0.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-0.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697C361.493148 60.273758 343.054193 61.470003 332.091514 74.487481z"></path>
</svg>

            </i>
          </a>
      </nav>
    </footer>
  </article>

  
  

  
  

  

  
  

  

  

  <div class="disqus-comment">
  <div class="disqus-button" id="load_disqus" onclick="load_disqus()">
    显示 Disqus 评论
  </div>
  <div id="disqus_thread"></div>
  <script type="text/javascript">
    var disqus_config = function () {
      this.page.url = "https://weedge.github.io/post/multimoding/voices/vall-e-x/";
    };
    function load_disqus() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'weedge';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);

      $('#load_disqus').remove();
    };
  </script>
  <noscript>Please enable JavaScript to view the
    <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
  </noscript>
  
  </div>

    

  

        </div>
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="icon-links">
  
  
    <a href="mailto:weege007@gmail.com" rel="me noopener" class="iconfont"
      title="email" >
      <svg class="icon" viewBox="0 0 1451 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M664.781909 681.472759 0 97.881301C0 3.997201 71.046997 0 71.046997 0L474.477909 0 961.649408 0 1361.641813 0C1361.641813 0 1432.688811 3.997201 1432.688811 97.881301L771.345323 681.472759C771.345323 681.472759 764.482731 685.154773 753.594283 688.65053L753.594283 688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858L682.561621 688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759L664.781909 681.472759ZM718.063616 811.603883C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633 0 212.052267 0 212.052267L0 942.809523C0 942.809523 0 1024 83.726336 1024L682.532949 1024 753.579947 1024 1348.948139 1024C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523L1432.688811 212.052267C1432.688811 212.052267 893.138176 701.759633 817.019477 767.734955 777.248 802.205449 742.347691 811.03081 718.063616 811.603883L718.063616 811.603883Z"></path>
</svg>

    </a>
  
    <a href="https://github.com/weedge" rel="me noopener" class="iconfont"
      title="github"  target="_blank"
      >
      <svg class="icon" style="" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M512 12.672c-282.88 0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667 0-12.16-0.426667-44.373333-0.64-87.04-142.421333 30.890667-172.458667-68.693333-172.458667-68.693333C188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333 0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333 0 0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52 0.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667 0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72 0 68.522667-0.64 123.562667-0.64 140.202666 0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"></path>
</svg>

    </a>
  
    <a href="https://weibo.com/weedge" rel="me noopener" class="iconfont"
      title="weibo"  target="_blank"
      >
      <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="36" height="36">
  <path d="M385.714286 733.714286q12-19.428571 6.285714-39.428571t-25.714286-28.571429q-19.428571-8-41.714286-0.571429t-34.285714 26.285714q-12.571429 19.428571-7.428571 39.142857t24.571429 28.857143 42.571429 1.428571 35.714286-27.142857zm53.714286-69.142857q4.571429-7.428571 2-15.142857t-10-10.571429q-8-2.857143-16.285714 2.857143t-12.285714 10.571429q-9.714286 17.714286 7.428571 25.714286 8 2.857143 16.571429 2.857143t12.571429-10.571429zm99.428571 61.142857q-25.714286 58.285714-90.285714 85.714286t-128 6.857143q-61.142857-19.428571-84.285714-72.285714t3.714286-107.142857q26.857143-53.142857 86.571429-79.428571t120.285714-10.857143q63.428571 16.571429 90.571429 68.285714t1.428571 108.857143zm178.285714-91.428571q-5.142857-54.857143-50.857143-97.142857t-119.142857-62.285714-156.857143-12q-127.428571 13.142857-211.142857 80.857143t-75.714286 151.142857q5.142857 54.857143 50.857143 97.142857t119.142857 62.285714 156.857143 12q127.428571-13.142857 211.142857-80.857143t75.714286-151.142857zm176 2.285714q0 38.857143-21.142857 79.714286t-62.285714 78.285714-96.285714 67.142857-129.142857 47.428571-154.571429 17.714286-157.142857-19.142857-137.428571-53.142857-98-86.285714-37.142857-114q0-65.714286 39.714286-140t112.857143-147.428571q96.571429-96.571429 195.142857-134.857143t140.857143 4q37.142857 36.571429 11.428571 119.428571-2.285714 8-0.571429 11.428571t5.714286 4 8.285714 2.857143 7.714286-2l3.428571-1.142857q79.428571-33.714286 140.571429-33.714286t87.428571 34.857143q25.714286 36 0 101.714286-1.142857 7.428571-2.571429 11.428571t2.571429 7.142857 6.857143 4.285714 9.714286 3.428571q32.571429 10.285714 58.857143 26.857143t45.714286 46.571429 19.428571 66.571429zm-42.285714-356.571429q24 26.857143 31.142857 62t-3.714286 67.142857q-4.571429 13.142857-16.857143 19.428571t-25.428571 2.285714q-13.142857-4.571429-19.428571-16.857143t-2.285714-25.428571q11.428571-36-13.714286-63.428571t-61.142857-20q-13.714286 2.857143-25.714286-4.571429t-14.285714-21.142857q-2.857143-13.714286 4.571429-25.428571t21.142857-14.571429q34.285714-7.428571 68 3.142857t57.714286 37.428571zm103.428571-93.142857q49.714286 54.857143 64.285714 127.142857t-7.714286 138q-5.142857 15.428571-19.428571 22.857143t-29.714286 2.285714-22.857143-19.428571-2.857143-29.714286q16-46.857143 5.714286-98.285714t-45.714286-90.285714q-35.428571-39.428571-84.571429-54.571429t-98.857143-4.857143q-16 3.428571-29.714286-5.428571t-17.142857-24.857143 5.428571-29.428571 24.857143-16.857143q70.285714-14.857143 139.428571 6.571429t118.857143 76.857143z"></path>
</svg>

    </a>


<a href="https://weedge.github.io/index.xml" rel="noopener alternate" type="application/rss&#43;xml"
    class="iconfont" title="rss" target="_blank">
    <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="30" height="30">
  <path d="M819.157333 1024C819.157333 574.592 449.408 204.8 0 204.8V0c561.706667 0 1024 462.293333 1024 1024h-204.842667zM140.416 743.04a140.8 140.8 0 0 1 140.501333 140.586667A140.928 140.928 0 0 1 140.074667 1024C62.72 1024 0 961.109333 0 883.626667s62.933333-140.544 140.416-140.586667zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667V345.173333c372.352 0 678.784 306.517333 678.784 678.826667z"></path>
</svg>

  </a>
   
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - <a class="theme-link" href="https://github.com/xianmin/hugo-theme-jane">Jane</a>
  </span>

  <span class="copyright-year">
    &copy;
    
      2013 -
    2025
    <span class="heart">
      
      <i class="iconfont">
        <svg class="icon" viewBox="0 0 1025 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="14" height="14">
  <path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7 0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1 0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2 0.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2 0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3 0.1-42.5-8-83.6-24-122.2z"
   fill="#8a8a8a"></path>
</svg>

      </i>
    </span><span class="author">
        weedge
        
      </span></span>

  
  

  
</div>

    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont">
        
        <svg class="icon" viewBox="0 0 1024 1024" version="1.1"
  xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"
  width="35" height="35">
  <path d="M510.866688 227.694839 95.449397 629.218702l235.761562 0-2.057869 328.796468 362.40389 0L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777l894.052392 0 0 131.813095L63.840492 195.775872 63.840492 63.962777 63.840492 63.962777zM63.840492 63.962777"></path>
</svg>

      </i>
    </div>
  </div>
  
<script type="text/javascript" src="/lib/jquery/jquery-3.2.1.min.js"></script>
  <script type="text/javascript" src="/lib/slideout/slideout-1.0.1.min.js"></script>




<script type="text/javascript" src="/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js" integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin="anonymous"></script>












  
    <script type="text/javascript" src="/js/load-photoswipe.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe.min.js"></script>
    <script type="text/javascript" src="/lib/photoswipe/photoswipe-ui-default.min.js"></script>
  









  <script id="dsq-count-scr" src="//weedge.disqus.com/count.js" async></script>






  <script src="/js/copy-to-clipboard.js"></script>


</body>
</html>

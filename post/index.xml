<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on æ—¶é—´é£˜è¿‡</title>
    <link>https://weedge.github.io/post/</link>
    <description>Recent content in Posts on æ—¶é—´é£˜è¿‡</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Fri, 17 Jan 2025 10:26:23 +0800</lastBuildDate><atom:link href="https://weedge.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>è®ºæ–‡è§£è¯»ï¼šCosyVoice2: Scalable Streaming Speech Synthesis with Large Language Models</title>
      <link>https://weedge.github.io/post/multimoding/voices/cosyvoice2/</link>
      <pubDate>Fri, 17 Jan 2025 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/cosyvoice2/</guid>
      <description>&lt;h2 id=&#34;cosyvoice2&#34;&gt;CosyVoice2&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2412.10117&#34;&gt;2024.12  &lt;strong&gt;CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models&lt;/strong&gt;&lt;/a&gt;ï¼ˆæµå¼åˆæˆï¼‰&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/FunAudioLLM/CosyVoice&#34;&gt;paper code&lt;/a&gt;: å…¬å¼€æ¨ç†å’Œæƒé‡ï¼Œè®­ç»ƒè¿‡ç¨‹éœ€è¦åœ¨CosyVoiceçš„åŸºç¡€ä¸Šä¿®æ”¹ä¸‹ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;zero-shot-tts-models-é›¶æ ·æœ¬-tts-æ¨¡å‹&#34;&gt;zero-shot TTS models é›¶æ ·æœ¬ TTS æ¨¡å‹&lt;/h2&gt;
&lt;h3 id=&#34;codec-language-models-ç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹&#34;&gt;codec language models ç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;speech &lt;strong&gt;codec model&lt;/strong&gt;  to extract discrete speech representation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2107.03312&#34;&gt;2021.7 SoundStream: An End-to-End Neural Audio Codec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2210.13438&#34;&gt;2022.10 &lt;strong&gt;High Fidelity Neural Audio Compression&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;http://github.com/facebookresearch/encodec&#34;&gt;facebookresearch/encodec&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.07405&#34;&gt;2023.10 FunCodec: A Fundamental, Reproducible and Integrable Open-source Toolkit for Neural Speech Codec&lt;/a&gt; | &lt;a href=&#34;https://github.com/modelscope/FunCodec&#34;&gt;modelscope/FunCodec&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;speech &lt;strong&gt;codec model&lt;/strong&gt; + &lt;strong&gt;autoregressive model&lt;/strong&gt; to predict the speech tokens (acoustic tokens):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2301.02111&#34;&gt;2023.1 &lt;strong&gt;Neural Codec Language Models are Zero-Shot Text to Speech Synthesizers&lt;/strong&gt;&lt;/a&gt; (Vall-E) | ä»¥åŠåç»­ Vall-E å‡çº§ç³»åˆ— (ä¸åŒ…æ‹¬MELLE): &lt;a href=&#34;https://www.microsoft.com/en-us/research/project/vall-e-x/&#34;&gt;https://www.microsoft.com/en-us/research/project/vall-e-x/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2302.03540&#34;&gt;2023.2 Speak, Read and Prompt: High-Fidelity Text-to-Speech with Minimal Supervision&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;speech &lt;strong&gt;codec model&lt;/strong&gt; (speech semantics Codec) +  &lt;strong&gt;non-autoregressive masked model&lt;/strong&gt; to predict the speech tokens (acoustic tokens):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2409.00750&#34;&gt;2024.9 &lt;strong&gt;MaskGCT: Zero-Shot Text-to-Speech with Masked Generative Codec Transformer&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/open-mmlab/Amphion/tree/main/models/tts/maskgct&#34;&gt;paper code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;codec model (speech acoustic Codec) or  &lt;strong&gt;vocoder&lt;/strong&gt; to synthesize waveforms from mel-spectrograms:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2306.00814&#34;&gt;2023.6 &lt;strong&gt;Vocos: Closing the gap between time-domain and Fourier-based neural vocoders for high-quality audio synthesis&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/gemelo-ai/vocos&#34;&gt;paper code&lt;/a&gt; | æ¨ç†é€Ÿåº¦å¿«ï¼šè¿è¡Œé€Ÿåº¦æ¯” HiFi-GAN å¿«çº¦ 13 å€ï¼Œæ¯” BigVGAN å¿«è¿‘ 70 å€ã€‚åœ¨æ²¡æœ‰ GPU åŠ é€Ÿçš„æƒ…å†µä¸‹è¿è¡Œæ—¶ï¼Œè¿™ç§é€Ÿåº¦ä¼˜åŠ¿å°¤å…¶æ˜æ˜¾ã€‚è¿™ä¸»è¦æ˜¯ç”±äºä½¿ç”¨äº†çŸ­æ—¶å‚…é‡Œå¶é€†å˜æ¢ï¼ˆISTFTï¼‰ç®—æ³•è€Œä¸æ˜¯è½¬ç½®å·ç§¯ã€‚è¿˜è¯„ä¼°äº† Vocos çš„ä¸€ä¸ªå˜ä½“ï¼Œå®ƒåˆ©ç”¨ ResBlock çš„æ‰©å¼ å·ç§¯è€Œä¸æ˜¯ ConvNeXt å—ã€‚åœ¨ GPU ä¸Šæ‰§è¡Œæ—¶ï¼Œæ·±åº¦å¯åˆ†ç¦»å·ç§¯å¯æä¾›é¢å¤–çš„åŠ é€Ÿã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://ieeexplore.ieee.org/document/10389765&#34;&gt;2023.12 &lt;strong&gt;WaveNeXt: ConvNeXt-Based Fast Neural Vocoder Without ISTFT layer&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://ast-astrec.nict.go.jp/demo_samples/asru_2023_okamoto/index.html&#34;&gt;demo samples&lt;/a&gt; | paper codeåŸºäº &lt;a href=&#34;https://arxiv.org/abs/2110.07840&#34;&gt;ESPNet2-TTS&lt;/a&gt;  | ä¸€ç§æ–°å‹çš„åŸºäºConvNeXtçš„å¿«é€Ÿç¥ç»å£°ç å™¨WaveNeXtï¼Œå®ƒé€šè¿‡æ›¿æ¢Vocosä¸­çš„é€†çŸ­æ—¶å‚…é‡Œå¶å˜æ¢ï¼ˆiSTFTï¼‰å±‚ä¸ºå¯è®­ç»ƒçš„çº¿æ€§å±‚ï¼Œç›´æ¥é¢„æµ‹è¯­éŸ³æ³¢å½¢æ ·æœ¬ï¼Œè€Œä¸ä¾èµ–äºSTFTé¢‘è°±ã€‚è¿™ä¸€æ”¹è¿›ä¸ä»…ä¿æŒäº†Vocosçš„å¿«é€Ÿæ¨ç†é€Ÿåº¦ï¼Œè¿˜æé«˜äº†è¯­éŸ³åˆæˆçš„è´¨é‡ã€‚æ–‡ç« è¿˜æ¢è®¨äº†å¦‚ä½•å°†WaveNeXtä¸åŸºäºJETSçš„ç«¯åˆ°ç«¯æ–‡æœ¬åˆ°è¯­éŸ³ï¼ˆE2E TTSï¼‰æ¡†æ¶é›†æˆï¼Œå¹¶ç ”ç©¶äº†é‡‡æ ·é¢‘ç‡ä¸º48kHzçš„å…¨å¸¦æ¨¡å‹ï¼ˆFull-band Modelï¼šèƒ½å¤Ÿå¤„ç†å’Œç”Ÿæˆè¦†ç›–æ•´ä¸ªéŸ³é¢‘é¢‘è°±èŒƒå›´çš„æ¨¡å‹ï¼Œé€šå¸¸æ˜¯æŒ‡èƒ½å¤Ÿå¤„ç†ä»æœ€ä½é¢‘åˆ°æœ€é«˜é¢‘çš„å®Œæ•´éŸ³é¢‘ä¿¡å·çš„æ¨¡å‹ï¼‰ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒWaveNeXtåœ¨åˆ†æ-åˆæˆå’ŒE2E TTSæ¡ä»¶ä¸‹å‡ä¼˜äºVocosï¼ŒåŒæ—¶ä¿æŒäº†å¿«é€Ÿæ¨ç†çš„èƒ½åŠ›ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/4a1eeaff-528f-4706-b5fc-210caea2c13b&#34; alt=&#34;image&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;feature-diffusion-models-ç‰¹å¾æ‰©æ•£æ¨¡å‹&#34;&gt;feature diffusion models ç‰¹å¾æ‰©æ•£æ¨¡å‹&lt;/h3&gt;
&lt;p&gt;DDPM + CFM + NAR(non-autoregressive) model, æ²¡æœ‰ codec&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Base module:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Denoising Diffusion Probabilistic Model(DDPM)ï¼š &lt;a href=&#34;https://arxiv.org/abs/2006.11239&#34;&gt;2020.6 &lt;strong&gt;Denoising Diffusion Probabilistic Models&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/hojonathanho/diffusion&#34;&gt;paper code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Conditional Flow Matching (CFM)ï¼š  &lt;a href=&#34;https://arxiv.org/abs/2210.02747&#34;&gt;2022.10 &lt;strong&gt;Flow Matching for Generative Modeling&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/atong01/conditional-flow-matching&#34;&gt;CFM lib&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;the alignment modeling between input text and synthesized speech&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;phoneme-level duration model:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2403.03100&#34;&gt;2024.5 NaturalSpeech 3&lt;/a&gt;  and &lt;a href=&#34;https://arxiv.org/abs/2306.15687&#34;&gt;2023.6 Voicebox&lt;/a&gt; use frame-wise phoneme alignment;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.03199&#34;&gt;2023.9 Matcha-TTS&lt;/a&gt; adopts monotonic alignment search(MAS) and relies on phoneme-level duration model;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2406.18009&#34;&gt;2024.6 E2 TTS&lt;/a&gt; å’Œ&lt;a href=&#34;https://arxiv.org/abs/2406.02430&#34;&gt;2024.6 Seed-TTS&lt;/a&gt; ç ”ç©¶è¡¨æ˜åœ¨æ–‡æœ¬å’Œè¯­éŸ³ä¹‹é—´å¼•å…¥è¿™ç§åƒµåŒ–å’Œä¸çµæ´»çš„å¯¹é½æ–¹å¼ä¼šé˜»ç¢æ¨¡å‹ç”Ÿæˆæ›´è‡ªç„¶çš„ç»“æœã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;E3 TTS æ”¾å¼ƒéŸ³ç´ çº§æŒç»­æ—¶é—´å¹¶å¯¹è¾“å…¥åºåˆ—åº”ç”¨äº¤å‰æ³¨æ„åŠ›ï¼Œä½†äº§ç”Ÿçš„éŸ³é¢‘è´¨é‡æœ‰é™ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DiTTo-TTS ä½¿ç”¨æ‰©æ•£å˜æ¢å™¨ (DiT) ï¼Œå¹¶ä»¥æ¥è‡ªé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹çš„ç¼–ç æ–‡æœ¬ä¸ºæ¡ä»¶è¿›è¡Œäº¤å‰æ³¨æ„ã€‚ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºå¯¹é½ï¼Œå®ƒä½¿ç”¨é¢„è®­ç»ƒçš„è¯­è¨€æ¨¡å‹æ¥å¾®è°ƒç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨ï¼Œå°†è¯­ä¹‰ä¿¡æ¯æ³¨å…¥ç”Ÿæˆçš„è¡¨ç¤ºä¸­ï¼›&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ç›¸æ¯”ä¹‹ä¸‹ï¼ŒåŸºäº Voiceboxçš„ E2 TTSé‡‡ç”¨äº†æ›´ç®€å•çš„æ–¹æ³•ï¼Œåˆ é™¤äº†éŸ³ç´ å’ŒæŒç»­æ—¶é—´é¢„æµ‹å™¨ï¼Œç›´æ¥ä½¿ç”¨å¡«å……tokenå¡«å……åˆ°æ¢…å°”é¢‘è°±å›¾é•¿åº¦çš„å­—ç¬¦ä½œä¸ºè¾“å…¥ã€‚è¿™ä¸ªç®€å•çš„æ–¹æ¡ˆä¹Ÿå®ç°äº†éå¸¸è‡ªç„¶å’ŒçœŸå®çš„åˆæˆç»“æœã€‚ç„¶è€Œï¼ŒF5-TTS å‘ç° E2 TTS ä¸­æ–‡æœ¬å’Œè¯­éŸ³å¯¹é½å­˜åœ¨é²æ£’æ€§é—®é¢˜ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2406.02430&#34;&gt;2024.6 Seed-TTS&lt;/a&gt; é‡‡ç”¨äº†ç±»ä¼¼çš„ç­–ç•¥å¹¶å–å¾—äº†ä¼˜å¼‚çš„ç»“æœï¼Œå°½ç®¡æ²¡æœ‰è¯¦ç»†è¯´æ˜æ¨¡å‹ç»†èŠ‚ã€‚åœ¨è¿™äº›æœªæ˜ç¡®å»ºæ¨¡éŸ³ç´ çº§æŒç»­æ—¶é—´çš„æ–¹æ³•ä¸­ï¼Œæ¨¡å‹å­¦ä¹ æ ¹æ®ç»™å®šçš„æ€»åºåˆ—é•¿åº¦åˆ†é…æ¯ä¸ªå•è¯æˆ–éŸ³ç´ çš„é•¿åº¦ï¼Œä»è€Œæ”¹è¿›éŸµå¾‹å’ŒèŠ‚å¥ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://arxiv.org/abs/2410.06885&#34;&gt;2024.10 &lt;strong&gt;F5-TTS: A fairytaler that fakes fluent and faithful speech with flow matching&lt;/strong&gt;&lt;/a&gt; ä¿æŒäº†ç®¡é“çš„ç®€å•æ€§ï¼Œæ— éœ€éŸ³ç´ å¯¹é½ã€æŒç»­æ—¶é—´é¢„æµ‹å™¨ã€æ–‡æœ¬ç¼–ç å™¨å’Œè¯­ä¹‰æ³¨å…¥ç¼–è§£ç å™¨æ¨¡å‹ï¼Œåˆ©ç”¨å¸¦æœ‰ &lt;a href=&#34;https://arxiv.org/abs/2301.00808&#34;&gt;ConvNeXt V2&lt;/a&gt;|&lt;a href=&#34;https://github.com/facebookresearch/ConvNeXt-V2&#34;&gt;paper code&lt;/a&gt; çš„Diffusion Transformer(DiT)æ¥æ›´å¥½åœ°è§£å†³ä¸Šä¸‹æ–‡å­¦ä¹ æœŸé—´çš„æ–‡æœ¬è¯­éŸ³å¯¹é½é—®é¢˜ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;codec-language-and-feature-diffusion-hybrid-systems-æ··åˆç³»ç»Ÿ&#34;&gt;codec language and feature diffusion hybrid systems æ··åˆç³»ç»Ÿ&lt;/h3&gt;
&lt;p&gt;text-to-codec language model  å’Œ codec-to-feature diffusion model&lt;/p&gt;
&lt;p&gt;è¯­è¨€æ¨¡å‹è§£å†³æ–‡æœ¬å’Œè¯­éŸ³ä¹‹é—´çš„å¯¹é½ä»¥åŠè¯è¯­æŒç»­æ—¶é—´é¢„æµ‹ï¼Œè€Œç¼–è§£ç å™¨åˆ°ç‰¹å¾æ‰©æ•£æ¨¡å‹åˆ™æ ¹æ®ç”Ÿæˆçš„ç¼–è§£ç å™¨å’Œå…¶ä»–æ¡ä»¶åˆæˆè¯­éŸ³ç‰¹å¾ï¼ˆæ¢…å°”è°±ï¼‰ã€‚é€šè¿‡åˆ©ç”¨ä¸¤ç§ç”Ÿæˆæ¨¡å‹çš„ä¼˜åŠ¿ï¼Œæ··åˆç³»ç»Ÿå®ç°äº†é«˜åº¦å¤šæ ·æ€§ã€éŸµå¾‹ä¸€è‡´æ€§å’Œè¯­éŸ³è´¨é‡ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2406.02430&#34;&gt;2024.6 Seed-TTS&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.05407&#34;&gt;2024.7 Cosyvoice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2409.03283&#34;&gt;2024.9 Fireredtts&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;language-model-based-zero-shot-tts-models--streaming-synthesis&#34;&gt;language model-based zero-shot TTS models  &lt;strong&gt;streaming&lt;/strong&gt; synthesis&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2402.08093&#34;&gt;2024.2 &lt;strong&gt;BASE TTS: Lessons from building a billion-parameter Text-to-Speech model on 100K hours of data&lt;/strong&gt;&lt;/a&gt; | å°çº¢ä¹¦çš„FireRedTTS æ¥æºäºæ­¤ &lt;a href=&#34;https://github.com/FireRedTeam/FireRedTTS&#34;&gt;FireRedTTS paper code&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2406.02897&#34;&gt;2024.6 LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.11210&#34;&gt;2024.9 Speak While You Think: Streaming Speech Synthesis During Text Generation&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2410.00767&#34;&gt;2024.10 Zero-Shot Text-to-Speech from Continuous Text Streams&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯»ï¼šCosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens</title>
      <link>https://weedge.github.io/post/multimoding/voices/cosyvoice/</link>
      <pubDate>Wed, 15 Jan 2025 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/cosyvoice/</guid>
      <description>&lt;h2 id=&#34;cosyvoice&#34;&gt;CosyVoice&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.04051&#34;&gt;2024.7 FunAudioLLM: Voice Understanding and Generation Foundation Models for Natural Interaction Between Humans and LLMs&lt;/a&gt; ï¼ˆä¸»è¦ä»‹ç»ASR SenseVoice å’Œ TTS CosyVoice,å…¶ä¸­ SenseVoice æ²¡æœ‰å•ç‹¬è®ºæ–‡ï¼Œç›¸å…³CosyVoice å’Œå•ç‹¬è®ºæ–‡æ˜¯é‡å¤çš„, SenseVoice Largeçš„å·¥ä½œå¯ä»¥ç”¨äº CosyVoice åœ¨å¤šè¯­è¨€ä¸Šï¼Œ Supervised speech tokenizer æ¨¡å—çš„è®­ç»ƒå’Œæ¨ç†ï¼‰&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2407.05407&#34;&gt;2024.7 &lt;strong&gt;CosyVoice: A Scalable Multilingual Zero-shot Text-to-speech Synthesizer based on Supervised Semantic Tokens&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2412.10117&#34;&gt;2024.12 CosyVoice 2: Scalable Streaming Speech Synthesis with Large Language Models&lt;/a&gt; ï¼ˆæµå¼åˆæˆï¼‰&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/FunAudioLLM/CosyVoice&#34;&gt;paper code&lt;/a&gt;: å…¬å¼€æ¨ç†å’Œæƒé‡ï¼Œåœ¨openslrå…¬å¼€æ•°æ®é›†è‹±æ–‡æ•°æ®é›†LibriSpeech å’Œä¸­æ–‡æ•°æ®é›† MAGICDATA å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒä»£ç ï¼› æ— supervised Speech Tokenizer (å¯¹SenseVoice ASRçš„æ”¹é€ å¾®è°ƒ) å’ŒSpeaker Embedding model(context-aware masking CAM++) çš„è®­ç»ƒè¿‡ç¨‹ä»£ç ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åˆ›æ–°ç‚¹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å°†ç›‘ç£è¯­éŸ³tokené›†æˆåˆ°TTS æ¨¡å‹ï¼Œå¢å¼ºäº†é›¶æ ·æœ¬è¯­éŸ³å…‹éš†ä¸­çš„å†…å®¹ä¸€è‡´æ€§å’Œè¯´è¯è€…ç›¸ä¼¼æ€§ã€‚&lt;/li&gt;
&lt;li&gt;ä¸€ç§å¯æ‰©å±•çš„é›¶æ ·æœ¬ TTS åˆæˆç³»ç»Ÿï¼Œå®ƒå°†ç”¨äºæ–‡æœ¬åˆ°tokenç”Ÿæˆçš„ LLM ä¸ç”¨äºtokenåˆ°è¯­éŸ³åˆæˆçš„æ¡ä»¶æµåŒ¹é…æ¨¡å‹(conditional flow matching model(CFM))ç›¸ç»“åˆï¼Œä¸ä¾èµ–äºéŸ³ç´ æŒç»­æ—¶é—´é¢„æµ‹(Duration predictor)ï¼Œä¸éœ€è¦ä½¿ç”¨è¡¥å……éŸ³ç´ å™¨(phonemizers)å’Œå¼ºåˆ¶å¯¹é½å™¨aligners (æ¯”å¦‚ï¼šGlow-TTSä¸­ Monotonic Alignment Search(MAS))ã€‚&lt;/li&gt;
&lt;li&gt;ä¸ºäº†è¿›ä¸€æ­¥ç»†åŒ–ç”Ÿæˆè¯­éŸ³çš„è´¨é‡ï¼Œå°† x-vector åˆå¹¶åˆ° LLM ä¸­ï¼Œå°†è¯­éŸ³å»ºæ¨¡åˆ†ä¸ºè¯­ä¹‰ã€è¯´è¯è€…å’ŒéŸµå¾‹(semantic, speaker, and prosody)ç»„ä»¶ã€‚ LLM å¯¹è¯­ä¹‰(semantic)å†…å®¹å’ŒéŸµå¾‹(prosody)è¿›è¡Œå»ºæ¨¡ï¼Œè€Œæ¡ä»¶æµåŒ¹é…æ¨¡å‹(CFM)åˆ™æ•è·éŸ³è‰²(timbre)å’Œç¯å¢ƒä¿¡æ¯ã€‚æˆ‘ä»¬ä½¿ç”¨&lt;strong&gt;Classifier-Free Guidance&lt;/strong&gt;(&lt;a href=&#34;https://arxiv.org/abs/2207.12598&#34;&gt;2022. &lt;strong&gt;Classifier-free diffusion guidance&lt;/strong&gt;&lt;/a&gt;)ã€ä½™å¼¦è°ƒåº¦å™¨(&lt;a href=&#34;https://d2l.ai/chapter_optimization/lr-scheduler.html#cosine-scheduler&#34;&gt;cosine scheduler&lt;/a&gt;)å’Œå±è”½æ¡ä»¶(masked conditions)ç­‰æŠ€æœ¯æ¥ä¼˜åŒ–æµåŒ¹é…è¿‡ç¨‹ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/3e8c1132-e146-4b73-8d0c-f3972bf7c8bd&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;CosyVoiceç”±å››ä¸ªç»„ä»¶ç»„æˆï¼Œå³æ–‡æœ¬ç¼–ç å™¨(text encoder)ã€è¯­éŸ³åˆ†è¯å™¨(speech tokenizer)ã€å¤§è¯­è¨€æ¨¡å‹(large language model)å’Œæ¡ä»¶æµåŒ¹é…æ¨¡å‹(conditional flow matching model)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ–‡æœ¬ç¼–ç å™¨(text encoder)ç”¨äºå¯¹é½æ–‡æœ¬å’Œè¯­éŸ³tokençš„è¯­ä¹‰ç©ºé—´;&lt;/li&gt;
&lt;li&gt;è¯­éŸ³æ ‡è®°å™¨(speech tokenizer)ç”¨äºæå–è¯­ä¹‰token;&lt;/li&gt;
&lt;li&gt;LLM(GLM)å­¦ä¹ æ–‡æœ¬ç¼–ç å’Œè¯­éŸ³æ ‡è®°çš„æ•´ä¸ªåºåˆ—ï¼Œå°† TTS é‡æ–°è¡¨è¿°ä¸ºä»¥æ–‡æœ¬ä½œä¸ºæç¤ºçš„è‡ªå›å½’åºåˆ—ç”Ÿæˆé—®é¢˜;&lt;/li&gt;
&lt;li&gt;åˆ©ç”¨æ¡ä»¶æµåŒ¹é…æ¨¡å‹(conditional flow matching model), é€šè¿‡æœ€ä¼˜è·¯å¾„ä¸Šçš„å»å™ªå¤„ç†,å°†è¯­éŸ³æ ‡è®°è½¬æ¢ä¸ºæ¢…å°”è°±å›¾(Mel spectrogram); é€šè¿‡&lt;strong&gt;Classifier-Free Guidance&lt;/strong&gt;ï¼ˆClassifier-free diffusion guidance CFGï¼‰æé«˜æ‰©æ•£æ¦‚ç‡æ¨¡å‹çš„ç”Ÿæˆè´¨é‡, å°†CFGé€‚åº”åˆ°æ¡ä»¶æµåŒ¹é…æ¨¡å‹ä¸­;&lt;/li&gt;
&lt;li&gt;è·å¾—äººç±»è€³æœµå¯æ„ŸçŸ¥çš„å£°éŸ³ä¿¡å·ï¼Œå£°ç å™¨(vocoder)ä½¿ç”¨ Hifi-GAN Generator ç”¨äºå°†ç”Ÿæˆçš„æ¢…å°”é¢‘è°±å›¾ä½œä¸ºè¾“å…¥æ¥åˆæˆæ³¢å½¢(waveform)ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å…¶ä¸­ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;conditional flow matching model (OT-CFM) æ¥è‡ª &lt;a href=&#34;https://arxiv.org/abs/2309.03199&#34;&gt;2023.9 &lt;strong&gt;Matcha-TTS: A fast TTS architecture with conditional flow matching&lt;/strong&gt;&lt;/a&gt;(CFMçš„æ”¹è¿›ç‰ˆæœ¬OT-CFM)&lt;/li&gt;
&lt;li&gt;Classifier-free diffusion guidance (CFG) æ¥è‡ª &lt;a href=&#34;https://arxiv.org/abs/2207.12598&#34;&gt;2022. &lt;strong&gt;Classifier-free diffusion guidance&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;vocoder æ¥è‡ª &lt;a href=&#34;https://arxiv.org/abs/2010.05646&#34;&gt;2020. &lt;strong&gt;HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis&lt;/strong&gt;&lt;/a&gt; Generatorã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é™„ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;æ¨ç†å’Œè®­ç»ƒæ“ä½œç¬”è®°ï¼šhttps://github.com/weedge/doraemon-nb/blob/main/CosyVoice.ipynb&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;achatbot æ¥å…¥ CosyVoice:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ai-bot-pro/achatbot/pull/21&#34;&gt;https://github.com/ai-bot-pro/achatbot/pull/21&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/ai-bot-pro/achatbot/pull/23&#34;&gt;https://github.com/ai-bot-pro/achatbot/pull/23&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯» Matcha-TTS: A fast TTS architecture with conditional flow matching</title>
      <link>https://weedge.github.io/post/multimoding/voices/matcha-tts/</link>
      <pubDate>Tue, 14 Jan 2025 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/matcha-tts/</guid>
      <description>&lt;h1 id=&#34;-matcha-tts&#34;&gt;ğŸµ matcha-tts&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.03199&#34;&gt;2023.9 &lt;strong&gt;Matcha-TTS: A fast TTS architecture with conditional flow matching&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/shivammehta25/Matcha-TTS&#34;&gt;paper code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;æ‘˜è¦&#34;&gt;æ‘˜è¦ï¼š&lt;/h1&gt;
&lt;p&gt;ä¸€ç§ç”¨äºå¿«é€Ÿ TTS å£°å­¦å»ºæ¨¡çš„æ–°ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œä½¿ç”¨æœ€ä½³ä¼ è¾“æ¡ä»¶æµåŒ¹é… (OT-CFM) è¿›è¡Œè®­ç»ƒã€‚ä¸ä½¿ç”¨åˆ†æ•°åŒ¹é…è®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼Œè¿™äº§ç”Ÿäº†åŸºäº ODE çš„è§£ç å™¨ï¼Œèƒ½å¤Ÿä»¥æ›´å°‘çš„åˆæˆæ­¥éª¤å®ç°é«˜è¾“å‡ºè´¨é‡ã€‚ä»”ç»†çš„è®¾è®¡é€‰æ‹©è¿˜ç¡®ä¿æ¯ä¸ªåˆæˆæ­¥éª¤éƒ½èƒ½å¿«é€Ÿè¿è¡Œã€‚è¯¥æ–¹æ³•æ˜¯æ¦‚ç‡æ€§çš„ã€éè‡ªå›å½’çš„ï¼Œå¹¶ä¸”æ— éœ€å¤–éƒ¨å¯¹é½å³å¯ä»å¤´å¼€å§‹å­¦ä¹ è¯´è¯ã€‚ä¸å¼ºå¤§çš„é¢„è®­ç»ƒåŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒMatcha-TTS ç³»ç»Ÿå…·æœ‰æœ€å°çš„å†…å­˜å ç”¨ï¼Œå¯ä»¥ä¸é•¿è¯­éŸ³ä¸Šæœ€å¿«çš„æ¨¡å‹ç›¸åª²ç¾ï¼Œå¹¶åœ¨å¬åŠ›æµ‹è¯•ä¸­è·å¾—æœ€é«˜çš„å¹³å‡æ„è§å¾—åˆ†ã€‚&lt;/p&gt;
&lt;p&gt;ä¸€ç§éè‡ªå›å½’ç¥ç» TTS çš„æ–°æ–¹æ³•ï¼Œå®ƒä½¿ç”¨æ¡ä»¶æµåŒ¹é…(CFM from &lt;a href=&#34;https://arxiv.org/abs/2210.02747&#34;&gt;2022.10 &lt;strong&gt;Flow Matching for Generative Modeling&lt;/strong&gt;&lt;/a&gt;)ï¼ˆç±»ä¼¼äºæ ¡æ­£æµ(Rectified Flow &lt;a href=&#34;https://arxiv.org/abs/2209.03003&#34;&gt;2022.9 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow&lt;/a&gt;ï¼‰æ¥åŠ é€ŸåŸºäº ODE çš„è¯­éŸ³åˆæˆã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is probabilistic  æ˜¯æ¦‚ç‡æ€§çš„&lt;/li&gt;
&lt;li&gt;Has compact memory footprint å…·æœ‰ç´§å‡‘çš„å†…å­˜å ç”¨&lt;/li&gt;
&lt;li&gt;Sounds highly natural  å¬èµ·æ¥éå¸¸è‡ªç„¶&lt;/li&gt;
&lt;li&gt;Is very fast to synthesise from åˆæˆé€Ÿåº¦éå¸¸å¿«&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ç®€æ´çš„ç»“æ„ï¼Œè®­ç»ƒæ¨ç†å¿«ï¼Œä½¿ç”¨æ›´å°‘é¢å†…å­˜ç©ºé—´ï¼Œ&lt;/p&gt;
&lt;p&gt;ä¸€ç§åŸºäºè¿ç»­å½’ä¸€åŒ–æµçš„æ¦‚ç‡æ€§ã€éè‡ªå›å½’ã€å¿«é€Ÿé‡‡æ ·çš„ TTS å£°å­¦æ¨¡å‹ã€‚ä¸»è¦æœ‰ä¸¤ä¸ªåˆ›æ–°ç‚¹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æå‡ºäº†ä¸€ç§æ”¹è¿›çš„ç¼–ç å™¨-è§£ç å™¨ TTS ç»“æ„ï¼Œè¯¥ç»“æ„åœ¨è§£ç å™¨ä¸­ç»“åˆä½¿ç”¨ 1D CNN å’Œ Transformerã€‚è¿™å‡å°‘äº†å†…å­˜æ¶ˆè€—å¹¶ä¸”å¯ä»¥å¿«é€Ÿè¯„ä¼°ï¼Œä»è€Œæé«˜ç»¼åˆé€Ÿåº¦ã€‚&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨æœ€ä¼˜ä¼ è¾“æ¡ä»¶æµåŒ¹é… optimal-transport conditional flow matching(OT-CFM) æ¥è®­ç»ƒè¿™äº›æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§å­¦ä¹ ä»æ•°æ®åˆ†å¸ƒä¸­é‡‡æ ·çš„ ODE çš„æ–°æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„ è¿ç»­æ—¶é—´å½’ä¸€åŒ–æµ CNFï¼ˆcontinuous-time normalising flows ï¼‰ å’Œåˆ†æ•°åŒ¹é…æ¦‚ç‡æµ ODE ï¼ˆprobability flow ODEï¼‰ ç›¸æ¯”ï¼ŒOT-CFM å®šä¹‰äº†ä»æºåˆ°ç›®æ ‡çš„æ›´ç®€å•çš„è·¯å¾„ï¼Œä»è€Œèƒ½å¤Ÿä»¥æ¯” DPMï¼ˆDiffusion probabilistic modelï¼‰ æ›´å°‘çš„æ­¥éª¤è¿›è¡Œå‡†ç¡®åˆæˆã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ä¸¤ç§åˆ›æ–°éƒ½åŠ é€Ÿäº†åˆæˆï¼Œå‡å°‘äº†é€Ÿåº¦å’Œåˆæˆè´¨é‡ä¹‹é—´çš„æƒè¡¡ã€‚å°½ç®¡é€Ÿåº¦å¿«ä¸”è½»é‡çº§ï¼ŒMatcha-TTSèƒ½å¤Ÿåœ¨ä¸éœ€è¦å¤–éƒ¨å¯¹é½å™¨çš„æƒ…å†µä¸‹å­¦ä¹ è¯´è¯å’Œå¯¹é½ã€‚ä¸å¼ºå¤§çš„é¢„è®­ç»ƒåŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒMatcha-TTSå®ç°äº†å¿«é€Ÿåˆæˆï¼Œå¹¶è·å¾—äº†æ›´å¥½çš„è‡ªç„¶åº¦è¯„åˆ†ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;é™„&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;ä½¿ç”¨LJ Speechæ•°æ®é›†è®­ç»ƒ202 epochs, åœ¨1xGPU ä¸Šè®­ç»ƒäº† 79,372 step çš„ckpt(è®ºæ–‡ä¸­æ˜¯2x3080GPU 50K step)ï¼š&lt;/p&gt;
&lt;p&gt;&lt;a href=&#34;https://huggingface.co/weege007/matchaTTS/tree/main&#34;&gt;https://huggingface.co/weege007/matchaTTS/tree/main&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ç¬”è®°åœ°å€ï¼š &lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb&#34;&gt;https://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/95bccbf2-b164-484f-a6c9-8ab7e235c018&#34; alt=&#34;loss&#34;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯»ï¼š VALL-E ç³»åˆ—</title>
      <link>https://weedge.github.io/post/multimoding/voices/vall-e-x/</link>
      <pubDate>Mon, 13 Jan 2025 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/vall-e-x/</guid>
      <description>&lt;p&gt;å‰æ–‡è®²åˆ°VITSï¼Œé‡‡ç”¨çš„ç«¯åˆ°ç«¯çš„NARæ¨¡å‹ï¼Œè¿™ç¯‡æ–‡ç« è®°å½•ä¸‹å¾®è½¯æå‡ºçš„VALL-Eç³»åˆ—ï¼Œä» AR+NAR åˆ° AR æ¨¡å‹çš„è½¬å˜ï¼Œä»¥åŠåé¢MELLEå¼•å…¥çš„VAEå’ŒMel-Spectorgramï¼Œå°†neural codec text speech LM (AR+NAR Transformer Decoder) è½¬å˜ä¸º  autoregressive  mel-spectrogram text speech LM  (AR Transformer Decoder) ï¼›ç”±äºLMç”Ÿæˆçš„æ˜¯mel-spectrogram éœ€è¦é€šè¿‡vocoder è½¬æ¢æˆ waveformï¼› ç”Ÿæˆçš„å†…å®¹é‡‡æ ·æ¨¡å—ï¼šä»top-p random sampling å˜æˆ Latent Samplingæ½œåœ¨é‡‡æ ·æ¨¡å—ï¼ˆæ€æƒ³æºè‡ªVAE, ä»é¢„æµ‹çš„é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·æ½œåœ¨åµŒå…¥ï¼Œç„¶åå°†å…¶æŠ•å½±å›é¢‘è°±å›¾ç©ºé—´ï¼‰&lt;/p&gt;
&lt;h2 id=&#34;vall-e-ç³»åˆ—&#34;&gt;VALL-E ç³»åˆ—&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/project/vall-e-x/&#34;&gt;https://www.microsoft.com/en-us/research/project/vall-e-x/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vall-E: &lt;a href=&#34;https://ar5iv.labs.arxiv.org/html/2301.02111&#34;&gt;https://ar5iv.labs.arxiv.org/html/2301.02111&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»ç°æˆçš„ç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨æ¨¡å‹æ´¾ç”Ÿçš„ç¦»æ•£ä»£ç æ¥è®­ç»ƒ&lt;em&gt;&lt;strong&gt;ç¥ç»ç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹ï¼ˆneural codec language modelï¼‰&lt;/strong&gt;&lt;/em&gt;ï¼ˆç§°ä¸ºVALL-E ï¼‰ï¼Œå¹¶å°† TTS è§†ä¸ºæ¡ä»¶è¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œè€Œä¸æ˜¯åƒä¹‹å‰çš„å·¥ä½œé‚£æ ·å°† TTS è§†ä¸ºè¿ç»­ä¿¡å·å›å½’ã€‚ åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬å°† TTS è®­ç»ƒæ•°æ®æ‰©å±•åˆ° 60K å°æ—¶çš„è‹±è¯­è¯­éŸ³ï¼Œæ¯”ç°æœ‰ç³»ç»Ÿå¤§æ•°ç™¾å€ã€‚ VALL-Eå…·æœ‰æƒ…å¢ƒå­¦ä¹ åŠŸèƒ½ï¼Œå¯ç”¨äºåˆæˆé«˜è´¨é‡çš„ä¸ªæ€§åŒ–è¯­éŸ³ï¼Œåªéœ€å¯¹çœ‹ä¸è§çš„è¯´è¯è€…è¿›è¡Œ 3 ç§’çš„æ³¨å†Œå½•éŸ³ä½œä¸ºå£°éŸ³æç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ VALL-Eåœ¨è¯­éŸ³è‡ªç„¶åº¦å’Œè¯´è¯äººç›¸ä¼¼åº¦æ–¹é¢æ˜¾ç€ä¼˜äºæœ€å…ˆè¿›çš„é›¶æ ·æœ¬ TTS ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°VALL-Eå¯ä»¥åœ¨åˆæˆæ—¶ä¿ç•™è¯´è¯è€…çš„æƒ…æ„Ÿå’Œå£°éŸ³æç¤ºçš„å£°å­¦ç¯å¢ƒã€‚&lt;/p&gt;
&lt;p&gt;ä¸ä¹‹å‰çš„ç®¡é“ä¸åŒï¼ˆä¾‹å¦‚ï¼ŒéŸ³ç´  â†’ æ¢…å°”è°±å›¾ â†’ æ³¢å½¢ï¼‰ï¼Œ VALL-Eçš„ç®¡çº¿æ˜¯éŸ³ç´  â†’ ç¦»æ•£ç  â†’ æ³¢å½¢ã€‚&lt;/p&gt;
&lt;p&gt;VALL-Eæ ¹æ®éŸ³ç´ å’Œå£°å­¦ä»£ç æç¤ºç”Ÿæˆä¸ç›®æ ‡å†…å®¹å’Œè¯´è¯è€…çš„å£°éŸ³ç›¸å¯¹åº”çš„ç¦»æ•£éŸ³é¢‘ç¼–è§£ç å™¨ä»£ç ã€‚ VALL-Eç›´æ¥æ”¯æŒå„ç§è¯­éŸ³åˆæˆåº”ç”¨ï¼Œä¾‹å¦‚é›¶æ ·æœ¬ TTSã€è¯­éŸ³ç¼–è¾‘ä»¥åŠä¸ GPT-3 ç­‰å…¶ä»–ç”Ÿæˆå¼ AI æ¨¡å‹ç›¸ç»“åˆçš„å†…å®¹åˆ›å»ºã€‚&lt;/p&gt;
&lt;p&gt;VALL-Eç³»åˆ—ï¼š2023å¹´çš„1æœˆä»½å¼€å§‹ - 2024å¹´çš„7æœˆä»½&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VALL-E ä½¿ç”¨ä»ç°æˆçš„ç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨æ¨¡å‹æ´¾ç”Ÿçš„ç¦»æ•£ä»£ç æ¥è®­ç»ƒç¥ç»ç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹ï¼Œå¹¶å°† TTS è§†ä¸ºæ¡ä»¶è¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œè€Œä¸æ˜¯åƒä¹‹å‰çš„å·¥ä½œé‚£æ ·å°† TTS è§†ä¸ºè¿ç»­ä¿¡å·å›å½’ã€‚ VALL-E å…·æœ‰æƒ…å¢ƒå­¦ä¹ åŠŸèƒ½ï¼Œå¯ç”¨äºåˆæˆé«˜è´¨é‡çš„ä¸ªæ€§åŒ–è¯­éŸ³ï¼Œåªéœ€å½•åˆ¶æœªè§è¿‡çš„è®²è¯è€…çš„ 3 ç§’æ³¨å†Œå½•éŸ³ä½œä¸ºæç¤ºã€‚åœ¨è¯­éŸ³è‡ªç„¶åº¦å’Œè¯´è¯äººç›¸ä¼¼åº¦æ–¹é¢ï¼ŒVALL-E æ˜¾ç€ä¼˜äºæœ€å…ˆè¿›çš„é›¶æ ·æœ¬ TTS ç³»ç»Ÿã€‚æ­¤å¤–ï¼ŒVALL-Eå¯ä»¥åœ¨åˆæˆæ—¶ä¿ç•™è¯´è¯è€…çš„æƒ…ç»ªå’Œå£°éŸ³æç¤ºçš„å£°å­¦ç¯å¢ƒã€‚&lt;/li&gt;
&lt;li&gt;VALL-E X æ‰©å±•å…¶èƒ½åŠ›ï¼Œé€‚åº”å¤šè¯­è¨€åœºæ™¯ï¼Œä¿ƒè¿›è·¨è¯­è¨€é›¶æ ·æœ¬ TTSã€‚&lt;/li&gt;
&lt;li&gt;VALL-E R å¼•å…¥äº†éŸ³ç´ å•è°ƒå¯¹é½ç­–ç•¥ï¼Œå¢å¼ºäº†è¯­éŸ³ç”Ÿæˆçš„é²æ£’æ€§ã€‚&lt;/li&gt;
&lt;li&gt;VALL-E 2 é€šè¿‡é›†æˆé‡å¤æ„ŸçŸ¥é‡‡æ ·å’Œåˆ†ç»„ä»£ç å»ºæ¨¡æŠ€æœ¯ï¼Œ å®ç°äº†ä¸€ä¸ªçªç ´æ€§çš„é‡Œç¨‹ç¢‘ï¼šåœ¨ LibriSpeech å’Œ VCTK æ•°æ®é›†ä¸Šçš„é›¶æ ·æœ¬ TTS æ€§èƒ½ä¸äººç±»ç›¸å½“ã€‚è¿™æ ‡å¿—ç€æ­¤ç±»æˆå°±çš„é¦–æ¬¡å®ä¾‹ï¼Œä¸ºè¯¥é¢†åŸŸæ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚&lt;/li&gt;
&lt;li&gt;MELLE æ˜¯ä¸€ç§æ–°é¢–çš„åŸºäºè¿ç»­å€¼æ ‡è®°çš„è¯­è¨€å»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºæ–‡æœ¬åˆ°è¯­éŸ³åˆæˆ (TTS)ã€‚ MELLE ç›´æ¥ä»æ–‡æœ¬æ¡ä»¶è‡ªå›å½’ç”Ÿæˆè¿ç»­çš„æ¢…å°”é¢‘è°±å›¾å¸§ï¼Œç»•è¿‡äº†çŸ¢é‡é‡åŒ–çš„éœ€è¦ï¼ŒçŸ¢é‡é‡åŒ–æœ€åˆæ˜¯ä¸ºéŸ³é¢‘å‹ç¼©è€Œè®¾è®¡çš„ï¼Œä¸æ¢…å°”é¢‘è°±å›¾ç›¸æ¯”ï¼Œç‰ºç‰²äº†ä¿çœŸåº¦ã€‚&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯» VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</title>
      <link>https://weedge.github.io/post/multimoding/voices/vits/</link>
      <pubDate>Sat, 11 Jan 2025 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/vits/</guid>
      <description>&lt;p&gt;å‰æ–‡è®²åˆ°OpenVoicev2ï¼Œè¡¥å……ä¸‹ç»†èŠ‚ï¼Œç„¶åæ¢³ç†ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹VITSï¼š&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ğŸ““&lt;/p&gt;
&lt;p&gt;melo-tts ç”ŸæˆåŸå§‹éŸ³é¢‘ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenVoice ç‰ˆæœ¬1ä¸ä¾èµ–melo-tts, å‡çº§åçš„V2ç‰ˆæœ¬ä¾èµ–melo-tts, ä¸»è¦æ˜¯ç”ŸæˆåŸå§‹éŸ³é¢‘è´¨é‡åŠ å¼ºäº†(ç”±melo-ttsç”Ÿæˆ);&lt;/li&gt;
&lt;li&gt;é»˜è®¤é…ç½®ä½¿ç”¨äº†TransformerCouplingBlock listä½œä¸ºflow å’Œ reverse flow, è€Œç¬¬ä¸€ç‰ˆçš„OpenVoice æ¨¡å‹ä½¿ç”¨çš„ ResidualCouplingBlock ;&lt;/li&gt;
&lt;li&gt;melo-ttsçš„æ¨¡å‹æƒé‡æ”¯æŒå¤šè¯­è¨€ï¼Œæ›´å…·è¯­è¨€åŒºåˆ†ï¼Œæ¯”å¦‚ ZH: &lt;a href=&#34;https://huggingface.co/myshell-ai/MeloTTS-Chinese&#34;&gt;myshell-ai/MeloTTS-Chinese&lt;/a&gt;, EN_NEWEST: &lt;a href=&#34;https://huggingface.co/myshell-ai/MeloTTS-English-v3&#34;&gt;myshell-ai/MeloTTS-English-v3&lt;/a&gt;;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;éŸ³è‰²è½¬æ¢ç”Ÿæˆç›®æ ‡éŸ³é¢‘ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é€šè¿‡è®­ç»ƒå¥½çš„&lt;strong&gt;éŸ³è‰²æŠ½å–å™¨&lt;/strong&gt;æŠ½å–ç›®æ ‡è¯´è¯è€…çš„éŸ³è‰² (&lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoiceV2/tree/main/base_speakers/ses&#34;&gt;myshell-ai/OpenVoiceV2/converter&lt;/a&gt;)ï¼›&lt;/li&gt;
&lt;li&gt;ç”Ÿæˆçš„åŸå§‹éŸ³é¢‘ä¿¡æ¯é€šè¿‡ è®­ç»ƒæŠ½å–å¥½çš„åŸºç¡€è¯´è¯è€…çš„éŸ³è‰²(&lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoiceV2/tree/main/converter&#34;&gt;myshell-ai/OpenVoiceV2/base_speakers/ses&lt;/a&gt;)ï¼Œå°†åŸå§‹éŸ³é¢‘ä¸­çš„éŸ³è‰²å»é™¤ ï¼ˆflowï¼‰ï¼›&lt;/li&gt;
&lt;li&gt;å°†å»é™¤åŸå§‹éŸ³è‰²çš„éŸ³é¢‘ å’Œ æŠ½å–å¥½çš„ç›®æ ‡è¯´è¯è€…çš„éŸ³è‰² åˆå¹¶ ï¼ˆreverse flowï¼‰ï¼› æœ€ç»ˆé€šè¿‡ vocoder(ä¹Ÿæ˜¯è®ºæ–‡ä¸­çš„Decoder,ä½¿ç”¨çš„ HiFi-Ganæ¨¡å‹)åˆæˆç›®æ ‡éŸ³é¢‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é¢å¤–æ³¨æ„çš„æ˜¯ï¼Œç”±melo-ttsç”ŸæˆåŸå§‹éŸ³é¢‘sample rateæ˜¯ 44100ï¼Œ è€Œé€šè¿‡éŸ³è‰²æå–å™¨ æå– å¹¶ä¸” ç”Ÿæˆç›®æ ‡éŸ³é¢‘sample rateæ˜¯ 22050&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;å‰æçŸ¥è¯†è¿™é‡Œç®€å•æ¦‚æ‹¬å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;p&gt;AE(Autoencoder): è‡ªç¼–ç å™¨æ˜¯&lt;a href=&#34;https://www.ibm.com/cn-zh/topics/self-supervised-learning&#34;&gt;è‡ªç›‘ç£&lt;/a&gt;ç³»ç»Ÿï¼Œå…¶è®­ç»ƒç›®æ ‡æ˜¯é€šè¿‡é™ç»´æ¥å‹ç¼©ï¼ˆæˆ–&lt;em&gt;ç¼–ç &lt;/em&gt;ï¼‰è¾“å…¥æ•°æ®ï¼Œç„¶åä½¿ç”¨è¯¥å‹ç¼©åçš„è¡¨ç¤ºå‡†ç¡®é‡å»ºï¼ˆæˆ–&lt;em&gt;è§£ç &lt;/em&gt;ï¼‰å…¶åŸå§‹è¾“å…¥ã€‚æ— æ³›åŒ–ç”Ÿæˆèƒ½åŠ›ï¼Œä½†æ˜¯å¯ä»¥æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼šå¸¸ç”¨äºæ•°æ®å‹ç¼©ã€å›¾åƒå»å™ªã€å¼‚å¸¸æ£€æµ‹å’Œé¢éƒ¨è¯†åˆ«ç­‰ä»»åŠ¡ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;VAE(Variational Autoencoder)&lt;/strong&gt; :ä¸å…¶ä»–è‡ªç¼–ç å™¨(Autoencoder(AE)çš„åŒºåˆ«åœ¨äºå®ƒä»¬å¯¹æ½œåœ¨ç©ºé—´è¿›è¡Œç¼–ç çš„ç‹¬ç‰¹æ–¹å¼ï¼Œä»¥åŠå¯ä»¥åº”ç”¨å…¶æ¦‚ç‡ç¼–ç çš„ä¸åŒç”¨ä¾‹ï¼Œå³éšæœºç”Ÿæˆè®­ç»ƒæ•°æ®çš„å˜ä½“ã€‚å…·æœ‰æ³›åŒ–ç”Ÿæˆèƒ½åŠ›ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CVAE(Conditional Variational Autoencoder)&lt;/strong&gt;: æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ å¯ä»¥ä»¥ç‰¹å®šè¾“å…¥ä¸ºæ¡ä»¶è¿›è¡Œè¾“å‡ºï¼Œè€Œä¸ä»…ä»…æ˜¯éšæœºç”Ÿæˆè®­ç»ƒæ•°æ®çš„å˜ä½“ã€‚è¿™æ˜¯é€šè¿‡å°†ç›‘ç£å­¦ä¹ ï¼ˆæˆ–åŠç›‘ç£å­¦ä¹ ï¼‰çš„å…ƒç´ ä¸å¸¸è§„è‡ªç¼–ç å™¨çš„ä¼ ç»Ÿæ— ç›‘ç£è®­ç»ƒç›®æ ‡ç›¸ç»“åˆæ¥å®ç°çš„ã€‚å…·æœ‰æŒ‡å®šç‰¹å¾çš„æ³›åŒ–èƒ½åŠ›ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;VAE ä¸ GANçš„åŒºåˆ«ï¼š&lt;/p&gt;
&lt;p&gt;VAE ç»å¸¸ä¸ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ (GAN) è¿›è¡Œæ¯”è¾ƒï¼ŒGAN æ˜¯å¦ä¸€ç§æ¨¡å‹æ¶æ„ï¼Œç”¨äºç”Ÿæˆç±»ä¼¼äºè®­ç»ƒæ•°æ®çš„æ ·æœ¬ï¼Œå°¤å…¶æ˜¯å›¾åƒã€‚&lt;/p&gt;
&lt;p&gt;ä¸ VAE ç±»ä¼¼ï¼ŒGAN æ˜¯ç»“åˆä¸¤ç§ç¥ç»ç½‘ç»œçš„è”åˆæ¶æ„ï¼šä¸€ä¸ªç”Ÿæˆå™¨ç½‘ç»œï¼Œè´Ÿè´£è¾“å‡ºä¸è®­ç»ƒæ•°æ®é›†ä¸­çš„å›¾åƒç›¸ä¼¼çš„å›¾åƒæ ·æœ¬ï¼Œå¦ä¸€ä¸ªåˆ¤åˆ«å™¨ç½‘ç»œï¼Œè´Ÿè´£ç¡®å®šç‰¹å®šå›¾åƒæ˜¯è®­ç»ƒæ•°æ®ä¸­çš„â€œçœŸå®â€å›¾åƒè¿˜æ˜¯æ¥è‡ªç”Ÿæˆå™¨ç½‘ç»œçš„â€œè™šå‡â€å›¾åƒã€‚&lt;/p&gt;
&lt;p&gt;è¿™ä¸¤ä¸ªç½‘ç»œåœ¨é›¶å’Œåšå¼ˆä¸­è¿›è¡Œå¯¹æŠ—æ€§è®­ç»ƒï¼šæ¥è‡ªåˆ¤åˆ«å™¨çš„åé¦ˆç”¨äºæ”¹è¿›ç”Ÿæˆå™¨çš„è¾“å‡ºï¼Œç›´åˆ°åˆ¤åˆ«å™¨ä¸å†èƒ½å¤ŸåŒºåˆ†çœŸå‡æ ·æœ¬ã€‚&lt;/p&gt;
&lt;p&gt;å°±å›¾åƒåˆæˆè€Œè¨€ï¼Œä¸¤è€…å„æœ‰ä¼˜åŠ£ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GAN å¯ä»¥ç”Ÿæˆæ›´æ¸…æ™°çš„å›¾åƒï¼Œä½†ç”±äºä¸¤ç§å¤åˆæ¨¡å‹ä¹‹é—´çš„å¯¹æŠ—æ€§æƒè¡¡ï¼Œåœ¨è®­ç»ƒä¸­å¹¶ä¸ç¨³å®šã€‚&lt;/li&gt;
&lt;li&gt;VAE æ›´å®¹æ˜“è®­ç»ƒï¼Œä½†ç”±äºå…¶æ ¹æ®è®­ç»ƒæ•°æ®çš„â€œå¹³å‡â€ç‰¹å¾ç”Ÿæˆå›¾åƒçš„æ€§è´¨ï¼Œå¾€å¾€ä¼šç”Ÿæˆæ¯”è¾ƒæ¨¡ç³Šçš„å›¾åƒã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VAE-GAN ä¸¤è€…ç»“åˆ
é¡¾åæ€ä¹‰ï¼ŒVAE-GAN æ˜¯å˜åˆ†è‡ªç¼–ç å™¨ (VAE) å’Œç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ (GAN) çš„æ··åˆä½“ã€‚é€šè¿‡ç”¨åˆ¤åˆ«å™¨ç½‘ç»œæ›¿æ¢ VAE æ¨¡å‹çš„é‡å»ºæŸå¤±é¡¹ï¼Œæ¥é™ä½ VAE ç”Ÿæˆå›¾åƒçš„æ¨¡ç³Šæ€§ï¼Œæé«˜ç”Ÿæˆè´¨é‡ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;VITS ä½¿ç”¨äº† æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ (Conditional Variational Autoencoder (CVAE)) å’Œç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ (&lt;a href=&#34;https://en.wikipedia.org/wiki/Generative_adversarial_network&#34;&gt;Generative adversarial network&lt;/a&gt;(GAN)) ä¸¤ä¸ªæ¨¡å‹æ¶æ„ã€‚ è‡³äºVAEå’ŒGANçš„ç»†èŠ‚å¯ä»¥å…³æ³¨ä¸‹baby-llmè¿™ä¸ªå­¦ä¹ é¡¹ç›®ä¸­çš„å¯¹åº”æ¨¡å—PRå­¦ä¹ èµ„æ–™:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VAE: &lt;a href=&#34;https://github.com/ai-bot-pro/baby-llm/tree/main/modules/VAE&#34;&gt;https://github.com/ai-bot-pro/baby-llm/tree/main/modules/VAE&lt;/a&gt; | PR:  &lt;a href=&#34;https://github.com/ai-bot-pro/baby-llm/pull/13&#34;&gt;https://github.com/ai-bot-pro/baby-llm/pull/13&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GAN: &lt;a href=&#34;https://github.com/ai-bot-pro/baby-llm/tree/main/modules/GAN&#34;&gt;https://github.com/ai-bot-pro/baby-llm/tree/main/modules/GAN&lt;/a&gt; | PR: &lt;a href=&#34;https://github.com/ai-bot-pro/baby-llm/pull/12&#34;&gt;https://github.com/ai-bot-pro/baby-llm/pull/12&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™ç¯‡æ–‡ç« æ˜¯è®²è§£VITSï¼Œæ˜¯ç°åœ¨å·¥ä¸šä¸ŠTTSå¸¸ç”¨çš„åŸºç¡€æ–¹æ¡ˆ(NARæ¨¡å‹ï¼Œæˆæœ¬ç›¸å¯¹ARæ¨¡å‹ä½ï¼Œ æ¨ç†å¿«ï¼Œç”Ÿæˆè´¨é‡å°½å¯èƒ½è¿½å¹³æˆ–è¶…è¶ŠSOTA ARæ¨¡å‹)ã€‚ä½œè€…æ¥è‡ªéŸ©å›½ç°ä»£æ±½è½¦å…¬å¸çš„ AIR å®éªŒå®¤ï¼ˆäººå·¥æ™ºèƒ½ç ”ç©¶å®éªŒå®¤ï¼‰ï¼Œè®ºæ–‡ç»“åˆäº†ä»¥å‰çš„ç ”ç©¶æˆæœï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.02155&#34;&gt;2018. &lt;strong&gt;FloWaveNet : A Generative Flow for Raw Audio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.11129&#34;&gt;2020. &lt;strong&gt;Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.05646&#34;&gt;2020. &lt;strong&gt;HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åç»­ä½œè€…è¿˜ç ”ç©¶äº†åŠ å…¥æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆè¯­éŸ³ï¼Œä¸éœ€è¦ä½¿ç”¨åˆ†ç±»å™¨æŒ‡å¯¼çš„ç›®æ ‡è¯´è¯è€…çš„ä»»ä½•è½¬å½•ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2111.11755&#34;&gt;2022. Guided-TTS: A Diffusion Model for Text-to-Speech via Classifier Guidance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Guided-TTS å°†æ— æ¡ä»¶æ‰©æ•£æ¦‚ç‡æ¨¡å‹(unconditional Diffusion Model)ä¸å•ç‹¬è®­ç»ƒçš„éŸ³ç´ åˆ†ç±»å™¨(phoneme classifier )ç›¸ç»“åˆï¼Œç”¨äºåˆ†ç±»å™¨æŒ‡å¯¼ã€‚æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹å­¦ä¹ åœ¨æ²¡æœ‰ä»»ä½•ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ä»æœªè½¬å½•çš„è¯­éŸ³æ•°æ®ä¸­ç”Ÿæˆè¯­éŸ³ã€‚å¯¹äº TTS åˆæˆï¼Œä½¿ç”¨åœ¨å¤§è§„æ¨¡è¯­éŸ³è¯†åˆ«æ•°æ®é›†ä¸Šè®­ç»ƒçš„éŸ³ç´ åˆ†ç±»å™¨æ¥æŒ‡å¯¼æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ã€‚&lt;/p&gt;
&lt;h1 id=&#34;vits&#34;&gt;VITS&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.06103&#34;&gt;2021. &lt;strong&gt;Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech&lt;/strong&gt;&lt;/a&gt;  | &lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;paper coder&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸»è¦è´¡çŒ®ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æå‡ºäº†ä¸€ç§å¹¶è¡Œçš„ç«¯åˆ°ç«¯ TTS æ–¹æ³•ï¼Œå®ƒå¯ä»¥ç”Ÿæˆæ¯”å½“å‰ä¸¤é˜¶æ®µæ¨¡å‹æ›´è‡ªç„¶çš„éŸ³é¢‘ï¼›&lt;/li&gt;
&lt;li&gt;é‡‡ç”¨é€šè¿‡å½’ä¸€åŒ–æµç¨‹å’Œå¯¹æŠ—æ€§è®­ç»ƒè¿‡ç¨‹å¢å¼ºçš„å˜åˆ†æ¨ç†ï¼Œæé«˜äº†ç”Ÿæˆæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼›&lt;/li&gt;
&lt;li&gt;ä¸€ä¸ªéšæœºæŒç»­æ—¶é—´é¢„æµ‹å™¨ï¼ˆstochastic duration predictorï¼‰æ¥ä»è¾“å…¥æ–‡æœ¬ä¸­åˆæˆå…·æœ‰ä¸åŒèŠ‚å¥çš„è¯­éŸ³ï¼›&lt;/li&gt;
&lt;li&gt;é€šè¿‡å¯¹æ½œåœ¨å˜é‡çš„ä¸ç¡®å®šæ€§å»ºæ¨¡å’ŒéšæœºæŒç»­æ—¶é—´é¢„æµ‹å™¨ï¼Œè¡¨è¾¾äº†è‡ªç„¶çš„ä¸€å¯¹å¤šå…³ç³»ï¼Œå…¶ä¸­æ–‡æœ¬è¾“å…¥å¯ä»¥ä»¥ä¸åŒçš„éŸ³è°ƒï¼ˆpitchesï¼‰å’ŒèŠ‚å¥ï¼ˆrhythmsï¼‰ä»¥å¤šç§æ–¹å¼è¯´å‡ºã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é€šè¿‡åˆ©ç”¨æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ CVAEï¼Œæ¨¡å‹ç‰¹ç‚¹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;å­¦ä¹ ç›´æ¥ä»æ–‡æœ¬åˆæˆåŸå§‹æ³¢å½¢ï¼Œè€Œä¸éœ€è¦é¢å¤–çš„è¾“å…¥æ¡ä»¶ï¼›&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨åŠ¨æ€ç¼–ç¨‹æ–¹æ³• MAS æ¥æœç´¢æœ€ä½³å¯¹é½æ–¹å¼ï¼Œè€Œä¸æ˜¯ä¸è®¡ç®—æŸå¤±ç›¸æ¯”,ä¸éœ€è¦ä»»ä½•å¤–éƒ¨å¯¹é½å™¨ï¼›&lt;/li&gt;
&lt;li&gt;å¹¶è¡Œç”Ÿæˆæ ·æœ¬ï¼›&lt;/li&gt;
&lt;li&gt;é«˜æ•ˆçš„ç«¯åˆ°ç«¯è®­ç»ƒæ–¹æ³•, å¹¶ä¸”ç”Ÿæˆè´¨é‡ä¼˜äºæœ€å¥½çš„å…¬å¼€å¯ç”¨çš„ä¸¤é˜¶æ®µæ¨¡å‹ã€‚é™„ä¸¤é˜¶æ®µçš„æ•°æ®å¤„ç†è¿‡ç¨‹(åœ¨åç»­çš„ç ”ç©¶è®ºæ–‡ä¸­ç§°ä¹‹ä¸ºçº§è”æ–¹æ³•(cascaded)ï¼Œè§&lt;a href=&#34;https://www.microsoft.com/en-us/research/project/vall-e-x/&#34;&gt;VALL-E&lt;/a&gt;ç³»åˆ—è®ºæ–‡ç ”ç©¶)ï¼š
&lt;ul&gt;
&lt;li&gt;ç¬¬ä¸€é˜¶æ®µæ˜¯ä»é¢„å¤„ç†çš„æ–‡æœ¬ä¸­ç”Ÿæˆä¸­é—´è¯­éŸ³è¡¨ç¤ºï¼Œä¾‹å¦‚æ¢…å°”è°±å›¾(mel-spectrograms)æˆ–è¯­è¨€ç‰¹å¾(linguistic features)&lt;/li&gt;
&lt;li&gt;ç¬¬äºŒé˜¶æ®µæ˜¯ç”Ÿæˆä»¥ä¸­é—´è¡¨ç¤ºä¸ºæ¡ä»¶çš„åŸå§‹æ³¢å½¢ã€‚&lt;/li&gt;
&lt;li&gt;ä¸¤é˜¶æ®µçš„ç›¸å…³æ¨¡å‹å¤§éƒ½æ˜¯ç‹¬ç«‹å¼€å‘çš„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ç»“æ„ï¼š&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/3ddec975-a9fd-460c-91fa-894b8ebd8c8c&#34; alt=&#34;VITS&#34;&gt;&lt;/p&gt;
&lt;p&gt;PSï¼š &lt;a href=&#34;https://github.com/ai-bot-pro/achatbot&#34;&gt;achatbot&lt;/a&gt; é›†æˆäº†OpenVoiceV2 with meloTTS(meloTTSä»£ç å¤§éƒ¨åˆ†æ¥è‡ªVITSï¼ŒFlow é‡‡ç”¨ Transformer Encoder ç»“æ„æ¥è‡ª &lt;a href=&#34;https://arxiv.org/abs/2307.16430&#34;&gt;VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design&lt;/a&gt; | &lt;a href=&#34;https://github.com/daniilrobnikov/vits2&#34;&gt;paper code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PRåœ°å€ï¼š &lt;a href=&#34;https://github.com/ai-bot-pro/achatbot/pull/103&#34;&gt;https://github.com/ai-bot-pro/achatbot/pull/103&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯» OpenVoice: Versatile Instant Voice Cloning</title>
      <link>https://weedge.github.io/post/multimoding/voices/open_voice_extra_se_and_convert/</link>
      <pubDate>Sat, 11 May 2024 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/open_voice_extra_se_and_convert/</guid>
      <description>&lt;p&gt;ä½¿ç”¨meloTTS æœ¬æ–‡ç”Ÿæˆçš„éŸ³é¢‘&lt;/p&gt;



&lt;figure &gt;
  &lt;audio controls class=&#34;player&#34; preload=&#34;&#34;&gt;
    &lt;source src=&#34;https://media.githubusercontent.com/media/weedge/paper-speaker/main/multimoding/voices/open_voice_inference/zh-tts.wav&#34; type=&#34;audio/mpeg&#34;&gt;
  &lt;/audio&gt;
  
  
&lt;/figure&gt;

&lt;p&gt;ä½¿ç”¨openVoice clone è‡ªå·±çš„å£°éŸ³ é˜…è¯»æœ¬æ–‡å†…å®¹ 


&lt;figure &gt;
  &lt;audio controls class=&#34;player&#34; preload=&#34;&#34;&gt;
    &lt;source src=&#34;https://media.githubusercontent.com/media/weedge/paper-speaker/main/multimoding/voices/open_voice_inference/clone-me-zh-tts.wav&#34; type=&#34;audio/mpeg&#34;&gt;
  &lt;/audio&gt;
  
  
&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;æ–‡ä»¶ç›´æ¥ä¸Šä¼ åœ¨githubä¸­, æš‚æœªèµ°cdn, ç¼“å­˜æ¯”è¾ƒæ…¢ï¼Œå¯ä¸‹è½½æ’­æ”¾ï¼Œ ä¸‹è½½åœ°å€ï¼š &lt;a href=&#34;http://github.com/weedge/paper-speaker/tree/main/multimoding/voices/open_voice_inference&#34;&gt;http://github.com/weedge/paper-speaker/tree/main/multimoding/voices/open_voice_inference&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;openVoiceV2 tone color clone: base TTS + extra tone color + convert&lt;/p&gt;
&lt;p&gt;Base TTS: use meloTTS , æ”¯æŒTTSæ¨¡å‹è®­ç»ƒï¼Œä»¥åŠload Pre-Trained ckpt è¿›è¡ŒTTS,  åœ¨ &lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;VITS&lt;/a&gt;åŸºç¡€ä¸Šæ”¯æŒå¤šç§è¯­è¨€ï¼›&lt;/p&gt;
&lt;p&gt;è®ºæ–‡åœ°å€ï¼š&lt;a href=&#34;https://arxiv.org/abs/2312.01479&#34;&gt;OpenVoice: Versatile Instant Voice Cloning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;è®ºæ–‡ä¸»ä½œè€…ï¼šZengyi Qin (åŒæ—¶æ˜¯JetMoEçš„ä½œè€…ï¼Œç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šåˆ›æ–°)&lt;/p&gt;
&lt;p&gt;å…¬å¼€çš„æƒé‡ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenVoice: &lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoice&#34;&gt;https://huggingface.co/myshell-ai/OpenVoice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenVoiceV2: &lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoiceV2&#34;&gt;https://huggingface.co/myshell-ai/OpenVoiceV2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æºç ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/myshell-ai/OpenVoice&#34;&gt;https://github.com/myshell-ai/OpenVoice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/myshell-ai/MeloTTS&#34;&gt;https://github.com/myshell-ai/MeloTTS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è®­ç»ƒï¼š MSML dataset å’Œ è®­ç»ƒè¿‡ç¨‹ æœªå…¬å¼€&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;é™„æ“ä½œç¬”è®°&lt;/strong&gt;ï¼š &lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/myshell_ai_OpenVoiceV2.ipynb&#34;&gt;https://github.com/weedge/doraemon-nb/blob/main/myshell_ai_OpenVoiceV2.ipynb&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯» DeLighT: Very Deep and Light-weight Transformers</title>
      <link>https://weedge.github.io/post/paper/transformer/delight/</link>
      <pubDate>Sun, 28 Apr 2024 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/paper/transformer/delight/</guid>
      <description>&lt;p&gt;åœ¨çœ‹apple æœ€è¿‘å‘å¸ƒçš„OpenELM æ¨¡å‹ï¼Œå…¶è®ºæ–‡ä¸­æåˆ° block-wise scaling æ¨¡å‹ç»“æ„ä¼˜åŒ–æ–¹æ³•ï¼Œï¼ˆè®ºæ–‡è§ï¼š &lt;a href=&#34;https://machinelearning.apple.com/research/openelm&#34;&gt;&lt;strong&gt;OpenELM: An Efficient Language Model Family with Open-source Training and Inference Framework&lt;/strong&gt;&lt;/a&gt;ï¼‰ï¼Œè¿™é‡Œè®°å½•ä¸‹DeLighTè®ºæ–‡ä¸­çš„ block-wise scalingï¼Œç¿»è¯‘æ•´ç†ä¸‹ä»¥ä¾¿å¯¹ç…§ä»£ç å®ç°ï¼Œäº†è§£èƒŒæ™¯å’ŒåŸç†ã€‚DeLighTè®ºæ–‡ä¸­çš„å®éªŒä»»åŠ¡ä¸»è¦æ˜¯åœ¨ä¸¤ä¸ªæ ‡å‡†çš„åºåˆ—å»ºæ¨¡ä»»åŠ¡ä¸Šè¯„ä¼°äº†DeLighTçš„æ€§èƒ½ï¼šæœºå™¨ç¿»è¯‘ï¼ˆmachine translationï¼‰ä»»åŠ¡ encoder-decoder architecture å’Œ è¯­è¨€å»ºæ¨¡ï¼ˆ language modelingï¼‰decoder architectureï¼Œè®ºæ–‡ä¸­æœºå™¨ç¿»è¯‘ä»»åŠ¡æœªå¯¹En-Zh(è‹±æ–‡è¯‘ä¸­æ–‡)è¿›è¡Œå®éªŒï¼Œå¯ä»¥ä½œä¸ºä¸€ä¸ªå¤ç°ç»ƒä¹ ï¼Œæ ¹æ®æºç å®æ“ä¸€ä¸‹è®ºæ–‡ä¸­çš„å®éªŒï¼›è€Œè¯­è¨€å»ºæ¨¡å¯ä»¥ä½œä¸ºopenELMçš„æ¥æºå»¶ä¼¸~ ç»“åˆcornetè¿›è¡Œå¤ç°(ä¹Ÿæœ‰mxlç¤ºä¾‹ï¼Œmxlé’ˆå¯¹Apple Silicon ç¡¬ä»¶è¿›è¡Œçš„ä¼˜åŒ–æ·±åº¦å­¦ä¹ æ¡†æ¶)ã€‚&lt;/p&gt;
&lt;p&gt;è®ºæ–‡ä¸»ä½œè€…ï¼š&lt;a href=&#34;https://sacmehta.github.io/&#34;&gt;Sachin Mehta &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;è®ºæ–‡åœ°å€ï¼šhttps://arxiv.org/pdf/2008.00623&lt;/p&gt;
&lt;p&gt;è®ºæ–‡ä»£ç ï¼š &lt;a href=&#34;https://github.com/sacmehta/delight&#34;&gt;https://github.com/sacmehta/delight&lt;/a&gt; ï¼ˆåŸºäºå½“æ—¶facebookçš„ &lt;a href=&#34;https://github.com/facebookresearch/fairseq&#34;&gt;fairseq&lt;/a&gt; seq2seqå·¥å…·åº“å¼€å‘ï¼‰&lt;/p&gt;
&lt;p&gt;è¯¥è®ºæ–‡ç ”ç©¶æ˜¯åœ¨ä½œè€…ä»¥å‰çš„DeFINE: DEep Factorized INput Token Embeddings for Neural Sequence Modeling è¿›è¡Œæ”¹è¿›ï¼Œæ¨¡å‹ç»“æ„å¼•å…¥æ›´å¤šçš„GLTsï¼Œæ¥å­¦ä¹ æ›´å®½çš„æƒé‡ï¼Œå¹¶ä¸”å‡å°‘äº†å‚æ•°æ•°é‡ã€‚&lt;/p&gt;
&lt;h2 id=&#34;æ‘˜è¦&#34;&gt;&lt;strong&gt;æ‘˜è¦&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;æˆ‘ä»¬ä»‹ç»äº†ä¸€ç§æ·±åº¦ä¸”è½»é‡çº§çš„Transformerï¼Œåä¸ºDeLighTï¼Œå®ƒåœ¨å‚æ•°æ•°é‡æ˜¾è‘—å‡å°‘çš„æƒ…å†µä¸‹ï¼Œæä¾›äº†ä¸æ ‡å‡†åŸºäºTransformerçš„æ¨¡å‹ç›¸ä¼¼æˆ–æ›´å¥½çš„æ€§èƒ½ã€‚DeLighTæ›´æœ‰æ•ˆåœ°åœ¨æ¯ä¸ªTransformerå—å†…éƒ¨ï¼ˆé€šè¿‡DeLighTå˜æ¢ï¼‰ä»¥åŠè·¨å—ï¼ˆé€šè¿‡å—çº§ç¼©æ”¾ï¼‰åˆ†é…å‚æ•°ï¼Œå…è®¸è¾“å…¥ç«¯ä½¿ç”¨è¾ƒæµ…è¾ƒçª„çš„DeLighTå—ï¼Œè¾“å‡ºç«¯ä½¿ç”¨è¾ƒå®½è¾ƒæ·±çš„DeLighTå—ã€‚æ€»ä½“è€Œè¨€ï¼ŒDeLighTç½‘ç»œæ¯”æ ‡å‡†Transformeræ¨¡å‹æ·±2.5åˆ°4å€ï¼Œä½†å‚æ•°å’Œè¿ç®—é‡æ›´å°‘ã€‚åœ¨åŸºå‡†æœºå™¨ç¿»è¯‘å’Œè¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒDeLighTåœ¨å¹³å‡å‚æ•°æ•°é‡å‡å°‘2åˆ°3å€çš„æƒ…å†µä¸‹ï¼Œè¾¾åˆ°æˆ–æé«˜äº†åŸºçº¿Transformerçš„æ€§èƒ½ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>è§£è¯»è®ºæ–‡ï¼šLeave No Context Behind: Efficient Infinite Context Transformers with Infini-attention</title>
      <link>https://weedge.github.io/post/paper/transformer/infini_attention/</link>
      <pubDate>Fri, 12 Apr 2024 10:26:12 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/paper/transformer/infini_attention/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://aiptcomics.com/ezoimgfmt/i0.wp.com/aiptcomics.com/wp-content/uploads/2024/04/transformers-7.jpg?w=1500&amp;amp;ssl=1&amp;amp;ezimgfmt=ngcb4/notWebP&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;å›¾ç‰‡æ¥æºï¼š &lt;a href=&#34;https://aiptcomics.com/2024/04/10/transformers-7-2024-review/&#34;&gt;https://aiptcomics.com/2024/04/10/transformers-7-2024-review/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ‘˜è¦&lt;/strong&gt;ï¼š æœ¬æ–‡ä»‹ç»äº†ä¸€ç§æœ‰æ•ˆçš„æ–¹æ³•ï¼Œå°†åŸºäºTransformerçš„å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰æ‰©å±•åˆ°æ— é™é•¿çš„è¾“å…¥ï¼ŒåŒæ—¶å—åˆ°å†…å­˜å’Œè®¡ç®—çš„é™åˆ¶ã€‚æˆ‘ä»¬æå‡ºçš„æ–¹æ³•çš„å…³é”®ç»„æˆéƒ¨åˆ†æ˜¯ä¸€ç§æ–°çš„æ³¨æ„åŠ›æŠ€æœ¯ï¼Œç§°ä¸ºInfini-attentionã€‚Infini-attentionå°†ä¸€ç§å‹ç¼©å†…å­˜é›†æˆåˆ°äº†ä¼ ç»Ÿçš„æ³¨æ„åŠ›æœºåˆ¶ä¸­ï¼Œå¹¶åœ¨å•ä¸ªTransformerå—ä¸­æ„å»ºäº†æ©ç å±€éƒ¨æ³¨æ„åŠ›å’Œé•¿æœŸçº¿æ€§æ³¨æ„åŠ›æœºåˆ¶ã€‚æˆ‘ä»¬é€šè¿‡åœ¨é•¿ä¸Šä¸‹æ–‡è¯­è¨€å»ºæ¨¡åŸºå‡†ã€1Måºåˆ—é•¿åº¦çš„å£ä»¤(keypass)ä¸Šä¸‹æ–‡å—æ£€ç´¢å’Œ500Ké•¿åº¦çš„ä¹¦ç±æ‘˜è¦ä»»åŠ¡ä¸­ä½¿ç”¨1Bå’Œ8B LLMsï¼Œå±•ç¤ºäº†æˆ‘ä»¬æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„æ–¹æ³•å¼•å…¥äº†æœ€å°çš„æœ‰ç•Œå†…å­˜å‚æ•°ï¼Œå¹¶å®ç°äº†LLMsçš„å¿«é€Ÿæµå¼æ¨ç†ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ³¨&lt;/strong&gt;ï¼šä¸ºè§£å†³å¤§æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤„ç†è¶…é•¿è¾“å…¥åºåˆ—æ—¶é‡åˆ°çš„å†…å­˜é™åˆ¶é—®é¢˜ï¼Œæœ¬æ–‡ä½œè€…æå‡ºäº†ä¸€ç§æ–°å‹æ¶æ„ï¼šInfini-Transformerï¼Œå®ƒå¯ä»¥åœ¨æœ‰é™å†…å­˜æ¡ä»¶ä¸‹ï¼Œè®©åŸºäºTransformerçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é«˜æ•ˆå¤„ç†æ— é™é•¿çš„è¾“å…¥åºåˆ—ã€‚å®éªŒç»“æœè¡¨æ˜ï¼šInfini-Transformeråœ¨é•¿ä¸Šä¸‹æ–‡è¯­è¨€å»ºæ¨¡ä»»åŠ¡ä¸Šè¶…è¶Šäº†åŸºçº¿æ¨¡å‹ï¼Œå†…å­˜æœ€é«˜å¯èŠ‚çº¦114å€ã€‚&lt;/p&gt;
&lt;p&gt;æ„Ÿè§‰æœ‰ç§å¤–æŒ‚å­˜å‚¨åº“(ç±»ä¼¼å‘é‡æ•°æ®åº“)åµŒå…¥åˆ°æ¨¡å‹ç»“æ„ä¸­ã€‚æ¯”å¦‚ï¼š &lt;a href=&#34;https://arxiv.org/abs/2203.08913&#34;&gt;Memorizing Transformers&lt;/a&gt; + &lt;a href=&#34;https://github.com/lucidrains/memorizing-transformers-pytorch&#34;&gt;code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;åœ¨è®ºæ–‡ã€ŠMemorizing Transformersã€‹ä¸­ï¼Œä½œè€…æå‡ºäº†ä¸€ç§æ–°çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç§°ä¸ºkNN-augmented attention layerï¼Œå®ƒç»“åˆäº†å±€éƒ¨ä¸Šä¸‹æ–‡çš„å¯†é›†è‡ªæ³¨æ„åŠ›å’Œå¯¹å¤–éƒ¨è®°å¿†çš„è¿‘ä¼¼k-æœ€è¿‘é‚»ï¼ˆkNNï¼‰æœç´¢ã€‚è¿™ä¸ªæœºåˆ¶çš„å…³é”®éƒ¨åˆ†ä¹‹ä¸€æ˜¯ä½¿ç”¨äº†ä¸€ä¸ªé—¨æ§æœºåˆ¶ï¼ˆgating mechanismï¼‰æ¥ç»“åˆå±€éƒ¨æ³¨æ„åŠ›å’Œå¤–éƒ¨è®°å¿†çš„æ³¨æ„åŠ›ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ç¿»è¯‘æ¨¡å‹ inference å’Œ å¾®è°ƒ</title>
      <link>https://weedge.github.io/post/nlp/translate_model_inference_and_finetune/</link>
      <pubDate>Thu, 28 Mar 2024 21:51:52 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/nlp/translate_model_inference_and_finetune/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/nlp/translate_model_inference_and_finetune/1.png&#34; alt=&#34;image-20240328231303644&#34;&gt;&lt;/p&gt;
&lt;p&gt;æƒ³æŠŠ HuggingFaceTB/cosmopedia è‹±æ–‡æ•°æ®ä¸­çš„promptå’Œtext ç¿»è¯‘æˆ ä¸­æ–‡ï¼Œ ç„¶åçœ‹äº†ä¸‹pythonåº“ &lt;a href=&#34;https://github.com/nidhaloff/deep-translator&#34;&gt;deep_translator&lt;/a&gt;çš„å®ç°ï¼Œ ç¿»è¯‘è°ƒç”¨çš„æ˜¯ä¸‰æ–¹æ¥å£é›†æˆåº“ï¼Œ äºæ˜¯ä½¿ç”¨è¿™ä¸ªåº“å°è£…çš„è°·æ­Œç¿»è¯‘æ¥å£æ¥ç¿»è¯‘ï¼Œä½†æ˜¯ä¸‰æ–¹å¹³å°æ¥å£å¤šä¼šæœ‰é™æµå’Œæ¥å£è°ƒç”¨é¢‘ç‡é™åˆ¶ï¼Œå³ä½¿åœ¨ä»£ç ä¸­æœ‰å®¹é”™å¤„ç†ï¼Œ æ¯”å¦‚å¸¸è§„çš„sleepä¸‹å†è°ƒç”¨ï¼Œä¸å½±å“æ•´ç†å¤„ç†æµç¨‹ï¼Œä½†æ˜¯æ•´ä½“å¤„ç†æ—¶é—´å—æ¥å£é™åˆ¶ï¼Œå³ä½¿ç”¨æ‰¹å¤„ç†ä¹Ÿå¦‚æ­¤ï¼Œè¿™ä¸ªåœ¨å¤§è§„æ¨¡æ•°æ®å¤„ç†ä¸­ä½¿ç”¨ä¸‰æ–¹æ¥å£æ—¶ï¼Œç»å¸¸ä¼šé‡åˆ°çš„é—®é¢˜ï¼Œç”¨çš„ä¸‰æ–¹æœåŠ¡ï¼Œå¦‚æœä¸å‡çº§æ¥å£æœåŠ¡ï¼Œåœ¨æŠ€æœ¯ä¸Šä¸å¤ªå¥½è§£å†³ï¼› äºæ˜¯é€‰æ‹©å¦å¤–ä¸€ç§æ–¹æ¡ˆï¼Œçœ‹æ˜¯å¦æœ‰å¼€æºçš„ç¿»è¯‘æ¨¡å‹ï¼Œåº•å±‚æ¨¡å‹ç»“æ„ä¸€èˆ¬ä¹Ÿæ˜¯Transformæ¶æ„ Encoder-Decoder model ï¼Œä¹Ÿç§°sequence-to-sequence modelï¼› æ¯”å¦‚ è°·æ­Œçš„T5æ¨¡å‹ï¼Œ ä½†æ˜¯æ¨ç†é€Ÿåº¦å—ç¡¬ä»¶æ¡ä»¶å½±å“ï¼Œæ¯”è¾ƒæ…¢ï¼Œè€Œä¸”åŸå§‹æ¨¡å‹ä¸æ”¯æŒè‹±æ–‡ç¿»è¯‘æˆä¸­æ–‡ã€‚&lt;/p&gt;
&lt;p&gt;ç„¶åçœ‹äº†ä¸‹meta nllb æ¨¡å‹ï¼Œä¸“é—¨ç”¨æ¥å¤„ç†ç¿»è¯‘çš„æ¨¡å‹ï¼Œå•ä¸ª AI æ¨¡å‹ä¸­æ”¯æŒ 200 ç§è¯­è¨€ï¼Œå¼€æºåœ°å€ï¼š &lt;a href=&#34;https://github.com/facebookresearch/fairseq/tree/nllb&#34;&gt;https://github.com/facebookresearch/fairseq/tree/nllb&lt;/a&gt; æ¨¡å‹ç›¸å¯¹ç°åœ¨çš„LLMå‚æ•°é‡å°ä¸€äº›ï¼Œä¹Ÿåœ¨huggingfaceçš„Transformsåº“ä¸­é›†æˆ nllb-200-distilled-600Mï¼Œç›´æ¥å¯ä»¥loadä½¿ç”¨ï¼Œ ç­‰ç­‰ã€‚ã€‚ã€‚ æ—¢ç„¶llmæ¨ç†å¯ä»¥é€šè¿‡æƒ³llama.cppé€šè¿‡åŠ è½½ggmlæ ¼å¼è¿›è¡Œé‡åŒ–ï¼Œåœ¨æ€§èƒ½æœ‰å°‘è®¸æŠ˜æŸçš„æƒ…å†µä¸‹é™ä½æ¨ç†æˆæœ¬ï¼Œä½†æ˜¯ggml ggufæ ¼å¼è¿˜ä¸æ”¯æŒnllbæ¨¡å‹æƒé‡æ–‡ä»¶(è²Œä¼¼llama.cppåªæ”¯æŒTransform Decoderæ¨¡å‹ç»“æ„)ï¼›é‚£å°±ç›´æ¥ç”¨Transformsåº“æ¥åŠ è½½facebook/nllb-200-distilled-600M æ¨¡å‹æ¥æ‰¹é‡ç¿»è¯‘è¯•è¯•çœ‹ï¼›åç»­è¿˜å°è¯•ä½¿ç”¨ &lt;a href=&#34;https://huggingface.co/Helsinki-NLP/opus-mt-en-zh&#34;&gt;Helsinki-NLP/opus-mt-en-zh&lt;/a&gt; æ¨¡å‹ï¼Œè¿›è¡Œäº†ç®€å•å¯¹æ¯”ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>ä½¿ç”¨Gemma LLMæ„å»ºRAGåº”ç”¨ç¨‹åº</title>
      <link>https://weedge.github.io/post/doraemon/gemma_faiss_langchain_rag/</link>
      <pubDate>Tue, 26 Mar 2024 20:16:30 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/doraemon/gemma_faiss_langchain_rag/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/rag/gemma_faiss_langchain_rag/0.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;ä»‹ç»&#34;&gt;ä»‹ç»&lt;/h2&gt;
&lt;p&gt;éšç€å¤§å‹è¯­è¨€æ¨¡å‹çš„ä¸æ–­å‘å±•ï¼Œæ„å»º RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰åº”ç”¨ç¨‹åºçš„çƒ­æ½®ä¸æ—¥ä¿±å¢ã€‚è°·æ­Œæ¨å‡ºäº†ä¸€ä¸ªå¼€æºæ¨¡å‹ï¼šGemmaã€‚ä¼—æ‰€å‘¨çŸ¥ï¼ŒRAG ä»£è¡¨äº†ä¸¤ç§åŸºæœ¬æ–¹æ³•ä¹‹é—´çš„èåˆ: åŸºäºæ£€ç´¢çš„æŠ€æœ¯å’Œç”Ÿæˆæ¨¡å‹ã€‚åŸºäºæ£€ç´¢çš„æŠ€æœ¯æ¶‰åŠä»å¹¿æ³›çš„çŸ¥è¯†åº“æˆ–è¯­æ–™åº“ä¸­è·å–ç›¸å…³ä¿¡æ¯ä»¥å“åº”ç‰¹å®šçš„æŸ¥è¯¢ã€‚ç”Ÿæˆæ¨¡å‹æ“…é•¿åˆ©ç”¨è®­ç»ƒæ•°æ®ä¸­çš„è§è§£ä»å¤´å¼€å§‹åˆ›å»ºæ–°å†…å®¹ï¼Œä»è€Œç²¾å¿ƒåˆ¶ä½œåŸå§‹æ–‡æœ¬æˆ–å“åº”ã€‚&lt;/p&gt;
&lt;p&gt;ç›®çš„ï¼šä½¿ç”¨å¼€æºæ¨¡å‹gemmaæ¥æ„å»º RAG ç®¡é“å¹¶çœ‹çœ‹å®ƒçš„æ€§èƒ½å¦‚ä½•ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>é€šè¿‡chatGPTèŠå¤©è§£å†³rustçº¿ç¨‹å®‰å…¨é—®é¢˜</title>
      <link>https://weedge.github.io/post/rust/chatgpt_rust_check_thread_safety/</link>
      <pubDate>Sat, 16 Mar 2024 20:16:30 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/rust/chatgpt_rust_check_thread_safety/</guid>
      <description>&lt;iframe frameborder=&#34;no&#34; border=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; width=330 height=86 src=&#34;//music.163.com/outchain/player?type=2&amp;id=27445288&amp;auto=1&amp;height=66&#34;&gt;&lt;/iframe&gt;



&lt;p&gt;å‘ç°ä¸€ä¸ªæœ‰è¶£ç©æ³•ï¼Œé’ˆå¯¹rust ç¼–è¯‘æ£€æŸ¥çš„é—®é¢˜ï¼ˆè¿™ä¸ªåœ¨ç¼–å†™ä»£ç é€»è¾‘çš„æ—¶å€™ç»å¸¸ä¼šé‡åˆ°ï¼Œé€»è¾‘æ˜¯OKï¼Œä½†æ˜¯é€šä¸è¿‡rustçš„å®‰å…¨æ£€æŸ¥ï¼‰ï¼Œå¯ä»¥ç›´æ¥å‘ç»™ chatGPT (å…¶ä»–é€šè¿‡ä»£ç åº“è¿›è¡ŒPTçš„æ¨¡å‹ï¼Œæˆ–è€…SFTçš„æ¨¡å‹)ï¼Œ ä¼šç»™å‡ºä¿®æ”¹æ„è§ï¼Œå¹¶ä¸”å¯ä»¥æ ¹æ®å®ƒçš„æç¤ºç»§ç»­è¿½é—®æ€ä¹ˆè§£å†³ï¼› å¦‚æœç›´æ¥é€šè¿‡ä¼ ç»Ÿçš„æœç´¢å¼•æ“æ¯”å¦‚google, ä¹Ÿå¾ˆéš¾æ‰¾å‡ºå¥½çš„è§£å†³æ–¹æ³•ï¼Œè€Œä¸”è¿˜è¦å»ç­›é€‰ï¼Œå»å°è¯•è¿™ä¸ªæ–¹æ³•ï¼Œå¦‚æœä¸æ˜¯æƒå¨ç½‘ç«™ï¼Œå¯èƒ½è¿˜è¢«å‘ã€‚æ¥æ¥å›å›æŠ˜è…¾ï¼Œæ•ˆç‡å¤ªä½äº†ã€‚åƒæœ€è¿‘çš„AIç¨‹åºå‘˜ davidï¼š &lt;a href=&#34;https://www.cognition-labs.com/introducing-devin&#34;&gt;&lt;strong&gt;introducing-devin&lt;/strong&gt;&lt;/a&gt; ï¼Œå…¶å®ç±»ä¼¼æ€è·¯ï¼Œä¹Ÿæ˜¯é€šè¿‡èŠå¤©æ¥è§£å†³é—®é¢˜ï¼Œåªä¸è¿‡æ›´åŠ çš„ä¸“ä¸šï¼Œå½’æ ¹ç»“åº•è¿˜æ˜¯éœ€è¦ä¸“ä¸šæ•°æ®å»PT/SFTåº•å±‚çš„æ¨¡å‹ï¼Œä¸Šå±‚åº”ç”¨é€šè¿‡pipelineå¯¹åº”æ¡†æ¶å»æ•´ä½“ç³»ç»Ÿè°ƒä¼˜ã€‚(ä¸çŸ¥æ˜¯å¦æ»¡è¶³ç±»ä¼¼è¿™ç§ruståœºæ™¯çš„è§£å†³æ–¹æ¡ˆpipelineï¼Œç›´æ¥ç»™å®ƒä»£ç ï¼Œå¸®å¿™ä¿®æ”¹)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Rediså’ŒGCP AIæœåŠ¡æ­å»ºRAGå‚è€ƒæ¶æ„è§£å†³æ–¹æ¡ˆ</title>
      <link>https://weedge.github.io/post/doraemon/redis_gcp_rag_stack/</link>
      <pubDate>Thu, 14 Mar 2024 20:16:30 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/doraemon/redis_gcp_rag_stack/</guid>
      <description>&lt;p&gt;æœ¬æ–‡ä¸»è¦æ˜¯è®²è§£ä¸€ä¸ªå¿«é€Ÿæ­å»ºæ¯”å¦‚RAG pipelineç›¸å…³åº”ç”¨å‚è€ƒæ–¹æ¡ˆï¼Œç»“åˆäº‘å‚å•†GCP AIæœåŠ¡ï¼Œä»¥åŠ&lt;a href=&#34;https://redis.io/docs/about/about-stack/&#34;&gt;redis stack&lt;/a&gt; | &lt;a href=&#34;https://redis.io/docs/get-started/vector-database/&#34;&gt;vector index&lt;/a&gt;ï¼Œå€ŸåŠ© Google Cloud Platform ä¸Šæ˜“ç”¨çš„å¼€å‘&lt;a href=&#34;https://cloud.google.com/sdk&#34;&gt;SDK&lt;/a&gt;,  ä»¥åŠä½¿ç”¨&lt;a href=&#34;https://app.redislabs.com&#34;&gt;redislabs&lt;/a&gt; æä¾›çš„å…è´¹30Må†…å­˜ç©ºé—´æœåŠ¡ï¼›GCPæ–°ç”¨æˆ·å‰ä¸‰ä¸ªæœˆå¥½åƒæ˜¯å…è´¹ä½¿ç”¨ä¸€äº›æœåŠ¡ï¼Œè€Œä¸”æä¾› &lt;strong&gt;$300&lt;/strong&gt; çš„èµ é‡‘ä½¿ç”¨ï¼Œå¯¹äºå‰æœŸå­¦ä¹ å’Œä½¿ç”¨ä½“éªŒæœåŠ¡è¿˜æ˜¯ä¸é”™çš„é€‰æ‹©ï¼Œè€Œä¸”ä¸ªäººæ„Ÿè§‰å­¦ä¹ æ–‡æ¡£å¾ˆé½å…¨ï¼Œä¸ä¼šå¾ˆé›¶æ•£ã€‚ä½†æ˜¯è§£å†³æ–¹æ¡ˆç›¸å¯¹AWSè¦å°‘äº›ï¼Œæ¯•ç«ŸAWSåšçš„å¾ˆæ·±å…¥ï¼Œæ­å»ºè§£å†³æ–¹æ¡ˆå¾ˆæ–¹ä¾¿ï¼Œé›†æˆå¼€å‘å·¥å…·æ¯”è¾ƒé½å…¨ï¼Œç‰¹åˆ«æ˜¯serverless lambdaæœåŠ¡ï¼Œå¯ä»¥çœ‹ä¸‹ä»¥å‰å†™çš„æ–‡ç« ã€ &lt;a href=&#34;https://weedge.github.io/post/user-behavior-analytics-solution/&#34;&gt;ç”¨æˆ·è¡Œä¸ºåˆ†ææ–¹æ¡ˆè®¾è®¡&lt;/a&gt;ã€é€šè¿‡CDKæ„å»ºè§£å†³æ–¹æ¡ˆstack(ç”¨äºå‰æœŸæ¶æ„æ¨æ¼”ï¼Œä¸è¦YYï¼Œè¦åŠ¨æ‰‹ï¼ŒèŠ‚çº¦æˆæœ¬æ˜¯å¹²å‡ºæ¥çš„)ã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/doraemon/redis_gcp_rag_stack/gcp-cost.png&#34; alt=&#34;image-20240314215720290&#34;&gt;&lt;/p&gt;
&lt;p&gt;ä»¥å‰æ³¨å†Œçš„ï¼Œå¿˜è®°ç”¨äº†ã€‚ã€‚ã€‚&lt;/p&gt;
&lt;p&gt;ç¬”è®°åœ°å€ï¼š&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/Google_BigQuery_Palm_Redis.ipynb&#34;&gt;https://github.com/weedge/doraemon-nb/blob/main/Google_BigQuery_Palm_Redis.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ³¨&lt;/strong&gt;ï¼šè¿™é‡Œä½¿ç”¨redisä½œä¸ºå‘é‡ç´¢å¼•æ•°æ®åº“ï¼Œä¹Ÿå¯ä»¥ç»“åˆå…¶ä»–å‘é‡ç´¢å¼•åº“æ¥æ­å»ºç›¸åº”æ–¹æ¡ˆã€‚ä¸»è¦ç›®çš„æ˜¯ç†Ÿæ‚‰GCPæœåŠ¡å’Œredis cloudæœåŠ¡ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡ï¼šRetrieval-Augmented Generation for Large Language Models: A Survey [v4]</title>
      <link>https://weedge.github.io/post/paper/rag/rag-for-llms-a-survey/</link>
      <pubDate>Fri, 08 Mar 2024 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/paper/rag/rag-for-llms-a-survey/</guid>
      <description>&lt;p&gt;å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰å±•ç¤ºäº†æ˜¾è‘—çš„èƒ½åŠ›ï¼Œä½†é¢ä¸´ç€å¹»è§‰ã€è¿‡æ—¶çŸ¥è¯†å’Œä¸é€æ˜ã€ä¸å¯è¿½è¸ªçš„æ¨ç†è¿‡ç¨‹ç­‰æŒ‘æˆ˜ã€‚æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRAGï¼‰å·²ç»æˆä¸ºä¸€ä¸ªæœ‰å‰é€”çš„è§£å†³æ–¹æ¡ˆï¼Œé€šè¿‡æ•´åˆå¤–éƒ¨æ•°æ®åº“çš„çŸ¥è¯†ã€‚è¿™å¢å¼ºäº†æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå¯ä¿¡åº¦ï¼Œç‰¹åˆ«é€‚ç”¨äºçŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ï¼Œå¹¶å…è®¸æŒç»­çš„çŸ¥è¯†æ›´æ–°å’Œé¢†åŸŸç‰¹å®šä¿¡æ¯çš„æ•´åˆã€‚RAGé€šè¿‡å°†LLMsçš„å†…åœ¨çŸ¥è¯†ä¸åºå¤§ã€åŠ¨æ€çš„å¤–éƒ¨æ•°æ®åº“èµ„æºç›¸ç»“åˆï¼Œäº§ç”Ÿäº†ååŒæ•ˆåº”ã€‚è¿™ç¯‡ç»¼è¿°è®ºæ–‡è¯¦ç»†è€ƒå¯Ÿäº†RAGèŒƒå¼çš„å‘å±•ï¼ŒåŒ…æ‹¬æœ´ç´ RAGã€é«˜çº§RAGå’Œæ¨¡å—åŒ–RAGã€‚å®ƒå¯¹RAGæ¡†æ¶çš„ä¸‰æ–¹åŸºç¡€è¿›è¡Œäº†ç»†è‡´çš„äº†è§£ï¼Œå…¶ä¸­åŒ…æ‹¬æ£€ç´¢ã€ç”Ÿæˆå’Œå¢å¼ºæŠ€æœ¯ã€‚è¯¥è®ºæ–‡å¼ºè°ƒåµŒå…¥(embedding)åœ¨æ¯ä¸ªå…³é”®ç»„æˆéƒ¨åˆ†çš„æœ€å…ˆè¿›æŠ€æœ¯ï¼Œå¹¶æå¯¹RAGç³»ç»Ÿè¿›å±•çš„æ·±å…¥ç ”ç©¶äº†è§£ã€‚æ­¤å¤–ï¼Œè¯¥è®ºæ–‡ä»‹ç»äº†è¯„ä¼°RAGæ¨¡å‹çš„æŒ‡æ ‡å’ŒåŸºå‡†ï¼Œä»¥åŠæœ€æ–°çš„è¯„ä¼°æ¡†æ¶ã€‚æœ€åï¼Œè¯¥è®ºæ–‡è®²äº†ä¸€äº›ç ”ç©¶å‰æ™¯ï¼ŒåŒ…æ‹¬æœªæ¥æŒ‘æˆ˜ã€å¤šæ¨¡æ€çš„æ‰©å±•ä»¥åŠRAGåŸºç¡€è®¾æ–½åŠå…¶ç”Ÿæ€ç³»ç»Ÿçš„è¿›å±•&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;ã€‚&lt;/p&gt;
&lt;p&gt;è®ºæ–‡åœ°å€:  &lt;a href=&#34;https://arxiv.org/pdf/2312.10997.pdf&#34;&gt;Retrieval-Augmented Generation for Large Language Models: A Survey&lt;/a&gt; |  &lt;a href=&#34;https://github.com/Tongji-KGLLM/RAG-Survey/blob/main/assets/RAG_Slide_ENG.pdf&#34;&gt;PPT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;æ³¨ï¼š ä¸»è¦æ˜¯äº†è§£RAGçš„å‘å±•è¿‡ç¨‹(å¬å›ç‡)ï¼Œä»¥åŠå¯¹ç›¸å…³å­æ¨¡å—é¢†åŸŸçš„ç°é˜¶æ®µäº†è§£ï¼Œå¦‚æœæ„Ÿå…´è¶£ï¼Œé€šè¿‡ç´¢å¼•åˆ°è®ºæ–‡å¼•ç”¨å¤„è¿›ä¸€æ­¥äº†è§£ã€‚(æé«˜çœ‹ç›¸åº”è®ºæ–‡çš„å‡†ç¡®ç‡)&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>è¯‘ï¼šå†…å­˜åˆ†æ</title>
      <link>https://weedge.github.io/post/cpu/memory_profiling/</link>
      <pubDate>Sun, 03 Mar 2024 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/cpu/memory_profiling/</guid>
      <description>&lt;h3 id=&#34;å†…å­˜åˆ†æç®€ä»‹&#34;&gt;å†…å­˜åˆ†æç®€ä»‹&lt;/h3&gt;
&lt;p&gt;åœ¨è¿™ä¸ªç³»åˆ—çš„&lt;a href=&#34;https://easyperf.net/blog/2024/02/12/Memory-Profiling-Part1&#34;&gt;åŸæ–‡åšå®¢æ–‡ç« &lt;/a&gt;ä¸­ï¼Œä½ å°†å­¦ä¹ å¦‚ä½•æ”¶é›†æœ‰å…³ç¨‹åºä¸å†…å­˜äº¤äº’çš„é«˜å±‚æ¬¡ä¿¡æ¯ã€‚è¿™ä¸ªè¿‡ç¨‹é€šå¸¸è¢«ç§°ä¸º&lt;em&gt;å†…å­˜åˆ†æ&lt;/em&gt;ã€‚å†…å­˜åˆ†æå¸®åŠ©ä½ ç†è§£åº”ç”¨ç¨‹åºéšæ—¶é—´å˜åŒ–çš„å†…å­˜ä½¿ç”¨æƒ…å†µï¼Œå¹¶å¸®åŠ©ä½ æ„å»ºç¨‹åºè¡Œä¸ºçš„æ­£ç¡®å¿ƒç†æ¨¡å‹ã€‚ä»¥ä¸‹æ˜¯å®ƒå¯ä»¥å›ç­”çš„ä¸€äº›é—®é¢˜ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ç¨‹åºçš„æ€»å†…å­˜æ¶ˆè€—æ˜¯å¤šå°‘ï¼Œä»¥åŠå®ƒéšæ—¶é—´å¦‚ä½•å˜åŒ–ï¼Ÿ&lt;/li&gt;
&lt;li&gt;ç¨‹åºä½•æ—¶ä½•åœ°è¿›è¡Œå †åˆ†é…ï¼Ÿ&lt;/li&gt;
&lt;li&gt;å“ªäº›ä»£ç ä½ç½®åˆ†é…äº†æœ€å¤§é‡çš„å†…å­˜ï¼Ÿ&lt;/li&gt;
&lt;li&gt;ç¨‹åºæ¯ç§’è®¿é—®å¤šå°‘å†…å­˜ï¼Ÿ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;å½“å¼€å‘è€…è°ˆè®ºå†…å­˜æ¶ˆè€—æ—¶ï¼Œä»–ä»¬é€šå¸¸æŒ‡çš„æ˜¯å †ä½¿ç”¨æƒ…å†µã€‚å®é™…ä¸Šï¼Œå †æ˜¯å¤§å¤šæ•°åº”ç”¨ç¨‹åºä¸­æœ€å¤§çš„å†…å­˜æ¶ˆè´¹è€…ï¼Œå› ä¸ºå®ƒå®¹çº³äº†æ‰€æœ‰åŠ¨æ€åˆ†é…çš„å¯¹è±¡ã€‚ä½†å †å¹¶ä¸æ˜¯å”¯ä¸€çš„å†…å­˜æ¶ˆè´¹è€…ã€‚ä¸ºäº†å®Œæ•´æ€§ï¼Œè®©æˆ‘ä»¬æåŠå…¶ä»–å†…å­˜æ¶ˆè´¹è€…ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æ ˆï¼šåº”ç”¨ç¨‹åºä¸­å¸§æ ˆä½¿ç”¨çš„å†…å­˜ã€‚åº”ç”¨ç¨‹åºä¸­çš„æ¯ä¸ªçº¿ç¨‹éƒ½æœ‰è‡ªå·±çš„æ ˆå†…å­˜ç©ºé—´ã€‚é€šå¸¸ï¼Œæ ˆçš„å¤§å°åªæœ‰å‡ MBï¼Œå¦‚æœè¶…å‡ºé™åˆ¶ï¼Œåº”ç”¨ç¨‹åºå°†å´©æºƒã€‚æ€»çš„æ ˆå†…å­˜æ¶ˆè€—ä¸ç³»ç»Ÿä¸­è¿è¡Œçš„çº¿ç¨‹æ•°é‡æˆæ­£æ¯”ã€‚&lt;/li&gt;
&lt;li&gt;ä»£ç ï¼šç”¨äºå­˜å‚¨åº”ç”¨ç¨‹åºåŠå…¶åº“çš„ä»£ç ï¼ˆæŒ‡ä»¤ï¼‰çš„å†…å­˜ã€‚åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œå®ƒå¯¹å†…å­˜æ¶ˆè€—çš„è´¡çŒ®ä¸å¤§ï¼Œä½†ä¹Ÿæœ‰ä¾‹å¤–ã€‚ä¾‹å¦‚ï¼ŒClang C++ç¼–è¯‘å™¨å’ŒChromeæµè§ˆå™¨æ‹¥æœ‰åºå¤§çš„ä»£ç åº“ï¼Œå®ƒä»¬çš„äºŒè¿›åˆ¶æ–‡ä»¶ä¸­æœ‰æ•°åMBçš„ä»£ç æ®µã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æ¥ä¸‹æ¥ï¼Œæˆ‘ä»¬å°†ä»‹ç»&lt;em&gt;å†…å­˜ä½¿ç”¨(memory usage)&lt;em&gt;å’Œ&lt;/em&gt;å†…å­˜è¶³è¿¹(memory footprint)&lt;em&gt;æˆ–è€…ç¿»è¯‘æˆ&lt;/em&gt;å†…å­˜å ç”¨&lt;/em&gt;è¿™ä¸¤ä¸ªæœ¯è¯­ï¼Œå¹¶çœ‹çœ‹å¦‚ä½•å¯¹å®ƒä»¬è¿›è¡Œåˆ†æã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ³¨ï¼š&lt;/strong&gt; ä¸»è¦æ˜¯é€šè¿‡å·¥å…·åˆ†æå†…å­˜ä½¿ç”¨æƒ…å†µï¼Œå°½é‡åˆ©ç”¨å±€éƒ¨æ€§åŸç†ï¼šæ—¶é—´å±€éƒ¨æ€§å’Œç©ºé—´å±€éƒ¨æ€§ï¼Œæé«˜æ€§èƒ½ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Performance Analysis and Tuning on Modern CPU ä¸­æ–‡ç¿»è¯‘</title>
      <link>https://weedge.github.io/post/book/performance-analysis-and-tuning-on-modern-cpu-cn/</link>
      <pubDate>Fri, 01 Mar 2024 01:16:30 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/book/performance-analysis-and-tuning-on-modern-cpu-cn/</guid>
      <description>&lt;h1 id=&#34;heading&#34;&gt;ğŸ“š&lt;/h1&gt;
&lt;p&gt;è¿™æ˜¯ä¸€æœ¬åä¸ºPerformance Analysis and Tuning on Modern CPUä¹¦ç±çš„&lt;a href=&#34;https://github.com/dendibakh/perf-book&#34;&gt;æºæ–‡ä»¶å­˜å‚¨åº“&lt;/a&gt;çš„ä¸­æ–‡ç¿»è¯‘ï¼ŒåŸç‰ˆç”± Denis Bakhvalov ç­‰äººç¼–å†™ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;åŸç‰ˆç”µå­ä¹¦ï¼šhttps://book.easyperf.net/perf_book&lt;/li&gt;
&lt;li&gt;ä¸­æ–‡ç¿»è¯‘(ç¬¬ä¸€ç‰ˆ)ï¼šhttps://book.douban.com/subject/36243215/&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;åŸä½œè€…ç¬¬äºŒç‰ˆæ­£åœ¨è¿›è¡Œä¸­ï¼&lt;/strong&gt; è®¡åˆ’çš„æ›´æ”¹åœ¨è°·æ­Œ&lt;a href=&#34;https://docs.google.com/document/d/1tr2qRDe72VSBYypIANYjJLM_zCdPB6S9m4LmXsQb0vQ/edit?usp=sharing&#34;&gt;æ–‡æ¡£&lt;/a&gt;ä¸­è¿›è¡Œäº†æ¦‚è¿°ã€‚è®¡åˆ’ä¸­çš„æ–°ç›®å½•åœ¨ &lt;a href=&#34;https://github.com/dendibakh/perf-book/blob/main/new_toc.md&#34;&gt;new_toc.md&lt;/a&gt; ä¸­ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ç›®çš„&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;è™½ç„¶å·²ç»æœ‰ç¿»è¯‘çš„ä¹¦ç±;ä½†æ˜¯æƒ³followæ›´æ–°,å€ŸåŠ© ã€chatGPTã€/ã€gemini/moonshot(kimi)ã€ ç¿»è¯‘æˆä¸­æ–‡ï¼Œ(åŠ é€Ÿå­¦ä¹ èŠ‚å¥ï¼ŒæŒæ¡ï¼Œå¹¶ä¸¾ä¸€åä¸‰)&lt;/li&gt;
&lt;li&gt;è‹±æ–‡æºä¹¦æ˜¯å¼€æºçš„ï¼Œç¿»è¯‘æˆä¸­æ–‡å·¥ä½œä¹ŸæŒç»­æ›´æ–°ï¼Œä¹Ÿæ˜¯å¼€æºçš„ï¼Œå¯ä»¥ä½œä¸ºå­¦ä¹ èµ„æ–™, åœ¨çº¿é˜…è¯»å¯ç¼–è¾‘ï¼Œå¸Œæœ›ä¸€èµ·å‚ä¸æ”¹è¿›ã€‚&lt;/li&gt;
&lt;li&gt;å¯¹æ¯ç« èŠ‚çš„å†…å®¹é€šè¿‡ ã€chatGPTã€/ã€gemini/moonshot(kimi)ã€ è¿›è¡Œå½’çº³æ€»ç»“ï¼Œç»“å·©å›ºçŸ¥è¯†ç‚¹ï¼Œå¹¶å¯¹è¯¾åç»ƒä¹ è¿›è¡Œå›ç­”,å¹¶éªŒè¯ç­”æ¡ˆã€‚&lt;/li&gt;
&lt;li&gt;æœ€åæ•´ä½“å‹˜è¯¯ï¼Œå®šæã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;[!TIP]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æˆä¹‹ä»¥é±¼ä¸å¦‚æˆä¹‹ä»¥æ¸”, ä½¿ç”¨AIèµ‹èƒ½ã€‚&lt;/li&gt;
&lt;li&gt;æ€§èƒ½ä¼˜åŒ–åˆ†ææ•°æ®å¯ä»¥å€ŸåŠ©ã€chatGPTã€åˆ†æã€‚&lt;/li&gt;
&lt;li&gt;ã€chatGPTã€å’Œã€moonshot(kimi)ã€ ç¿»è¯‘æ•ˆæœå·®ä¸å¤š(ç›¸åŒçš„prompt)ï¼Œä½†æ˜¯å½“é—®æ–‡ä¸­çš„è§„åˆ’ç»ƒä¹ å’Œä»£ç ç»ƒä¹ æ—¶ï¼Œã€moonshot(kimi)ã€ä¸èƒ½ç†è§£é—®é¢˜ï¼Œä¸è¿‡é•¿æ–‡æœ¬ä¸Šä¼ æ ¹æ®ç« èŠ‚ç¿»è¯‘å’Œå½’çº³æ€»ç»“ä¸é”™ï¼Œæ¯•ç«Ÿä¸ç”¨ç¿»å¢™å°±å¯ä»¥ä½¿ç”¨ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;strong&gt;åœ¨çº¿é˜…è¯»åœ°å€&lt;/strong&gt;: &lt;a href=&#34;https://weedge.github.io/perf-book-cn/zh/&#34;&gt;https://weedge.github.io/perf-book-cn/zh/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ä¸­æ–‡ç‰ˆPDF(æ¨è)&lt;/strong&gt;: &lt;a href=&#34;https://raw.githubusercontent.com/weedge/perf-book-cn/main/perf-book-cn.pdf&#34;&gt;https://raw.githubusercontent.com/weedge/perf-book-cn/main/perf-book-cn.pdf&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>é€å»çš„å¥¶å¥¶</title>
      <link>https://weedge.github.io/post/nainai/</link>
      <pubDate>Fri, 02 Feb 2024 00:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/nainai/</guid>
      <description>&lt;iframe frameborder=&#34;no&#34; border=&#34;0&#34; marginwidth=&#34;0&#34; marginheight=&#34;0&#34; width=330 height=86 src=&#34;//music.163.com/outchain/player?type=2&amp;id=32574246&amp;auto=1&amp;height=66&#34;&gt;&lt;/iframe&gt;



&lt;blockquote&gt;
&lt;p&gt;å¤©ä¸Šçš„æ¯ä¸€é¢—æ˜Ÿ éƒ½æ˜¯çˆ±è¿‡æˆ‘ä»¬çš„äºº&lt;/p&gt;
&lt;p&gt;å¬è¯´ï¼Œåœ°ä¸Šå°‘ä¸ªäººï¼Œå¤©ä¸Šå¤šé¢—æ˜Ÿï¼Œæ¯ä¸€é¢—é—ªçƒçš„æ˜Ÿæ˜Ÿéƒ½åœ¨è·Ÿåœ°ä¸Šçš„äº²äººè¯´è¯ã€‚&lt;/p&gt;
&lt;p&gt;ä½†æ„¿ï¼Œä»Šå¤œæœ‰æ˜Ÿã€‚&lt;/p&gt;
&lt;p&gt;ä½†æ„¿ï¼Œæ˜Ÿæ˜Ÿä¼šé—ªã€‚&lt;/p&gt;
&lt;p&gt;&amp;ndash; äººç”Ÿå¤§äº‹&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;ç®€å•è¸å®å°±å¥½ï¼Œå¥¶å¥¶ç»å¸¸ç»™è¯´çš„è¯ï¼Œä¸€ç›´è®°ç€ã€‚ã€step by step, æ‡‚å¾—çæƒœã€‘&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>æ„å»ºä¸€ä¸ªç®€å•çš„æ•°æ®åº“[golangç‰ˆ]</title>
      <link>https://weedge.github.io/post/db_tutorial_go/</link>
      <pubDate>Wed, 10 Jan 2024 10:58:28 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/db_tutorial_go/</guid>
      <description>&lt;p&gt;ä¸Šç¯‡æ–‡ç« ä½¿ç”¨chatGPTç¿»è¯‘äº†&lt;a href=&#34;https://cstack.github.io/db_tutorial/&#34;&gt;db_tutorial&lt;/a&gt; æ–‡ç« ï¼Œæ–‡ä¸­ä½¿ç”¨çš„æ˜¯cè¯­è¨€å¼€å‘ï¼› è¿™ç¯‡æ–‡ç« ä½¿ç”¨chatGPTæ ¹æ®db_tutorialä¸­çš„cæºç ï¼Œä½¿ç”¨golangè¿›è¡Œé‡å†™, æµ‹è¯•çš„rubyä»£ç ä½¿ç”¨pythonè¿›è¡Œé‡å†™ï¼›åŒç†å…¶ä»–è¯­è¨€ä¹Ÿé€‚ç”¨ã€‚&lt;/p&gt;
&lt;p&gt;æ³¨ï¼šåˆ©ç”¨å·²æœ‰çŸ¥è¯†ç»“æ„ï¼Œé€šè¿‡chatGPTæ¥ç”Ÿæˆå¦ä¸€ç§è¡¨è¾¾(ç°å®ä¸­è¿™ç§è½¬æ¢ç»å¸¸å‡ºç°ï¼Œæ¯”å¦‚ä¸€ä¸ªåŸºç¡€çŸ¥è¯†ç‚¹ï¼Œåš¼ç¢äº†ï¼Œæ‰çƒ‚äº†ï¼Œåº•å±‚ç›¸é€šï¼Œè¡¨è¾¾æ–¹å¼ä¸åŒï¼Œå˜äº†ä¸ªèŠ±æ ·ç©ï¼Œè€Œä¸”è¿˜èƒ½é€šè¿‡è®¤çŸ¥å·®æ¥ç›ˆåˆ©ï¼Œä¹Ÿè®¸ç²¾ç»†åˆ©å·±ä¸»ä¹‰ä¼šåˆ©ç›Šæœ€å¤§åŒ–å§)ï¼Œä½¿ç”¨AGIå·¥å…·è¿›è¡Œæ•ˆç‡ç¼–ç çš„ä¸€ç§å°å°å®è·µã€‚åœ¨å®è·µè¿‡ç¨‹ä¸­ï¼ŒchatGPTç”Ÿæˆçš„ä»£ç ä¸å¯èƒ½éƒ½èƒ½æ­£å¸¸è¿è¡Œï¼Œéœ€è¦è°ƒè¯•ä¸‹(ç‰¹åˆ«æ˜¯æŒ‡é’ˆæ“ä½œ)ã€‚&lt;/p&gt;
&lt;p&gt;æ•´ä½“å®ç°ä»£ç ï¼šhttps://github.com/weedge/baby-db/tree/main/golang&lt;/p&gt;
&lt;p&gt;ä¸»è¦çš„btreeæ•°æ®ç»“æ„ä¸ºleafNode å’Œ internalNodeï¼Œå¶å­èŠ‚ç‚¹è¡¨æ•°æ®å­˜æ”¾åœ¨valueä¸­ï¼Œidå­˜æ”¾åœ¨keyä¸­ï¼Œåºåˆ—åŒ–å’Œéå†æ“ä½œéœ€è¦é¢å¤–åç§»æ“ä½œï¼›è¿™é‡Œä»…å®ç°ç®€å•çš„insertå’Œselectæ“ä½œã€‚&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cstack.github.io/db_tutorial/assets/images/leaf-node-format.png&#34; alt=&#34;leafNode&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://cstack.github.io/db_tutorial/assets/images/internal-node-format.png&#34; alt=&#34;internalNode&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>[è¯‘]æ„å»ºä¸€ä¸ªç®€å•çš„æ•°æ®åº“</title>
      <link>https://weedge.github.io/post/db_tutorial_zh/</link>
      <pubDate>Tue, 09 Jan 2024 11:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/db_tutorial_zh/</guid>
      <description>&lt;p&gt;ç”¨ C ä»å¤´å¼€å§‹ç¼–å†™ SQLite å…‹éš†ï¼›&lt;/p&gt;
&lt;p&gt;æ³¨ï¼šç”¨chatGPTç¿»è¯‘+äººå·¥ç¨å¾®æ•´ç†ä¸‹ï¼Œè€—æ—¶ä¸€ä¸ªå¤šå°æ—¶æ•´ç†å®Œæˆï¼Œä½¿ç”¨è¿™ä¸ªç®€å•çš„db from scratchè¯•ä¸‹æ•ˆæœ, ä»£ç ç®€å•ï¼›ç°åœ¨é«˜ä¸­ç”šè‡³åˆä¸­ç”Ÿæœ‰åœ¨å­¦è¿™ä¸ªã€‚&lt;/p&gt;
&lt;p&gt;åŸæ–‡åœ°å€ï¼š &lt;a href=&#34;https://cstack.github.io/db_tutorial/&#34;&gt;https://cstack.github.io/db_tutorial/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;æ•°æ®åº“å¦‚ä½•å·¥ä½œ&#34;&gt;æ•°æ®åº“å¦‚ä½•å·¥ä½œï¼Ÿ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;æ•°æ®ä»¥ä»€ä¹ˆæ ¼å¼ä¿å­˜ï¼Ÿï¼ˆåœ¨å†…å­˜å’Œç£ç›˜ä¸Šï¼‰&lt;/li&gt;
&lt;li&gt;å®ƒä»€ä¹ˆæ—¶å€™ä»å†…å­˜ç§»åŠ¨åˆ°ç£ç›˜ï¼Ÿ&lt;/li&gt;
&lt;li&gt;ä¸ºä»€ä¹ˆä¸€å¼ è¡¨åªèƒ½æœ‰ä¸€ä¸ªä¸»é”®ï¼Ÿ&lt;/li&gt;
&lt;li&gt;å›æ»šäº‹åŠ¡å¦‚ä½•è¿›è¡Œï¼Ÿ&lt;/li&gt;
&lt;li&gt;ç´¢å¼•æ˜¯å¦‚ä½•æ ¼å¼åŒ–çš„ï¼Ÿ&lt;/li&gt;
&lt;li&gt;å…¨è¡¨æ‰«æä½•æ—¶ä»¥åŠå¦‚ä½•å‘ç”Ÿï¼Ÿ&lt;/li&gt;
&lt;li&gt;å‡†å¤‡å¥½çš„è¯­å¥ä»¥ä»€ä¹ˆæ ¼å¼ä¿å­˜ï¼Ÿ&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ç®€è€Œè¨€ä¹‹ï¼Œæ•°æ®åº“æ˜¯å¦‚ä½•&lt;strong&gt;å·¥ä½œçš„&lt;/strong&gt;ï¼Ÿ&lt;/p&gt;
&lt;p&gt;ä¸ºäº†ç†è§£ï¼Œæˆ‘æ­£åœ¨ç”¨ C ä»å¤´å¼€å§‹æ„å»º&lt;a href=&#34;https://www.sqlite.org/arch.html&#34;&gt;sqlite&lt;/a&gt;çš„å…‹éš†ï¼Œå¹¶ä¸”æˆ‘å°†è®°å½•æˆ‘çš„è¿‡ç¨‹ã€‚&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;â€œæˆ‘æ— æ³•åˆ›é€ çš„ä¸œè¥¿ï¼Œæˆ‘å°±ä¸æ˜ç™½ã€‚&lt;em&gt;What I cannot create, I do not understand&lt;/em&gt;â€ â€”â€”&lt;a href=&#34;https://en.m.wikiquote.org/wiki/Richard_Feynman&#34;&gt;ç†æŸ¥å¾·Â·è´¹æ›¼&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;img src=&#34;https://cstack.github.io/db_tutorial/assets/images/arch2.gif&#34; alt=&#34;sqlite æ¶æ„ï¼ˆhttps://www.sqlite.org/arch.htmlï¼‰&#34;&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>LLM çŸ¥è¯†ç‚¹ All u need</title>
      <link>https://weedge.github.io/post/llm/llm-knowledge-point-all-u-need/</link>
      <pubDate>Mon, 01 Jan 2024 20:26:12 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/llm/llm-knowledge-point-all-u-need/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/llm/LLM.png&#34; alt=&#34;LLMçŸ¥è¯†ç‚¹&#34;&gt;&lt;/p&gt;
&lt;p&gt;ä¸Šå›¾ç»™å‡ºäº†å­¦ä¹ LLMæ‰€éœ€è¦çš„çŸ¥è¯†ç‚¹ã€‚&lt;/p&gt;
&lt;p&gt;è¯¥æ–‡ä¸»è¦æ˜¯æ¢³ç†LLMåŸºç¡€ç»“æ„çŸ¥è¯†ç‚¹ï¼Œæ¨¡å‹ç»“æ„å¤§å¤šç›¸åŒï¼Œä»¥llama2æ¨¡å‹ç»“æ„ä¸ºåˆ‡å…¥ç‚¹ï¼Œæ¢³ç†ç›¸å…³çŸ¥è¯†ç‚¹ï¼Œä»¥ä¾¿æ„å»ºæ•´ä½“çŸ¥è¯†ä½“ç³»ï¼Œå¯æ–¹ä¾¿å¿«é€Ÿé˜…è¯»å…¶ä»–è®ºæ–‡çš„æ”¹è¿›ç‚¹ï¼›ç»“åˆ&lt;a href=&#34;https://weedge.github.io/post/llm/llm-knowledge-point-all-u-need/#%E5%8F%82%E8%80%83%E5%AD%A6%E4%B9%A0&#34;&gt;å‚è€ƒå­¦ä¹ &lt;/a&gt;ä¸­ç»™å‡ºçš„é“¾æ¥è¡¥å……åŸºç¡€çŸ¥è¯†ã€‚&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>è¯‘ï¼šæŒæ¡ LLM æŠ€æœ¯ï¼šæ¨ç†ä¼˜åŒ–</title>
      <link>https://weedge.github.io/post/llm/mastering-llm-techniques-inference-optimization/</link>
      <pubDate>Sat, 30 Dec 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/llm/mastering-llm-techniques-inference-optimization/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/llm/mastering-llm-techniques-inference-optimization/0.png&#34; alt=&#34;llm-optimize-deploy&#34;&gt;&lt;/p&gt;
&lt;p&gt;å°†transformerå±‚å ä»¥åˆ›å»ºå¤§å‹æ¨¡å‹ä¼šåœ¨å„ç§è¯­è¨€ä»»åŠ¡ä¸­å¸¦æ¥æ›´é«˜çš„å‡†ç¡®æ€§ã€å°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›ï¼Œç”šè‡³æ¥è¿‘äººç±»çš„æ–°å…´èƒ½åŠ›ã€‚è¿™äº›åŸºç¡€æ¨¡å‹åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æˆæœ¬é«˜æ˜‚ï¼Œè€Œåœ¨æ¨ç†è¿‡ç¨‹ä¸­ï¼ˆä¸€ä¸ªç»å¸¸å‘ç”Ÿçš„æˆæœ¬ï¼‰å¯èƒ½éœ€è¦å¤§é‡å†…å­˜å’Œè®¡ç®—èµ„æºã€‚å¦‚ä»Šæœ€å—æ¬¢è¿çš„&lt;a href=&#34;https://www.nvidia.com/en-us/glossary/data-science/large-language-models/&#34;&gt;å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰&lt;/a&gt;å¯ä»¥è¾¾åˆ°æ•°ç™¾äº¿åˆ°æ•°åƒäº¿ä¸ªå‚æ•°çš„è§„æ¨¡ï¼Œå¹¶ä¸”æ ¹æ®ä½¿ç”¨æƒ…å†µï¼Œå¯èƒ½éœ€è¦å¤„ç†é•¿è¾“å…¥ï¼ˆæˆ–ä¸Šä¸‹æ–‡ï¼‰ï¼Œè¿™ä¹Ÿä¼šå¢åŠ æˆæœ¬ã€‚&lt;/p&gt;
&lt;p&gt;æœ¬æ–‡è®¨è®ºäº†LLMæ¨ç†ä¸­æœ€ç´§è¿«çš„æŒ‘æˆ˜ï¼Œä»¥åŠä¸€äº›å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚è¯»è€…åº”è¯¥å¯¹&lt;a href=&#34;https://arxiv.org/pdf/1706.03762.pdf&#34;&gt;transformeræ¶æ„&lt;/a&gt;å’Œæ³¨æ„åŠ›æœºåˆ¶æœ‰åŸºæœ¬çš„ç†è§£ã€‚ç†è§£LLMæ¨ç†çš„å¤æ‚æ€§è‡³å…³é‡è¦ï¼Œæˆ‘ä»¬å°†åœ¨æ¥ä¸‹æ¥çš„éƒ¨åˆ†è¿›è¡Œä»‹ç»ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;æ³¨&lt;/strong&gt;ï¼šä¸Šç¯‡è¯‘æ–‡æœ‰å¯¹ transformer æœ‰ç›¸å…³çš„ä»‹ç»ï¼Œä»¥åŠç›¸å…³ç¼–ç ç¬”è®°å…¥é—¨ï¼›æˆ–è€…æ·±å…¥å­¦ä¹ &lt;a href=&#34;https://web.stanford.edu/class/cs25/prev_years/2023_winter/index.html&#34;&gt;CS25: Transformers United V2&lt;/a&gt; &lt;a href=&#34;https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM&#34;&gt;video&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>

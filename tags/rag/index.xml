<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>rag on 时间飘过</title>
    <link>https://weedge.github.io/tags/rag/</link>
    <description>Recent content in rag on 时间飘过</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 26 Mar 2024 20:16:30 +0800</lastBuildDate><atom:link href="https://weedge.github.io/tags/rag/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>使用Gemma LLM构建RAG应用程序</title>
      <link>https://weedge.github.io/post/doraemon/gemma_faiss_langchain_rag/</link>
      <pubDate>Tue, 26 Mar 2024 20:16:30 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/doraemon/gemma_faiss_langchain_rag/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/rag/gemma_faiss_langchain_rag/0.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;介绍&#34;&gt;介绍&lt;/h2&gt;
&lt;p&gt;随着大型语言模型的不断发展，构建 RAG（检索增强生成）应用程序的热潮与日俱增。谷歌推出了一个开源模型：Gemma。众所周知，RAG 代表了两种基本方法之间的融合: 基于检索的技术和生成模型。基于检索的技术涉及从广泛的知识库或语料库中获取相关信息以响应特定的查询。生成模型擅长利用训练数据中的见解从头开始创建新内容，从而精心制作原始文本或响应。通过这次发布，为什么不尝试使用新的开源模型来构建 RAG 管道并看看它的性能如何呢？&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redis和GCP AI服务搭建RAG参考架构解决方案</title>
      <link>https://weedge.github.io/post/doraemon/redis_gcp_rag_stack/</link>
      <pubDate>Thu, 14 Mar 2024 20:16:30 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/doraemon/redis_gcp_rag_stack/</guid>
      <description>&lt;p&gt;本文主要是讲解一个快速搭建比如RAG pipeline相关应用参考方案，结合云厂商GCP AI服务，以及&lt;a href=&#34;https://redis.io/docs/about/about-stack/&#34;&gt;redis stack&lt;/a&gt; | &lt;a href=&#34;https://redis.io/docs/get-started/vector-database/&#34;&gt;vector index&lt;/a&gt;，借助 Google Cloud Platform 上易用的开发&lt;a href=&#34;https://cloud.google.com/sdk&#34;&gt;SDK&lt;/a&gt;,  以及使用&lt;a href=&#34;https://app.redislabs.com&#34;&gt;redislabs&lt;/a&gt; 提供的免费30M内存空间服务；GCP新用户前三个月好像是免费使用一些服务，而且提供 &lt;strong&gt;$300&lt;/strong&gt; 的赠金使用，对于前期学习和使用体验服务还是不错的选择，而且个人感觉学习文档很齐全，不会很零散。但是解决方案相对AWS要少些，毕竟AWS做的很深入，搭建解决方案很方便，集成开发工具比较齐全，特别是serverless lambda服务，可以看下以前写的文章『 &lt;a href=&#34;https://weedge.github.io/post/user-behavior-analytics-solution/&#34;&gt;用户行为分析方案设计&lt;/a&gt;』通过CDK构建解决方案stack(用于前期架构推演，不要YY，要动手，节约成本是干出来的)。&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/weedge/mypic/master/doraemon/redis_gcp_rag_stack/gcp-cost.png&#34; alt=&#34;image-20240314215720290&#34;&gt;&lt;/p&gt;
&lt;p&gt;以前注册的，忘记用了。。。&lt;/p&gt;
&lt;p&gt;笔记地址：&lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/Google_BigQuery_Palm_Redis.ipynb&#34;&gt;https://github.com/weedge/doraemon-nb/blob/main/Google_BigQuery_Palm_Redis.ipynb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;注&lt;/strong&gt;：这里使用redis作为向量索引数据库，也可以结合其他向量索引库来搭建相应方案。主要目的是熟悉GCP服务和redis cloud服务。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>论文：Retrieval-Augmented Generation for Large Language Models: A Survey [v4]</title>
      <link>https://weedge.github.io/post/paper/rag/rag-for-llms-a-survey/</link>
      <pubDate>Fri, 08 Mar 2024 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/paper/rag/rag-for-llms-a-survey/</guid>
      <description>&lt;p&gt;大型语言模型（LLMs）展示了显著的能力，但面临着幻觉、过时知识和不透明、不可追踪的推理过程等挑战。检索增强生成（RAG）已经成为一个有前途的解决方案，通过整合外部数据库的知识。这增强了模型的准确性和可信度，特别适用于知识密集型任务，并允许持续的知识更新和领域特定信息的整合。RAG通过将LLMs的内在知识与庞大、动态的外部数据库资源相结合，产生了协同效应。这篇综述论文详细考察了RAG范式的发展，包括朴素RAG、高级RAG和模块化RAG。它对RAG框架的三方基础进行了细致的了解，其中包括检索、生成和增强技术。该论文强调嵌入(embedding)在每个关键组成部分的最先进技术，并提对RAG系统进展的深入研究了解。此外，该论文介绍了评估RAG模型的指标和基准，以及最新的评估框架。最后，该论文讲了一些研究前景，包括未来挑战、多模态的扩展以及RAG基础设施及其生态系统的进展&lt;sup id=&#34;fnref:1&#34;&gt;&lt;a href=&#34;#fn:1&#34; class=&#34;footnote-ref&#34; role=&#34;doc-noteref&#34;&gt;1&lt;/a&gt;&lt;/sup&gt;。&lt;/p&gt;
&lt;p&gt;论文地址:  &lt;a href=&#34;https://arxiv.org/pdf/2312.10997.pdf&#34;&gt;Retrieval-Augmented Generation for Large Language Models: A Survey&lt;/a&gt; |  &lt;a href=&#34;https://github.com/Tongji-KGLLM/RAG-Survey/blob/main/assets/RAG_Slide_ENG.pdf&#34;&gt;PPT&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;注： 主要是了解RAG的发展过程(召回率)，以及对相关子模块领域的现阶段了解，如果感兴趣，通过索引到论文引用处进一步了解。(提高看相应论文的准确率)&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>

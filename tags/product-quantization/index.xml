<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>product quantization on 时间飘过</title>
    <link>https://weedge.github.io/tags/product-quantization/</link>
    <description>Recent content in product quantization on 时间飘过</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Mon, 25 Sep 2023 11:26:23 +0800</lastBuildDate><atom:link href="https://weedge.github.io/tags/product-quantization/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>译：相似性搜索，第 3 部分：混合倒排文件索引和乘积量化</title>
      <link>https://weedge.github.io/post/oneday/similarity-search/3.blending-inverted-file-index-and-product-quantization/</link>
      <pubDate>Mon, 25 Sep 2023 11:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/similarity-search/3.blending-inverted-file-index-and-product-quantization/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/blending-inverted-file-index-and-product-quantization/0.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;了解如何结合两个基本的相似性搜索索引以发挥两者的优势&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;介绍&#34;&gt;介绍&lt;/h1&gt;
&lt;p&gt;在数据科学中，相似性搜索经常出现在 NLP 领域、搜索引擎或推荐系统中，其中需要检索最相关的文档或项目以进行查询。有多种不同的方法可以提高海量数据的搜索性能。&lt;/p&gt;
&lt;p&gt;在本系列的前两部分中，我们讨论了信息检索中的两种基本算法：&lt;strong&gt;倒排文件索引&lt;/strong&gt;和&lt;strong&gt;乘积量化&lt;/strong&gt;。它们都优化了搜索性能，但侧重于不同的方面：第一个加速了搜索速度，而后者将向量压缩为更小的、节省内存的表示形式。&lt;/p&gt;
&lt;p&gt;由于两种算法侧重于不同的方面，自然出现的问题是是否可以将这两种算法合并为一种新算法&lt;/p&gt;
&lt;p&gt;在本文中，我们将结合这两种方法的优点来产生快速且内存高效的算法。作为参考，大多数讨论的想法都将基于&lt;a href=&#34;https://inria.hal.science/inria-00514462v2/document&#34;&gt;本文&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;在深入研究细节之前，有必要了解残差向量(residual vectors)是什么，并对它们的有用属性有一个简单的直觉。稍后我们将在设计算法时使用它们。&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>译：相似性搜索，第 2 部分：乘积量化</title>
      <link>https://weedge.github.io/post/oneday/similarity-search/2.product-quantization/</link>
      <pubDate>Mon, 25 Sep 2023 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/oneday/similarity-search/2.product-quantization/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;https://github.com/weedge/mypic/raw/master/oneday/product-quantization/0.png&#34; alt=&#34;img&#34;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;学习有效压缩大数据的强大技术&lt;/strong&gt;&lt;/p&gt;
&lt;h1 id=&#34;介绍&#34;&gt;介绍&lt;/h1&gt;
&lt;p&gt;在数据科学中，相似性搜索经常出现在 NLP 领域、搜索引擎或推荐系统中，其中需要检索最相关的文档或项目以进行查询。有多种不同的方法可以提高海量数据的搜索性能。&lt;/p&gt;
&lt;p&gt;在本系列文章的&lt;a href=&#34;https://weedge.github.io/post/oneday/similarity-search/1.knn-inverted-file-index/&#34;&gt;第一部分&lt;/a&gt;中，我们研究了用于执行相似性搜索的 kNN 和倒排文件索引结构。正如我们所知，kNN 是最直接的方法，而倒排文件索引则在其之上发挥作用，建议在速度加速和准确性之间进行权衡。然而，这两种方法都不使用数据压缩技术，这可能会导致内存问题，特别是在数据集较大且 RAM 有限的情况下。在本文中，我们将尝试通过研究另一种称为“&lt;strong&gt;乘积量化(Product Quantization)&lt;/strong&gt;”的方法来解决此问题。&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>

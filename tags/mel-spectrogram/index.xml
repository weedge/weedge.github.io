<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>mel-spectrogram on æ—¶é—´é£˜è¿‡</title>
    <link>https://weedge.github.io/tags/mel-spectrogram/</link>
    <description>Recent content in mel-spectrogram on æ—¶é—´é£˜è¿‡</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Tue, 14 Jan 2025 10:26:23 +0800</lastBuildDate><atom:link href="https://weedge.github.io/tags/mel-spectrogram/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>è®ºæ–‡è§£è¯» Matcha-TTS: A fast TTS architecture with conditional flow matching</title>
      <link>https://weedge.github.io/post/multimoding/voices/matcha-tts/</link>
      <pubDate>Tue, 14 Jan 2025 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/matcha-tts/</guid>
      <description>&lt;h1 id=&#34;-matcha-tts&#34;&gt;ğŸµ matcha-tts&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2309.03199&#34;&gt;2024.1 &lt;strong&gt;Matcha-TTS: A fast TTS architecture with conditional flow matching&lt;/strong&gt;&lt;/a&gt; | &lt;a href=&#34;https://github.com/shivammehta25/Matcha-TTS&#34;&gt;paper code&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id=&#34;æ‘˜è¦&#34;&gt;æ‘˜è¦ï¼š&lt;/h1&gt;
&lt;p&gt;ä¸€ç§ç”¨äºå¿«é€Ÿ TTS å£°å­¦å»ºæ¨¡çš„æ–°ç¼–ç å™¨-è§£ç å™¨æ¶æ„ï¼Œä½¿ç”¨æœ€ä½³ä¼ è¾“æ¡ä»¶æµåŒ¹é… (OT-CFM) è¿›è¡Œè®­ç»ƒã€‚ä¸ä½¿ç”¨åˆ†æ•°åŒ¹é…è®­ç»ƒçš„æ¨¡å‹ç›¸æ¯”ï¼Œè¿™äº§ç”Ÿäº†åŸºäº ODE çš„è§£ç å™¨ï¼Œèƒ½å¤Ÿä»¥æ›´å°‘çš„åˆæˆæ­¥éª¤å®ç°é«˜è¾“å‡ºè´¨é‡ã€‚ä»”ç»†çš„è®¾è®¡é€‰æ‹©è¿˜ç¡®ä¿æ¯ä¸ªåˆæˆæ­¥éª¤éƒ½èƒ½å¿«é€Ÿè¿è¡Œã€‚è¯¥æ–¹æ³•æ˜¯æ¦‚ç‡æ€§çš„ã€éè‡ªå›å½’çš„ï¼Œå¹¶ä¸”æ— éœ€å¤–éƒ¨å¯¹é½å³å¯ä»å¤´å¼€å§‹å­¦ä¹ è¯´è¯ã€‚ä¸å¼ºå¤§çš„é¢„è®­ç»ƒåŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒMatcha-TTS ç³»ç»Ÿå…·æœ‰æœ€å°çš„å†…å­˜å ç”¨ï¼Œå¯ä»¥ä¸é•¿è¯­éŸ³ä¸Šæœ€å¿«çš„æ¨¡å‹ç›¸åª²ç¾ï¼Œå¹¶åœ¨å¬åŠ›æµ‹è¯•ä¸­è·å¾—æœ€é«˜çš„å¹³å‡æ„è§å¾—åˆ†ã€‚&lt;/p&gt;
&lt;p&gt;ä¸€ç§éè‡ªå›å½’ç¥ç» TTS çš„æ–°æ–¹æ³•ï¼Œå®ƒä½¿ç”¨æ¡ä»¶æµåŒ¹é…(CFM from &lt;a href=&#34;https://arxiv.org/abs/2210.02747&#34;&gt;2022.10 &lt;strong&gt;Flow Matching for Generative Modeling&lt;/strong&gt;&lt;/a&gt;)ï¼ˆç±»ä¼¼äºæ ¡æ­£æµ(Rectified Flow &lt;a href=&#34;https://arxiv.org/abs/2209.03003&#34;&gt;2022.9 Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow&lt;/a&gt;ï¼‰æ¥åŠ é€ŸåŸºäº ODE çš„è¯­éŸ³åˆæˆã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Is probabilistic  æ˜¯æ¦‚ç‡æ€§çš„&lt;/li&gt;
&lt;li&gt;Has compact memory footprint å…·æœ‰ç´§å‡‘çš„å†…å­˜å ç”¨&lt;/li&gt;
&lt;li&gt;Sounds highly natural  å¬èµ·æ¥éå¸¸è‡ªç„¶&lt;/li&gt;
&lt;li&gt;Is very fast to synthesise from åˆæˆé€Ÿåº¦éå¸¸å¿«&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ç®€æ´çš„ç»“æ„ï¼Œè®­ç»ƒæ¨ç†å¿«ï¼Œä½¿ç”¨æ›´å°‘é¢å†…å­˜ç©ºé—´ï¼Œ&lt;/p&gt;
&lt;p&gt;ä¸€ç§åŸºäºè¿ç»­å½’ä¸€åŒ–æµçš„æ¦‚ç‡æ€§ã€éè‡ªå›å½’ã€å¿«é€Ÿé‡‡æ ·çš„ TTS å£°å­¦æ¨¡å‹ã€‚ä¸»è¦æœ‰ä¸¤ä¸ªåˆ›æ–°ç‚¹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;æå‡ºäº†ä¸€ç§æ”¹è¿›çš„ç¼–ç å™¨-è§£ç å™¨ TTS ç»“æ„ï¼Œè¯¥ç»“æ„åœ¨è§£ç å™¨ä¸­ç»“åˆä½¿ç”¨ 1D CNN å’Œ Transformerã€‚è¿™å‡å°‘äº†å†…å­˜æ¶ˆè€—å¹¶ä¸”å¯ä»¥å¿«é€Ÿè¯„ä¼°ï¼Œä»è€Œæé«˜ç»¼åˆé€Ÿåº¦ã€‚&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨æœ€ä¼˜ä¼ è¾“æ¡ä»¶æµåŒ¹é… optimal-transport conditional flow matching(OT-CFM) æ¥è®­ç»ƒè¿™äº›æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§å­¦ä¹ ä»æ•°æ®åˆ†å¸ƒä¸­é‡‡æ ·çš„ ODE çš„æ–°æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„ è¿ç»­æ—¶é—´å½’ä¸€åŒ–æµ CNFï¼ˆcontinuous-time normalising flows ï¼‰ å’Œåˆ†æ•°åŒ¹é…æ¦‚ç‡æµ ODE ï¼ˆprobability flow ODEï¼‰ ç›¸æ¯”ï¼ŒOT-CFM å®šä¹‰äº†ä»æºåˆ°ç›®æ ‡çš„æ›´ç®€å•çš„è·¯å¾„ï¼Œä»è€Œèƒ½å¤Ÿä»¥æ¯” DPMï¼ˆDiffusion probabilistic modelï¼‰ æ›´å°‘çš„æ­¥éª¤è¿›è¡Œå‡†ç¡®åˆæˆã€‚&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ä¸¤ç§åˆ›æ–°éƒ½åŠ é€Ÿäº†åˆæˆï¼Œå‡å°‘äº†é€Ÿåº¦å’Œåˆæˆè´¨é‡ä¹‹é—´çš„æƒè¡¡ã€‚å°½ç®¡é€Ÿåº¦å¿«ä¸”è½»é‡çº§ï¼ŒMatcha-TTSèƒ½å¤Ÿåœ¨ä¸éœ€è¦å¤–éƒ¨å¯¹é½å™¨çš„æƒ…å†µä¸‹å­¦ä¹ è¯´è¯å’Œå¯¹é½ã€‚ä¸å¼ºå¤§çš„é¢„è®­ç»ƒåŸºçº¿æ¨¡å‹ç›¸æ¯”ï¼ŒMatcha-TTSå®ç°äº†å¿«é€Ÿåˆæˆï¼Œå¹¶è·å¾—äº†æ›´å¥½çš„è‡ªç„¶åº¦è¯„åˆ†ã€‚&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;strong&gt;é™„&lt;/strong&gt;ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ä½¿ç”¨LJ Speechæ•°æ®é›†è®­ç»ƒ202 epochs çš„ckpt: &lt;a href=&#34;https://huggingface.co/weege007/matchaTTS/tree/main&#34;&gt;https://huggingface.co/weege007/matchaTTS/tree/main&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;ç¬”è®°åœ°å€ï¼šhttps://github.com/weedge/doraemon-nb/blob/main/matcha_tts.ipynb&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯»ï¼š VALL-E ç³»åˆ—</title>
      <link>https://weedge.github.io/post/multimoding/voices/vall-e-x/</link>
      <pubDate>Mon, 13 Jan 2025 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/vall-e-x/</guid>
      <description>&lt;p&gt;å‰æ–‡è®²åˆ°VITSï¼Œé‡‡ç”¨çš„ç«¯åˆ°ç«¯çš„NARæ¨¡å‹ï¼Œè¿™ç¯‡æ–‡ç« è®°å½•ä¸‹å¾®è½¯æå‡ºçš„VALL-Eç³»åˆ—ï¼Œä» AR+NAR åˆ° AR æ¨¡å‹çš„è½¬å˜ï¼Œä»¥åŠåé¢MELLEå¼•å…¥çš„VAEå’ŒMel-Spectorgramï¼Œå°†neural codec text speech LM (AR+NAR Transformer Decoder) è½¬å˜ä¸º  autoregressive  mel-spectrogram text speech LM  (AR Transformer Decoder) ï¼›ç”±äºLMç”Ÿæˆçš„æ˜¯mel-spectrogram éœ€è¦é€šè¿‡vocoder è½¬æ¢æˆ waveformï¼› ç”Ÿæˆçš„å†…å®¹é‡‡æ ·æ¨¡å—ï¼šä»top-p random sampling å˜æˆ Latent Samplingæ½œåœ¨é‡‡æ ·æ¨¡å—ï¼ˆæ€æƒ³æºè‡ªVAE, ä»é¢„æµ‹çš„é«˜æ–¯åˆ†å¸ƒä¸­é‡‡æ ·æ½œåœ¨åµŒå…¥ï¼Œç„¶åå°†å…¶æŠ•å½±å›é¢‘è°±å›¾ç©ºé—´ï¼‰&lt;/p&gt;
&lt;h2 id=&#34;vall-e-ç³»åˆ—&#34;&gt;VALL-E ç³»åˆ—&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://www.microsoft.com/en-us/research/project/vall-e-x/&#34;&gt;https://www.microsoft.com/en-us/research/project/vall-e-x/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Vall-E: &lt;a href=&#34;https://ar5iv.labs.arxiv.org/html/2301.02111&#34;&gt;https://ar5iv.labs.arxiv.org/html/2301.02111&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬ä½¿ç”¨ä»ç°æˆçš„ç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨æ¨¡å‹æ´¾ç”Ÿçš„ç¦»æ•£ä»£ç æ¥è®­ç»ƒ&lt;em&gt;&lt;strong&gt;ç¥ç»ç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹ï¼ˆneural codec language modelï¼‰&lt;/strong&gt;&lt;/em&gt;ï¼ˆç§°ä¸ºVALL-E ï¼‰ï¼Œå¹¶å°† TTS è§†ä¸ºæ¡ä»¶è¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œè€Œä¸æ˜¯åƒä¹‹å‰çš„å·¥ä½œé‚£æ ·å°† TTS è§†ä¸ºè¿ç»­ä¿¡å·å›å½’ã€‚ åœ¨é¢„è®­ç»ƒé˜¶æ®µï¼Œæˆ‘ä»¬å°† TTS è®­ç»ƒæ•°æ®æ‰©å±•åˆ° 60K å°æ—¶çš„è‹±è¯­è¯­éŸ³ï¼Œæ¯”ç°æœ‰ç³»ç»Ÿå¤§æ•°ç™¾å€ã€‚ VALL-Eå…·æœ‰æƒ…å¢ƒå­¦ä¹ åŠŸèƒ½ï¼Œå¯ç”¨äºåˆæˆé«˜è´¨é‡çš„ä¸ªæ€§åŒ–è¯­éŸ³ï¼Œåªéœ€å¯¹çœ‹ä¸è§çš„è¯´è¯è€…è¿›è¡Œ 3 ç§’çš„æ³¨å†Œå½•éŸ³ä½œä¸ºå£°éŸ³æç¤ºã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œ VALL-Eåœ¨è¯­éŸ³è‡ªç„¶åº¦å’Œè¯´è¯äººç›¸ä¼¼åº¦æ–¹é¢æ˜¾ç€ä¼˜äºæœ€å…ˆè¿›çš„é›¶æ ·æœ¬ TTS ç³»ç»Ÿã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°VALL-Eå¯ä»¥åœ¨åˆæˆæ—¶ä¿ç•™è¯´è¯è€…çš„æƒ…æ„Ÿå’Œå£°éŸ³æç¤ºçš„å£°å­¦ç¯å¢ƒã€‚&lt;/p&gt;
&lt;p&gt;ä¸ä¹‹å‰çš„ç®¡é“ä¸åŒï¼ˆä¾‹å¦‚ï¼ŒéŸ³ç´  â†’ æ¢…å°”è°±å›¾ â†’ æ³¢å½¢ï¼‰ï¼Œ VALL-Eçš„ç®¡çº¿æ˜¯éŸ³ç´  â†’ ç¦»æ•£ç  â†’ æ³¢å½¢ã€‚&lt;/p&gt;
&lt;p&gt;VALL-Eæ ¹æ®éŸ³ç´ å’Œå£°å­¦ä»£ç æç¤ºç”Ÿæˆä¸ç›®æ ‡å†…å®¹å’Œè¯´è¯è€…çš„å£°éŸ³ç›¸å¯¹åº”çš„ç¦»æ•£éŸ³é¢‘ç¼–è§£ç å™¨ä»£ç ã€‚ VALL-Eç›´æ¥æ”¯æŒå„ç§è¯­éŸ³åˆæˆåº”ç”¨ï¼Œä¾‹å¦‚é›¶æ ·æœ¬ TTSã€è¯­éŸ³ç¼–è¾‘ä»¥åŠä¸ GPT-3 ç­‰å…¶ä»–ç”Ÿæˆå¼ AI æ¨¡å‹ç›¸ç»“åˆçš„å†…å®¹åˆ›å»ºã€‚&lt;/p&gt;
&lt;p&gt;VALL-Eç³»åˆ—ï¼š2023å¹´çš„1æœˆä»½å¼€å§‹ - 2024å¹´çš„7æœˆä»½&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VALL-E ä½¿ç”¨ä»ç°æˆçš„ç¥ç»éŸ³é¢‘ç¼–è§£ç å™¨æ¨¡å‹æ´¾ç”Ÿçš„ç¦»æ•£ä»£ç æ¥è®­ç»ƒç¥ç»ç¼–è§£ç å™¨è¯­è¨€æ¨¡å‹ï¼Œå¹¶å°† TTS è§†ä¸ºæ¡ä»¶è¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼Œè€Œä¸æ˜¯åƒä¹‹å‰çš„å·¥ä½œé‚£æ ·å°† TTS è§†ä¸ºè¿ç»­ä¿¡å·å›å½’ã€‚ VALL-E å…·æœ‰æƒ…å¢ƒå­¦ä¹ åŠŸèƒ½ï¼Œå¯ç”¨äºåˆæˆé«˜è´¨é‡çš„ä¸ªæ€§åŒ–è¯­éŸ³ï¼Œåªéœ€å½•åˆ¶æœªè§è¿‡çš„è®²è¯è€…çš„ 3 ç§’æ³¨å†Œå½•éŸ³ä½œä¸ºæç¤ºã€‚åœ¨è¯­éŸ³è‡ªç„¶åº¦å’Œè¯´è¯äººç›¸ä¼¼åº¦æ–¹é¢ï¼ŒVALL-E æ˜¾ç€ä¼˜äºæœ€å…ˆè¿›çš„é›¶æ ·æœ¬ TTS ç³»ç»Ÿã€‚æ­¤å¤–ï¼ŒVALL-Eå¯ä»¥åœ¨åˆæˆæ—¶ä¿ç•™è¯´è¯è€…çš„æƒ…ç»ªå’Œå£°éŸ³æç¤ºçš„å£°å­¦ç¯å¢ƒã€‚&lt;/li&gt;
&lt;li&gt;VALL-E X æ‰©å±•å…¶èƒ½åŠ›ï¼Œé€‚åº”å¤šè¯­è¨€åœºæ™¯ï¼Œä¿ƒè¿›è·¨è¯­è¨€é›¶æ ·æœ¬ TTSã€‚&lt;/li&gt;
&lt;li&gt;VALL-E R å¼•å…¥äº†éŸ³ç´ å•è°ƒå¯¹é½ç­–ç•¥ï¼Œå¢å¼ºäº†è¯­éŸ³ç”Ÿæˆçš„é²æ£’æ€§ã€‚&lt;/li&gt;
&lt;li&gt;VALL-E 2 é€šè¿‡é›†æˆé‡å¤æ„ŸçŸ¥é‡‡æ ·å’Œåˆ†ç»„ä»£ç å»ºæ¨¡æŠ€æœ¯ï¼Œ å®ç°äº†ä¸€ä¸ªçªç ´æ€§çš„é‡Œç¨‹ç¢‘ï¼šåœ¨ LibriSpeech å’Œ VCTK æ•°æ®é›†ä¸Šçš„é›¶æ ·æœ¬ TTS æ€§èƒ½ä¸äººç±»ç›¸å½“ã€‚è¿™æ ‡å¿—ç€æ­¤ç±»æˆå°±çš„é¦–æ¬¡å®ä¾‹ï¼Œä¸ºè¯¥é¢†åŸŸæ ‘ç«‹äº†æ–°æ ‡å‡†ã€‚&lt;/li&gt;
&lt;li&gt;MELLE æ˜¯ä¸€ç§æ–°é¢–çš„åŸºäºè¿ç»­å€¼æ ‡è®°çš„è¯­è¨€å»ºæ¨¡æ–¹æ³•ï¼Œç”¨äºæ–‡æœ¬åˆ°è¯­éŸ³åˆæˆ (TTS)ã€‚ MELLE ç›´æ¥ä»æ–‡æœ¬æ¡ä»¶è‡ªå›å½’ç”Ÿæˆè¿ç»­çš„æ¢…å°”é¢‘è°±å›¾å¸§ï¼Œç»•è¿‡äº†çŸ¢é‡é‡åŒ–çš„éœ€è¦ï¼ŒçŸ¢é‡é‡åŒ–æœ€åˆæ˜¯ä¸ºéŸ³é¢‘å‹ç¼©è€Œè®¾è®¡çš„ï¼Œä¸æ¢…å°”é¢‘è°±å›¾ç›¸æ¯”ï¼Œç‰ºç‰²äº†ä¿çœŸåº¦ã€‚&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯» VITS: Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech</title>
      <link>https://weedge.github.io/post/multimoding/voices/vits/</link>
      <pubDate>Sat, 11 Jan 2025 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/vits/</guid>
      <description>&lt;p&gt;å‰æ–‡è®²åˆ°OpenVoicev2ï¼Œè¡¥å……ä¸‹ç»†èŠ‚ï¼Œç„¶åæ¢³ç†ä½¿ç”¨çš„åŸºç¡€æ¨¡å‹VITSï¼š&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;ğŸ““&lt;/p&gt;
&lt;p&gt;melo-tts ç”ŸæˆåŸå§‹éŸ³é¢‘ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenVoice ç‰ˆæœ¬1ä¸ä¾èµ–melo-tts, å‡çº§åçš„V2ç‰ˆæœ¬ä¾èµ–melo-tts, ä¸»è¦æ˜¯ç”ŸæˆåŸå§‹éŸ³é¢‘è´¨é‡åŠ å¼ºäº†(ç”±melo-ttsç”Ÿæˆ);&lt;/li&gt;
&lt;li&gt;é»˜è®¤é…ç½®ä½¿ç”¨äº†TransformerCouplingBlock listä½œä¸ºflow å’Œ reverse flow, è€Œç¬¬ä¸€ç‰ˆçš„OpenVoice æ¨¡å‹ä½¿ç”¨çš„ ResidualCouplingBlock ;&lt;/li&gt;
&lt;li&gt;melo-ttsçš„æ¨¡å‹æƒé‡æ”¯æŒå¤šè¯­è¨€ï¼Œæ›´å…·è¯­è¨€åŒºåˆ†ï¼Œæ¯”å¦‚ ZH: &lt;a href=&#34;https://huggingface.co/myshell-ai/MeloTTS-Chinese&#34;&gt;myshell-ai/MeloTTS-Chinese&lt;/a&gt;, EN_NEWEST: &lt;a href=&#34;https://huggingface.co/myshell-ai/MeloTTS-English-v3&#34;&gt;myshell-ai/MeloTTS-English-v3&lt;/a&gt;;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;éŸ³è‰²è½¬æ¢ç”Ÿæˆç›®æ ‡éŸ³é¢‘ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;é€šè¿‡è®­ç»ƒå¥½çš„&lt;strong&gt;éŸ³è‰²æŠ½å–å™¨&lt;/strong&gt;æŠ½å–ç›®æ ‡è¯´è¯è€…çš„éŸ³è‰² (&lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoiceV2/tree/main/base_speakers/ses&#34;&gt;myshell-ai/OpenVoiceV2/converter&lt;/a&gt;)ï¼›&lt;/li&gt;
&lt;li&gt;ç”Ÿæˆçš„åŸå§‹éŸ³é¢‘ä¿¡æ¯é€šè¿‡ è®­ç»ƒæŠ½å–å¥½çš„åŸºç¡€è¯´è¯è€…çš„éŸ³è‰²(&lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoiceV2/tree/main/converter&#34;&gt;myshell-ai/OpenVoiceV2/base_speakers/ses&lt;/a&gt;)ï¼Œå°†åŸå§‹éŸ³é¢‘ä¸­çš„éŸ³è‰²å»é™¤ ï¼ˆflowï¼‰ï¼›&lt;/li&gt;
&lt;li&gt;å°†å»é™¤åŸå§‹éŸ³è‰²çš„éŸ³é¢‘ å’Œ æŠ½å–å¥½çš„ç›®æ ‡è¯´è¯è€…çš„éŸ³è‰² åˆå¹¶ ï¼ˆreverse flowï¼‰ï¼› æœ€ç»ˆé€šè¿‡ vocoder(ä¹Ÿæ˜¯è®ºæ–‡ä¸­çš„Decoder,ä½¿ç”¨çš„ HiFi-Ganæ¨¡å‹)åˆæˆç›®æ ‡éŸ³é¢‘ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é¢å¤–æ³¨æ„çš„æ˜¯ï¼Œç”±melo-ttsç”ŸæˆåŸå§‹éŸ³é¢‘sample rateæ˜¯ 44100ï¼Œ è€Œé€šè¿‡éŸ³è‰²æå–å™¨ æå– å¹¶ä¸” ç”Ÿæˆç›®æ ‡éŸ³é¢‘sample rateæ˜¯ 22050&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;å‰æçŸ¥è¯†è¿™é‡Œç®€å•æ¦‚æ‹¬å¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;p&gt;AE(Autoencoder): è‡ªç¼–ç å™¨æ˜¯&lt;a href=&#34;https://www.ibm.com/cn-zh/topics/self-supervised-learning&#34;&gt;è‡ªç›‘ç£&lt;/a&gt;ç³»ç»Ÿï¼Œå…¶è®­ç»ƒç›®æ ‡æ˜¯é€šè¿‡é™ç»´æ¥å‹ç¼©ï¼ˆæˆ–&lt;em&gt;ç¼–ç &lt;/em&gt;ï¼‰è¾“å…¥æ•°æ®ï¼Œç„¶åä½¿ç”¨è¯¥å‹ç¼©åçš„è¡¨ç¤ºå‡†ç¡®é‡å»ºï¼ˆæˆ–&lt;em&gt;è§£ç &lt;/em&gt;ï¼‰å…¶åŸå§‹è¾“å…¥ã€‚æ— æ³›åŒ–ç”Ÿæˆèƒ½åŠ›ï¼Œä½†æ˜¯å¯ä»¥æ‰§è¡Œç‰¹å®šä»»åŠ¡ï¼šå¸¸ç”¨äºæ•°æ®å‹ç¼©ã€å›¾åƒå»å™ªã€å¼‚å¸¸æ£€æµ‹å’Œé¢éƒ¨è¯†åˆ«ç­‰ä»»åŠ¡ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;VAE(Variational Autoencoder)&lt;/strong&gt; :ä¸å…¶ä»–è‡ªç¼–ç å™¨(Autoencoder(AE)çš„åŒºåˆ«åœ¨äºå®ƒä»¬å¯¹æ½œåœ¨ç©ºé—´è¿›è¡Œç¼–ç çš„ç‹¬ç‰¹æ–¹å¼ï¼Œä»¥åŠå¯ä»¥åº”ç”¨å…¶æ¦‚ç‡ç¼–ç çš„ä¸åŒç”¨ä¾‹ï¼Œå³éšæœºç”Ÿæˆè®­ç»ƒæ•°æ®çš„å˜ä½“ã€‚å…·æœ‰æ³›åŒ–ç”Ÿæˆèƒ½åŠ›ã€‚&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;CVAE(Conditional Variational Autoencoder)&lt;/strong&gt;: æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ å¯ä»¥ä»¥ç‰¹å®šè¾“å…¥ä¸ºæ¡ä»¶è¿›è¡Œè¾“å‡ºï¼Œè€Œä¸ä»…ä»…æ˜¯éšæœºç”Ÿæˆè®­ç»ƒæ•°æ®çš„å˜ä½“ã€‚è¿™æ˜¯é€šè¿‡å°†ç›‘ç£å­¦ä¹ ï¼ˆæˆ–åŠç›‘ç£å­¦ä¹ ï¼‰çš„å…ƒç´ ä¸å¸¸è§„è‡ªç¼–ç å™¨çš„ä¼ ç»Ÿæ— ç›‘ç£è®­ç»ƒç›®æ ‡ç›¸ç»“åˆæ¥å®ç°çš„ã€‚å…·æœ‰æŒ‡å®šç‰¹å¾çš„æ³›åŒ–èƒ½åŠ›ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;VAE ä¸ GANçš„åŒºåˆ«ï¼š&lt;/p&gt;
&lt;p&gt;VAE ç»å¸¸ä¸ç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ (GAN) è¿›è¡Œæ¯”è¾ƒï¼ŒGAN æ˜¯å¦ä¸€ç§æ¨¡å‹æ¶æ„ï¼Œç”¨äºç”Ÿæˆç±»ä¼¼äºè®­ç»ƒæ•°æ®çš„æ ·æœ¬ï¼Œå°¤å…¶æ˜¯å›¾åƒã€‚&lt;/p&gt;
&lt;p&gt;ä¸ VAE ç±»ä¼¼ï¼ŒGAN æ˜¯ç»“åˆä¸¤ç§ç¥ç»ç½‘ç»œçš„è”åˆæ¶æ„ï¼šä¸€ä¸ªç”Ÿæˆå™¨ç½‘ç»œï¼Œè´Ÿè´£è¾“å‡ºä¸è®­ç»ƒæ•°æ®é›†ä¸­çš„å›¾åƒç›¸ä¼¼çš„å›¾åƒæ ·æœ¬ï¼Œå¦ä¸€ä¸ªåˆ¤åˆ«å™¨ç½‘ç»œï¼Œè´Ÿè´£ç¡®å®šç‰¹å®šå›¾åƒæ˜¯è®­ç»ƒæ•°æ®ä¸­çš„â€œçœŸå®â€å›¾åƒè¿˜æ˜¯æ¥è‡ªç”Ÿæˆå™¨ç½‘ç»œçš„â€œè™šå‡â€å›¾åƒã€‚&lt;/p&gt;
&lt;p&gt;è¿™ä¸¤ä¸ªç½‘ç»œåœ¨é›¶å’Œåšå¼ˆä¸­è¿›è¡Œå¯¹æŠ—æ€§è®­ç»ƒï¼šæ¥è‡ªåˆ¤åˆ«å™¨çš„åé¦ˆç”¨äºæ”¹è¿›ç”Ÿæˆå™¨çš„è¾“å‡ºï¼Œç›´åˆ°åˆ¤åˆ«å™¨ä¸å†èƒ½å¤ŸåŒºåˆ†çœŸå‡æ ·æœ¬ã€‚&lt;/p&gt;
&lt;p&gt;å°±å›¾åƒåˆæˆè€Œè¨€ï¼Œä¸¤è€…å„æœ‰ä¼˜åŠ£ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GAN å¯ä»¥ç”Ÿæˆæ›´æ¸…æ™°çš„å›¾åƒï¼Œä½†ç”±äºä¸¤ç§å¤åˆæ¨¡å‹ä¹‹é—´çš„å¯¹æŠ—æ€§æƒè¡¡ï¼Œåœ¨è®­ç»ƒä¸­å¹¶ä¸ç¨³å®šã€‚&lt;/li&gt;
&lt;li&gt;VAE æ›´å®¹æ˜“è®­ç»ƒï¼Œä½†ç”±äºå…¶æ ¹æ®è®­ç»ƒæ•°æ®çš„â€œå¹³å‡â€ç‰¹å¾ç”Ÿæˆå›¾åƒçš„æ€§è´¨ï¼Œå¾€å¾€ä¼šç”Ÿæˆæ¯”è¾ƒæ¨¡ç³Šçš„å›¾åƒã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;VAE-GAN ä¸¤è€…ç»“åˆ
é¡¾åæ€ä¹‰ï¼ŒVAE-GAN æ˜¯å˜åˆ†è‡ªç¼–ç å™¨ (VAE) å’Œç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ (GAN) çš„æ··åˆä½“ã€‚é€šè¿‡ç”¨åˆ¤åˆ«å™¨ç½‘ç»œæ›¿æ¢ VAE æ¨¡å‹çš„é‡å»ºæŸå¤±é¡¹ï¼Œæ¥é™ä½ VAE ç”Ÿæˆå›¾åƒçš„æ¨¡ç³Šæ€§ï¼Œæé«˜ç”Ÿæˆè´¨é‡ã€‚&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;VITS ä½¿ç”¨äº† æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ (Conditional Variational Autoencoder (CVAE)) å’Œç”Ÿæˆå¼å¯¹æŠ—ç½‘ç»œ (&lt;a href=&#34;https://en.wikipedia.org/wiki/Generative_adversarial_network&#34;&gt;Generative adversarial network&lt;/a&gt;(GAN)) ä¸¤ä¸ªæ¨¡å‹æ¶æ„ã€‚ è‡³äºVAEå’ŒGANçš„ç»†èŠ‚å¯ä»¥å…³æ³¨ä¸‹baby-llmè¿™ä¸ªå­¦ä¹ é¡¹ç›®ä¸­çš„å¯¹åº”æ¨¡å—PRå­¦ä¹ èµ„æ–™:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VAE: &lt;a href=&#34;https://github.com/ai-bot-pro/baby-llm/tree/main/modules/VAE&#34;&gt;https://github.com/ai-bot-pro/baby-llm/tree/main/modules/VAE&lt;/a&gt; | PR:  &lt;a href=&#34;https://github.com/ai-bot-pro/baby-llm/pull/13&#34;&gt;https://github.com/ai-bot-pro/baby-llm/pull/13&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;GAN: &lt;a href=&#34;https://github.com/ai-bot-pro/baby-llm/tree/main/modules/GAN&#34;&gt;https://github.com/ai-bot-pro/baby-llm/tree/main/modules/GAN&lt;/a&gt; | PR: &lt;a href=&#34;https://github.com/ai-bot-pro/baby-llm/pull/12&#34;&gt;https://github.com/ai-bot-pro/baby-llm/pull/12&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è¿™ç¯‡æ–‡ç« æ˜¯è®²è§£VITSï¼Œæ˜¯ç°åœ¨å·¥ä¸šä¸ŠTTSå¸¸ç”¨çš„åŸºç¡€æ–¹æ¡ˆ(NARæ¨¡å‹ï¼Œæˆæœ¬ç›¸å¯¹ARæ¨¡å‹ä½ï¼Œ æ¨ç†å¿«ï¼Œç”Ÿæˆè´¨é‡å°½å¯èƒ½è¿½å¹³æˆ–è¶…è¶ŠSOTA ARæ¨¡å‹)ã€‚ä½œè€…æ¥è‡ªéŸ©å›½ç°ä»£æ±½è½¦å…¬å¸çš„ AIR å®éªŒå®¤ï¼ˆäººå·¥æ™ºèƒ½ç ”ç©¶å®éªŒå®¤ï¼‰ï¼Œè®ºæ–‡ç»“åˆäº†ä»¥å‰çš„ç ”ç©¶æˆæœï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1811.02155&#34;&gt;2018. &lt;strong&gt;FloWaveNet : A Generative Flow for Raw Audio&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2005.11129&#34;&gt;2020. &lt;strong&gt;Glow-TTS: A Generative Flow for Text-to-Speech via Monotonic Alignment Search&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2010.05646&#34;&gt;2020. &lt;strong&gt;HiFi-GAN: Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;åç»­ä½œè€…è¿˜ç ”ç©¶äº†åŠ å…¥æ‰©æ•£æ¨¡å‹æ¥ç”Ÿæˆè¯­éŸ³ï¼Œä¸éœ€è¦ä½¿ç”¨åˆ†ç±»å™¨æŒ‡å¯¼çš„ç›®æ ‡è¯´è¯è€…çš„ä»»ä½•è½¬å½•ã€‚&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2111.11755&#34;&gt;2022. Guided-TTS: A Diffusion Model for Text-to-Speech via Classifier Guidance&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Guided-TTS å°†æ— æ¡ä»¶æ‰©æ•£æ¦‚ç‡æ¨¡å‹(unconditional Diffusion Model)ä¸å•ç‹¬è®­ç»ƒçš„éŸ³ç´ åˆ†ç±»å™¨(phoneme classifier )ç›¸ç»“åˆï¼Œç”¨äºåˆ†ç±»å™¨æŒ‡å¯¼ã€‚æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹å­¦ä¹ åœ¨æ²¡æœ‰ä»»ä½•ä¸Šä¸‹æ–‡çš„æƒ…å†µä¸‹ä»æœªè½¬å½•çš„è¯­éŸ³æ•°æ®ä¸­ç”Ÿæˆè¯­éŸ³ã€‚å¯¹äº TTS åˆæˆï¼Œä½¿ç”¨åœ¨å¤§è§„æ¨¡è¯­éŸ³è¯†åˆ«æ•°æ®é›†ä¸Šè®­ç»ƒçš„éŸ³ç´ åˆ†ç±»å™¨æ¥æŒ‡å¯¼æ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹ã€‚&lt;/p&gt;
&lt;h1 id=&#34;vits&#34;&gt;VITS&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/2106.06103&#34;&gt;2021. &lt;strong&gt;Conditional Variational Autoencoder with Adversarial Learning for End-to-End Text-to-Speech&lt;/strong&gt;&lt;/a&gt;  | &lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;paper coder&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;ä¸»è¦è´¡çŒ®ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;æå‡ºäº†ä¸€ç§å¹¶è¡Œçš„ç«¯åˆ°ç«¯ TTS æ–¹æ³•ï¼Œå®ƒå¯ä»¥ç”Ÿæˆæ¯”å½“å‰ä¸¤é˜¶æ®µæ¨¡å‹æ›´è‡ªç„¶çš„éŸ³é¢‘ï¼›&lt;/li&gt;
&lt;li&gt;é‡‡ç”¨é€šè¿‡å½’ä¸€åŒ–æµç¨‹å’Œå¯¹æŠ—æ€§è®­ç»ƒè¿‡ç¨‹å¢å¼ºçš„å˜åˆ†æ¨ç†ï¼Œæé«˜äº†ç”Ÿæˆæ¨¡å‹çš„è¡¨è¾¾èƒ½åŠ›ï¼›&lt;/li&gt;
&lt;li&gt;ä¸€ä¸ªéšæœºæŒç»­æ—¶é—´é¢„æµ‹å™¨ï¼ˆstochastic duration predictorï¼‰æ¥ä»è¾“å…¥æ–‡æœ¬ä¸­åˆæˆå…·æœ‰ä¸åŒèŠ‚å¥çš„è¯­éŸ³ï¼›&lt;/li&gt;
&lt;li&gt;é€šè¿‡å¯¹æ½œåœ¨å˜é‡çš„ä¸ç¡®å®šæ€§å»ºæ¨¡å’ŒéšæœºæŒç»­æ—¶é—´é¢„æµ‹å™¨ï¼Œè¡¨è¾¾äº†è‡ªç„¶çš„ä¸€å¯¹å¤šå…³ç³»ï¼Œå…¶ä¸­æ–‡æœ¬è¾“å…¥å¯ä»¥ä»¥ä¸åŒçš„éŸ³è°ƒï¼ˆpitchesï¼‰å’ŒèŠ‚å¥ï¼ˆrhythmsï¼‰ä»¥å¤šç§æ–¹å¼è¯´å‡ºã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;é€šè¿‡åˆ©ç”¨æ¡ä»¶å˜åˆ†è‡ªç¼–ç å™¨ CVAEï¼Œæ¨¡å‹ç‰¹ç‚¹ï¼š&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;å­¦ä¹ ç›´æ¥ä»æ–‡æœ¬åˆæˆåŸå§‹æ³¢å½¢ï¼Œè€Œä¸éœ€è¦é¢å¤–çš„è¾“å…¥æ¡ä»¶ï¼›&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨åŠ¨æ€ç¼–ç¨‹æ–¹æ³• MAS æ¥æœç´¢æœ€ä½³å¯¹é½æ–¹å¼ï¼Œè€Œä¸æ˜¯ä¸è®¡ç®—æŸå¤±ç›¸æ¯”,ä¸éœ€è¦ä»»ä½•å¤–éƒ¨å¯¹é½å™¨ï¼›&lt;/li&gt;
&lt;li&gt;å¹¶è¡Œç”Ÿæˆæ ·æœ¬ï¼›&lt;/li&gt;
&lt;li&gt;é«˜æ•ˆçš„ç«¯åˆ°ç«¯è®­ç»ƒæ–¹æ³•, å¹¶ä¸”ç”Ÿæˆè´¨é‡ä¼˜äºæœ€å¥½çš„å…¬å¼€å¯ç”¨çš„ä¸¤é˜¶æ®µæ¨¡å‹ã€‚é™„ä¸¤é˜¶æ®µçš„æ•°æ®å¤„ç†è¿‡ç¨‹(åœ¨åç»­çš„ç ”ç©¶è®ºæ–‡ä¸­ç§°ä¹‹ä¸ºçº§è”æ–¹æ³•(cascaded)ï¼Œè§&lt;a href=&#34;https://www.microsoft.com/en-us/research/project/vall-e-x/&#34;&gt;VALL-E&lt;/a&gt;ç³»åˆ—è®ºæ–‡ç ”ç©¶)ï¼š
&lt;ul&gt;
&lt;li&gt;ç¬¬ä¸€é˜¶æ®µæ˜¯ä»é¢„å¤„ç†çš„æ–‡æœ¬ä¸­ç”Ÿæˆä¸­é—´è¯­éŸ³è¡¨ç¤ºï¼Œä¾‹å¦‚æ¢…å°”è°±å›¾(mel-spectrograms)æˆ–è¯­è¨€ç‰¹å¾(linguistic features)&lt;/li&gt;
&lt;li&gt;ç¬¬äºŒé˜¶æ®µæ˜¯ç”Ÿæˆä»¥ä¸­é—´è¡¨ç¤ºä¸ºæ¡ä»¶çš„åŸå§‹æ³¢å½¢ã€‚&lt;/li&gt;
&lt;li&gt;ä¸¤é˜¶æ®µçš„ç›¸å…³æ¨¡å‹å¤§éƒ½æ˜¯ç‹¬ç«‹å¼€å‘çš„ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;ç»“æ„ï¼š&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://github.com/user-attachments/assets/3ddec975-a9fd-460c-91fa-894b8ebd8c8c&#34; alt=&#34;VITS&#34;&gt;&lt;/p&gt;
&lt;p&gt;PSï¼š &lt;a href=&#34;https://github.com/ai-bot-pro/achatbot&#34;&gt;achatbot&lt;/a&gt; é›†æˆäº†OpenVoiceV2 with meloTTS(meloTTSä»£ç å¤§éƒ¨åˆ†æ¥è‡ªVITSï¼ŒFlow é‡‡ç”¨ Transformer Encoder ç»“æ„æ¥è‡ª &lt;a href=&#34;https://arxiv.org/abs/2307.16430&#34;&gt;VITS2: Improving Quality and Efficiency of Single-Stage Text-to-Speech with Adversarial Learning and Architecture Design&lt;/a&gt; | &lt;a href=&#34;https://github.com/daniilrobnikov/vits2&#34;&gt;paper code&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;PRåœ°å€ï¼š &lt;a href=&#34;https://github.com/ai-bot-pro/achatbot/pull/103&#34;&gt;https://github.com/ai-bot-pro/achatbot/pull/103&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>è®ºæ–‡è§£è¯» OpenVoice: Versatile Instant Voice Cloning</title>
      <link>https://weedge.github.io/post/multimoding/voices/open_voice_extra_se_and_convert/</link>
      <pubDate>Sat, 11 May 2024 10:26:23 +0800</pubDate>
      
      <guid>https://weedge.github.io/post/multimoding/voices/open_voice_extra_se_and_convert/</guid>
      <description>&lt;p&gt;ä½¿ç”¨meloTTS æœ¬æ–‡ç”Ÿæˆçš„éŸ³é¢‘&lt;/p&gt;



&lt;figure &gt;
  &lt;audio controls class=&#34;player&#34; preload=&#34;&#34;&gt;
    &lt;source src=&#34;https://media.githubusercontent.com/media/weedge/paper-speaker/main/multimoding/voices/open_voice_inference/zh-tts.wav&#34; type=&#34;audio/mpeg&#34;&gt;
  &lt;/audio&gt;
  
  
&lt;/figure&gt;

&lt;p&gt;ä½¿ç”¨openVoice clone è‡ªå·±çš„å£°éŸ³ é˜…è¯»æœ¬æ–‡å†…å®¹ 


&lt;figure &gt;
  &lt;audio controls class=&#34;player&#34; preload=&#34;&#34;&gt;
    &lt;source src=&#34;https://media.githubusercontent.com/media/weedge/paper-speaker/main/multimoding/voices/open_voice_inference/clone-me-zh-tts.wav&#34; type=&#34;audio/mpeg&#34;&gt;
  &lt;/audio&gt;
  
  
&lt;/figure&gt;
&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;æ–‡ä»¶ç›´æ¥ä¸Šä¼ åœ¨githubä¸­, æš‚æœªèµ°cdn, ç¼“å­˜æ¯”è¾ƒæ…¢ï¼Œå¯ä¸‹è½½æ’­æ”¾ï¼Œ ä¸‹è½½åœ°å€ï¼š &lt;a href=&#34;http://github.com/weedge/paper-speaker/tree/main/multimoding/voices/open_voice_inference&#34;&gt;http://github.com/weedge/paper-speaker/tree/main/multimoding/voices/open_voice_inference&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;openVoiceV2 tone color clone: base TTS + extra tone color + convert&lt;/p&gt;
&lt;p&gt;Base TTS: use meloTTS , æ”¯æŒTTSæ¨¡å‹è®­ç»ƒï¼Œä»¥åŠload Pre-Trained ckpt è¿›è¡ŒTTS,  åœ¨ &lt;a href=&#34;https://github.com/jaywalnut310/vits&#34;&gt;VITS&lt;/a&gt;åŸºç¡€ä¸Šæ”¯æŒå¤šç§è¯­è¨€ï¼›&lt;/p&gt;
&lt;p&gt;è®ºæ–‡åœ°å€ï¼š&lt;a href=&#34;https://arxiv.org/abs/2312.01479&#34;&gt;OpenVoice: Versatile Instant Voice Cloning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;è®ºæ–‡ä¸»ä½œè€…ï¼šZengyi Qin (åŒæ—¶æ˜¯JetMoEçš„ä½œè€…ï¼Œç«™åœ¨å·¨äººçš„è‚©è†€ä¸Šåˆ›æ–°)&lt;/p&gt;
&lt;p&gt;å…¬å¼€çš„æƒé‡ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenVoice: &lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoice&#34;&gt;https://huggingface.co/myshell-ai/OpenVoice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;OpenVoiceV2: &lt;a href=&#34;https://huggingface.co/myshell-ai/OpenVoiceV2&#34;&gt;https://huggingface.co/myshell-ai/OpenVoiceV2&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;æºç ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/myshell-ai/OpenVoice&#34;&gt;https://github.com/myshell-ai/OpenVoice&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/myshell-ai/MeloTTS&#34;&gt;https://github.com/myshell-ai/MeloTTS&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;è®­ç»ƒï¼š MSML dataset å’Œ è®­ç»ƒè¿‡ç¨‹ æœªå…¬å¼€&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;é™„æ“ä½œç¬”è®°&lt;/strong&gt;ï¼š &lt;a href=&#34;https://github.com/weedge/doraemon-nb/blob/main/myshell_ai_OpenVoiceV2.ipynb&#34;&gt;https://github.com/weedge/doraemon-nb/blob/main/myshell_ai_OpenVoiceV2.ipynb&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
